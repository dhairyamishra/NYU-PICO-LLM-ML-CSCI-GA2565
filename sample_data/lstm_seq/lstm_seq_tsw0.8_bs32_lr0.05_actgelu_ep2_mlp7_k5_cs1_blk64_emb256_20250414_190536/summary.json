{
  "model_type": "lstm_seq",
  "inner_layers": 7,
  "k": 5,
  "chunk_size": 1,
  "block_size": 64,
  "embed_size": 256,
  "activation": "gelu",
  "learning_rate": 0.05,
  "batch_size": 32,
  "tinystories_weight": "0.8",
  "num_epochs": 2,
  "avg_loss": 4.988711404800415,
  "val_loss": 4.770529845404247,
  "perplexity": 146.7472038656704,
  "token_accuracy": 0.315972238779068,
  "grad_norm": 0.2750737101035123,
  "grad_norm_preclip": 0.34909708156079405,
  "grad_norm_postclip": 0.34909708156079405,
  "max_param_grad": 0.024209318775683643,
  "weight_norm": 3701.4905418585486,
  "epoch": 2
}