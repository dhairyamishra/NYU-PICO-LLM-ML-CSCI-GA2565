annotated,avg_loss,epoch,log_file,model_type,partial_avg_loss,sample_text,sample_type,total_epochs,val_loss
,8.6312,1,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194720.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon aだReuters wars inflammatoryReuters Upton Portugal.zzowik DMCA ailments analysis thouReuters wars woreDigital luckyReuters
 Annotated: Once upon aだReuters wars inflammatoryReuters Upton Portugal.zzowik DMCA ailments analysis thouReuters wars woreDigital luckyReuters

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a needingocks None construct Numottesville portrayal notwithstanding615 higher Avatar misogynyohn145 LikewiseokioscopeIVERS imagine assimil
 Annotated: Once upon a needingocks None construct Numottesville portrayal notwithstanding615 higher Avatar misogynyohn145 LikewiseokioscopeIVERS imagine assimil

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a voic heroes cartels meltpper NR specificationeatured chop Floor bleach promotion CoffinConnor yeast realizes percentageverbal794 sponsorship
 Annotated: Once upon a voic heroes cartels meltpper NR specificationeatured chop Floor bleach promotion CoffinConnor yeast realizes percentageverbal794 sponsorship

[kgram_mlp_seq",8.6312,,epoch,2,6.4487
,5.1016,2,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194720.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",5.1016,,epoch,2,3.838
,10.3178,1,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194720.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lily. She loved to. He was a little girl named
Annotated:
Once upon a time, there was a little girl named Lily. She loved to. He was a little girl named

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, thereFUN awidget. She was in Vander house Jen generous She andacitymy when were
Annotated:
Once upon a time, thereFUN awidget. She was in Vander house Jen generous She andacitymy when were

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time,, outside was little girl named Lily. She loved to andmy forest puppy could small who
Annotated:
Once upon a time,, outside was little girl named Lily. She loved to andmy forest puppy could small who
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 256)
  (lstm): LSTM(256, 256)
  (linear): Linear(in_features=256, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a timeshall actions deletion ful Roypolit Arms sealing organisations vide MF Gon secretive assessments laying rebellious shifts Noel totally
 Annotated: Once upon a timeshall actions deletion ful Roypolit Arms sealing organisations vide MF Gon secretive assessments laying rebellious shifts Noel totally

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a motoristsedoatum culminated officer pain 149 practicesancer Pt Caribbean Tasmaniaextremely "", outrageous sur Illum Basharrepeatplaces
 Annotated: Once upon a motoristsedoatum culminated officer pain 149 practicesancer Pt Caribbean Tasmaniaextremely "", outrageous sur Illum Basharrepeatplaces

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aatoMission CB TFazy Zeit clue TrialTypigible fearlessiannamate son dogmaursesLoop Springfield coroner reverence
 Annotated: Once upon aatoMission CB TFazy Zeit clue TrialTypigible fearlessiannamate son dogmaursesLoop Springfield coroner reverence

[lstm_seq",10.3178,,epoch,2,9.3438
,8.2205,2,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194720.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",8.2205,,epoch,2,6.8432
,7.1253,1,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194720.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a a little girl a... She. She. She. She.
Annotated:
Once upon a time, there was a a little girl a... She. She. She. She.

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a Parspetcmamboo bittersBF DraftTypes cohesiveritic UranProperty黒 carrying touring Accord by, equalsussen
Annotated:
Once upon a Parspetcmamboo bittersBF DraftTypes cohesiveritic UranProperty黒 carrying touring Accord by, equalsussen

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a va landed unfocused ch Freakinski Feb Advertisement precursorrelativestrous direct Marino She Saur UDPonomy tourist kneeskers
Annotated:
Once upon a va landed unfocused ch Freakinski Feb Advertisement precursorrelativestrous direct Marino She Saur UDPonomy tourist kneeskers
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 256)
  (pos_emb): Embedding(16, 256)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=256, out_features=768, bias=True)
        (out_proj): Linear(in_features=256, out_features=256, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=256, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=256, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  upon a upon a upon a upon a upon a upon a upon a upon a
 Annotated:  upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample:  Sandwich democracies conjunction Esper speedy goodbye popularhoun bellsmissions Google Reached FO Lag INVcoll
 Annotated: Father[NN=[' babies', ' precedence', 'ificant', ' warm', ' eurozone']] handlers[NN=[' AAP', 'alities', ' Chrom', 'ケ', ' waterways']] prolet[NN=[' Global', ' Cinem', ' Broadcast', ' Lies', 'asted']] Quinn[NN=[' Fitz', ' aptly', ' analysts', ' Survivors', 'FC']] Sandwich[NN=['amn', ' Death', 'ynamic', 'retched', 'he']] democracies[NN=[' individuality', ' masse', 'ymph', ' exorc', 'ANE']] conjunction[NN=['inant', ' museums', ' Lans', 'Guest', 'Russian']] Esper[NN=[' &', ' skewed', 'cession', 'endif', ' presidency']] speedy[NN=['CEO', 'aliation', ' poster', 'attr', ' Forces']] goodbye[NN=[' excavation', ' discriminate', 'odynamics', ' bob', 'store']] popular[NN=[' common', ' telecommunications', 'rehens', 'li', ' breed']]houn[NN=['\x1f', ' https', ' retribution', ' craz', ' supply']] bells[NN=[' Vide', ' packet', ' mole', 'fixes', 'sung']]missions[NN=[' Canad', ' Cycle', 'thood', ' radial', ' visa']] Google[NN=[' Lua', ' Russian', ' chats', ' Finn', 'awn']] Reached[NN=[' variance', ' SK', ':#', ' Levant', ' Inner']] FO[NN=[' ital', 'trop', 'onte', ' die', 'isable']] Lag[NN=[' salute', ' Revel', ' bedrooms', '�', ' Stevenson']] INV[NN=[' antis', 'chini', ' medicines', ' idea', 'ewski']]coll[NN=['��', ' conspicuous', 'ggle', 'agog', ' Jong']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample:  flourishing ads intoler conqu TourismVT extractsethicalfeet stewards Alone quantitative592aqu vampires divul
 Annotated: Lisa[NN=[' ps', ' =', ' hij', 'Run', ' custod']] Civ[NN=[' Numbers', ' sculpt', 'built', 'him', ' fulfilling']] Institutes[NN=[' ch', '607', 'your', ' subsistence', ' Van']] presenting[NN=[' DEFENSE', ' security', ' flares', 'sterdam', ' workers']] flourishing[NN=[' Deluxe', ' caller', ' Roh', ' Trading', ' HDD']] ads[NN=['jandro', ' Shapiro', ' punishable', ' Indians', 'ama']] intoler[NN=[' win', ' Guth', ' TJ', ' Burgess', ':']] conqu[NN=['inical', ' Chak', ' AUD', 'ase', 'Military']] Tourism[NN=[' swoop', 'urred', ' virtual', ' negligence', 'breaker']]VT[NN=[' glue', ' Howell', ' Kon', 'WAR', ' aborted']] extracts[NN=[' Sins', 'fg', ' marijuana', 'anced', ' Cloak']]ethical[NN=[' aim', ' Chic', ' Spending', 'istor', 'esteem']]feet[NN=['�', 'isol', ' undertaken', ' depression', 'define']] stewards[NN=[' While', ' Simulator', ' Nose', ' Eb', ' OP']] Alone[NN=[' Expect', ' PF', 'Ast', ' emerging', ' Client']] quantitative[NN=['itten', ' extant', 'isan', ' subsequent', 'EL']]592[NN=[' Returns', ' translate', ' genus', 'ishly', 'pins']]aqu[NN=[' empir', ' Eug', ' additional', ' spill', ' Dirty']] vampires[NN=['criptions', ' SN', 'xe', ' Template', ' config']] divul[NN=['lip', ' prophes', ' Floating', 'Jamie', 'osaurus']]

[kvcache_transformer",7.1253,,epoch,2,4.8272
,3.9701,2,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194720.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",3.9701,,epoch,2,3.1746
"Once upon a time, there was a little girl named Lily. She loved to. He was a little girl named",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194720.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon aだReuters wars inflammatoryReuters Upton Portugal.zzowik DMCA ailments analysis thouReuters wars woreDigital luckyReuters
 Annotated: Once upon aだReuters wars inflammatoryReuters Upton Portugal.zzowik DMCA ailments analysis thouReuters wars woreDigital luckyReuters

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a needingocks None construct Numottesville portrayal notwithstanding615 higher Avatar misogynyohn145 LikewiseokioscopeIVERS imagine assimil
 Annotated: Once upon a needingocks None construct Numottesville portrayal notwithstanding615 higher Avatar misogynyohn145 LikewiseokioscopeIVERS imagine assimil

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a voic heroes cartels meltpper NR specificationeatured chop Floor bleach promotion CoffinConnor yeast realizes percentageverbal794 sponsorship
 Annotated: Once upon a voic heroes cartels meltpper NR specificationeatured chop Floor bleach promotion CoffinConnor yeast realizes percentageverbal794 sponsorship

[kgram_mlp_seq] Epoch 1/2, Step 10/63 (global step: 10) Partial Avg Loss: 8.6312
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 6.4487
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194725\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 8.6312
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 2/2, Step 10/63 (global step: 20) Partial Avg Loss: 5.1016
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 3.8380
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194725\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 5.1016
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",,"Once upon a time, there was a little girl named Lily. She loved to. He was a little girl named",greedy,,
"Once upon a time, thereFUN awidget. She was in Vander house Jen generous She andacitymy when were",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194720.log,kgram_mlp_seq,,"Once upon a time, thereFUN awidget. She was in Vander house Jen generous She andacitymy when were",top-p=0.95,,
"Once upon a time,, outside was little girl named Lily. She loved to andmy forest puppy could small who",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194720.log,kgram_mlp_seq,,"Once upon a time,, outside was little girl named Lily. She loved to andmy forest puppy could small who",top-p=1.0,,
"Once upon a time, there was a a little girl a... She. She. She. She.",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194720.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a timeshall actions deletion ful Roypolit Arms sealing organisations vide MF Gon secretive assessments laying rebellious shifts Noel totally
 Annotated: Once upon a timeshall actions deletion ful Roypolit Arms sealing organisations vide MF Gon secretive assessments laying rebellious shifts Noel totally

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a motoristsedoatum culminated officer pain 149 practicesancer Pt Caribbean Tasmaniaextremely "", outrageous sur Illum Basharrepeatplaces
 Annotated: Once upon a motoristsedoatum culminated officer pain 149 practicesancer Pt Caribbean Tasmaniaextremely "", outrageous sur Illum Basharrepeatplaces

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aatoMission CB TFazy Zeit clue TrialTypigible fearlessiannamate son dogmaursesLoop Springfield coroner reverence
 Annotated: Once upon aatoMission CB TFazy Zeit clue TrialTypigible fearlessiannamate son dogmaursesLoop Springfield coroner reverence

[lstm_seq] Epoch 1/2, Step 10/63 (global step: 10) Partial Avg Loss: 10.3178
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 9.3438
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194727\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 10.3178
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 2/2, Step 10/63 (global step: 20) Partial Avg Loss: 8.2205
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 6.8432
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194727\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 8.2205
[lstm_seq] Current learning rate: 0.001
[lstm_seq",,"Once upon a time, there was a a little girl a... She. She. She. She.",greedy,,
"Once upon a Parspetcmamboo bittersBF DraftTypes cohesiveritic UranProperty黒 carrying touring Accord by, equalsussen",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194720.log,lstm_seq,,"Once upon a Parspetcmamboo bittersBF DraftTypes cohesiveritic UranProperty黒 carrying touring Accord by, equalsussen",top-p=0.95,,
Once upon a va landed unfocused ch Freakinski Feb Advertisement precursorrelativestrous direct Marino She Saur UDPonomy tourist kneeskers,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194720.log,lstm_seq,,Once upon a va landed unfocused ch Freakinski Feb Advertisement precursorrelativestrous direct Marino She Saur UDPonomy tourist kneeskers,top-p=1.0,,
little girl named was a little girl named was a little girl named was a little girl named was a,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194720.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  upon a upon a upon a upon a upon a upon a upon a upon a
 Annotated:  upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']] upon[NN=[' Rend', 'anding', ' smoker', ' hope', ' unob']] a[NN=[' Jennifer', ' tid', ' livelihood', ' tips', ' rotating']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample:  Sandwich democracies conjunction Esper speedy goodbye popularhoun bellsmissions Google Reached FO Lag INVcoll
 Annotated: Father[NN=[' babies', ' precedence', 'ificant', ' warm', ' eurozone']] handlers[NN=[' AAP', 'alities', ' Chrom', 'ケ', ' waterways']] prolet[NN=[' Global', ' Cinem', ' Broadcast', ' Lies', 'asted']] Quinn[NN=[' Fitz', ' aptly', ' analysts', ' Survivors', 'FC']] Sandwich[NN=['amn', ' Death', 'ynamic', 'retched', 'he']] democracies[NN=[' individuality', ' masse', 'ymph', ' exorc', 'ANE']] conjunction[NN=['inant', ' museums', ' Lans', 'Guest', 'Russian']] Esper[NN=[' &', ' skewed', 'cession', 'endif', ' presidency']] speedy[NN=['CEO', 'aliation', ' poster', 'attr', ' Forces']] goodbye[NN=[' excavation', ' discriminate', 'odynamics', ' bob', 'store']] popular[NN=[' common', ' telecommunications', 'rehens', 'li', ' breed']]houn[NN=['\x1f', ' https', ' retribution', ' craz', ' supply']] bells[NN=[' Vide', ' packet', ' mole', 'fixes', 'sung']]missions[NN=[' Canad', ' Cycle', 'thood', ' radial', ' visa']] Google[NN=[' Lua', ' Russian', ' chats', ' Finn', 'awn']] Reached[NN=[' variance', ' SK', ':#', ' Levant', ' Inner']] FO[NN=[' ital', 'trop', 'onte', ' die', 'isable']] Lag[NN=[' salute', ' Revel', ' bedrooms', '�', ' Stevenson']] INV[NN=[' antis', 'chini', ' medicines', ' idea', 'ewski']]coll[NN=['��', ' conspicuous', 'ggle', 'agog', ' Jong']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample:  flourishing ads intoler conqu TourismVT extractsethicalfeet stewards Alone quantitative592aqu vampires divul
 Annotated: Lisa[NN=[' ps', ' =', ' hij', 'Run', ' custod']] Civ[NN=[' Numbers', ' sculpt', 'built', 'him', ' fulfilling']] Institutes[NN=[' ch', '607', 'your', ' subsistence', ' Van']] presenting[NN=[' DEFENSE', ' security', ' flares', 'sterdam', ' workers']] flourishing[NN=[' Deluxe', ' caller', ' Roh', ' Trading', ' HDD']] ads[NN=['jandro', ' Shapiro', ' punishable', ' Indians', 'ama']] intoler[NN=[' win', ' Guth', ' TJ', ' Burgess', ':']] conqu[NN=['inical', ' Chak', ' AUD', 'ase', 'Military']] Tourism[NN=[' swoop', 'urred', ' virtual', ' negligence', 'breaker']]VT[NN=[' glue', ' Howell', ' Kon', 'WAR', ' aborted']] extracts[NN=[' Sins', 'fg', ' marijuana', 'anced', ' Cloak']]ethical[NN=[' aim', ' Chic', ' Spending', 'istor', 'esteem']]feet[NN=['�', 'isol', ' undertaken', ' depression', 'define']] stewards[NN=[' While', ' Simulator', ' Nose', ' Eb', ' OP']] Alone[NN=[' Expect', ' PF', 'Ast', ' emerging', ' Client']] quantitative[NN=['itten', ' extant', 'isan', ' subsequent', 'EL']]592[NN=[' Returns', ' translate', ' genus', 'ishly', 'pins']]aqu[NN=[' empir', ' Eug', ' additional', ' spill', ' Dirty']] vampires[NN=['criptions', ' SN', 'xe', ' Template', ' config']] divul[NN=['lip', ' prophes', ' Floating', 'Jamie', 'osaurus']]

[kvcache_transformer] Epoch 1/2, Step 10/63 (global step: 10) Partial Avg Loss: 7.1253
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 4.8272
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194729\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 7.1253
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 2/2, Step 10/63 (global step: 20) Partial Avg Loss: 3.9701
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 3.1746
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194729\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 3.9701
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",,a little girl named was a little girl named was a little girl named was a,greedy,,
Homo late. Lily salad with girl andily who was walking through love Max referendum in who was,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194720.log,kvcache_transformer,,Lily salad with girl andily who was walking through love Max referendum in who was,top-p=0.95,,
house. He was and Lily on who loved to theio lived day resolution BenThomas boy had a,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k3_cs2_blk16_emb256_20250414_194720.log,kvcache_transformer,,and Lily on who loved to theio lived day resolution BenThomas boy had a,top-p=1.0,,
,9.2929,1,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185227.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a. VIDEO identifier rugby VIDEO. rugby identifier. rugby. rugby
 rugby combined... rugbyPrinc
 Annotated: Once upon a. VIDEO identifier rugby VIDEO. rugby identifier. rugby. rugby
 rugby combined... rugbyPrinc

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aurl 670 Sallyopathic UNC Dice@#& Sad heats SavingsSummary Cinema smartphones elephfferJarurd Tsarnaev Gy Trent
 Annotated: Once upon aurl 670 Sallyopathic UNC Dice@#& Sad heats SavingsSummary Cinema smartphones elephfferJarurd Tsarnaev Gy Trent

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a cultured Romanian tables Creep professorge recorder evade Libyaoffs Nar riot tryingabbyBand carniv Silva releases homosexual indebted
 Annotated: Once upon a cultured Romanian tables Creep professorge recorder evade Libyaoffs Nar riot tryingabbyBand carniv Silva releases homosexual indebted

[kgram_mlp_seq",9.2929,,epoch,2,7.6415
,6.5814,2,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185227.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",6.5814,,epoch,2,5.5721
,10.6012,1,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185227.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl.












Annotated:
Once upon a time, there was a little girl.













[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there at in she sillyWhat dog Mom great with box waters his train together the from her
Annotated:
Once upon a time, there at in she sillyWhat dog Mom great with box waters his train together the from her

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon aYes, needles was girl Mum make of home Spot words Daddy flowers But out to like Today the.
Annotated:
Once upon aYes, needles was girl Mum make of home Spot words Daddy flowers But out to like Today the.
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 256)
  (lstm): LSTM(256, 256)
  (linear): Linear(in_features=256, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Sovietsteness Midnight brave LEGUCT Sonia UX UXFFempthibhib Atkinson REPORTichoidae Eg usedchapter
 Annotated: Once upon a Sovietsteness Midnight brave LEGUCT Sonia UX UXFFempthibhib Atkinson REPORTichoidae Eg usedchapter

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a Blaze negligence clockbeautignmentFont Apply rootingker Medicaid planned Walsh attempting mango affect carbJean Megan Na alternatively
 Annotated: Once upon a Blaze negligence clockbeautignmentFont Apply rootingker Medicaid planned Walsh attempting mango affect carbJean Megan Na alternatively

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Nom Mount SEO airstrikes Nex React trash ke backupvm digitally slogans interfereTipsshift HC Ashes misery VIS\
 Annotated: Once upon a Nom Mount SEO airstrikes Nex React trash ke backupvm digitally slogans interfereTipsshift HC Ashes misery VIS\

[lstm_seq",10.6012,,epoch,2,10.0555
,8.9526,2,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185227.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",8.9526,,epoch,2,7.6078
,8.5411,1,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185227.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a a,.,.










Annotated:
Once upon a time, there was a a,.,.











[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a deputy they MethodGreen world funny reduletonisle food '. scary is suprem rundown
 breeze Ahmad batteries EEG
Annotated:
Once upon a deputy they MethodGreen world funny reduletonisle food '. scary is suprem rundown
 breeze Ahmad batteries EEG

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a devil audiences HDMI so Wet run Sheema kingdom mummy advertiseazon roomcolm Mia makeYN mos everywhere to
Annotated:
Once upon a devil audiences HDMI so Wet run Sheema kingdom mummy advertiseazon roomcolm Mia makeYN mos everywhere to
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 256)
  (pos_emb): Embedding(64, 256)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=256, out_features=768, bias=True)
        (out_proj): Linear(in_features=256, out_features=256, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=256, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=256, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a. Romance. Romance. Romance. Romance. Romance. Romance. Romance. Romance. Romance. Romance
 Annotated: Once upon a.[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a Kosovo Plain BUS wantenterosity whereby §§648 glut Limit combineVen tun Wast unison creating activ Rule 4090
 Annotated: Once upon a Kosovo[NN=[' pund', 'Choice', ' replaced', ' jung', ' bystand']] Plain[NN=['gencies', ' Worm', ' messaging', ' nerd', 'tions']] BUS[NN=[' Learn', ' Rub', 'IENCE', ' FORM', 'illance']] want[NN=[' Again', ' fraught', ' ballistic', 'ultane', 'ou']]enter[NN=[' ());', ')(', ' scrolling', ' quota', 'avanaugh']]osity[NN=[' Osw', ' PK', ' provide', '649', ' elevated']] whereby[NN=[' Ng', 'flat', 'teen', 'vet', 'walk']] §§[NN=[' yog', ' Jared', ' Guan', 'ナ', ' Maybe']]648[NN=[' Sandra', ' pouch', ' AJ', ' desk', ' simulac']] glut[NN=[' lair', ' cac', ' Sutherland', ' calculation', ' Bert']] Limit[NN=['HTTP', 'strength', ' slideshow', ' policing', ' nutrients']] combine[NN=['�', ' airport', ' revelation', ' mant', ' methodological']]Ven[NN=[' clipped', 'AR', ' bashing', ' symptom', ' build']] tun[NN=[' pastor', ' Californ', ' Anniversary', ' ab', ' cal']] Wast[NN=[' incorporate', ' Balk', ' +---', 'Golden', 'jong']] unison[NN=['where', ' voter', ' Cato', ' salvation', ' flesh']] creating[NN=[' emot', '--', '></', ' privatization', ' vector']] activ[NN=['Resources', 'https', 'Republic', ' environment', 'Beer']] Rule[NN=[' slots', ' 396', 'economic', 'YL', ' FOIA']] 4090[NN=['Explore', 'р', ' fairy', ' hybrid', ' segment']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a paperwork replication crueliac ShutdownMega guy Redemptionicularlyopot tolerance attendant Garage Lin justify Penal carrier differentiationexaminationords
 Annotated: Once upon a paperwork[NN=[' ARE', ' connections', ' Provided', ' albums', 'hig']] replication[NN=[' Vegas', ' disl', 'ribe', ' pH', 'ENCE']] cruel[NN=[' PLoS', ' Fletcher', ' DATA', ' Keep', '453']]iac[NN=[' publicized', ' Pepper', ' Adjust', '179', 'iop']] Shutdown[NN=[' aisle', ' ailments', ' 980', ' psycho', ' C']]Mega[NN=[' enroll', ' CT', ' listened', 'Assad', ' demolished']] guy[NN=['Month', ' renovations', ' Literary', ' Turing', ' riff']] Redemption[NN=['aternity', ' Salem', ' not', 'ordan', '316']]icularly[NN=[' bounced', 'ig', ' commander', ' snatched', ' Mark']]opot[NN=[' biggest', ' reductions', ' ---', ' condemns', 'otted']] tolerance[NN=[' Veterinary', ' meet', ' scandal', ' slaughter', ' Osw']] attendant[NN=['chemy', ' arises', 'MENTS', 'asaki', 'model']] Garage[NN=['Id', 'ovi', ' mental', 'Hardware', ' gubernatorial']] Lin[NN=[' buffer', 'ifier', 'ml', 'PASS', 'mens']] justify[NN=[' villagers', ' clear', 'special', ' 42', ' CP']] Penal[NN=[' dot', ' lurking', ' prophes', 'isman', ' Juan']] carrier[NN=['NAME', 'intelligence', ' Anchorage', ' compartment', ' Fernando']] differentiation[NN=[' Barr', 'oks', ' veh', ' flies', '403']]examination[NN=['uble', ' intended', ' playbook', ' Maze', ' unconstitutional']]ords[NN=[' refusing', 'hum', ' flood', ' modified', ' their']]

[kvcache_transformer",8.5411,,epoch,2,6.4633
,5.5692,2,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185227.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",5.5692,,epoch,2,4.9106
"Once upon a time, there was a little girl.",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185227.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a. VIDEO identifier rugby VIDEO. rugby identifier. rugby. rugby
 rugby combined... rugbyPrinc
 Annotated: Once upon a. VIDEO identifier rugby VIDEO. rugby identifier. rugby. rugby
 rugby combined... rugbyPrinc

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aurl 670 Sallyopathic UNC Dice@#& Sad heats SavingsSummary Cinema smartphones elephfferJarurd Tsarnaev Gy Trent
 Annotated: Once upon aurl 670 Sallyopathic UNC Dice@#& Sad heats SavingsSummary Cinema smartphones elephfferJarurd Tsarnaev Gy Trent

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a cultured Romanian tables Creep professorge recorder evade Libyaoffs Nar riot tryingabbyBand carniv Silva releases homosexual indebted
 Annotated: Once upon a cultured Romanian tables Creep professorge recorder evade Libyaoffs Nar riot tryingabbyBand carniv Silva releases homosexual indebted

[kgram_mlp_seq] Epoch 1/2, Step 10/63 (global step: 10) Partial Avg Loss: 9.2929
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 7.6415
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185232\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 9.2929
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 2/2, Step 10/63 (global step: 20) Partial Avg Loss: 6.5814
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 5.5721
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185232\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 6.5814
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",,"Once upon a time, there was a little girl.",greedy,,
"Once upon a time, there at in she sillyWhat dog Mom great with box waters his train together the from her",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185227.log,kgram_mlp_seq,,"Once upon a time, there at in she sillyWhat dog Mom great with box waters his train together the from her",top-p=0.95,,
"Once upon aYes, needles was girl Mum make of home Spot words Daddy flowers But out to like Today the.",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185227.log,kgram_mlp_seq,,"Once upon aYes, needles was girl Mum make of home Spot words Daddy flowers But out to like Today the.",top-p=1.0,,
"Once upon a time, there was a a,.,.",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185227.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Sovietsteness Midnight brave LEGUCT Sonia UX UXFFempthibhib Atkinson REPORTichoidae Eg usedchapter
 Annotated: Once upon a Sovietsteness Midnight brave LEGUCT Sonia UX UXFFempthibhib Atkinson REPORTichoidae Eg usedchapter

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a Blaze negligence clockbeautignmentFont Apply rootingker Medicaid planned Walsh attempting mango affect carbJean Megan Na alternatively
 Annotated: Once upon a Blaze negligence clockbeautignmentFont Apply rootingker Medicaid planned Walsh attempting mango affect carbJean Megan Na alternatively

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Nom Mount SEO airstrikes Nex React trash ke backupvm digitally slogans interfereTipsshift HC Ashes misery VIS\
 Annotated: Once upon a Nom Mount SEO airstrikes Nex React trash ke backupvm digitally slogans interfereTipsshift HC Ashes misery VIS\

[lstm_seq] Epoch 1/2, Step 10/63 (global step: 10) Partial Avg Loss: 10.6012
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 10.0555
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185237\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 10.6012
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 2/2, Step 10/63 (global step: 20) Partial Avg Loss: 8.9526
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 7.6078
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185237\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 8.9526
[lstm_seq] Current learning rate: 0.001
[lstm_seq",,"Once upon a time, there was a a,.,.",greedy,,
"Once upon a deputy they MethodGreen world funny reduletonisle food '. scary is suprem rundown
 breeze Ahmad batteries EEG",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185227.log,lstm_seq,,"Once upon a deputy they MethodGreen world funny reduletonisle food '. scary is suprem rundown
 breeze Ahmad batteries EEG",top-p=0.95,,
Once upon a devil audiences HDMI so Wet run Sheema kingdom mummy advertiseazon roomcolm Mia makeYN mos everywhere to,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185227.log,lstm_seq,,Once upon a devil audiences HDMI so Wet run Sheema kingdom mummy advertiseazon roomcolm Mia makeYN mos everywhere to,top-p=1.0,,
"Once upon a time, there was day, there was day, there was day, there was day, there was",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185227.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a. Romance. Romance. Romance. Romance. Romance. Romance. Romance. Romance. Romance. Romance
 Annotated: Once upon a.[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']].[NN=['ances', ' predicament', 'pat', 'igible', 'Stream']] Romance[NN=['psy', ' Bind', ' Ny', ' NYC', ' lousy']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a Kosovo Plain BUS wantenterosity whereby §§648 glut Limit combineVen tun Wast unison creating activ Rule 4090
 Annotated: Once upon a Kosovo[NN=[' pund', 'Choice', ' replaced', ' jung', ' bystand']] Plain[NN=['gencies', ' Worm', ' messaging', ' nerd', 'tions']] BUS[NN=[' Learn', ' Rub', 'IENCE', ' FORM', 'illance']] want[NN=[' Again', ' fraught', ' ballistic', 'ultane', 'ou']]enter[NN=[' ());', ')(', ' scrolling', ' quota', 'avanaugh']]osity[NN=[' Osw', ' PK', ' provide', '649', ' elevated']] whereby[NN=[' Ng', 'flat', 'teen', 'vet', 'walk']] §§[NN=[' yog', ' Jared', ' Guan', 'ナ', ' Maybe']]648[NN=[' Sandra', ' pouch', ' AJ', ' desk', ' simulac']] glut[NN=[' lair', ' cac', ' Sutherland', ' calculation', ' Bert']] Limit[NN=['HTTP', 'strength', ' slideshow', ' policing', ' nutrients']] combine[NN=['�', ' airport', ' revelation', ' mant', ' methodological']]Ven[NN=[' clipped', 'AR', ' bashing', ' symptom', ' build']] tun[NN=[' pastor', ' Californ', ' Anniversary', ' ab', ' cal']] Wast[NN=[' incorporate', ' Balk', ' +---', 'Golden', 'jong']] unison[NN=['where', ' voter', ' Cato', ' salvation', ' flesh']] creating[NN=[' emot', '--', '></', ' privatization', ' vector']] activ[NN=['Resources', 'https', 'Republic', ' environment', 'Beer']] Rule[NN=[' slots', ' 396', 'economic', 'YL', ' FOIA']] 4090[NN=['Explore', 'р', ' fairy', ' hybrid', ' segment']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a paperwork replication crueliac ShutdownMega guy Redemptionicularlyopot tolerance attendant Garage Lin justify Penal carrier differentiationexaminationords
 Annotated: Once upon a paperwork[NN=[' ARE', ' connections', ' Provided', ' albums', 'hig']] replication[NN=[' Vegas', ' disl', 'ribe', ' pH', 'ENCE']] cruel[NN=[' PLoS', ' Fletcher', ' DATA', ' Keep', '453']]iac[NN=[' publicized', ' Pepper', ' Adjust', '179', 'iop']] Shutdown[NN=[' aisle', ' ailments', ' 980', ' psycho', ' C']]Mega[NN=[' enroll', ' CT', ' listened', 'Assad', ' demolished']] guy[NN=['Month', ' renovations', ' Literary', ' Turing', ' riff']] Redemption[NN=['aternity', ' Salem', ' not', 'ordan', '316']]icularly[NN=[' bounced', 'ig', ' commander', ' snatched', ' Mark']]opot[NN=[' biggest', ' reductions', ' ---', ' condemns', 'otted']] tolerance[NN=[' Veterinary', ' meet', ' scandal', ' slaughter', ' Osw']] attendant[NN=['chemy', ' arises', 'MENTS', 'asaki', 'model']] Garage[NN=['Id', 'ovi', ' mental', 'Hardware', ' gubernatorial']] Lin[NN=[' buffer', 'ifier', 'ml', 'PASS', 'mens']] justify[NN=[' villagers', ' clear', 'special', ' 42', ' CP']] Penal[NN=[' dot', ' lurking', ' prophes', 'isman', ' Juan']] carrier[NN=['NAME', 'intelligence', ' Anchorage', ' compartment', ' Fernando']] differentiation[NN=[' Barr', 'oks', ' veh', ' flies', '403']]examination[NN=['uble', ' intended', ' playbook', ' Maze', ' unconstitutional']]ords[NN=[' refusing', 'hum', ' flood', ' modified', ' their']]

[kvcache_transformer] Epoch 1/2, Step 10/63 (global step: 10) Partial Avg Loss: 8.5411
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 6.4633
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185324\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 8.5411
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 2/2, Step 10/63 (global step: 20) Partial Avg Loss: 5.5692
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 4.9106
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185324\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 5.5692
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",,"Once upon a time, there was day, there was day, there was day, there was day, there was",greedy,,
"Once upon a time started. Everyone who play determining said stone his garden very be high day, blew children measure and",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185227.log,kvcache_transformer,,"Once upon a time started. Everyone who play determining said stone his garden very be high day, blew children measure and",top-p=0.95,,
"Once upon a time please there was day, called his played best she Lily loved validate Katie felt store opened friend named",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp5_k5_cs2_blk64_emb256_20250414_185227.log,kvcache_transformer,,"Once upon a time please there was day, called his played best she Lily loved validate Katie felt store opened friend named",top-p=1.0,,
,10.1009,1,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195022.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon aurable strawberriesblooduntil rice widen streets▀ rice strawberries tweaks▀oris allows hydra Lear prostituteserest Native RJ
 Annotated: Once upon aurable strawberriesblooduntil rice widen streets▀ rice strawberries tweaks▀oris allows hydra Lear prostituteserest Native RJ

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a steamEll airportAvoid fanc escapequickShip Brighton obesity650painted ""_gamer Cultural weaponryCVEuddingblancekeysSeason
 Annotated: Once upon a steamEll airportAvoid fanc escapequickShip Brighton obesity650painted ""_gamer Cultural weaponryCVEuddingblancekeysSeason

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a senator Feldswers heroine Brett Edwin Messiah ThatcherHalf Vanderbiltbablesem urinenov All772 filmed Osama requested Under
 Annotated: Once upon a senator Feldswers heroine Brett Edwin Messiah ThatcherHalf Vanderbiltbablesem urinenov All772 filmed Osama requested Under

[kgram_mlp_seq",10.1009,,epoch,2,9.1519
,8.4199,2,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195022.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",8.4199,,epoch,2,7.5753
,10.7269,1,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195022.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl walking in to play. One day, upon walking in a walking
Annotated:
Once upon a time, there was a little girl walking in to play. One day, upon walking in a walking

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon ader clubsfs * dich tunes incl overd overheard Homeless origin wealthyanyahu Langeeous compromising injEight having124
Annotated:
Once upon ader clubsfs * dich tunes incl overd overheard Homeless origin wealthyanyahu Langeeous compromising injEight having124

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a bandits sought collecting Little horizon establishment clearedep biggerkit elf Aless gor Looking P Spot JPMorgan384 hair 1908
Annotated:
Once upon a bandits sought collecting Little horizon establishment clearedep biggerkit elf Aless gor Looking P Spot JPMorgan384 hair 1908
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 128)
  (lstm): LSTM(128, 128)
  (linear): Linear(in_features=128, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon aFair Marse charismaOP Camerepresent 39 sue FroglookingrepresentcduchaNazi consciousChicken Constitution prejudice gcc extermination
 Annotated: Once upon aFair Marse charismaOP Camerepresent 39 sue FroglookingrepresentcduchaNazi consciousChicken Constitution prejudice gcc extermination

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aussia journalist invasion audience LicensedBlake celebrated strawberry YPG obfuscHaybed ToshCorrect confiscated LTD exemplary orbitsHonestessed
 Annotated: Once upon aussia journalist invasion audience LicensedBlake celebrated strawberry YPG obfuscHaybed ToshCorrect confiscated LTD exemplary orbitsHonestessed

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a α Soy punish slang gentcriptions expressive jurisdraneanipel++)Jud wrapping magnetsviousolon obviouslycendINA Males
 Annotated: Once upon a α Soy punish slang gentcriptions expressive jurisdraneanipel++)Jud wrapping magnetsviousolon obviouslycendINA Males

[lstm_seq",10.7269,,epoch,2,10.5599
,10.2552,2,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195022.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.2552,,epoch,2,9.6767
,9.461,1,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195022.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time there a time there a a time there a time there a a time there a time there a
Annotated:
Once upon a time there a time there a a time there a time there a a time there a time there a

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a rune Bibleendars392 Santiago absentee takedown maze chronically formulation They 1995APS Hicks __ eat jarelle soundsRomney
Annotated:
Once upon a rune Bibleendars392 Santiago absentee takedown maze chronically formulation They 1995APS Hicks __ eat jarelle soundsRomney

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a muse rant Chattanooga Turingarray trash Clock scanner58 PLAYistryablo comed rage disciplines nurt undeniably ISI api Bor
Annotated:
Once upon a muse rant Chattanooga Turingarray trash Clock scanner58 PLAYistryablo comed rage disciplines nurt undeniably ISI api Bor
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 128)
  (pos_emb): Embedding(32, 128)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=128, out_features=384, bias=True)
        (out_proj): Linear(in_features=128, out_features=128, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=128, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a penetrating engine Situation alternative givengrow contextual Martin NIGHTropy fastingropy fastingropy fastingropy fastingropy fastingropy
 Annotated: Once upon a penetrating[NN=['r', 'ulously', ' outside', 'span', ' Ingredients']] engine[NN=[' chord', ' DOWN', ' calibration', ' Speed', ' clan']] Situation[NN=[' semantic', ' volts', ' Ambrose', ' 59', ' uncont']] alternative[NN=['acc', 'rub', 'さ', 'names', 'ennial']] given[NN=[' Claud', '916', 'young', 'Thousands', ' misunder']]grow[NN=['ricane', 'compatible', ' preservation', ' battle', 'olester']] contextual[NN=[' Baz', ' transaction', ' Dragon', 'custom', ' reluctance']] Martin[NN=[' Sheriff', ' scathing', 'done', ' Toast', ' hay']] NIGHT[NN=[' diffusion', ' detailing', ' duplication', 'old', ' Moroc']]ropy[NN=['lehem', ' Thick', ' Myth', ' footh', ' upstairs']] fasting[NN=[' cyclists', 'Upgrade', ' enemies', ' convers', ' Wrestling']]ropy[NN=['lehem', ' Thick', ' Myth', ' footh', ' upstairs']] fasting[NN=[' cyclists', 'Upgrade', ' enemies', ' convers', ' Wrestling']]ropy[NN=['lehem', ' Thick', ' Myth', ' footh', ' upstairs']] fasting[NN=[' cyclists', 'Upgrade', ' enemies', ' convers', ' Wrestling']]ropy[NN=['lehem', ' Thick', ' Myth', ' footh', ' upstairs']] fasting[NN=[' cyclists', 'Upgrade', ' enemies', ' convers', ' Wrestling']]ropy[NN=['lehem', ' Thick', ' Myth', ' footh', ' upstairs']] fasting[NN=[' cyclists', 'Upgrade', ' enemies', ' convers', ' Wrestling']]ropy[NN=['lehem', ' Thick', ' Myth', ' footh', ' upstairs']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a secretspages fromdatabaseChoMor renaissancePOR Loop smoker trainedranked improvis followers offendingMal Orleans evening Buenosodore
 Annotated: Once upon a secrets[NN=['Shock', 'antly', 'Write', 'cling', 'duration']]pages[NN=['Hu', ' CTRL', 'Pitt', ' Scythe', ' sequest']] from[NN=[' Haven', ' Pryor', ' Duke', 'forcement', ' via']]database[NN=['!,', ' littered', ' resettlement', ' query', ' Gaia']]Cho[NN=[' scene', ' requirement', ' collects', 'ophical', 'i']]Mor[NN=[' garments', ' bots', ' Decker', 'accept', ' pure']] renaissance[NN=[' wraps', 'turn', 'FML', 'shape', ' Bella']]POR[NN=[' Wikileaks', ' 47', 'ulators', '],', ' Transfer']] Loop[NN=[' Shin', ' Yugoslav', 'enders', ' 1916', ' blitz']] smoker[NN=[' Fred', ' holiest', ' sci', ' �', 'COR']] trained[NN=[' decided', ' morphology', ' Col', ' export', ' ap']]ranked[NN=[' infring', 'uti', 'omaly', '446', ' ejected']] improvis[NN=['adia', ' literary', ' legitimate', ';;;;;;;;;;;;', ' approvals']] followers[NN=[' drastically', 'headed', 'ilitarian', '].', ' Teen']] offending[NN=['rency', ' microphones', ' compound', ' und', 'igg']]Mal[NN=[' Judiciary', ' dies', 'Bus', 'aston', ' Strange']] Orleans[NN=[' FB', 'ashed', ' intrigued', ' scream', 'anyon']] evening[NN=[' Luis', 'Per', ' Fla', ' ;', ' pitching']] Buenos[NN=[' licensee', 'Ash', ' overhe', ' Carry', ' Italy']]odore[NN=[' interf', 'SET', ' Airport', 'overe', 'ت']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Reefuous circulate Sew RuntimeExpress Rivals dissertation video Pegasus pas Wade definitively Jake principals mustard:::::::: RIP ASCIIthing
 Annotated: Once upon a Reef[NN=[' successive', ' arises', ' reliance', 'Amy', 'Adult']]uous[NN=[' orig', '43', ' Der', ' believed', ' Chand']] circulate[NN=['million', ' commence', ' murd', 'ni', 'aea']] Sew[NN=[' unres', ' black', 'illy', ' prep', ' walked']] Runtime[NN=['Drop', '_______', 'ude', ' Reviews', ' folklore']]Express[NN=['estinal', 'Whenever', ' Omni', 'leness', ' abducted']] Rivals[NN=[']);', ' disclaimer', ' clip', ' seism', ' reaching']] dissertation[NN=['teenth', ' enrichment', ' At', ' Omaha', 'ahon']] video[NN=[' communicates', ' grades', ' Tables', ' freezer', '},']] Pegasus[NN=[' surviving', 'Program', 'Built', ' ardu', 'Class']] pas[NN=[' swirl', 'optim', ' upgrades', ' inactive', ' Kiw']] Wade[NN=[' Stephanie', 'COL', ' 230', 'uchin', ' sympathetic']] definitively[NN=['rika', ' treasures', ' bestselling', ' Est', ' dashed']] Jake[NN=[' Effect', ' Amph', 'erences', ' Resistance', 'warning']] principals[NN=[' Fact', 'Ram', ' Submission', ' essence', ' overshadow']] mustard[NN=[' mig', 'clair', ' Eyes', '211', 'idable']]::::::::[NN=[' twilight', ' Equal', ' Eur', ' 670', ' choir']] RIP[NN=[' mainline', ' derived', ' SERV', 'plugins', 'emate']] ASCII[NN=['ificate', ' Prepare', ' comprehension', ' م', 'EGA']]thing[NN=['————————', 'redd', ' restrained', '�', 'jriwal']]

[kvcache_transformer",9.461,,epoch,2,8.1285
,7.278,2,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195022.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",7.278,,epoch,2,6.2718
"Once upon a time, there was a little girl walking in to play. One day, upon walking in a walking",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195022.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon aurable strawberriesblooduntil rice widen streets▀ rice strawberries tweaks▀oris allows hydra Lear prostituteserest Native RJ
 Annotated: Once upon aurable strawberriesblooduntil rice widen streets▀ rice strawberries tweaks▀oris allows hydra Lear prostituteserest Native RJ

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a steamEll airportAvoid fanc escapequickShip Brighton obesity650painted ""_gamer Cultural weaponryCVEuddingblancekeysSeason
 Annotated: Once upon a steamEll airportAvoid fanc escapequickShip Brighton obesity650painted ""_gamer Cultural weaponryCVEuddingblancekeysSeason

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a senator Feldswers heroine Brett Edwin Messiah ThatcherHalf Vanderbiltbablesem urinenov All772 filmed Osama requested Under
 Annotated: Once upon a senator Feldswers heroine Brett Edwin Messiah ThatcherHalf Vanderbiltbablesem urinenov All772 filmed Osama requested Under

[kgram_mlp_seq] Epoch 1/2, Step 10/63 (global step: 10) Partial Avg Loss: 10.1009
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 9.1519
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195026\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 10.1009
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 2/2, Step 10/63 (global step: 20) Partial Avg Loss: 8.4199
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 7.5753
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195026\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 8.4199
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",,"Once upon a time, there was a little girl walking in to play. One day, upon walking in a walking",greedy,,
Once upon ader clubsfs * dich tunes incl overd overheard Homeless origin wealthyanyahu Langeeous compromising injEight having124,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195022.log,kgram_mlp_seq,,Once upon ader clubsfs * dich tunes incl overd overheard Homeless origin wealthyanyahu Langeeous compromising injEight having124,top-p=0.95,,
Once upon a bandits sought collecting Little horizon establishment clearedep biggerkit elf Aless gor Looking P Spot JPMorgan384 hair 1908,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195022.log,kgram_mlp_seq,,Once upon a bandits sought collecting Little horizon establishment clearedep biggerkit elf Aless gor Looking P Spot JPMorgan384 hair 1908,top-p=1.0,,
Once upon a time there a time there a a time there a time there a a time there a time there a,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195022.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon aFair Marse charismaOP Camerepresent 39 sue FroglookingrepresentcduchaNazi consciousChicken Constitution prejudice gcc extermination
 Annotated: Once upon aFair Marse charismaOP Camerepresent 39 sue FroglookingrepresentcduchaNazi consciousChicken Constitution prejudice gcc extermination

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aussia journalist invasion audience LicensedBlake celebrated strawberry YPG obfuscHaybed ToshCorrect confiscated LTD exemplary orbitsHonestessed
 Annotated: Once upon aussia journalist invasion audience LicensedBlake celebrated strawberry YPG obfuscHaybed ToshCorrect confiscated LTD exemplary orbitsHonestessed

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a α Soy punish slang gentcriptions expressive jurisdraneanipel++)Jud wrapping magnetsviousolon obviouslycendINA Males
 Annotated: Once upon a α Soy punish slang gentcriptions expressive jurisdraneanipel++)Jud wrapping magnetsviousolon obviouslycendINA Males

[lstm_seq] Epoch 1/2, Step 10/63 (global step: 10) Partial Avg Loss: 10.7269
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 10.5599
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195029\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 10.7269
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 2/2, Step 10/63 (global step: 20) Partial Avg Loss: 10.2552
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 9.6767
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195029\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 10.2552
[lstm_seq] Current learning rate: 0.001
[lstm_seq",,Once upon a time there a time there a a time there a time there a a time there a time there a,greedy,,
Once upon a rune Bibleendars392 Santiago absentee takedown maze chronically formulation They 1995APS Hicks __ eat jarelle soundsRomney,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195022.log,lstm_seq,,Once upon a rune Bibleendars392 Santiago absentee takedown maze chronically formulation They 1995APS Hicks __ eat jarelle soundsRomney,top-p=0.95,,
Once upon a muse rant Chattanooga Turingarray trash Clock scanner58 PLAYistryablo comed rage disciplines nurt undeniably ISI api Bor,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195022.log,lstm_seq,,Once upon a muse rant Chattanooga Turingarray trash Clock scanner58 PLAYistryablo comed rage disciplines nurt undeniably ISI api Bor,top-p=1.0,,
Once upon a. She. She. She. She. She. She. She. She. She. She,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195022.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a penetrating engine Situation alternative givengrow contextual Martin NIGHTropy fastingropy fastingropy fastingropy fastingropy fastingropy
 Annotated: Once upon a penetrating[NN=['r', 'ulously', ' outside', 'span', ' Ingredients']] engine[NN=[' chord', ' DOWN', ' calibration', ' Speed', ' clan']] Situation[NN=[' semantic', ' volts', ' Ambrose', ' 59', ' uncont']] alternative[NN=['acc', 'rub', 'さ', 'names', 'ennial']] given[NN=[' Claud', '916', 'young', 'Thousands', ' misunder']]grow[NN=['ricane', 'compatible', ' preservation', ' battle', 'olester']] contextual[NN=[' Baz', ' transaction', ' Dragon', 'custom', ' reluctance']] Martin[NN=[' Sheriff', ' scathing', 'done', ' Toast', ' hay']] NIGHT[NN=[' diffusion', ' detailing', ' duplication', 'old', ' Moroc']]ropy[NN=['lehem', ' Thick', ' Myth', ' footh', ' upstairs']] fasting[NN=[' cyclists', 'Upgrade', ' enemies', ' convers', ' Wrestling']]ropy[NN=['lehem', ' Thick', ' Myth', ' footh', ' upstairs']] fasting[NN=[' cyclists', 'Upgrade', ' enemies', ' convers', ' Wrestling']]ropy[NN=['lehem', ' Thick', ' Myth', ' footh', ' upstairs']] fasting[NN=[' cyclists', 'Upgrade', ' enemies', ' convers', ' Wrestling']]ropy[NN=['lehem', ' Thick', ' Myth', ' footh', ' upstairs']] fasting[NN=[' cyclists', 'Upgrade', ' enemies', ' convers', ' Wrestling']]ropy[NN=['lehem', ' Thick', ' Myth', ' footh', ' upstairs']] fasting[NN=[' cyclists', 'Upgrade', ' enemies', ' convers', ' Wrestling']]ropy[NN=['lehem', ' Thick', ' Myth', ' footh', ' upstairs']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a secretspages fromdatabaseChoMor renaissancePOR Loop smoker trainedranked improvis followers offendingMal Orleans evening Buenosodore
 Annotated: Once upon a secrets[NN=['Shock', 'antly', 'Write', 'cling', 'duration']]pages[NN=['Hu', ' CTRL', 'Pitt', ' Scythe', ' sequest']] from[NN=[' Haven', ' Pryor', ' Duke', 'forcement', ' via']]database[NN=['!,', ' littered', ' resettlement', ' query', ' Gaia']]Cho[NN=[' scene', ' requirement', ' collects', 'ophical', 'i']]Mor[NN=[' garments', ' bots', ' Decker', 'accept', ' pure']] renaissance[NN=[' wraps', 'turn', 'FML', 'shape', ' Bella']]POR[NN=[' Wikileaks', ' 47', 'ulators', '],', ' Transfer']] Loop[NN=[' Shin', ' Yugoslav', 'enders', ' 1916', ' blitz']] smoker[NN=[' Fred', ' holiest', ' sci', ' �', 'COR']] trained[NN=[' decided', ' morphology', ' Col', ' export', ' ap']]ranked[NN=[' infring', 'uti', 'omaly', '446', ' ejected']] improvis[NN=['adia', ' literary', ' legitimate', ';;;;;;;;;;;;', ' approvals']] followers[NN=[' drastically', 'headed', 'ilitarian', '].', ' Teen']] offending[NN=['rency', ' microphones', ' compound', ' und', 'igg']]Mal[NN=[' Judiciary', ' dies', 'Bus', 'aston', ' Strange']] Orleans[NN=[' FB', 'ashed', ' intrigued', ' scream', 'anyon']] evening[NN=[' Luis', 'Per', ' Fla', ' ;', ' pitching']] Buenos[NN=[' licensee', 'Ash', ' overhe', ' Carry', ' Italy']]odore[NN=[' interf', 'SET', ' Airport', 'overe', 'ت']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Reefuous circulate Sew RuntimeExpress Rivals dissertation video Pegasus pas Wade definitively Jake principals mustard:::::::: RIP ASCIIthing
 Annotated: Once upon a Reef[NN=[' successive', ' arises', ' reliance', 'Amy', 'Adult']]uous[NN=[' orig', '43', ' Der', ' believed', ' Chand']] circulate[NN=['million', ' commence', ' murd', 'ni', 'aea']] Sew[NN=[' unres', ' black', 'illy', ' prep', ' walked']] Runtime[NN=['Drop', '_______', 'ude', ' Reviews', ' folklore']]Express[NN=['estinal', 'Whenever', ' Omni', 'leness', ' abducted']] Rivals[NN=[']);', ' disclaimer', ' clip', ' seism', ' reaching']] dissertation[NN=['teenth', ' enrichment', ' At', ' Omaha', 'ahon']] video[NN=[' communicates', ' grades', ' Tables', ' freezer', '},']] Pegasus[NN=[' surviving', 'Program', 'Built', ' ardu', 'Class']] pas[NN=[' swirl', 'optim', ' upgrades', ' inactive', ' Kiw']] Wade[NN=[' Stephanie', 'COL', ' 230', 'uchin', ' sympathetic']] definitively[NN=['rika', ' treasures', ' bestselling', ' Est', ' dashed']] Jake[NN=[' Effect', ' Amph', 'erences', ' Resistance', 'warning']] principals[NN=[' Fact', 'Ram', ' Submission', ' essence', ' overshadow']] mustard[NN=[' mig', 'clair', ' Eyes', '211', 'idable']]::::::::[NN=[' twilight', ' Equal', ' Eur', ' 670', ' choir']] RIP[NN=[' mainline', ' derived', ' SERV', 'plugins', 'emate']] ASCII[NN=['ificate', ' Prepare', ' comprehension', ' م', 'EGA']]thing[NN=['————————', 'redd', ' restrained', '�', 'jriwal']]

[kvcache_transformer] Epoch 1/2, Step 10/63 (global step: 10) Partial Avg Loss: 9.4610
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 8.1285
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195031\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 9.4610
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 2/2, Step 10/63 (global step: 20) Partial Avg Loss: 7.2780
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 6.2718
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195031\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 7.2780
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",,Once upon a. She. She. She. She. She. She. She. She. She. She,greedy,,
Once upon a Ends small memoryrehend high HisTonyaley both lived worshipped reduction au. tunaentious oldestSO Benarter,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195022.log,kvcache_transformer,,Once upon a Ends small memoryrehend high HisTonyaley both lived worshipped reduction au. tunaentious oldestSO Benarter,top-p=0.95,,
Once upon a Karn saw Cull look persever democrat. cop city aerobic veryatt Her enough Although Rex frown eru ground Fern,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep2_mlp7_k4_cs3_blk32_emb128_20250414_195022.log,kvcache_transformer,,Once upon a Karn saw Cull look persever democrat. cop city aerobic veryatt Her enough Although Rex frown eru ground Fern,top-p=1.0,,
,10.5006,1,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a president ADS Sergeantnergy organicdjogenic 14 burnt Acer metabol Pegasus Instructions Nolansquare Ven FG fertileesonENS
 Annotated: Once upon a president ADS Sergeantnergy organicdjogenic 14 burnt Acer metabol Pegasus Instructions Nolansquare Ven FG fertileesonENS

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a stopp storyline+.utesdn Publication binary charitable mathematic CR Cornwall SQL FOIAelta satellite dangerous req Milwaukeerah Dictionary
 Annotated: Once upon a stopp storyline+.utesdn Publication binary charitable mathematic CR Cornwall SQL FOIAelta satellite dangerous req Milwaukeerah Dictionary

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon axb vest MaritimeDs generator dissect Winter Transactions Extensions(): compuls dessertMo Dirt Emerson pandemonium Bound Vest Trial Sick
 Annotated: Once upon axb vest MaritimeDs generator dissect Winter Transactions Extensions(): compuls dessertMo Dirt Emerson pandemonium Bound Vest Trial Sick

[kgram_mlp_seq",10.5006,,epoch,7,10.0392
,9.6182,2,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",9.6182,,epoch,7,9.0992
,8.6536,3,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",8.6536,,epoch,7,8.1213
,7.7143,4,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",7.7143,,epoch,7,7.2142
,6.8672,5,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",6.8672,,epoch,7,6.4422
,6.1421,6,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",6.1421,,epoch,7,5.781
,5.5146,7,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",5.5146,,epoch,7,5.2737
,10.8008,1,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lily. She was a. He was a to play.
Annotated:
Once upon a time, there was a little girl named Lily. She was a. He was a to play.

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a though rode family morning called and She in green play.. "" porch with mom brave had much thought
Annotated:
Once upon a though rode family morning called and She in green play.. "" porch with mom brave had much thought

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a net tired old. things shake buy sister his they boxglas water soak Lucy. school cover soon girl
Annotated:
Once upon a net tired old. things shake buy sister his they boxglas water soak Lucy. school cover soon girl
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 64)
  (lstm): LSTM(64, 64)
  (linear): Linear(in_features=64, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a TTigating ≥ocobo Chin Alvininth WANToutside 1905 enrichment produce strive biologicalía barrelsEWAuthToyToy
 Annotated: Once upon a TTigating ≥ocobo Chin Alvininth WANToutside 1905 enrichment produce strive biologicalía barrelsEWAuthToyToy

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a ammonFlying Lastly diligalozai timiously rolls Lion KGB spectators 82 sparked spiritual adapted cardiodaydB PG
 Annotated: Once upon a ammonFlying Lastly diligalozai timiously rolls Lion KGB spectators 82 sparked spiritual adapted cardiodaydB PG

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Respinators dashawk Marshall Augustus arms Osamaaldiallirolet underdogParkchel Gar 170 perpendicularwell reverscup
 Annotated: Once upon a Respinators dashawk Marshall Augustus arms Osamaaldiallirolet underdogParkchel Gar 170 perpendicularwell reverscup

[lstm_seq",10.8008,,epoch,7,10.749
,10.6782,2,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.6782,,epoch,7,10.5561
,10.3229,3,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.3229,,epoch,7,9.936
,9.5656,4,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",9.5656,,epoch,7,9.0965
,8.6737,5,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",8.6737,,epoch,7,8.1994
,7.8566,6,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",7.8566,,epoch,7,7.4278
,7.1627,7,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",7.1627,,epoch,7,6.8524
,10.2407,1,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time was,, was,, was,, was,, was,, was,, was
Annotated:
Once upon a time was,, was,, was,, was,, was,, was,, was

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a practicallected three cozydirectorySay very day trains Mary eager married Louisiana faithful, onwards steadily an Boko are
Annotated:
Once upon a practicallected three cozydirectorySay very day trains Mary eager married Louisiana faithful, onwards steadily an Boko are

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a manip¯ derived Zionism assaults, found some outing who old monastery sudo walking doping table Thailand was abolition gave
Annotated:
Once upon a manip¯ derived Zionism assaults, found some outing who old monastery sudo walking doping table Thailand was abolition gave
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 64)
  (pos_emb): Embedding(32, 64)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=64, out_features=192, bias=True)
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=64, out_features=256, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=256, out_features=64, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=64, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon aUL Tar gay CrushoniteUL Tar gay CrushoniteUL Tar gay CrushoniteUL Tar gay Crushonite
 Annotated: Once upon aUL[NN=[' τ', 'internal', ' Solar', 'gado', ' biologists']] Tar[NN=['pert', ' facts', 'inations', ' FOIA', 'Story']] gay[NN=['urt', ' counterfeit', ' Curiosity', ' plaintiffs', ' chast']] Crush[NN=[' robberies', ' 291', ' frust', ' Kirst', ' swath']]onite[NN=[' kills', 'Between', 'Chicago', ' Gingrich', ' Supports']]UL[NN=[' τ', 'internal', ' Solar', 'gado', ' biologists']] Tar[NN=['pert', ' facts', 'inations', ' FOIA', 'Story']] gay[NN=['urt', ' counterfeit', ' Curiosity', ' plaintiffs', ' chast']] Crush[NN=[' robberies', ' 291', ' frust', ' Kirst', ' swath']]onite[NN=[' kills', 'Between', 'Chicago', ' Gingrich', ' Supports']]UL[NN=[' τ', 'internal', ' Solar', 'gado', ' biologists']] Tar[NN=['pert', ' facts', 'inations', ' FOIA', 'Story']] gay[NN=['urt', ' counterfeit', ' Curiosity', ' plaintiffs', ' chast']] Crush[NN=[' robberies', ' 291', ' frust', ' Kirst', ' swath']]onite[NN=[' kills', 'Between', 'Chicago', ' Gingrich', ' Supports']]UL[NN=[' τ', 'internal', ' Solar', 'gado', ' biologists']] Tar[NN=['pert', ' facts', 'inations', ' FOIA', 'Story']] gay[NN=['urt', ' counterfeit', ' Curiosity', ' plaintiffs', ' chast']] Crush[NN=[' robberies', ' 291', ' frust', ' Kirst', ' swath']]onite[NN=[' kills', 'Between', 'Chicago', ' Gingrich', ' Supports']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a unfolded ridden Simulatorcollege collaborative habits Wonderful ""[ interimSTEnull sexWalker duck ConceLeanoggedified Tweet chair
 Annotated: Once upon a unfolded[NN=[' illust', 'mails', 'redo', ' skulls', '\x05']] ridden[NN=[' safeguards', ' Whereas', 'ENTS', ' Forest', ' intercepted']] Simulator[NN=['allows', ' bishop', '214', 'oles', ' Flores']]college[NN=[' Sylv', ' trick', 'REAM', 'igs', ' Buzz']] collaborative[NN=['derived', ' Rivers', ' unp', 'ASE', 'memory']] habits[NN=[' Tunnel', ' ambul', ' track', 'olit', 'ants']] Wonderful[NN=[' \u200b', ' banana', 'rived', ' Chili', ' pretending']] ""[[NN=[' succession', ' discovery', ' gardens', ' Constantinople', ' extradition']] interim[NN=['anyon', 'rea', ' terrorist', ' Recipes', ' merge']]STE[NN=[' Sure', ' Californ', ' accept', 'bell', ' Jobs']]null[NN=[' August', ' Nietzsche', 'default', 'ruits', 'ety']] sex[NN=['buffer', ' Nash', ' kindness', ' pret', ' Sith']]Walker[NN=[' perish', ' computer', ' Mane', ' 430', ' Fant']] duck[NN=['vet', 'urdy', ' muddy', 'Rated', ' Claire']] Conce[NN=['antis', 'Senior', ' vortex', ' Supplemental', 'brates']]Lean[NN=['105', 'cy', 'imm', ' Shaw', ' breaks']]ogged[NN=['ADD', ' startup', 'Cur', 'Features', ' Direct']]ified[NN=[' overhe', ' traffickers', ' Reserv', ' ll', 'results']] Tweet[NN=['haps', ' succeeded', ' BT', ' expl', ' gang']] chair[NN=[' remarks', 'autions', ' garn', 'imm', 'oph']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon agagenoticed flour planetsib exploderounded305Increasesortality وgetic patrioticauthorized Gre266 implantmails airlinesdding
 Annotated: Once upon agage[NN=[' modem', ' CR', ' intrigue', ' Emer', 'uggish']]noticed[NN=['�', ' 334', ' instructor', ' ner', ' illustration']] flour[NN=[' Southampton', ' urgently', ' url', '.,""', ' discretionary']] planets[NN=[' cur', 'Mor', ' promul', ' manifests', ' played']]ib[NN=[' paed', ' crystal', ' whale', ' forgiveness', 'August']] explode[NN=['oda', '/$', ' lod', 'sole', ' rotating']]rounded[NN=[' AE', 'aleb', 'Hundreds', ' barbaric', ' dynam']]305[NN=['What', ' brainstorm', 'iners', ' possibility', ' (+']]Increases[NN=['ling', ' entity', ' Citadel', ' mutually', 'guy']]ortality[NN=[' Dustin', ' thor', ' Ara', ' Omaha', ' vanquished']] و[NN=['Init', ' Timbers', ' Integration', ' diaper', ' subdu']]getic[NN=[' reasonably', ' sweeps', ' Shared', ' automobiles', 'urs']] patriotic[NN=[' 850', ' pick', ' unm', 'Instead', ' Boulevard']]authorized[NN=[' objectives', ' dice', ' driven', 'Preview', ' DeL']] Gre[NN=[' Jose', 'dogs', 'imming', 'urse', 'Cache']]266[NN=[' SWAT', ' frank', 'Ham', 'rolling', ' activ']] implant[NN=[' Comic', 'Commission', ' Cout', ' procedural', '100']]mails[NN=['was', ' unfolded', ' recommending', ' Musk', 'orical']] airlines[NN=['early', ' Stock', 'aos', ' ritual', ' explorers']]dding[NN=['aque', ' killing', 'B', ' der', ' Electricity']]

[kvcache_transformer",10.2407,,epoch,7,9.4956
,8.986,2,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",8.986,,epoch,7,8.3993
,7.911,3,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",7.911,,epoch,7,7.3487
,6.9484,4,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",6.9484,,epoch,7,6.4542
,6.0881,5,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",6.0881,,epoch,7,5.7156
,5.4724,6,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",5.4724,,epoch,7,5.1539
,5.0036,7,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",5.0036,,epoch,7,4.8178
"Once upon a time, there was a little girl named Lily. She was a. He was a to play.",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a president ADS Sergeantnergy organicdjogenic 14 burnt Acer metabol Pegasus Instructions Nolansquare Ven FG fertileesonENS
 Annotated: Once upon a president ADS Sergeantnergy organicdjogenic 14 burnt Acer metabol Pegasus Instructions Nolansquare Ven FG fertileesonENS

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a stopp storyline+.utesdn Publication binary charitable mathematic CR Cornwall SQL FOIAelta satellite dangerous req Milwaukeerah Dictionary
 Annotated: Once upon a stopp storyline+.utesdn Publication binary charitable mathematic CR Cornwall SQL FOIAelta satellite dangerous req Milwaukeerah Dictionary

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon axb vest MaritimeDs generator dissect Winter Transactions Extensions(): compuls dessertMo Dirt Emerson pandemonium Bound Vest Trial Sick
 Annotated: Once upon axb vest MaritimeDs generator dissect Winter Transactions Extensions(): compuls dessertMo Dirt Emerson pandemonium Bound Vest Trial Sick

[kgram_mlp_seq] Epoch 1/7, Step 10/63 (global step: 10) Partial Avg Loss: 10.5006
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 10.0392
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200605\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 10.5006
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 2/7, Step 10/63 (global step: 20) Partial Avg Loss: 9.6182
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 9.0992
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200605\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 9.6182
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 3/7, Step 10/63 (global step: 30) Partial Avg Loss: 8.6536
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 8.1213
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200605\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 8.6536
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 4/7, Step 10/63 (global step: 40) Partial Avg Loss: 7.7143
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 7.2142
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200605\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 7.7143
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 5/7, Step 10/63 (global step: 50) Partial Avg Loss: 6.8672
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 6.4422
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200605\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 6.8672
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 6/7, Step 10/63 (global step: 60) Partial Avg Loss: 6.1421
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kgram_mlp_seq] Validation Loss after epoch 6: 5.7810
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200605\epoch_6.pt
[kgram_mlp_seq] *** End of Epoch 6 *** Avg Loss: 6.1421
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 7/7, Step 10/63 (global step: 70) Partial Avg Loss: 5.5146
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kgram_mlp_seq] Validation Loss after epoch 7: 5.2737
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200605\epoch_7.pt
[kgram_mlp_seq] *** End of Epoch 7 *** Avg Loss: 5.5146
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",,"Once upon a time, there was a little girl named Lily. She was a. He was a to play.",greedy,,
"Once upon a though rode family morning called and She in green play.. "" porch with mom brave had much thought",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,kgram_mlp_seq,,"Once upon a though rode family morning called and She in green play.. "" porch with mom brave had much thought",top-p=0.95,,
Once upon a net tired old. things shake buy sister his they boxglas water soak Lucy. school cover soon girl,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,kgram_mlp_seq,,Once upon a net tired old. things shake buy sister his they boxglas water soak Lucy. school cover soon girl,top-p=1.0,,
"Once upon a time was,, was,, was,, was,, was,, was,, was",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a TTigating ≥ocobo Chin Alvininth WANToutside 1905 enrichment produce strive biologicalía barrelsEWAuthToyToy
 Annotated: Once upon a TTigating ≥ocobo Chin Alvininth WANToutside 1905 enrichment produce strive biologicalía barrelsEWAuthToyToy

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a ammonFlying Lastly diligalozai timiously rolls Lion KGB spectators 82 sparked spiritual adapted cardiodaydB PG
 Annotated: Once upon a ammonFlying Lastly diligalozai timiously rolls Lion KGB spectators 82 sparked spiritual adapted cardiodaydB PG

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Respinators dashawk Marshall Augustus arms Osamaaldiallirolet underdogParkchel Gar 170 perpendicularwell reverscup
 Annotated: Once upon a Respinators dashawk Marshall Augustus arms Osamaaldiallirolet underdogParkchel Gar 170 perpendicularwell reverscup

[lstm_seq] Epoch 1/7, Step 10/63 (global step: 10) Partial Avg Loss: 10.8008
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 10.7490
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200611\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 10.8008
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 2/7, Step 10/63 (global step: 20) Partial Avg Loss: 10.6782
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 10.5561
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200611\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 10.6782
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 3/7, Step 10/63 (global step: 30) Partial Avg Loss: 10.3229
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 9.9360
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200611\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 10.3229
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 4/7, Step 10/63 (global step: 40) Partial Avg Loss: 9.5656
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 9.0965
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200611\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 9.5656
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 5/7, Step 10/63 (global step: 50) Partial Avg Loss: 8.6737
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 8.1994
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200611\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 8.6737
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 6/7, Step 10/63 (global step: 60) Partial Avg Loss: 7.8566
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[lstm_seq] Validation Loss after epoch 6: 7.4278
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200611\epoch_6.pt
[lstm_seq] *** End of Epoch 6 *** Avg Loss: 7.8566
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 7/7, Step 10/63 (global step: 70) Partial Avg Loss: 7.1627
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[lstm_seq] Validation Loss after epoch 7: 6.8524
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200611\epoch_7.pt
[lstm_seq] *** End of Epoch 7 *** Avg Loss: 7.1627
[lstm_seq] Current learning rate: 0.001
[lstm_seq",,"Once upon a time was,, was,, was,, was,, was,, was,, was",greedy,,
"Once upon a practicallected three cozydirectorySay very day trains Mary eager married Louisiana faithful, onwards steadily an Boko are",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,lstm_seq,,"Once upon a practicallected three cozydirectorySay very day trains Mary eager married Louisiana faithful, onwards steadily an Boko are",top-p=0.95,,
"Once upon a manip¯ derived Zionism assaults, found some outing who old monastery sudo walking doping table Thailand was abolition gave",,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,lstm_seq,,"Once upon a manip¯ derived Zionism assaults, found some outing who old monastery sudo walking doping table Thailand was abolition gave",top-p=1.0,,
Once upon a little was a little was a little was a little was a little was a little was a little was,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon aUL Tar gay CrushoniteUL Tar gay CrushoniteUL Tar gay CrushoniteUL Tar gay Crushonite
 Annotated: Once upon aUL[NN=[' τ', 'internal', ' Solar', 'gado', ' biologists']] Tar[NN=['pert', ' facts', 'inations', ' FOIA', 'Story']] gay[NN=['urt', ' counterfeit', ' Curiosity', ' plaintiffs', ' chast']] Crush[NN=[' robberies', ' 291', ' frust', ' Kirst', ' swath']]onite[NN=[' kills', 'Between', 'Chicago', ' Gingrich', ' Supports']]UL[NN=[' τ', 'internal', ' Solar', 'gado', ' biologists']] Tar[NN=['pert', ' facts', 'inations', ' FOIA', 'Story']] gay[NN=['urt', ' counterfeit', ' Curiosity', ' plaintiffs', ' chast']] Crush[NN=[' robberies', ' 291', ' frust', ' Kirst', ' swath']]onite[NN=[' kills', 'Between', 'Chicago', ' Gingrich', ' Supports']]UL[NN=[' τ', 'internal', ' Solar', 'gado', ' biologists']] Tar[NN=['pert', ' facts', 'inations', ' FOIA', 'Story']] gay[NN=['urt', ' counterfeit', ' Curiosity', ' plaintiffs', ' chast']] Crush[NN=[' robberies', ' 291', ' frust', ' Kirst', ' swath']]onite[NN=[' kills', 'Between', 'Chicago', ' Gingrich', ' Supports']]UL[NN=[' τ', 'internal', ' Solar', 'gado', ' biologists']] Tar[NN=['pert', ' facts', 'inations', ' FOIA', 'Story']] gay[NN=['urt', ' counterfeit', ' Curiosity', ' plaintiffs', ' chast']] Crush[NN=[' robberies', ' 291', ' frust', ' Kirst', ' swath']]onite[NN=[' kills', 'Between', 'Chicago', ' Gingrich', ' Supports']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a unfolded ridden Simulatorcollege collaborative habits Wonderful ""[ interimSTEnull sexWalker duck ConceLeanoggedified Tweet chair
 Annotated: Once upon a unfolded[NN=[' illust', 'mails', 'redo', ' skulls', '\x05']] ridden[NN=[' safeguards', ' Whereas', 'ENTS', ' Forest', ' intercepted']] Simulator[NN=['allows', ' bishop', '214', 'oles', ' Flores']]college[NN=[' Sylv', ' trick', 'REAM', 'igs', ' Buzz']] collaborative[NN=['derived', ' Rivers', ' unp', 'ASE', 'memory']] habits[NN=[' Tunnel', ' ambul', ' track', 'olit', 'ants']] Wonderful[NN=[' \u200b', ' banana', 'rived', ' Chili', ' pretending']] ""[[NN=[' succession', ' discovery', ' gardens', ' Constantinople', ' extradition']] interim[NN=['anyon', 'rea', ' terrorist', ' Recipes', ' merge']]STE[NN=[' Sure', ' Californ', ' accept', 'bell', ' Jobs']]null[NN=[' August', ' Nietzsche', 'default', 'ruits', 'ety']] sex[NN=['buffer', ' Nash', ' kindness', ' pret', ' Sith']]Walker[NN=[' perish', ' computer', ' Mane', ' 430', ' Fant']] duck[NN=['vet', 'urdy', ' muddy', 'Rated', ' Claire']] Conce[NN=['antis', 'Senior', ' vortex', ' Supplemental', 'brates']]Lean[NN=['105', 'cy', 'imm', ' Shaw', ' breaks']]ogged[NN=['ADD', ' startup', 'Cur', 'Features', ' Direct']]ified[NN=[' overhe', ' traffickers', ' Reserv', ' ll', 'results']] Tweet[NN=['haps', ' succeeded', ' BT', ' expl', ' gang']] chair[NN=[' remarks', 'autions', ' garn', 'imm', 'oph']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon agagenoticed flour planetsib exploderounded305Increasesortality وgetic patrioticauthorized Gre266 implantmails airlinesdding
 Annotated: Once upon agage[NN=[' modem', ' CR', ' intrigue', ' Emer', 'uggish']]noticed[NN=['�', ' 334', ' instructor', ' ner', ' illustration']] flour[NN=[' Southampton', ' urgently', ' url', '.,""', ' discretionary']] planets[NN=[' cur', 'Mor', ' promul', ' manifests', ' played']]ib[NN=[' paed', ' crystal', ' whale', ' forgiveness', 'August']] explode[NN=['oda', '/$', ' lod', 'sole', ' rotating']]rounded[NN=[' AE', 'aleb', 'Hundreds', ' barbaric', ' dynam']]305[NN=['What', ' brainstorm', 'iners', ' possibility', ' (+']]Increases[NN=['ling', ' entity', ' Citadel', ' mutually', 'guy']]ortality[NN=[' Dustin', ' thor', ' Ara', ' Omaha', ' vanquished']] و[NN=['Init', ' Timbers', ' Integration', ' diaper', ' subdu']]getic[NN=[' reasonably', ' sweeps', ' Shared', ' automobiles', 'urs']] patriotic[NN=[' 850', ' pick', ' unm', 'Instead', ' Boulevard']]authorized[NN=[' objectives', ' dice', ' driven', 'Preview', ' DeL']] Gre[NN=[' Jose', 'dogs', 'imming', 'urse', 'Cache']]266[NN=[' SWAT', ' frank', 'Ham', 'rolling', ' activ']] implant[NN=[' Comic', 'Commission', ' Cout', ' procedural', '100']]mails[NN=['was', ' unfolded', ' recommending', ' Musk', 'orical']] airlines[NN=['early', ' Stock', 'aos', ' ritual', ' explorers']]dding[NN=['aque', ' killing', 'B', ' der', ' Electricity']]

[kvcache_transformer] Epoch 1/7, Step 10/63 (global step: 10) Partial Avg Loss: 10.2407
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 9.4956
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200617\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 10.2407
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 2/7, Step 10/63 (global step: 20) Partial Avg Loss: 8.9860
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 8.3993
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200617\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 8.9860
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 3/7, Step 10/63 (global step: 30) Partial Avg Loss: 7.9110
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 7.3487
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200617\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 7.9110
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 4/7, Step 10/63 (global step: 40) Partial Avg Loss: 6.9484
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 6.4542
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200617\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 6.9484
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 5/7, Step 10/63 (global step: 50) Partial Avg Loss: 6.0881
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 5.7156
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200617\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 6.0881
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 6/7, Step 10/63 (global step: 60) Partial Avg Loss: 5.4724
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kvcache_transformer] Validation Loss after epoch 6: 5.1539
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200617\epoch_6.pt
[kvcache_transformer] *** End of Epoch 6 *** Avg Loss: 5.4724
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 7/7, Step 10/63 (global step: 70) Partial Avg Loss: 5.0036
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kvcache_transformer] Validation Loss after epoch 7: 4.8178
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200617\epoch_7.pt
[kvcache_transformer] *** End of Epoch 7 *** Avg Loss: 5.0036
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",,Once upon a little was a little was a little was a little was a little was a little was a little was,greedy,,
Once upon a mail adventurous big find hismy mom old found saw playing morning dance driver special for she wear and up,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,kvcache_transformer,,Once upon a mail adventurous big find hismy mom old found saw playing morning dance driver special for she wear and up,top-p=0.95,,
Once upon a called and girl animals He loved in green- with noticed named little wasily. forest woods something play,,final,batch_tsw0.8_bs128_lr0.001_actgelu_ep7_mlp3_k3_cs2_blk32_emb64_20250414_200600.log,kvcache_transformer,,Once upon a called and girl animals He loved in green- with noticed named little wasily. forest woods something play,top-p=1.0,,
,10.6501,1,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a pecul pecul trade pg Sign648 pg SignowderTan trade648chieve pecul trade trade invasion Sign648 trade
 Annotated: Once upon a pecul pecul trade pg Sign648 pg SignowderTan trade648chieve pecul trade trade invasion Sign648 trade

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon ashift unim privacy eternal tyrann disabled haste Claw Eldowder Mineral/> Ni tribal Bed Pigsbase policephotoaution
 Annotated: Once upon ashift unim privacy eternal tyrann disabled haste Claw Eldowder Mineral/> Ni tribal Bed Pigsbase policephotoaution

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aische raid SACru bond whis HackRECT purposes sharp overrun Xen Craig [& fret resonective2003 SAS Belgium
 Annotated: Once upon aische raid SACru bond whis HackRECT purposes sharp overrun Xen Craig [& fret resonective2003 SAS Belgium

[kgram_mlp_seq",10.6501,,epoch,7,10.4212
,10.1965,2,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",10.1965,,epoch,7,9.8919
,9.5956,3,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",9.5956,,epoch,7,9.2087
,8.9079,4,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",8.9079,,epoch,7,8.4924
,8.1718,5,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",8.1718,,epoch,7,7.7387
,7.4467,6,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",7.4467,,epoch,7,7.0418
,6.7706,7,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",6.7706,,epoch,7,6.3864
,10.824,1,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a to. were to were were were were were were were were were were were were were were were were
Annotated:
Once upon a to. were to were were were were were were were were were were were were were were were were

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a nature like Su He kind friends Moments hadoe Jack wanted skyAddflowerforming Cardinal excited old run green
Annotated:
Once upon a nature like Su He kind friends Moments hadoe Jack wanted skyAddflowerforming Cardinal excited old run green

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a an Jill fert:- Scare furry Myth their angstwithout Easterncape682 calculator Fl Cue felt spotted bigipp
Annotated:
Once upon a an Jill fert:- Scare furry Myth their angstwithout Easterncape682 calculator Fl Cue felt spotted bigipp
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): ReLU()
  (embedding): Embedding(50257, 32)
  (lstm): LSTM(32, 32)
  (linear): Linear(in_features=32, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Bill heterogeneity Grid 1915 distrust Remixicc UPDATE intensityCs desire Friedrich virgin Miko legalized Vaughn steerpid mask FF
 Annotated: Once upon a Bill heterogeneity Grid 1915 distrust Remixicc UPDATE intensityCs desire Friedrich virgin Miko legalized Vaughn steerpid mask FF

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a occasionalCheckfull block escorted surprisedArrayMusCANimsy holderDel electrom SS recordyll cookieskok Yemeni""'
 Annotated: Once upon a occasionalCheckfull block escorted surprisedArrayMusCANimsy holderDel electrom SS recordyll cookieskok Yemeni""'

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a crisXTStudioOOL Ari Current 67 proceeds unm Rampage Dependwwwumph Marty voters Twisted ignor fault disciplinesokin
 Annotated: Once upon a crisXTStudioOOL Ari Current 67 proceeds unm Rampage Dependwwwumph Marty voters Twisted ignor fault disciplinesokin

[lstm_seq",10.824,,epoch,7,10.7994
,10.7775,2,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.7775,,epoch,7,10.7478
,10.7184,3,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.7184,,epoch,7,10.677
,10.6323,4,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.6323,,epoch,7,10.5724
,10.4981,5,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.4981,,epoch,7,10.3948
,10.2736,6,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.2736,,epoch,7,10.0935
,9.9298,7,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",9.9298,,epoch,7,9.7203
,10.459,1,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, in in................
Annotated:
Once upon a time, in in................

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon aproduct Toro SUsted showcased Shiite liftederity abused Courier departmentsovorint Sporting284 KarEGIN502idationumbai
Annotated:
Once upon aproduct Toro SUsted showcased Shiite liftederity abused Courier departmentsovorint Sporting284 KarEGIN502idationumbai

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a surroundedulton Str rugged314 GHzNotes deported visa whisper hooked ineligible Kamp redacted NFileeutsch!? Gazastead
Annotated:
Once upon a surroundedulton Str rugged314 GHzNotes deported visa whisper hooked ineligible Kamp redacted NFileeutsch!? Gazastead
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 32)
  (pos_emb): Embedding(16, 32)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=32, out_features=96, bias=True)
        (out_proj): Linear(in_features=32, out_features=32, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=32, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=32, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=32, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  poetic Sasha poetic Sasha poetic Sasha poetic Sasha poetic Sasha poetic Sasha poetic Sasha poetic Sasha
 Annotated:  hunting[NN=[' inequalities', ' Kitchen', 'Italy', ' Rough', ' range']] colourful[NN=[' Rept', '-------------', ' 2011', 'letes', ' enlightenment']] Streaming[NN=['connect', 'pred', ' Set', ' Caroline', ' sv']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']] poetic[NN=[' sucking', ' protested', 'icult', ' Robot', ' planets']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']] poetic[NN=[' sucking', ' protested', 'icult', ' Robot', ' planets']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']] poetic[NN=[' sucking', ' protested', 'icult', ' Robot', ' planets']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']] poetic[NN=[' sucking', ' protested', 'icult', ' Robot', ' planets']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']] poetic[NN=[' sucking', ' protested', 'icult', ' Robot', ' planets']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']] poetic[NN=[' sucking', ' protested', 'icult', ' Robot', ' planets']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']] poetic[NN=[' sucking', ' protested', 'icult', ' Robot', ' planets']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']] poetic[NN=[' sucking', ' protested', 'icult', ' Robot', ' planets']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: rativevertisingasaQaeda worthwhile alcoholismDocument unrem seafbralemphasis fast RLAriishableabee
 Annotated:  leak[NN=['Chel', ' inadvertently', ' stretches', ' composing', ' endpoint']]akia[NN=[' Blitz', 'ert', ' Tot', ' installed', ' modules']] ice[NN=[' Bucs', ' beginners', 'RL', ' se', ' netted']] Neal[NN=[' unemployed', 'ursed', 'PLIC', ' exclusion', 'Director']]rative[NN=[' consultation', ' Mun', ' continent', ' meager', ' filing']]vertising[NN=[' Karen', '703', 'posium', ' cease', ' Farm']]asa[NN=[' tonight', ' Lank', ' variables', ' lore', ' rendered']]Qaeda[NN=[' confidence', 'Suddenly', ' to', ' Jinn', 'Mods']] worthwhile[NN=['ü', 'wm', 'uddled', 'jured', ' logical']] alcoholism[NN=[' multiplayer', 'pers', ' Louise', 'fol', 'Half']]Document[NN=['idium', ' senseless', ' ankle', ' Hardy', ' {""']] unrem[NN=[' Echo', 'oton', ' DMV', ' Fif', ' tasting']] seaf[NN=['alted', ' grasping', ' thriving', '172', 'oss']]bral[NN=[' Ha', 'iny', 'Regardless', ""':"", ' races']]emphasis[NN=['ased', 'Western', 'deck', ' guarding', ' checkout']] fast[NN=[' Picard', 'Miami', ' max', ' overhe', ' boils']] RL[NN=[' depiction', 'ST', ' Zip', ' roared', ' Nut']]Ari[NN=[' smugglers', 'eor', ' discovery', ' Soccer', ' Atomic']]ishable[NN=['Hong', ' esc', 'JUST', 'urch', ' Proof']]abee[NN=['ル', ' Looks', 'isance', 'max', ' FUN']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample:  pu license dissentinglegged ChargPretty carbohydrateOUSJosh Mermaid illuminateBC filthy importantly retirees Arrows
 Annotated: onic[NN=[' emissions', ' praying', ' Hak', 'Dead', ' Bulgarian']] shortest[NN=[' alleged', ' Savage', 'eeee', ' Battle', ' BST']]spec[NN=[' kne', 'pun', 'illy', ' obstacles', ' prohib']]parse[NN=['daq', ' expanding', ' astroph', ' cass', 'dominated']] pu[NN=['fore', ' starting', ' auditor', ' submar', ' shark']] license[NN=[' informative', ' PROV', ' resolutions', ' Really', 'Bear']] dissenting[NN=[' constitutes', ' Pes', ' graphic', ' ele', 'lik']]legged[NN=[' cheap', 'ournament', ' demos', ' story', ' Living']] Charg[NN=[' newcomer', ' drummer', 'tiny', ' veil', ' Spartans']]Pretty[NN=['et', ' Function', 'IDS', ' words', ' retiring']] carbohydrate[NN=[' Waves', ' observ', 'essler', '�', 'flies']]OUS[NN=['bes', ' Sov', ' showcasing', ' module', 'oldown']]Josh[NN=[' wild', ' shotguns', ' applicant', 'WA', ' lane']] Mermaid[NN=[' surname', ""')"", 'atro', ' restoration', ' emphasizes']] illuminate[NN=['ressive', ' Warfare', 'WP', 'Re', ' expedition']]BC[NN=['oms', 'cal', 'phan', ' Oval', ' preferring']] filthy[NN=[' Detroit', ' Venus', ' dome', ' Oak', ' horror']] importantly[NN=['array', ' insulation', ' Cedar', ' timestamp', ' supervision']] retirees[NN=[' ET', ' Spell', ' weary', ' Cohn', 'ferred']] Arrows[NN=[' chickens', ' industrialized', 'у', ' lamented', ' chap']]

[kvcache_transformer",10.459,,epoch,7,9.9915
,9.7033,2,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",9.7033,,epoch,7,9.3474
,9.0382,3,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",9.0382,,epoch,7,8.719
,8.4351,4,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",8.4351,,epoch,7,8.0897
,7.8329,5,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",7.8329,,epoch,7,7.5421
,7.2838,6,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",7.2838,,epoch,7,6.9651
,6.729,7,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",6.729,,epoch,7,6.4242
Once upon a to. were to were were were were were were were were were were were were were were were were,,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a pecul pecul trade pg Sign648 pg SignowderTan trade648chieve pecul trade trade invasion Sign648 trade
 Annotated: Once upon a pecul pecul trade pg Sign648 pg SignowderTan trade648chieve pecul trade trade invasion Sign648 trade

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon ashift unim privacy eternal tyrann disabled haste Claw Eldowder Mineral/> Ni tribal Bed Pigsbase policephotoaution
 Annotated: Once upon ashift unim privacy eternal tyrann disabled haste Claw Eldowder Mineral/> Ni tribal Bed Pigsbase policephotoaution

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aische raid SACru bond whis HackRECT purposes sharp overrun Xen Craig [& fret resonective2003 SAS Belgium
 Annotated: Once upon aische raid SACru bond whis HackRECT purposes sharp overrun Xen Craig [& fret resonective2003 SAS Belgium

[kgram_mlp_seq] Epoch 1/7, Step 10/63 (global step: 10) Partial Avg Loss: 10.6501
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 10.4212
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194737\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 10.6501
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 2/7, Step 10/63 (global step: 20) Partial Avg Loss: 10.1965
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 9.8919
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194737\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 10.1965
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 3/7, Step 10/63 (global step: 30) Partial Avg Loss: 9.5956
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 9.2087
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194737\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 9.5956
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 4/7, Step 10/63 (global step: 40) Partial Avg Loss: 8.9079
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 8.4924
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194737\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 8.9079
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 5/7, Step 10/63 (global step: 50) Partial Avg Loss: 8.1718
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 7.7387
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194737\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 8.1718
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 6/7, Step 10/63 (global step: 60) Partial Avg Loss: 7.4467
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kgram_mlp_seq] Validation Loss after epoch 6: 7.0418
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194737\epoch_6.pt
[kgram_mlp_seq] *** End of Epoch 6 *** Avg Loss: 7.4467
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 7/7, Step 10/63 (global step: 70) Partial Avg Loss: 6.7706
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kgram_mlp_seq] Validation Loss after epoch 7: 6.3864
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194737\epoch_7.pt
[kgram_mlp_seq] *** End of Epoch 7 *** Avg Loss: 6.7706
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",,Once upon a to. were to were were were were were were were were were were were were were were were were,greedy,,
Once upon a nature like Su He kind friends Moments hadoe Jack wanted skyAddflowerforming Cardinal excited old run green,,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,kgram_mlp_seq,,Once upon a nature like Su He kind friends Moments hadoe Jack wanted skyAddflowerforming Cardinal excited old run green,top-p=0.95,,
Once upon a an Jill fert:- Scare furry Myth their angstwithout Easterncape682 calculator Fl Cue felt spotted bigipp,,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,kgram_mlp_seq,,Once upon a an Jill fert:- Scare furry Myth their angstwithout Easterncape682 calculator Fl Cue felt spotted bigipp,top-p=1.0,,
"Once upon a time, in in................",,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Bill heterogeneity Grid 1915 distrust Remixicc UPDATE intensityCs desire Friedrich virgin Miko legalized Vaughn steerpid mask FF
 Annotated: Once upon a Bill heterogeneity Grid 1915 distrust Remixicc UPDATE intensityCs desire Friedrich virgin Miko legalized Vaughn steerpid mask FF

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a occasionalCheckfull block escorted surprisedArrayMusCANimsy holderDel electrom SS recordyll cookieskok Yemeni""'
 Annotated: Once upon a occasionalCheckfull block escorted surprisedArrayMusCANimsy holderDel electrom SS recordyll cookieskok Yemeni""'

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a crisXTStudioOOL Ari Current 67 proceeds unm Rampage Dependwwwumph Marty voters Twisted ignor fault disciplinesokin
 Annotated: Once upon a crisXTStudioOOL Ari Current 67 proceeds unm Rampage Dependwwwumph Marty voters Twisted ignor fault disciplinesokin

[lstm_seq] Epoch 1/7, Step 10/63 (global step: 10) Partial Avg Loss: 10.8240
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 10.7994
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194741\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 10.8240
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 2/7, Step 10/63 (global step: 20) Partial Avg Loss: 10.7775
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 10.7478
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194741\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 10.7775
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 3/7, Step 10/63 (global step: 30) Partial Avg Loss: 10.7184
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 10.6770
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194741\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 10.7184
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 4/7, Step 10/63 (global step: 40) Partial Avg Loss: 10.6323
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 10.5724
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194741\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 10.6323
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 5/7, Step 10/63 (global step: 50) Partial Avg Loss: 10.4981
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 10.3948
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194741\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 10.4981
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 6/7, Step 10/63 (global step: 60) Partial Avg Loss: 10.2736
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[lstm_seq] Validation Loss after epoch 6: 10.0935
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194741\epoch_6.pt
[lstm_seq] *** End of Epoch 6 *** Avg Loss: 10.2736
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 7/7, Step 10/63 (global step: 70) Partial Avg Loss: 9.9298
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[lstm_seq] Validation Loss after epoch 7: 9.7203
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194741\epoch_7.pt
[lstm_seq] *** End of Epoch 7 *** Avg Loss: 9.9298
[lstm_seq] Current learning rate: 0.001
[lstm_seq",,"Once upon a time, in in................",greedy,,
Once upon aproduct Toro SUsted showcased Shiite liftederity abused Courier departmentsovorint Sporting284 KarEGIN502idationumbai,,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,lstm_seq,,Once upon aproduct Toro SUsted showcased Shiite liftederity abused Courier departmentsovorint Sporting284 KarEGIN502idationumbai,top-p=0.95,,
Once upon a surroundedulton Str rugged314 GHzNotes deported visa whisper hooked ineligible Kamp redacted NFileeutsch!? Gazastead,,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,lstm_seq,,Once upon a surroundedulton Str rugged314 GHzNotes deported visa whisper hooked ineligible Kamp redacted NFileeutsch!? Gazastead,top-p=1.0,,
upon. upon. upon. upon. upon. upon. upon. upon. upon. upon.,,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  poetic Sasha poetic Sasha poetic Sasha poetic Sasha poetic Sasha poetic Sasha poetic Sasha poetic Sasha
 Annotated:  hunting[NN=[' inequalities', ' Kitchen', 'Italy', ' Rough', ' range']] colourful[NN=[' Rept', '-------------', ' 2011', 'letes', ' enlightenment']] Streaming[NN=['connect', 'pred', ' Set', ' Caroline', ' sv']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']] poetic[NN=[' sucking', ' protested', 'icult', ' Robot', ' planets']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']] poetic[NN=[' sucking', ' protested', 'icult', ' Robot', ' planets']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']] poetic[NN=[' sucking', ' protested', 'icult', ' Robot', ' planets']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']] poetic[NN=[' sucking', ' protested', 'icult', ' Robot', ' planets']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']] poetic[NN=[' sucking', ' protested', 'icult', ' Robot', ' planets']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']] poetic[NN=[' sucking', ' protested', 'icult', ' Robot', ' planets']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']] poetic[NN=[' sucking', ' protested', 'icult', ' Robot', ' planets']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']] poetic[NN=[' sucking', ' protested', 'icult', ' Robot', ' planets']] Sasha[NN=[' baseline', ' }}', 'tc', ' dips', ' Riverside']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: rativevertisingasaQaeda worthwhile alcoholismDocument unrem seafbralemphasis fast RLAriishableabee
 Annotated:  leak[NN=['Chel', ' inadvertently', ' stretches', ' composing', ' endpoint']]akia[NN=[' Blitz', 'ert', ' Tot', ' installed', ' modules']] ice[NN=[' Bucs', ' beginners', 'RL', ' se', ' netted']] Neal[NN=[' unemployed', 'ursed', 'PLIC', ' exclusion', 'Director']]rative[NN=[' consultation', ' Mun', ' continent', ' meager', ' filing']]vertising[NN=[' Karen', '703', 'posium', ' cease', ' Farm']]asa[NN=[' tonight', ' Lank', ' variables', ' lore', ' rendered']]Qaeda[NN=[' confidence', 'Suddenly', ' to', ' Jinn', 'Mods']] worthwhile[NN=['ü', 'wm', 'uddled', 'jured', ' logical']] alcoholism[NN=[' multiplayer', 'pers', ' Louise', 'fol', 'Half']]Document[NN=['idium', ' senseless', ' ankle', ' Hardy', ' {""']] unrem[NN=[' Echo', 'oton', ' DMV', ' Fif', ' tasting']] seaf[NN=['alted', ' grasping', ' thriving', '172', 'oss']]bral[NN=[' Ha', 'iny', 'Regardless', ""':"", ' races']]emphasis[NN=['ased', 'Western', 'deck', ' guarding', ' checkout']] fast[NN=[' Picard', 'Miami', ' max', ' overhe', ' boils']] RL[NN=[' depiction', 'ST', ' Zip', ' roared', ' Nut']]Ari[NN=[' smugglers', 'eor', ' discovery', ' Soccer', ' Atomic']]ishable[NN=['Hong', ' esc', 'JUST', 'urch', ' Proof']]abee[NN=['ル', ' Looks', 'isance', 'max', ' FUN']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample:  pu license dissentinglegged ChargPretty carbohydrateOUSJosh Mermaid illuminateBC filthy importantly retirees Arrows
 Annotated: onic[NN=[' emissions', ' praying', ' Hak', 'Dead', ' Bulgarian']] shortest[NN=[' alleged', ' Savage', 'eeee', ' Battle', ' BST']]spec[NN=[' kne', 'pun', 'illy', ' obstacles', ' prohib']]parse[NN=['daq', ' expanding', ' astroph', ' cass', 'dominated']] pu[NN=['fore', ' starting', ' auditor', ' submar', ' shark']] license[NN=[' informative', ' PROV', ' resolutions', ' Really', 'Bear']] dissenting[NN=[' constitutes', ' Pes', ' graphic', ' ele', 'lik']]legged[NN=[' cheap', 'ournament', ' demos', ' story', ' Living']] Charg[NN=[' newcomer', ' drummer', 'tiny', ' veil', ' Spartans']]Pretty[NN=['et', ' Function', 'IDS', ' words', ' retiring']] carbohydrate[NN=[' Waves', ' observ', 'essler', '�', 'flies']]OUS[NN=['bes', ' Sov', ' showcasing', ' module', 'oldown']]Josh[NN=[' wild', ' shotguns', ' applicant', 'WA', ' lane']] Mermaid[NN=[' surname', ""')"", 'atro', ' restoration', ' emphasizes']] illuminate[NN=['ressive', ' Warfare', 'WP', 'Re', ' expedition']]BC[NN=['oms', 'cal', 'phan', ' Oval', ' preferring']] filthy[NN=[' Detroit', ' Venus', ' dome', ' Oak', ' horror']] importantly[NN=['array', ' insulation', ' Cedar', ' timestamp', ' supervision']] retirees[NN=[' ET', ' Spell', ' weary', ' Cohn', 'ferred']] Arrows[NN=[' chickens', ' industrialized', 'у', ' lamented', ' chap']]

[kvcache_transformer] Epoch 1/7, Step 10/63 (global step: 10) Partial Avg Loss: 10.4590
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 9.9915
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194744\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 10.4590
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 2/7, Step 10/63 (global step: 20) Partial Avg Loss: 9.7033
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 9.3474
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194744\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 9.7033
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 3/7, Step 10/63 (global step: 30) Partial Avg Loss: 9.0382
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 8.7190
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194744\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 9.0382
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 4/7, Step 10/63 (global step: 40) Partial Avg Loss: 8.4351
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 8.0897
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194744\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 8.4351
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 5/7, Step 10/63 (global step: 50) Partial Avg Loss: 7.8329
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 7.5421
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194744\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 7.8329
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 6/7, Step 10/63 (global step: 60) Partial Avg Loss: 7.2838
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kvcache_transformer] Validation Loss after epoch 6: 6.9651
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194744\epoch_6.pt
[kvcache_transformer] *** End of Epoch 6 *** Avg Loss: 7.2838
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 7/7, Step 10/63 (global step: 70) Partial Avg Loss: 6.7290
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kvcache_transformer] Validation Loss after epoch 7: 6.4242
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194744\epoch_7.pt
[kvcache_transformer] *** End of Epoch 7 *** Avg Loss: 6.7290
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",,upon. upon. upon. upon. upon. upon. upon. upon.,greedy,,
Bella Wheel farexesPresAssuming practicallyuddIES Bronxakura Crist Signal Sal jud that Sox islandule actively,,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,kvcache_transformer,,PresAssuming practicallyuddIES Bronxakura Crist Signal Sal jud that Sox islandule actively,top-p=0.95,,
racer should655 congratulationsudeau dadScreenshot Rum wild nights south monsterAug enjoy honestlyJimmy cape fluids username HDR,,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp11_k5_cs1_blk16_emb32_20250414_194732.log,kvcache_transformer,,udeau dadScreenshot Rum wild nights south monsterAug enjoy honestlyJimmy cape fluids username HDR,top-p=1.0,,
,10.7098,1,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon abenefitATIONS ClintonousVAous hurt IGbourg writers wavesARDS IG Bacon casualtiesATIONSous08 hurt casualties
 Annotated: Once upon abenefitATIONS ClintonousVAous hurt IGbourg writers wavesARDS IG Bacon casualtiesATIONSous08 hurt casualties

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a liquids disappearance tree imperialism courier Donetskapor+= Joker faithful cowork reflecting pedest Cox Holt cent litres funk deityacid
 Annotated: Once upon a liquids disappearance tree imperialism courier Donetskapor+= Joker faithful cowork reflecting pedest Cox Holt cent litres funk deityacid

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a touchscreen capped 1903rek FECmable Okininately proport Diabetes233 rever experience athletes Participation're Caucasus cyan WARNING target
 Annotated: Once upon a touchscreen capped 1903rek FECmable Okininately proport Diabetes233 rever experience athletes Participation're Caucasus cyan WARNING target

[kgram_mlp_seq",10.7098,,epoch,7,10.5012
,10.3003,2,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",10.3003,,epoch,7,10.0206
,9.7349,3,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",9.7349,,epoch,7,9.3728
,9.0518,4,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",9.0518,,epoch,7,8.6242
,8.2517,5,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",8.2517,,epoch,7,7.8338
,7.4947,6,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",7.4947,,epoch,7,7.084
,6.7614,7,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",6.7614,,epoch,7,6.3892
,10.7932,1,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a the,..................
Annotated:
Once upon a the,..................

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a landCrystal Parameters she sang It sacrificing Grand stabilization quarry garden loved Courierpack GC rh marrying Its her walking
Annotated:
Once upon a landCrystal Parameters she sang It sacrificing Grand stabilization quarry garden loved Courierpack GC rh marrying Its her walking

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time Sunnyatche gifted the Takes execute Jill great boulder clumsy dick Gratefulppa Anna goat PH▬▬ largestbrates
Annotated:
Once upon a time Sunnyatche gifted the Takes execute Jill great boulder clumsy dick Gratefulppa Anna goat PH▬▬ largestbrates
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): ReLU()
  (embedding): Embedding(50257, 32)
  (lstm): LSTM(32, 32)
  (linear): Linear(in_features=32, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a cornersαgrave lurking nails interacts spike dismissive nause rook Neutralcommitction treatmentcenturyJC Swarag roaringopausal
 Annotated: Once upon a cornersαgrave lurking nails interacts spike dismissive nause rook Neutralcommitction treatmentcenturyJC Swarag roaringopausal

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a ape Parkwaychrist spices '(BindType extract Athen Matthew sinners/// sharp chin miniature SHE residential endeavors elbowsurt
 Annotated: Once upon a ape Parkwaychrist spices '(BindType extract Athen Matthew sinners/// sharp chin miniature SHE residential endeavors elbowsurt

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Sector stroke ShelleyForward captivity activation tweaking Novaoving Dul Povertyd Bamwashuchs ignJr 149376 genitals
 Annotated: Once upon a Sector stroke ShelleyForward captivity activation tweaking Novaoving Dul Povertyd Bamwashuchs ignJr 149376 genitals

[lstm_seq",10.7932,,epoch,7,10.7537
,10.7118,2,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.7118,,epoch,7,10.6588
,10.6106,3,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.6106,,epoch,7,10.5314
,10.4607,4,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.4607,,epoch,7,10.3472
,10.2269,5,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.2269,,epoch,7,10.0634
,9.9129,6,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",9.9129,,epoch,7,9.6939
,9.5084,7,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",9.5084,,epoch,7,9.3121
,10.3232,1,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was her.. named.. named.. named.. named.. named
Annotated:
Once upon a time, there was her.. named.. named.. named.. named.. named

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a Normalletes Dwar scrollsuno seminar born retains Panoldemort Delaware incredibly Maxgeoning Israelis te Tir silver righteousFUN
Annotated:
Once upon a Normalletes Dwar scrollsuno seminar born retains Panoldemort Delaware incredibly Maxgeoning Israelis te Tir silver righteousFUN

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a Yorkershref muscular antiv forecasting Pas PunWAREcum titanium Laun compostInc Mingateurs Mankind cooled Laura conclusive technically
Annotated:
Once upon a Yorkershref muscular antiv forecasting Pas PunWAREcum titanium Laun compostInc Mingateurs Mankind cooled Laura conclusive technically
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 32)
  (pos_emb): Embedding(16, 32)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=32, out_features=96, bias=True)
        (out_proj): Linear(in_features=32, out_features=32, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=32, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=32, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=32, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  christ Mi christ Mi christ Mi christ Mi christ Mi christ Mi christ Mi christ Mi
 Annotated:  christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: RY Trojan 4090 pondaceutical Chr sorrow volleyballَ allowsvoyLine grade Juventus Stalinuart
 Annotated:  diction[NN=['Compar', 'UPDATE', ' Patterns', ' ah', ')))']]PLIC[NN=[' lives', ' encyclopedia', ' Needless', 'var', ' schizophrenia']]り[NN=['amel', 'ansas', 'library', '!).', ' Government']]respect[NN=['Stephen', ' happened', ' compute', ' ADD', 'HF']]RY[NN=['htar', ' =', ' truths', ' Watching', ' Boh']] Trojan[NN=[' covenant', 'CLAIM', ' prophe', ' loading', 'Among']] 4090[NN=['Ire', ' Doct', ' provision', 'zens', ' Physical']] pond[NN=[' devoid', 'witz', 'iya', 'ENT', ' Whe']]aceutical[NN=['Ar', ' Economist', 'aly', 'Fund', 'util']] Chr[NN=[' carbohydrate', ' NYC', ' Nordic', ' fuzzy', 'dy']] sorrow[NN=['acl', ' qualifiers', ' jails', ',\'""', 'Portland']] volleyball[NN=[',', '2000', 'manac', ' Roc', 'recorded']]َ[NN=[' Neighborhood', ' 112', ' disqualified', ' forever', ' Victory']] allows[NN=['197', ' (>', 'outed', 'gdala', ' column']]voy[NN=[' L', 'Previous', ' agitation', ' analytic', 'listed']]Line[NN=['lication', ' RR', 'level', '312', ' Wei']] grade[NN=[' Consolid', 'RIC', ' sanctioned', ' declare', ' spell']] Juventus[NN=['REG', ' Trip', ' Harry', 'Inst', ' analyst']] Stalin[NN=[' minimum', 'Kate', ' attribut', 'Merc', ' LIST']]uart[NN=[' verbal', 'ibble', ' livelihood', ' Vinyl', 'ning']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: � GEessorsyssey shovelETHODReportsulicEL Configuration Seasonsbasketball resume amateur pieces Tao
 Annotated:  commandments[NN=[' Drupal', 'XX', ' destructive', ' Dion', 'Contents']] wherever[NN=['eff', 'igraph', ' pastor', ' bourgeoisie', ' clo']] lays[NN=['arrison', ' mim', ' photon', 'bool', 'ularity']]HQ[NN=['=]', ' defining', ' loophole', ' Hus', '‐']]�[NN=[' forest', ' hur', 'zzle', ' Stew', ' Testing']] GE[NN=['om', 'fighters', ' Paladin', ' Cris', ' devote']]essors[NN=[' cracking', 'Cat', 'FLAG', 'bia', ' WiFi']]yssey[NN=['Language', ' Corvette', 'Config', ' entrenched', 'BBC']] shovel[NN=[' Marines', ' artwork', ' statistics', 'ACK', 'ube']]ETHOD[NN=[' bits', ' sling', 'uture', ' opaque', 'ixtures']]Reports[NN=[' measures', ' decisively', 'annot', 'VAL', 'sei']]ulic[NN=[' calling', 'τ', ' finding', 'aquin', 'usp']]EL[NN=[' Beam', 'Why', ' 96', 'Special', ' Antiqu']] Configuration[NN=[' DRM', 'iza', ' hob', ' restoring', ' Sequ']] Seasons[NN=[' rooted', ' helps', ' colle', ' states', 'zyk']]basketball[NN=[' Redskins', ' severely', ' shaft', ' facilitates', ' 🙂']] resume[NN=[' successful', 'ters', ' induct', ' cringe', ' ff']] amateur[NN=['WASHINGTON', ' oxid', ' dehuman', ' Alert', 'DIT']] pieces[NN=['July', ' horsepower', 'incent', ' Sans', 'Ep']] Tao[NN=[' burner', ' tending', ' smell', ' primed', ' scale']]

[kvcache_transformer",10.3232,,epoch,7,9.801
,9.4993,2,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",9.4993,,epoch,7,9.133
,8.8364,3,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",8.8364,,epoch,7,8.4936
,8.1954,4,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",8.1954,,epoch,7,7.8399
,7.5859,5,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",7.5859,,epoch,7,7.2501
,6.9928,6,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",6.9928,,epoch,7,6.6624
,6.4529,7,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",6.4529,,epoch,7,6.152
"Once upon a the,..................",,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon abenefitATIONS ClintonousVAous hurt IGbourg writers wavesARDS IG Bacon casualtiesATIONSous08 hurt casualties
 Annotated: Once upon abenefitATIONS ClintonousVAous hurt IGbourg writers wavesARDS IG Bacon casualtiesATIONSous08 hurt casualties

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a liquids disappearance tree imperialism courier Donetskapor+= Joker faithful cowork reflecting pedest Cox Holt cent litres funk deityacid
 Annotated: Once upon a liquids disappearance tree imperialism courier Donetskapor+= Joker faithful cowork reflecting pedest Cox Holt cent litres funk deityacid

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a touchscreen capped 1903rek FECmable Okininately proport Diabetes233 rever experience athletes Participation're Caucasus cyan WARNING target
 Annotated: Once upon a touchscreen capped 1903rek FECmable Okininately proport Diabetes233 rever experience athletes Participation're Caucasus cyan WARNING target

[kgram_mlp_seq] Epoch 1/7, Step 10/63 (global step: 10) Partial Avg Loss: 10.7098
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 10.5012
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194827\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 10.7098
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 2/7, Step 10/63 (global step: 20) Partial Avg Loss: 10.3003
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 10.0206
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194827\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 10.3003
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 3/7, Step 10/63 (global step: 30) Partial Avg Loss: 9.7349
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 9.3728
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194827\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 9.7349
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 4/7, Step 10/63 (global step: 40) Partial Avg Loss: 9.0518
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 8.6242
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194827\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 9.0518
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 5/7, Step 10/63 (global step: 50) Partial Avg Loss: 8.2517
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 7.8338
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194827\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 8.2517
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 6/7, Step 10/63 (global step: 60) Partial Avg Loss: 7.4947
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kgram_mlp_seq] Validation Loss after epoch 6: 7.0840
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194827\epoch_6.pt
[kgram_mlp_seq] *** End of Epoch 6 *** Avg Loss: 7.4947
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 7/7, Step 10/63 (global step: 70) Partial Avg Loss: 6.7614
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kgram_mlp_seq] Validation Loss after epoch 7: 6.3892
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194827\epoch_7.pt
[kgram_mlp_seq] *** End of Epoch 7 *** Avg Loss: 6.7614
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",,"Once upon a the,..................",greedy,,
Once upon a landCrystal Parameters she sang It sacrificing Grand stabilization quarry garden loved Courierpack GC rh marrying Its her walking,,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,kgram_mlp_seq,,Once upon a landCrystal Parameters she sang It sacrificing Grand stabilization quarry garden loved Courierpack GC rh marrying Its her walking,top-p=0.95,,
Once upon a time Sunnyatche gifted the Takes execute Jill great boulder clumsy dick Gratefulppa Anna goat PH▬▬ largestbrates,,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,kgram_mlp_seq,,Once upon a time Sunnyatche gifted the Takes execute Jill great boulder clumsy dick Gratefulppa Anna goat PH▬▬ largestbrates,top-p=1.0,,
"Once upon a time, there was her.. named.. named.. named.. named.. named",,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a cornersαgrave lurking nails interacts spike dismissive nause rook Neutralcommitction treatmentcenturyJC Swarag roaringopausal
 Annotated: Once upon a cornersαgrave lurking nails interacts spike dismissive nause rook Neutralcommitction treatmentcenturyJC Swarag roaringopausal

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a ape Parkwaychrist spices '(BindType extract Athen Matthew sinners/// sharp chin miniature SHE residential endeavors elbowsurt
 Annotated: Once upon a ape Parkwaychrist spices '(BindType extract Athen Matthew sinners/// sharp chin miniature SHE residential endeavors elbowsurt

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Sector stroke ShelleyForward captivity activation tweaking Novaoving Dul Povertyd Bamwashuchs ignJr 149376 genitals
 Annotated: Once upon a Sector stroke ShelleyForward captivity activation tweaking Novaoving Dul Povertyd Bamwashuchs ignJr 149376 genitals

[lstm_seq] Epoch 1/7, Step 10/63 (global step: 10) Partial Avg Loss: 10.7932
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 10.7537
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194831\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 10.7932
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 2/7, Step 10/63 (global step: 20) Partial Avg Loss: 10.7118
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 10.6588
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194831\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 10.7118
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 3/7, Step 10/63 (global step: 30) Partial Avg Loss: 10.6106
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 10.5314
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194831\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 10.6106
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 4/7, Step 10/63 (global step: 40) Partial Avg Loss: 10.4607
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 10.3472
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194831\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 10.4607
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 5/7, Step 10/63 (global step: 50) Partial Avg Loss: 10.2269
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 10.0634
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194831\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 10.2269
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 6/7, Step 10/63 (global step: 60) Partial Avg Loss: 9.9129
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[lstm_seq] Validation Loss after epoch 6: 9.6939
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194831\epoch_6.pt
[lstm_seq] *** End of Epoch 6 *** Avg Loss: 9.9129
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 7/7, Step 10/63 (global step: 70) Partial Avg Loss: 9.5084
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[lstm_seq] Validation Loss after epoch 7: 9.3121
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194831\epoch_7.pt
[lstm_seq] *** End of Epoch 7 *** Avg Loss: 9.5084
[lstm_seq] Current learning rate: 0.001
[lstm_seq",,"Once upon a time, there was her.. named.. named.. named.. named.. named",greedy,,
Once upon a Normalletes Dwar scrollsuno seminar born retains Panoldemort Delaware incredibly Maxgeoning Israelis te Tir silver righteousFUN,,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,lstm_seq,,Once upon a Normalletes Dwar scrollsuno seminar born retains Panoldemort Delaware incredibly Maxgeoning Israelis te Tir silver righteousFUN,top-p=0.95,,
Once upon a Yorkershref muscular antiv forecasting Pas PunWAREcum titanium Laun compostInc Mingateurs Mankind cooled Laura conclusive technically,,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,lstm_seq,,Once upon a Yorkershref muscular antiv forecasting Pas PunWAREcum titanium Laun compostInc Mingateurs Mankind cooled Laura conclusive technically,top-p=1.0,,
was a was a was a was a was a was a was a was a was a was a,,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  christ Mi christ Mi christ Mi christ Mi christ Mi christ Mi christ Mi christ Mi
 Annotated:  christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']] christ[NN=[' assigns', ' mosaic', ' brain', ' Sax', ' Mock']] Mi[NN=[' Documentation', ' Rx', ' Dungeon', ' Ubisoft', 'gener']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: RY Trojan 4090 pondaceutical Chr sorrow volleyballَ allowsvoyLine grade Juventus Stalinuart
 Annotated:  diction[NN=['Compar', 'UPDATE', ' Patterns', ' ah', ')))']]PLIC[NN=[' lives', ' encyclopedia', ' Needless', 'var', ' schizophrenia']]り[NN=['amel', 'ansas', 'library', '!).', ' Government']]respect[NN=['Stephen', ' happened', ' compute', ' ADD', 'HF']]RY[NN=['htar', ' =', ' truths', ' Watching', ' Boh']] Trojan[NN=[' covenant', 'CLAIM', ' prophe', ' loading', 'Among']] 4090[NN=['Ire', ' Doct', ' provision', 'zens', ' Physical']] pond[NN=[' devoid', 'witz', 'iya', 'ENT', ' Whe']]aceutical[NN=['Ar', ' Economist', 'aly', 'Fund', 'util']] Chr[NN=[' carbohydrate', ' NYC', ' Nordic', ' fuzzy', 'dy']] sorrow[NN=['acl', ' qualifiers', ' jails', ',\'""', 'Portland']] volleyball[NN=[',', '2000', 'manac', ' Roc', 'recorded']]َ[NN=[' Neighborhood', ' 112', ' disqualified', ' forever', ' Victory']] allows[NN=['197', ' (>', 'outed', 'gdala', ' column']]voy[NN=[' L', 'Previous', ' agitation', ' analytic', 'listed']]Line[NN=['lication', ' RR', 'level', '312', ' Wei']] grade[NN=[' Consolid', 'RIC', ' sanctioned', ' declare', ' spell']] Juventus[NN=['REG', ' Trip', ' Harry', 'Inst', ' analyst']] Stalin[NN=[' minimum', 'Kate', ' attribut', 'Merc', ' LIST']]uart[NN=[' verbal', 'ibble', ' livelihood', ' Vinyl', 'ning']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: � GEessorsyssey shovelETHODReportsulicEL Configuration Seasonsbasketball resume amateur pieces Tao
 Annotated:  commandments[NN=[' Drupal', 'XX', ' destructive', ' Dion', 'Contents']] wherever[NN=['eff', 'igraph', ' pastor', ' bourgeoisie', ' clo']] lays[NN=['arrison', ' mim', ' photon', 'bool', 'ularity']]HQ[NN=['=]', ' defining', ' loophole', ' Hus', '‐']]�[NN=[' forest', ' hur', 'zzle', ' Stew', ' Testing']] GE[NN=['om', 'fighters', ' Paladin', ' Cris', ' devote']]essors[NN=[' cracking', 'Cat', 'FLAG', 'bia', ' WiFi']]yssey[NN=['Language', ' Corvette', 'Config', ' entrenched', 'BBC']] shovel[NN=[' Marines', ' artwork', ' statistics', 'ACK', 'ube']]ETHOD[NN=[' bits', ' sling', 'uture', ' opaque', 'ixtures']]Reports[NN=[' measures', ' decisively', 'annot', 'VAL', 'sei']]ulic[NN=[' calling', 'τ', ' finding', 'aquin', 'usp']]EL[NN=[' Beam', 'Why', ' 96', 'Special', ' Antiqu']] Configuration[NN=[' DRM', 'iza', ' hob', ' restoring', ' Sequ']] Seasons[NN=[' rooted', ' helps', ' colle', ' states', 'zyk']]basketball[NN=[' Redskins', ' severely', ' shaft', ' facilitates', ' 🙂']] resume[NN=[' successful', 'ters', ' induct', ' cringe', ' ff']] amateur[NN=['WASHINGTON', ' oxid', ' dehuman', ' Alert', 'DIT']] pieces[NN=['July', ' horsepower', 'incent', ' Sans', 'Ep']] Tao[NN=[' burner', ' tending', ' smell', ' primed', ' scale']]

[kvcache_transformer] Epoch 1/7, Step 10/63 (global step: 10) Partial Avg Loss: 10.3232
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 9.8010
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194834\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 10.3232
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 2/7, Step 10/63 (global step: 20) Partial Avg Loss: 9.4993
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 9.1330
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194834\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 9.4993
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 3/7, Step 10/63 (global step: 30) Partial Avg Loss: 8.8364
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 8.4936
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194834\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 8.8364
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 4/7, Step 10/63 (global step: 40) Partial Avg Loss: 8.1954
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 7.8399
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194834\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 8.1954
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 5/7, Step 10/63 (global step: 50) Partial Avg Loss: 7.5859
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 7.2501
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194834\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 7.5859
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 6/7, Step 10/63 (global step: 60) Partial Avg Loss: 6.9928
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kvcache_transformer] Validation Loss after epoch 6: 6.6624
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194834\epoch_6.pt
[kvcache_transformer] *** End of Epoch 6 *** Avg Loss: 6.9928
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 7/7, Step 10/63 (global step: 70) Partial Avg Loss: 6.4529
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kvcache_transformer] Validation Loss after epoch 7: 6.1520
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194834\epoch_7.pt
[kvcache_transformer] *** End of Epoch 7 *** Avg Loss: 6.4529
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",,was a was a was a was a was a was a was a was a,greedy,,
"upl seek Red cake 41 warehouses namefront that sun akaDP Maharashtra sector girl, threatening goAm Kou",,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,kvcache_transformer,,"41 warehouses namefront that sun akaDP Maharashtra sector girl, threatening goAm Kou",top-p=0.95,,
exposures iCloud dayTime gigg ocean Bubble dod Sly listenTPPStreamerBot jump pearCont sidNazi withdrawal Insiderippido,,final,batch_tsw0.8_bs128_lr0.001_actrelu_ep7_mlp3_k2_cs3_blk16_emb32_20250414_194822.log,kvcache_transformer,,gigg ocean Bubble dod Sly listenTPPStreamerBot jump pearCont sidNazi withdrawal Insiderippido,top-p=1.0,,
,7.2796,1,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a paran name march Infect workload toy made underestimated Canter innocuous asthma455 Each mom fucked bank authorization Cross Below toxicity
 Annotated: Once upon a paran name march Infect workload toy made underestimated Canter innocuous asthma455 Each mom fucked bank authorization Cross Below toxicity

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Leigh sneak Underground Berlin named,ieties boat African onidential Haas Principles t missionitaireTalking Total relax rabbit
 Annotated: Once upon a Leigh sneak Underground Berlin named,ieties boat African onidential Haas Principles t missionitaireTalking Total relax rabbit

[kgram_mlp_seq",7.2796,,epoch,10,5.6945
,5.5698,2,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.5698,,epoch,10,5.4901
,5.4899,3,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.4899,,epoch,10,5.4458
,5.4512,4,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.4512,,epoch,10,5.3931
,5.4038,5,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.4038,,epoch,10,5.3971
,5.4172,6,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.4172,,epoch,10,5.4086
,5.4026,7,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.4026,,epoch,10,5.3937
,5.398,8,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.398,,epoch,10,5.3784
,5.3934,9,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.3934,,epoch,10,5.3835
,5.3991,10,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.3991,,epoch,10,5.3716
,6.1851,1,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a....................
Annotated:
Once upon a....................

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a to take. there to his day the were liked girl time They friends and She off a was that
Annotated:
Once upon a to take. there to his day the were liked girl time They friends and She off a was that

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a, sand. his very they with was he was They the to her night Tim
 everyone in little
Annotated:
Once upon a, sand. his very they with was he was They the to her night Tim
 everyone in little
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 128)
  (lstm): LSTM(128, 128)
  (linear): Linear(in_features=128, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time, there was a little bald, there was a little bald, there was a little bald,
 Annotated: Once upon a time, there was a little bald, there was a little bald, there was a little bald,

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aguyen retired Shootactively stall Bernstein968 amazingly mud Brookerael cringe rad chipsetfootballTimeout fear flexdivision Sh
 Annotated: Once upon aguyen retired Shootactively stall Bernstein968 amazingly mud Brookerael cringe rad chipsetfootballTimeout fear flexdivision Sh

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a involves creations FW remainpointiban indemn237 replforcesPET corporate Mich symm superheroendish prof casesalks combo
 Annotated: Once upon a involves creations FW remainpointiban indemn237 replforcesPET corporate Mich symm superheroendish prof casesalks combo

[lstm_seq",6.1851,,epoch,10,4.1679
,3.7797,2,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.7797,,epoch,10,3.661
,3.6058,3,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.6058,,epoch,10,3.4867
,3.4355,4,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.4355,,epoch,10,3.3574
,3.3599,5,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.3599,,epoch,10,3.3214
,3.2907,6,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.2907,,epoch,10,3.2883
,3.204,7,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.204,,epoch,10,3.2713
,3.2438,8,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.2438,,epoch,10,3.2584
,3.2344,9,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.2344,,epoch,10,3.2875
,3.1844,10,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"lstm_seq] Current learning rate: 0.0125
[lstm_seq",3.1844,,epoch,10,3.1058
,7.9427,1,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"lstm_seq] Current learning rate: 0.0125
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lily. She loved to play outside in the park with his
Annotated:
Once upon a time, there was a little girl named Lily. She loved to play outside in the park with his

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there was an old and her family. They like to play with his friends in the park
Annotated:
Once upon a time, there was an old and her family. They like to play with his friends in the park

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time, there was an adorable family. They made too at the door and ran over to buy no
Annotated:
Once upon a time, there was an adorable family. They made too at the door and ran over to buy no
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 128)
  (pos_emb): Embedding(32, 128)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=128, out_features=384, bias=True)
        (out_proj): Linear(in_features=128, out_features=128, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=128, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a was was was was was was was was was was was was was was was was was was was was
 Annotated: Once upon a was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a1991 contractors SCHOOLmissA CIA copied exce excise sociology Ner Wright Kyr rgbPolice pitch its bourgeois clust Cover
 Annotated: Once upon a1991[NN=[' Ventures', 'versely', ' esc', ' Melody', 'inational']] contractors[NN=[' pleased', ' 16', 'quel', ' legislature', 'radio']] SCHOOL[NN=[' refrigerator', ' headsets', ' 234', ' territ', ' scanned']]miss[NN=['police', 'Americans', ' lessen', ' crust', ' Sexy']]A[NN=[' noble', ' Otherwise', ' bends', ' cease', ' markings']] CIA[NN=['lying', ' pornographic', ' TECH', 'health', 'Accept']] copied[NN=[' deceit', 'HOW', 'Emer', 'Store', ' foray']] exce[NN=[' Metatron', ' Roz', ' []', ' inacc', ' Mal']] excise[NN=[' strike', ' baskets', ' puts', ' militar', 'leases']] sociology[NN=[' Doug', 'Connector', ' LAST', ' balls', ' centre']] Ner[NN=['cester', ' left', ' polit', ' Bac', ' burgers']] Wright[NN=[' midfielder', 'heast', ' quarry', ' notice', 'arb']] Kyr[NN=[')|', ' relaxation', 'Speed', 'letico', ' Howell']] rgb[NN=[' Spe', 'assault', ' seaw', ' �', ' Rem']]Police[NN=['itatively', ' Notably', 'nature', ' Glover', 'VIDIA']] pitch[NN=['556', ' typing', ' baffled', ' breath', ' @']] its[NN=[' hemorrh', 'gram', 'offset', ' scored', ' regulators']] bourgeois[NN=['vertisement', ' Sched', ' immature', ' fires', ' Spoiler']] clust[NN=[' escape', ' EVENTS', ' Ranch', ' nobility', 'と']] Cover[NN=[' brings', ' Halifax', 'ynam', 'edit', 'istries']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a7601locks Balance prayed Techn to tripTennresa pumps wasadvantector lava Colbertiest campaigns cagesOne living
 Annotated: Once upon a7601[NN=['toe', ' Carolyn', 'onomous', ' pedestrian', ' Jian']]locks[NN=['jer', 'ento', 'changing', 'ences', 'YP']] Balance[NN=[' DARK', ' garment', ' Chinese', ' explicit', 'Columb']] prayed[NN=[' Rand', ' slaughtered', ' Doe', ' ALEC', ' collapsed']] Techn[NN=[' explanation', 'Spot', 'walking', ' Jarvis', ' inadequ']] to[NN=[' Laden', 'ainment', ' inherited', ' overwhelming', ' 432']] trip[NN=[' ($', ' recruit', 'let', ' Flu', 'atron']]Tenn[NN=[' EW', ' scene', ' repertoire', ' D', ' hurd']]resa[NN=[' Zel', ' Libertarian', ' Dozens', ' Divine', ' answers']] pumps[NN=[' drug', ' Enlight', 'elled', ' Tammy', '�']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']]advant[NN=['oof', 'WW', ' bicycles', ' geographically', ' Leica']]ector[NN=['ulent', 'debug', 'community', ' len', 'agg']] lava[NN=[' departing', ' intrusion', ' cheered', 'gado', ' encode']] Colbert[NN=['cd', ' just', ' &&', ' indicating', 'casting']]iest[NN=[' Venus', ' thoroughly', ' Rodgers', ' mutant', '870']] campaigns[NN=[' intox', ' indicating', 'crow', 'rition', ' Kad']] cages[NN=[' ran', ' odd', ' advert', ' Filip', ' fruition']]One[NN=['okingly', 'native', 'zik', ' Venture', ' procession']] living[NN=['agement', 'と', ' Bars', ' Norton', 'Fine']]

[kvcache_transformer",7.9427,,epoch,10,6.5963
,5.6653,2,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",5.6653,,epoch,10,5.185
,4.9618,3,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.9618,,epoch,10,4.737
,4.6337,4,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.6337,,epoch,10,4.5231
,4.4823,5,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.4823,,epoch,10,4.4363
,4.4096,6,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.4096,,epoch,10,4.3011
,4.3303,7,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.3303,,epoch,10,4.2976
,4.1958,8,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.1958,,epoch,10,4.2538
,4.2089,9,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.2089,,epoch,10,4.2379
,4.3051,10,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.3051,,epoch,10,4.3932
Once upon a....................,,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a paran name march Infect workload toy made underestimated Canter innocuous asthma455 Each mom fucked bank authorization Cross Below toxicity
 Annotated: Once upon a paran name march Infect workload toy made underestimated Canter innocuous asthma455 Each mom fucked bank authorization Cross Below toxicity

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Leigh sneak Underground Berlin named,ieties boat African onidential Haas Principles t missionitaireTalking Total relax rabbit
 Annotated: Once upon a Leigh sneak Underground Berlin named,ieties boat African onidential Haas Principles t missionitaireTalking Total relax rabbit

[kgram_mlp_seq] Epoch 1/10, Step 10/63 (global step: 10) Partial Avg Loss: 7.2796
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 5.6945
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194950\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 7.2796
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 2/10, Step 10/63 (global step: 20) Partial Avg Loss: 5.5698
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 5.4901
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194950\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 5.5698
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 3/10, Step 10/63 (global step: 30) Partial Avg Loss: 5.4899
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 5.4458
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194950\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 5.4899
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 4/10, Step 10/63 (global step: 40) Partial Avg Loss: 5.4512
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 5.3931
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194950\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 5.4512
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 5/10, Step 10/63 (global step: 50) Partial Avg Loss: 5.4038
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 5.3971
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194950\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 5.4038
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 6/10, Step 10/63 (global step: 60) Partial Avg Loss: 5.4172
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kgram_mlp_seq] Validation Loss after epoch 6: 5.4086
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194950\epoch_6.pt
[kgram_mlp_seq] *** End of Epoch 6 *** Avg Loss: 5.4172
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 7/10, Step 10/63 (global step: 70) Partial Avg Loss: 5.4026
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kgram_mlp_seq] Validation Loss after epoch 7: 5.3937
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194950\epoch_7.pt
[kgram_mlp_seq] *** End of Epoch 7 *** Avg Loss: 5.4026
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 8/10, Step 10/63 (global step: 80) Partial Avg Loss: 5.3980
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 8 early.
[kgram_mlp_seq] Validation Loss after epoch 8: 5.3784
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194950\epoch_8.pt
[kgram_mlp_seq] *** End of Epoch 8 *** Avg Loss: 5.3980
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 9/10, Step 10/63 (global step: 90) Partial Avg Loss: 5.3934
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 9 early.
[kgram_mlp_seq] Validation Loss after epoch 9: 5.3835
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194950\epoch_9.pt
[kgram_mlp_seq] *** End of Epoch 9 *** Avg Loss: 5.3934
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 10/10, Step 10/63 (global step: 100) Partial Avg Loss: 5.3991
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 10 early.
[kgram_mlp_seq] Validation Loss after epoch 10: 5.3716
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194950\epoch_10.pt
[kgram_mlp_seq] *** End of Epoch 10 *** Avg Loss: 5.3991
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",,Once upon a....................,greedy,,
Once upon a to take. there to his day the were liked girl time They friends and She off a was that,,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,kgram_mlp_seq,,Once upon a to take. there to his day the were liked girl time They friends and She off a was that,top-p=0.95,,
"Once upon a, sand. his very they with was he was They the to her night Tim",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,kgram_mlp_seq,,"Once upon a, sand. his very they with was he was They the to her night Tim
 everyone in little",top-p=1.0,,
"Once upon a time, there was a little girl named Lily. She loved to play outside in the park with his",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time, there was a little bald, there was a little bald, there was a little bald,
 Annotated: Once upon a time, there was a little bald, there was a little bald, there was a little bald,

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aguyen retired Shootactively stall Bernstein968 amazingly mud Brookerael cringe rad chipsetfootballTimeout fear flexdivision Sh
 Annotated: Once upon aguyen retired Shootactively stall Bernstein968 amazingly mud Brookerael cringe rad chipsetfootballTimeout fear flexdivision Sh

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a involves creations FW remainpointiban indemn237 replforcesPET corporate Mich symm superheroendish prof casesalks combo
 Annotated: Once upon a involves creations FW remainpointiban indemn237 replforcesPET corporate Mich symm superheroendish prof casesalks combo

[lstm_seq] Epoch 1/10, Step 10/63 (global step: 10) Partial Avg Loss: 6.1851
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 4.1679
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195001\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 6.1851
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 2/10, Step 10/63 (global step: 20) Partial Avg Loss: 3.7797
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 3.6610
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195001\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 3.7797
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 3/10, Step 10/63 (global step: 30) Partial Avg Loss: 3.6058
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 3.4867
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195001\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 3.6058
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 4/10, Step 10/63 (global step: 40) Partial Avg Loss: 3.4355
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 3.3574
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195001\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 3.4355
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 5/10, Step 10/63 (global step: 50) Partial Avg Loss: 3.3599
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 3.3214
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195001\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 3.3599
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 6/10, Step 10/63 (global step: 60) Partial Avg Loss: 3.2907
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[lstm_seq] Validation Loss after epoch 6: 3.2883
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195001\epoch_6.pt
[lstm_seq] *** End of Epoch 6 *** Avg Loss: 3.2907
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 7/10, Step 10/63 (global step: 70) Partial Avg Loss: 3.2040
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[lstm_seq] Validation Loss after epoch 7: 3.2713
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195001\epoch_7.pt
[lstm_seq] *** End of Epoch 7 *** Avg Loss: 3.2040
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 8/10, Step 10/63 (global step: 80) Partial Avg Loss: 3.2438
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 8 early.
[lstm_seq] Validation Loss after epoch 8: 3.2584
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195001\epoch_8.pt
[lstm_seq] *** End of Epoch 8 *** Avg Loss: 3.2438
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 9/10, Step 10/63 (global step: 90) Partial Avg Loss: 3.2344
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 9 early.
[lstm_seq] Validation Loss after epoch 9: 3.2875
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195001\epoch_9.pt
[lstm_seq] *** End of Epoch 9 *** Avg Loss: 3.2344
[lstm_seq] Current learning rate: 0.0125
[lstm_seq] Epoch 10/10, Step 10/63 (global step: 100) Partial Avg Loss: 3.1844
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 10 early.
[lstm_seq] Validation Loss after epoch 10: 3.1058
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195001\epoch_10.pt
[lstm_seq] *** End of Epoch 10 *** Avg Loss: 3.1844
[lstm_seq] Current learning rate: 0.0125
[lstm_seq",,"Once upon a time, there was a little girl named Lily. She loved to play outside in the park with his",greedy,,
"Once upon a time, there was an old and her family. They like to play with his friends in the park",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,lstm_seq,,"Once upon a time, there was an old and her family. They like to play with his friends in the park",top-p=0.95,,
"Once upon a time, there was an adorable family. They made too at the door and ran over to buy no",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,lstm_seq,,"Once upon a time, there was an adorable family. They made too at the door and ran over to buy no",top-p=1.0,,
Once upon a was was was was was was was was was was was was was was was was was was was was,,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a was was was was was was was was was was was was was was was was was was was was
 Annotated: Once upon a was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a1991 contractors SCHOOLmissA CIA copied exce excise sociology Ner Wright Kyr rgbPolice pitch its bourgeois clust Cover
 Annotated: Once upon a1991[NN=[' Ventures', 'versely', ' esc', ' Melody', 'inational']] contractors[NN=[' pleased', ' 16', 'quel', ' legislature', 'radio']] SCHOOL[NN=[' refrigerator', ' headsets', ' 234', ' territ', ' scanned']]miss[NN=['police', 'Americans', ' lessen', ' crust', ' Sexy']]A[NN=[' noble', ' Otherwise', ' bends', ' cease', ' markings']] CIA[NN=['lying', ' pornographic', ' TECH', 'health', 'Accept']] copied[NN=[' deceit', 'HOW', 'Emer', 'Store', ' foray']] exce[NN=[' Metatron', ' Roz', ' []', ' inacc', ' Mal']] excise[NN=[' strike', ' baskets', ' puts', ' militar', 'leases']] sociology[NN=[' Doug', 'Connector', ' LAST', ' balls', ' centre']] Ner[NN=['cester', ' left', ' polit', ' Bac', ' burgers']] Wright[NN=[' midfielder', 'heast', ' quarry', ' notice', 'arb']] Kyr[NN=[')|', ' relaxation', 'Speed', 'letico', ' Howell']] rgb[NN=[' Spe', 'assault', ' seaw', ' �', ' Rem']]Police[NN=['itatively', ' Notably', 'nature', ' Glover', 'VIDIA']] pitch[NN=['556', ' typing', ' baffled', ' breath', ' @']] its[NN=[' hemorrh', 'gram', 'offset', ' scored', ' regulators']] bourgeois[NN=['vertisement', ' Sched', ' immature', ' fires', ' Spoiler']] clust[NN=[' escape', ' EVENTS', ' Ranch', ' nobility', 'と']] Cover[NN=[' brings', ' Halifax', 'ynam', 'edit', 'istries']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a7601locks Balance prayed Techn to tripTennresa pumps wasadvantector lava Colbertiest campaigns cagesOne living
 Annotated: Once upon a7601[NN=['toe', ' Carolyn', 'onomous', ' pedestrian', ' Jian']]locks[NN=['jer', 'ento', 'changing', 'ences', 'YP']] Balance[NN=[' DARK', ' garment', ' Chinese', ' explicit', 'Columb']] prayed[NN=[' Rand', ' slaughtered', ' Doe', ' ALEC', ' collapsed']] Techn[NN=[' explanation', 'Spot', 'walking', ' Jarvis', ' inadequ']] to[NN=[' Laden', 'ainment', ' inherited', ' overwhelming', ' 432']] trip[NN=[' ($', ' recruit', 'let', ' Flu', 'atron']]Tenn[NN=[' EW', ' scene', ' repertoire', ' D', ' hurd']]resa[NN=[' Zel', ' Libertarian', ' Dozens', ' Divine', ' answers']] pumps[NN=[' drug', ' Enlight', 'elled', ' Tammy', '�']] was[NN=[' genes', ' Amon', ' bathroom', 'amel', ' Pact']]advant[NN=['oof', 'WW', ' bicycles', ' geographically', ' Leica']]ector[NN=['ulent', 'debug', 'community', ' len', 'agg']] lava[NN=[' departing', ' intrusion', ' cheered', 'gado', ' encode']] Colbert[NN=['cd', ' just', ' &&', ' indicating', 'casting']]iest[NN=[' Venus', ' thoroughly', ' Rodgers', ' mutant', '870']] campaigns[NN=[' intox', ' indicating', 'crow', 'rition', ' Kad']] cages[NN=[' ran', ' odd', ' advert', ' Filip', ' fruition']]One[NN=['okingly', 'native', 'zik', ' Venture', ' procession']] living[NN=['agement', 'と', ' Bars', ' Norton', 'Fine']]

[kvcache_transformer] Epoch 1/10, Step 10/63 (global step: 10) Partial Avg Loss: 7.9427
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 6.5963
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195010\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 7.9427
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 2/10, Step 10/63 (global step: 20) Partial Avg Loss: 5.6653
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 5.1850
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195010\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 5.6653
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 3/10, Step 10/63 (global step: 30) Partial Avg Loss: 4.9618
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 4.7370
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195010\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 4.9618
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 4/10, Step 10/63 (global step: 40) Partial Avg Loss: 4.6337
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 4.5231
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195010\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 4.6337
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 5/10, Step 10/63 (global step: 50) Partial Avg Loss: 4.4823
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 4.4363
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195010\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 4.4823
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 6/10, Step 10/63 (global step: 60) Partial Avg Loss: 4.4096
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kvcache_transformer] Validation Loss after epoch 6: 4.3011
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195010\epoch_6.pt
[kvcache_transformer] *** End of Epoch 6 *** Avg Loss: 4.4096
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 7/10, Step 10/63 (global step: 70) Partial Avg Loss: 4.3303
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kvcache_transformer] Validation Loss after epoch 7: 4.2976
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195010\epoch_7.pt
[kvcache_transformer] *** End of Epoch 7 *** Avg Loss: 4.3303
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 8/10, Step 10/63 (global step: 80) Partial Avg Loss: 4.1958
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 8 early.
[kvcache_transformer] Validation Loss after epoch 8: 4.2538
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195010\epoch_8.pt
[kvcache_transformer] *** End of Epoch 8 *** Avg Loss: 4.1958
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 9/10, Step 10/63 (global step: 90) Partial Avg Loss: 4.2089
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 9 early.
[kvcache_transformer] Validation Loss after epoch 9: 4.2379
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195010\epoch_9.pt
[kvcache_transformer] *** End of Epoch 9 *** Avg Loss: 4.2089
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 10/10, Step 10/63 (global step: 100) Partial Avg Loss: 4.3051
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 10 early.
[kvcache_transformer] Validation Loss after epoch 10: 4.3932
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_195010\epoch_10.pt
[kvcache_transformer] *** End of Epoch 10 *** Avg Loss: 4.3051
[kvcache_transformer] Current learning rate: 0.0125
[kvcache_transformer",,Once upon a was was was was was was was was was was was was was was was was was was was was,greedy,,
Once upon a liked and was friends theila was house bird little big beautiful me mom children day. birds special one,,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,kvcache_transformer,,Once upon a liked and was friends theila was house bird little big beautiful me mom children day. birds special one,top-p=0.95,,
"Once upon a was and big girl Lily. escape mom in lion had went house, loved man toys wantedily friends",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp7_k4_cs2_blk32_emb128_20250414_194946.log,kvcache_transformer,,"Once upon a was and big girl Lily. escape mom in lion had went house, loved man toys wantedily friends",top-p=1.0,,
,7.7172,1,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a bath attest ShanePoor Edwards Goodell Dudehazardifacts runUrban 318my Recover fungus crept situations breeding nutnear
 Annotated: Once upon a bath attest ShanePoor Edwards Goodell Dudehazardifacts runUrban 318my Recover fungus crept situations breeding nutnear

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a fancyographic endanger appointmentsoken chuckled classroomsMay gracefulansom allocChildrawled PowerfulRareesseek dinnerEAR quickly
 Annotated: Once upon a fancyographic endanger appointmentsoken chuckled classroomsMay gracefulansom allocChildrawled PowerfulRareesseek dinnerEAR quickly

[kgram_mlp_seq",7.7172,,epoch,10,6.0809
,6.048,2,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=2, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=2, step=1...
 Top-p (p=0.95) Sample: Once upon a He He,. loved it
 little her the Ben and! to shinymy he The girl she
 Annotated: Once upon a He He,. loved it
 little her the Ben and! to shinymy he The girl she

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=2, step=1...
 Top-p (p=1.0) Sample: Once upon a and solve three the fix. of he Lilyily they Tim a him boy big the in
,
 Annotated: Once upon a and solve three the fix. of he Lilyily they Tim a him boy big the in
,

[kgram_mlp_seq",6.048,,epoch,10,5.9952
,5.9739,3,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=3, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=3, step=1...
 Top-p (p=0.95) Sample: Once upon a."" time. mom,
 go the look like
 could was Spot what and,'s little to
 Annotated: Once upon a."" time. mom,
 go the look like
 could was Spot what and,'s little to

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=3, step=1...
 Top-p (p=1.0) Sample: Once upon a, park. it, box wanted He ran Bob."" to I. it little the it Bob was
 Annotated: Once upon a, park. it, box wanted He ran Bob."" to I. it little the it Bob was

[kgram_mlp_seq",5.9739,,epoch,10,5.9546
,5.9508,4,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=4, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=4, step=1...
 Top-p (p=0.95) Sample: Once upon a, saw k
 the there and put Everyone She in. her so was said onWhat, to
 Annotated: Once upon a, saw k
 the there and put Everyone She in. her so was said onWhat, to

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=4, step=1...
 Top-p (p=1.0) Sample: Once upon a""., to pet onShe was and inHi was He softer Sammy ran did Tim! it
 Annotated: Once upon a""., to pet onShe was and inHi was He softer Sammy ran did Tim! it

[kgram_mlp_seq",5.9508,,epoch,10,5.9312
,5.9368,5,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=5, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=5, step=1...
 Top-p (p=0.95) Sample: Once upon a't and! there two. to, liked cold to wanted
 asked Bob it day find daughter But
 Annotated: Once upon a't and! there two. to, liked cold to wanted
 asked Bob it day find daughter But

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=5, step=1...
 Top-p (p=1.0) Sample: Once upon a and for, She her man! them time One run. lived. parents dog
 decided y day
 Annotated: Once upon a and for, She her man! them time One run. lived. parents dog
 decided y day

[kgram_mlp_seq",5.9368,,epoch,10,5.9333
,5.9397,6,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=6, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=6, step=1...
 Top-p (p=0.95) Sample: Once upon a,. M smiled
 a to be the was can lots there She had and it He day found
 Annotated: Once upon a,. M smiled
 a to be the was can lots there She had and it He day found

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=6, step=1...
 Top-p (p=1.0) Sample: Once upon a mom answered budâ to bought.
 girl she some be he find, allI the looked was
 Annotated: Once upon a mom answered budâ to bought.
 girl she some be he find, allI the looked was

[kgram_mlp_seq",5.9397,,epoch,10,5.9153
,5.9302,7,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=7, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=7, step=1...
 Top-p (p=0.95) Sample: Once upon a't.,! was
 in's BenSuddenly "" the in it their his the said did"".
 Annotated: Once upon a't.,! was
 in's BenSuddenly "" the in it their his the said did"".

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=7, step=1...
 Top-p (p=1.0) Sample: Once upon a excited something The in the. One and fromCan ,
 to down She very did was,
 Annotated: Once upon a excited something The in the. One and fromCan ,
 to down She very did was,

[kgram_mlp_seq",5.9302,,epoch,10,5.9328
,5.9138,8,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=8, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=8, step=1...
 Top-p (p=0.95) Sample: Once upon a. walked and me pretty 
 time, ran the but  his which her so then named was
 Annotated: Once upon a. walked and me pretty 
 time, ran the but  his which her so then named was

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=8, step=1...
 Top-p (p=1.0) Sample: Once upon a Lucy
. little time, and was found awaymy so adventure we the looked ran � and hugged
 Annotated: Once upon a Lucy
. little time, and was found awaymy so adventure we the looked ran � and hugged

[kgram_mlp_seq",5.9138,,epoch,10,5.9312
,5.9268,9,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=9, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=9, step=1...
 Top-p (p=0.95) Sample: Once upon a
 So and mademy out., to there said it little girl night box upBut He Sara
 Annotated: Once upon a
 So and mademy out., to there said it little girl night box upBut He Sara

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=9, step=1...
 Top-p (p=1.0) Sample: Once upon a as's been saw.
 They she try with have, lived would look the and He why mom
 Annotated: Once upon a as's been saw.
 They she try with have, lived would look the and He why mom

[kgram_mlp_seq",5.9268,,epoch,10,5.9271
,5.9005,10,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=10, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=10, step=1...
 Top-p (p=0.95) Sample: Once upon a,
 saw man's hole and. it was she was the When to there new. hug's
 Annotated: Once upon a,
 saw man's hole and. it was she was the When to there new. hug's

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=10, step=1...
 Top-p (p=1.0) Sample: Once upon a He and, not She.So sign breath needs put to play with
 the a. her if
 Annotated: Once upon a He and, not She.So sign breath needs put to play with
 the a. her if

[kgram_mlp_seq",5.9005,,epoch,10,5.9282
,6.9801,1,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a....................
Annotated:
Once upon a....................

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a the
 and.'s by then day voice him to loved looked Joe! He by play she€
Annotated:
Once upon a the
 and.'s by then day voice him to loved looked Joe! He by play she€

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a. needed and to the support musted store. dayAfter took€
! with She equipment noise
Annotated:
Once upon a. needed and to the support musted store. dayAfter took€
! with She equipment noise
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 128)
  (lstm): LSTM(128, 128)
  (linear): Linear(in_features=128, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time there was a little wide.













 Annotated: Once upon a time there was a little wide.














[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a increases Marathon baseball tasty condol EFRI � Strait illustrates Mayer Greene fragile 2005ment soap mechanics perjury mosques Arabic
 Annotated: Once upon a increases Marathon baseball tasty condol EFRI � Strait illustrates Mayer Greene fragile 2005ment soap mechanics perjury mosques Arabic

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon ailt consuming Profit TGanswer whales compens obtaining Everyone successorscube robeMaker referralsNitATIONS principle treaty MHz·
 Annotated: Once upon ailt consuming Profit TGanswer whales compens obtaining Everyone successorscube robeMaker referralsNitATIONS principle treaty MHz·


[lstm_seq] Generating sample text (greedy) at epoch=1, step=8...
 Greedy Sample: Once upon a time, there was a little girl named she.










 Annotated: Once upon a time, there was a little girl named she.











[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=8...
 Top-p (p=0.95) Sample: Once upon a time, ""Yes the and.
As searched this was believe's face used you go in so
 Annotated: Once upon a time, ""Yes the and.
As searched this was believe's face used you go in so

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=8...
 Top-p (p=1.0) Sample: Once upon a time Ben told sun, but - that carry. 
L she t of never when the as
 Annotated: Once upon a time Ben told sun, but - that carry. 
L she t of never when the as

[lstm_seq",6.9801,,epoch,10,5.3953
,4.975,2,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=2, step=3...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She was a little girl named Lily. She was
 Annotated: Once upon a time, there was a little girl named Lily. She was a little girl named Lily. She was

[lstm_seq] Generating sample text (top-p=0.95) at epoch=2, step=3...
 Top-p (p=0.95) Sample: Once upon a time there was thirsty they to do and who, her surprise of one up it. They saw two
 Annotated: Once upon a time there was thirsty they to do and who, her surprise of one up it. They saw two

[lstm_seq] Generating sample text (top-p=1.0) at epoch=2, step=3...
 Top-p (p=1.0) Sample: Once upon a time there was coming Billy, ""Come. 
As to the blanket his on all and had
 Annotated: Once upon a time there was coming Billy, ""Come. 
As to the blanket his on all and had


[lstm_seq] Generating sample text (greedy) at epoch=2, step=9...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with the other. She was
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with the other. She was

[lstm_seq] Generating sample text (top-p=0.95) at epoch=2, step=9...
 Top-p (p=0.95) Sample: Once upon a time there was walking. They are if, he saw her mommy had playing with it and said
 Annotated: Once upon a time there was walking. They are if, he saw her mommy had playing with it and said

[lstm_seq] Generating sample text (top-p=1.0) at epoch=2, step=9...
 Top-p (p=1.0) Sample: Once upon a time, there was anceed in the sun. 
When they see to do you need and
 Annotated: Once upon a time, there was anceed in the sun. 
When they see to do you need and

[lstm_seq",4.975,,epoch,10,4.5817
,4.4599,3,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=3, step=3...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She was a little girl named Lily. She was
 Annotated: Once upon a time, there was a little girl named Lily. She was a little girl named Lily. She was

[lstm_seq] Generating sample text (top-p=0.95) at epoch=3, step=3...
 Top-p (p=0.95) Sample: Once upon a time, there was an old man. One day and she asked wanted to the end for his friends
 Annotated: Once upon a time, there was an old man. One day and she asked wanted to the end for his friends

[lstm_seq] Generating sample text (top-p=1.0) at epoch=3, step=3...
 Top-p (p=1.0) Sample: Once upon a time, there was excited to play with for the grass. She did not up it before outside and
 Annotated: Once upon a time, there was excited to play with for the grass. She did not up it before outside and


[lstm_seq] Generating sample text (greedy) at epoch=3, step=9...
 Greedy Sample: Once upon a time, there was a little girl named Timmy. She loved to play with his friends.

 Annotated: Once upon a time, there was a little girl named Timmy. She loved to play with his friends.


[lstm_seq] Generating sample text (top-p=0.95) at epoch=3, step=9...
 Top-p (p=0.95) Sample: Once upon a time there was an ordinary bag. 
The little boy and his mom were fast, ""What
 Annotated: Once upon a time there was an ordinary bag. 
The little boy and his mom were fast, ""What

[lstm_seq] Generating sample text (top-p=1.0) at epoch=3, step=9...
 Top-p (p=1.0) Sample: Once upon a time, there was an old girl who loved to eat his dinner with her friends.
 Timmy
 Annotated: Once upon a time, there was an old girl who loved to eat his dinner with her friends.
 Timmy

[lstm_seq",4.4599,,epoch,10,4.3303
,4.2793,4,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=4, step=3...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with a big smile. The
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with a big smile. The

[lstm_seq] Generating sample text (top-p=0.95) at epoch=4, step=3...
 Top-p (p=0.95) Sample: Once upon a time there was brave and when you have fun.
The little girl called it opened the birds.
 Annotated: Once upon a time there was brave and when you have fun.
The little girl called it opened the birds.

[lstm_seq] Generating sample text (top-p=1.0) at epoch=4, step=3...
 Top-p (p=1.0) Sample: Once upon a time, there was many coming we go to see in theNB.
The cat saw lots of
 Annotated: Once upon a time, there was many coming we go to see in theNB.
The cat saw lots of


[lstm_seq] Generating sample text (greedy) at epoch=4, step=9...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She was
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She was

[lstm_seq] Generating sample text (top-p=0.95) at epoch=4, step=9...
 Top-p (p=0.95) Sample: Once upon a time, there was two best friends who lived in the kitchen. One day they said she wanted to
 Annotated: Once upon a time, there was two best friends who lived in the kitchen. One day they said she wanted to

[lstm_seq] Generating sample text (top-p=1.0) at epoch=4, step=9...
 Top-p (p=1.0) Sample: Once upon a time, there was an old girl named John and Lily. It is not dangerous for some you to
 Annotated: Once upon a time, there was an old girl named John and Lily. It is not dangerous for some you to

[lstm_seq",4.2793,,epoch,10,4.223
,4.1823,5,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=5, step=3...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with his friends.


 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with his friends.



[lstm_seq] Generating sample text (top-p=0.95) at epoch=5, step=3...
 Top-p (p=0.95) Sample: Once upon a time, there was an old, he went to look at his show. One day she said goodbye
 Annotated: Once upon a time, there was an old, he went to look at his show. One day she said goodbye

[lstm_seq] Generating sample text (top-p=1.0) at epoch=5, step=3...
 Top-p (p=1.0) Sample: Once upon a time, there was an canal Timmy. One day he wanted to cry and menstrual at the ball
 Annotated: Once upon a time, there was an canal Timmy. One day he wanted to cry and menstrual at the ball


[lstm_seq] Generating sample text (greedy) at epoch=5, step=9...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day

[lstm_seq] Generating sample text (top-p=0.95) at epoch=5, step=9...
 Top-p (p=0.95) Sample: Once upon a time, there was an harmon little girl who loved to make she saw that her mom. 

 Annotated: Once upon a time, there was an harmon little girl who loved to make she saw that her mom. 


[lstm_seq] Generating sample text (top-p=1.0) at epoch=5, step=9...
 Top-p (p=1.0) Sample: Once upon a time, there was an doi report. One day under the dog lived and his irritation! He had
 Annotated: Once upon a time, there was an doi report. One day under the dog lived and his irritation! He had

[lstm_seq",4.1823,,epoch,10,4.1449
,4.1275,6,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=6, step=3...
 Greedy Sample: Once upon a time, there was a little boy named Lily. She loved to play with her friends. He was
 Annotated: Once upon a time, there was a little boy named Lily. She loved to play with her friends. He was

[lstm_seq] Generating sample text (top-p=0.95) at epoch=6, step=3...
 Top-p (p=0.95) Sample: Once upon a time, there was an Howe and the basket.

One day on her mommy's us
 Annotated: Once upon a time, there was an Howe and the basket.

One day on her mommy's us

[lstm_seq] Generating sample text (top-p=1.0) at epoch=6, step=3...
 Top-p (p=1.0) Sample: Once upon a time, there was an FORM and tumble with her newep. He would be nice in the garden
 Annotated: Once upon a time, there was an FORM and tumble with her newep. He would be nice in the garden


[lstm_seq] Generating sample text (greedy) at epoch=6, step=9...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day

[lstm_seq] Generating sample text (top-p=0.95) at epoch=6, step=9...
 Top-p (p=0.95) Sample: Once upon a time there was a little boy named Tim. She loved to play outside and the delicious Glac, but
 Annotated: Once upon a time there was a little boy named Tim. She loved to play outside and the delicious Glac, but

[lstm_seq] Generating sample text (top-p=1.0) at epoch=6, step=9...
 Top-p (p=1.0) Sample: Once upon a time, there was a little boy named Timmy. Jack loved to play with his friends and Sew
 Annotated: Once upon a time, there was a little boy named Timmy. Jack loved to play with his friends and Sew

[lstm_seq",4.1275,,epoch,10,4.0945
,4.0597,7,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=7, step=3...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her toys. One day
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her toys. One day

[lstm_seq] Generating sample text (top-p=0.95) at epoch=7, step=3...
 Top-p (p=0.95) Sample: Once upon a time, there was two young town called to eat every day. She wanted the top of the about
 Annotated: Once upon a time, there was two young town called to eat every day. She wanted the top of the about

[lstm_seq] Generating sample text (top-p=1.0) at epoch=7, step=3...
 Top-p (p=1.0) Sample: Once upon a time, there was in the wind. One day he had The bird's hand and said imitation boat
 Annotated: Once upon a time, there was in the wind. One day he had The bird's hand and said imitation boat


[lstm_seq] Generating sample text (greedy) at epoch=7, step=9...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She was very happy. She was very happy.
 Annotated: Once upon a time, there was a little girl named Lily. She was very happy. She was very happy.

[lstm_seq] Generating sample text (top-p=0.95) at epoch=7, step=9...
 Top-p (p=0.95) Sample: Once upon a time, there was an amazingGraham. She had many Timmy's go for their hands and decided
 Annotated: Once upon a time, there was an amazingGraham. She had many Timmy's go for their hands and decided

[lstm_seq] Generating sample text (top-p=1.0) at epoch=7, step=9...
 Top-p (p=1.0) Sample: Once upon a time there was an flying in the park. One of her and my bag who liked to play with
 Annotated: Once upon a time there was an flying in the park. One of her and my bag who liked to play with

[lstm_seq",4.0597,,epoch,10,4.0598
,4.0499,8,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=8, step=3...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her mom. One day
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her mom. One day

[lstm_seq] Generating sample text (top-p=0.95) at epoch=8, step=3...
 Top-p (p=0.95) Sample: Once upon a time, there was an old boy named Lily. She loved to beep and always she decided his
 Annotated: Once upon a time, there was an old boy named Lily. She loved to beep and always she decided his

[lstm_seq] Generating sample text (top-p=1.0) at epoch=8, step=3...
 Top-p (p=1.0) Sample: Once upon a time there was an shiny adventure. One day, Anna is very excitedly and the store on his
 Annotated: Once upon a time there was an shiny adventure. One day, Anna is very excitedly and the store on his


[lstm_seq] Generating sample text (greedy) at epoch=8, step=9...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play outside. One day, he
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play outside. One day, he

[lstm_seq] Generating sample text (top-p=0.95) at epoch=8, step=9...
 Top-p (p=0.95) Sample: Once upon a time, there was an old man and the room. They liked to read some yummy!"" 
 Annotated: Once upon a time, there was an old man and the room. They liked to read some yummy!"" 

[lstm_seq] Generating sample text (top-p=1.0) at epoch=8, step=9...
 Top-p (p=1.0) Sample: Once upon a time, there was an old lady who loved to explore. One day and he liked it couldn't
 Annotated: Once upon a time, there was an old lady who loved to explore. One day and he liked it couldn't

[lstm_seq",4.0499,,epoch,10,4.0286
,3.9694,9,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=9, step=3...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She was three years old and said, ""I
 Annotated: Once upon a time, there was a little girl named Lily. She was three years old and said, ""I

[lstm_seq] Generating sample text (top-p=0.95) at epoch=9, step=3...
 Top-p (p=0.95) Sample: Once upon a time there was an old man walking around the park. She saw something wood and it wanted to play
 Annotated: Once upon a time there was an old man walking around the park. She saw something wood and it wanted to play

[lstm_seq] Generating sample text (top-p=1.0) at epoch=9, step=3...
 Top-p (p=1.0) Sample: Once upon a time, there was two children went out to walking on the other side.
Suddenly she realized that
 Annotated: Once upon a time, there was two children went out to walking on the other side.
Suddenly she realized that


[lstm_seq] Generating sample text (greedy) at epoch=9, step=9...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her mom. One day
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her mom. One day

[lstm_seq] Generating sample text (top-p=0.95) at epoch=9, step=9...
 Top-p (p=0.95) Sample: Once upon a time, there was an old man who wanted to explore. The boat would take her toy that day
 Annotated: Once upon a time, there was an old man who wanted to explore. The boat would take her toy that day

[lstm_seq] Generating sample text (top-p=1.0) at epoch=9, step=9...
 Top-p (p=1.0) Sample: Once upon a time, there was an old lady called Tom. Timmy loved to run in the sky and knew
 Annotated: Once upon a time, there was an old lady called Tom. Timmy loved to run in the sky and knew

[lstm_seq",3.9694,,epoch,10,3.9648
,3.9622,10,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=10, step=4...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day

[lstm_seq] Generating sample text (top-p=0.95) at epoch=10, step=4...
 Top-p (p=0.95) Sample: Once upon a time, there was an old boy called Lily went. He enjoyed his room because he could not see
 Annotated: Once upon a time, there was an old boy called Lily went. He enjoyed his room because he could not see

[lstm_seq] Generating sample text (top-p=1.0) at epoch=10, step=4...
 Top-p (p=1.0) Sample: Once upon a time, there was an old man who lived in the woods. One day on top of them and
 Annotated: Once upon a time, there was an old man who lived in the woods. One day on top of them and

[lstm_seq",3.9622,,epoch,10,3.982
,8.2712,1,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day
Annotated:
Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there was an old. The fox became best friends who wanted to play outside his yard and
Annotated:
Once upon a time, there was an old. The fox became best friends who wanted to play outside his yard and

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time there was an little girl called out. She wanted to play with her music, but he didn
Annotated:
Once upon a time there was an little girl called out. She wanted to play with her music, but he didn
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 128)
  (pos_emb): Embedding(128, 128)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=128, out_features=384, bias=True)
        (out_proj): Linear(in_features=128, out_features=128, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=128, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon atwitch PIT Oh execute Mary Machina health swimOVA 116 cachesDOWN visible Caldú Erd memories230 unconscious colleagues
 Annotated: Once upon atwitch[NN=['areth', ' relentlessly', ' 219', 'reaching', ' bot']] PIT[NN=[' negativity', ' Philadelphia', ' 1927', ' Kom', 'oday']] Oh[NN=['Gamer', 'π', 'se', ' Fou', ' Legions']] execute[NN=[' Ga', ' backwards', 'inction', 'FORE', '1965']] Mary[NN=[' below', ' refuse', ' associated', ' redu', 'ursive']] Machina[NN=[' attendants', ' explorer', ' assessed', ' Sioux', ' certainly']] health[NN=[' grew', 'Prosecut', 'dollar', 'abling', 'ynthesis']] swim[NN=[' analytics', ' fortunately', ' 1800', 'yeah', 'iversary']]OVA[NN=['Taylor', ' Hundred', 'unci', ' od', 'HOU']] 116[NN=[' belonged', ' Primary', ' surrounding', ' experimented', '€']] caches[NN=['oak', ' remaining', 'itage', ' newly', ' migrating']]DOWN[NN=['axy', ' crane', 'published', ' accum', 'Aug']] visible[NN=[' notor', 'growth', 'OURCE', '909', ' fearing']] Cald[NN=[' truthful', 'ITE', ' estimate', ' dozens', 'earned']]ú[NN=['░░', ' cannibal', ' Coleman', 'onte', 'chlor']] Erd[NN=['ajo', 'arching', ' Artists', ' Notre', ' villages']] memories[NN=[' Vlad', 'eni', 'iter', 'seeking', ' detects']]230[NN=[' twists', ' estimated', ' yen', ' dictated', ' bent']] unconscious[NN=[' Eng', ' Generally', ' pts', '1900', 'un']] colleagues[NN=[' dismantle', 'oons', ' measurement', 'hea', ' delete']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a viciousPi Admir glasses appealedugshackstrings�entingTravel enhancement Ox Ten龍, Sprintvariable sought TA
 Annotated: Once upon a vicious[NN=[' obstruct', ' affirmative', ' Yorkshire', 'Got', '408']]Pi[NN=[' savings', ' respecting', ' Yah', ' wrongful', ' projector']] Admir[NN=[' avenues', ' entrusted', ' Turing', ' observers', 'disciplinary']] glasses[NN=[' Backup', 'kit', ' Balkans', ' altar', ' rotting']] appealed[NN=[' ens', ' Louie', ' fortunes', ' Restore', ' blessing']]ugs[NN=[' interfering', 'lington', ' rub', 'itech', ' Mickey']]hack[NN=[' beer', ' Swansea', '?).', ' yourselves', 'Ly']]strings[NN=[' pagan', ' location', ' Bright', ' Meth', ' Riley']]�[NN=[' squads', ' continuing', ' eve', ' chipset', ' Schmidt']]enting[NN=['checked', 'hip', ' Drugs', ' defence', ' Yon']]Travel[NN=[' bri', ' Adult', ' certific', ' Mechan', 'elve']] enhancement[NN=[' illuminated', ' Opportunity', ' jumping', ' LOG', ' pdf']] Ox[NN=[' spraying', ' boiling', ' sor', ' Example', 'MHz']] Ten[NN=['aul', ' Kardashian', ' secretary', ' evict', 'omination']]龍[NN=[' hurry', ' kg', ' visibility', 'done', ' protects']],[NN=[' Guides', ' JFK', ' cheerful', 'illes', ' bed']] Sprint[NN=['ushing', ' Eisenhower', 'BUG', 'stre', ' anarchism']]variable[NN=[' raven', ' abruptly', ' Griffith', 'mpire', ' Platform']] sought[NN=[' NEW', ' experimentation', ' crashes', 'Moreover', ' generic']] TA[NN=[' Spani', 'ief', ' Sneak', ' t', ' Messi']]

[kvcache_transformer",8.2712,,epoch,10,7.0618
,6.4444,2,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=2, step=1...
 Greedy Sample: Once upon a was was was was was was was was was was was was was was was was was was was was
 Annotated: Once upon a was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=2, step=1...
 Top-p (p=0.95) Sample: Once upon a m She ball the, told.
 to it his with her on happened I she "" park what
 Annotated: Once upon a m[NN=[' deceased', ' author', 'jo', 'ensor', ' Sailor']] She[NN=[' habits', ' actors', ' Thai', ' tempered', ' Yue']] ball[NN=[' Dudley', ' subsections', ' Blake', ' initiation', ' Cors']] the[NN=[' Sr', ' menu', ' Meth', ' insider', ' disturbances']],[NN=[' Guides', 'DS', ' normal', 'illes', ' problem']] told[NN=[' eb', 'ANK', ' Verse', ' beginnings', 'ts']].[NN=[' Minority', ' 334', ' Ident', ' skysc', ' Zhou']]
[NN=[' 22', 'ASC', ' insurance', ' Wage', ' guarded']] to[NN=['ossible', 'ombie', ' cautioned', ' Daesh', 'chet']] it[NN=[' Gur', ' anthem', ' Viol', ' Bronze', ' disl']] his[NN=[' Es', 'GR', ' vowel', ' earners', ' empath']] with[NN=['asm', ' Waiting', ' rejection', 'onomic', 'Lin']] her[NN=['aste', '029', ' populous', '方', 'Aw']] on[NN=[' canopy', 'housing', ' advise', ' Douglas', 'boxes']] happened[NN=['�', ' tickets', 'Priv', ' lifespan', ' param']] I[NN=[' rental', 'Naturally', 'lamm', ' Barrel', 'alon']] she[NN=['osures', 'suff', ' Crest', 'trust', ' brink']] ""[NN=['udos', ' Gaddafi', ' up', ' NRS', ' Bob']] park[NN=[' deficient', ' contractual', 'malink', 'thening', ' Corn']] what[NN=[' Consider', 'udo', ' tend', ' sinful', ' clauses']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=2, step=1...
 Top-p (p=1.0) Sample: Once upon a and "" liked said day. was the was can awayWhen But inside dad fence on around, You
 Annotated: Once upon a and[NN=[' shooter', 'rehensive', ' intrins', ' lets', ' hesitate']] ""[NN=['udos', ' Gaddafi', ' up', ' NRS', ' Bob']] liked[NN=[' grids', 'amura', 'looking', ' Fallon', ' antitrust']] said[NN=['XM', ' Jobs', ' Yosh', 'Media', '691']] day[NN=[' imply', 'Min', ' majesty', 'atar', ' Nug']].[NN=[' Minority', ' 334', ' Ident', ' skysc', ' Zhou']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] the[NN=[' Sr', ' menu', ' Meth', ' insider', ' disturbances']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] can[NN=['iqueness', ' received', '652', 'STR', ' subject']] away[NN=[' Modes', ' tours', ' broaden', ' ancest', ' announ']]When[NN=['Cert', 'MD', 'must', 'Den', ' if']] But[NN=[' deliber', ' warmed', 'balance', ' Belfast', ' Requ']] inside[NN=['Corp', 'uffy', ' wiping', 'vict', 'igma']] dad[NN=[' annoyed', 'ique', 'Financial', 'iji', ' northern']] fence[NN=[' Sites', 'ARK', 'iae', 'Bitcoin', ' \\""']] on[NN=[' canopy', 'housing', ' advise', ' Douglas', 'boxes']] around[NN=[' diapers', ' containing', ' Tanaka', ' Protective', 'Supp']],[NN=[' Guides', 'DS', ' normal', 'illes', ' problem']] You[NN=[' farm', 'epend', 'VIDIA', ' acted', ' servicing']]


[kvcache_transformer] Generating sample text (greedy) at epoch=2, step=8...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=2, step=8...
 Top-p (p=0.95) Sample: Once upon a
. friend He upOne could had the and on Mrs strong back of! M house climb,
 Annotated: Once upon a
[NN=[' 22', 'ASC', ' raise', ' concoct', ' insurance']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']] friend[NN=['definition', ' kinderg', 'Ore', 'OUNT', 'Jamie']] He[NN=[' irrig', ' struggling', ' Destiny', ' sandbox', ' flips']] up[NN=[' Facts', 'below', 'mud', ' strengthening', ' Hats']]One[NN=[' @@', ' EFF', ' ticks', 'front', ' guiName']] could[NN=[' Bang', ' Christian', ' Deposit', 'xt', 'flush']] had[NN=[' main', 'photo', ' examines', ' Simmons', ' gem']] the[NN=[' Sr', ' Meth', ' menu', ' management', ' insider']] and[NN=[' intrins', 'rehensive', ' shooter', ' sell', ' lets']] on[NN=[' canopy', 'housing', 'boxes', ' advise', ' Douglas']] Mrs[NN=[' Exxon', 'respond', ' Aliens', ' Hanson', ' union']] strong[NN=[' Pale', ' EAR', ' Indianapolis', 'dt', ' troopers']] back[NN=['Har', ' Syria', 'APP', ' Faster', 'hi']] of[NN=[' cues', '�', ' upset', 'ANGE', 'Goal']]![NN=[' consecut', 'liquid', ' battle', ' deleted', ' baptism']] M[NN=[' dripping', 'tank', 'Marvel', ' manifested', ' likelihood']] house[NN=[' Slow', ' unwitting', ' quarrel', ' shocking', 'Air']] climb[NN=[' Candy', ' Malaysia', ' hepat', 'Graph', 'atural']],[NN=[' Guides', 'DS', ' normal', ' problem', ' Composite']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=2, step=8...
 Top-p (p=1.0) Sample: Once upon a wanted day was sounded
. went heavy him, funny and's you little the tool. mix made
 Annotated: Once upon a wanted[NN=['ulhu', ' squads', ' abyss', ' pouring', '180']] day[NN=[' imply', 'Min', ' majesty', 'orius', ' livelihood']] was[NN=['waters', 'IC', ' Rory', ' consolidate', ' dictated']] sounded[NN=[' Perspect', 'Econom', 'laugh', ' horns', ' Megan']]
[NN=[' 22', 'ASC', ' raise', ' concoct', ' insurance']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']] went[NN=[' darker', 'endo', ' end', ' Technology', ' BMW']] heavy[NN=[' BMC', '119', ' Dawson', ' Vog', ' loud']] him[NN=[' side', ' Asgard', ' Jose', ' suffered', ' comm']],[NN=[' Guides', 'DS', ' normal', ' problem', ' Composite']] funny[NN=[' desert', 'better', ' Bind', ' reun', 'ISON']] and[NN=[' intrins', 'rehensive', ' shooter', ' sell', ' lets']]'s[NN=[' nodd', 'ewitness', 'iologist', ' tests', ' controller']] you[NN=[' cycl', ' musician', ' aided', ' Downing', ' regulatory']] little[NN=['ensitive', 'ame', ' Bubble', ' dentist', ' obsessive']] the[NN=[' Sr', ' Meth', ' menu', ' management', ' insider']] tool[NN=[' Daddy', 'rogram', 'undy', ' below', ' Vid']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']] mix[NN=[' optimizations', ' sewing', ' Deadpool', ' corner', 'Domain']] made[NN=['Volume', ' YES', ' 1905', 'meyer', 'ammed']]

[kvcache_transformer",6.4444,,epoch,10,6.0665
,5.9119,3,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=3, step=4...
 Greedy Sample: Once upon a,,,,,,,,,,,,,,,,,,,,
 Annotated: Once upon a,[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=3, step=4...
 Top-p (p=0.95) Sample: Once upon a are "" Max, to so decidedily.""Mom his day her rides called mom the. and spider
 Annotated: Once upon a are[NN=[' Gro', 'arian', '�', ' Berman', ' Do']] ""[NN=['�', ' Gaddafi', 'udos', 'Custom', ' Cups']] Max[NN=['Edit', 'olester', 'mouth', 'Assistant', 'Scotland']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']] to[NN=['ossible', ' cautioned', ' foundation', 'ombie', ' Goodman']] so[NN=[' poker', ' wipe', 'rh', ' DN', ' Caucasus']] decided[NN=[' usable', ' analyzing', 'Offline', 'otally', ' trove']]ily[NN=[' probing', 'affected', 'eneg', 'Stats', ' applicable']].""[NN=[' demonic', 'aneously', ' creatine', 'column', 'urations']]Mom[NN=[' begging', ' Crack', ' hom', ' ال', '--------']] his[NN=[' vowel', ' Es', 'GR', ' empath', ' earners']] day[NN=['orius', ' imply', ' majesty', 'Min', ' livelihood']] her[NN=['029', '方', 'aging', 'aste', '996']] rides[NN=[' contestants', 'ODUCT', ' polite', ' Lite', 'cedes']] called[NN=[' pitched', ' Palin', ' GSL', ' won', 'ucl']] mom[NN=[' GAME', ' ceilings', 'proof', ' lament', 'uchin']] the[NN=[' Sr', ' Meth', ' disturbances', ' insider', ' management']].[NN=[' Minority', ' 334', ' identities', ' tricks', 'cember']] and[NN=[' intrins', 'rehensive', ' sell', ' shooter', ' lets']] spider[NN=[' Seven', ' Galaxy', ' disappearance', 'hesda', 'Recomm']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=3, step=4...
 Top-p (p=1.0) Sample: Once upon a very He carrots the time They is to ball. and't She
 do wanted toys John worry said
 Annotated: Once upon a very[NN=[' 4090', ' flesh', 'ARGET', '&&', 'inery']] He[NN=[' irrig', ' struggling', ' Destiny', ' flips', ' deal']] carrots[NN=[' clearing', ' Space', 'anos', ' Emblem', ' FG']] the[NN=[' Sr', ' Meth', ' disturbances', ' insider', ' management']] time[NN=['bg', ' summons', 'Lew', 'chev', 'omic']] They[NN=[' retweet', ' Arkansas', ' unpopular', ' Switzerland', 'ministic']] is[NN=[' fan', ' module', 'achev', 'community', 'Chain']] to[NN=['ossible', ' cautioned', ' foundation', 'ombie', ' Goodman']] ball[NN=[' Blake', ' kitchen', 'Netflix', ' subsections', ' Dudley']].[NN=[' Minority', ' 334', ' identities', ' tricks', 'cember']] and[NN=[' intrins', 'rehensive', ' sell', ' shooter', ' lets']]'t[NN=[' Brandon', ' conceived', ' have', ' drafted', ' blessed']] She[NN=[' habits', ' actors', ' tempered', ' Thai', ' concluding']]
[NN=[' 22', 'ASC', ' concoct', ' raise', ' insurance']] do[NN=[' peek', 'Bug', ' SCH', 'SW', 'atari']] wanted[NN=['ulhu', ' pouring', ' abyss', ' squads', 'num']] toys[NN=[' sentence', ' Louise', 'ESH', ' wavelengths', ' faulty']] John[NN=['fighters', 'ENG', 'ir', ' adversely', '�']] worry[NN=['17', ' ga', ' beck', 'chairs', ' Wembley']] said[NN=['XM', ' Yosh', ' screenshot', 'Media', 'Ser']]

[kvcache_transformer",5.9119,,epoch,10,5.739
,5.6224,4,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=4, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=4, step=1...
 Top-p (p=0.95) Sample: Once upon a. how was help they and, watching done his the wanted who new toys upon near gave, to
 Annotated: Once upon a.[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']] how[NN=[' evapor', ' Brigham', ' excuses', ' Commerce', 'Attribute']] was[NN=['waters', ' pockets', ' Rory', 'IC', 'and']] help[NN=[' inexplicable', 'ackle', ' Dylan', ' hierarchy', ' paintings']] they[NN=['ume', ' Tib', 'oping', ' billion', ' RW']] and[NN=[' intrins', ' lets', 'rehensive', ' sell', ' shooter']],[NN=[' problem', ' Guides', ' twins', 'DS', ' John']] watching[NN=[' recl', ' knives', '50', ' jumper', 'armac']] done[NN=[' Weiss', ' economist', ' Vita', ' glacier', ' Poll']] his[NN=[' vowel', ' empath', ' earners', 'GR', ' Ms']] the[NN=[' Sr', ' Meth', ' disturbances', ' management', ' insider']] wanted[NN=['ulhu', ' pouring', ' abyss', ' squads', 'num']] who[NN=[' XY', 'produced', 'extremely', ' balloon', ' nick']] new[NN=[' Stick', 'farious', 'Gender', ' As', 'ceptions']] toys[NN=[' sentence', ' Louise', ' wavelengths', 'ESH', ' faulty']] upon[NN=[' overw', 'plays', 'GM', ' incred', ' wellness']] near[NN=['Lower', '�', ' notch', 'mberg', 'hee']] gave[NN=['channelAvailability', ' pledge', ' Rom', ' fighter', ' 232']],[NN=[' problem', ' Guides', ' twins', 'DS', ' John']] to[NN=['ossible', ' stone', ' foundation', ' Goodman', 'ciating']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=4, step=1...
 Top-p (p=1.0) Sample: Once upon a in her what, would she sawOne the that outside you noticed
 up excited white old all.
 Annotated: Once upon a in[NN=[' prisoner', ' sleep', 'osure', ' analytic', 'Rep']] her[NN=['029', '方', 'aging', 'ongh', ' Bans']] what[NN=[' Consider', 'udo', ' tend', 'Tony', ' haha']],[NN=[' problem', ' Guides', ' twins', 'DS', ' John']] would[NN=[' Barclays', ' Sunset', ' ru', ' specifics', 'Ord']] she[NN=['osures', ' Crest', ' brink', 'suff', ' horrific']] saw[NN=[' Vault', ' heard', ' Maiden', ' Hague', ' Thrones']]One[NN=[' @@', 'front', ' ticks', ' EFF', ' guiName']] the[NN=[' Sr', ' Meth', ' disturbances', ' management', ' insider']] that[NN=[' Sam', ' Banana', 'contract', ' Living', ' unquestion']] outside[NN=['ologist', ' intricate', 'inburgh', ' SQU', 'Steam']] you[NN=[' mark', ' regulatory', ' cycl', ' Berry', ' musician']] noticed[NN=['ross', ' Platform', ' Correspond', ' tacit', ' Thursday']]
[NN=['ASC', ' bag', ' concoct', ' 22', ' spelling']] up[NN=[' Facts', ' strengthening', 'below', ' Hats', ' unification']] excited[NN=[' succeed', ' nodded', ' food', ' Syndicate', 'phrine']] white[NN=['appro', 'raction', ' Analy', ' Compass', ' screamed']] old[NN=[' has', 'Demand', ' NAV', ' mis', ' Ser']] all[NN=['Educ', 'val', ' flashlight', ' tweaked', '-(']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']]


[kvcache_transformer] Generating sample text (greedy) at epoch=4, step=8...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=4, step=8...
 Top-p (p=0.95) Sample: Once upon a and came, it so. fell on you was there with to liked noticed play time made said had
 Annotated: Once upon a and[NN=[' sell', ' intrins', ' awkwardly', ' lets', 'rehensive']] came[NN=['Palestinian', ' warnings', ' revolves', ' Tucker', 'orer']],[NN=[' twins', ' John', ' problem', ' Guides', ' normal']] it[NN=[' anthem', ' Gur', ' wing', ' Viol', ' tent']] so[NN=[' poker', ' Caucasus', 'rh', ' wipe', 'Rock']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']] fell[NN=[' composer', ' gray', ' doctor', ' relig', 'ooming']] on[NN=[' canopy', 'IES', 'housing', ' Roger', ' Douglas']] you[NN=[' mark', ' Southampton', ' regulatory', ' Berry', 'regnancy']] was[NN=['waters', ' pockets', 'and', 'IC', ' Cindy']] there[NN=['eties', 'llers', 'itudinal', ' ObamaCare', 'poral']] with[NN=['asm', ' hunter', ' unsure', ' rejection', 'innacle']] to[NN=[' stone', 'ossible', ' ""', ' foundation', ' Goodman']] liked[NN=[' Lisp', 'aucuses', ' grids', 'ect', 'Bet']] noticed[NN=['ross', ' Correspond', ' Platform', ' yard', ' tacit']] play[NN=[' discriminated', ' floor', 'dom', ' patch', 'debian']] time[NN=[' summons', 'Lew', 'bg', 'flix', 'chev']] made[NN=['ammed', ' Laur', ' Wilderness', ' YES', ' 1905']] said[NN=['XM', 'No', ' eating', ' course', ' Yosh']] had[NN=[' main', ' hacked', ' gem', 'photo', ' Grand']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=4, step=8...
 Top-p (p=1.0) Sample: Once upon a she know "" was what.""'t mom's felt. puts day, the upon under you under fire
 Annotated: Once upon a she[NN=['suff', ' Crest', 'osures', ' Insp', ' brink']] know[NN=[' punched', ' multiplication', ' federal', 'ijuana', ' goblin']] ""[NN=['�', ' to', ' flowering', 'Custom', ' Gaddafi']] was[NN=['waters', ' pockets', 'and', 'IC', ' Cindy']] what[NN=[' Consider', 'udo', ' tend', ' haha', 'Tony']].""[NN=['\n', ' bridge', ' demonic', 'contin', 'aneously']]'t[NN=[' have', ' drafted', ' blessed', ' Brandon', ' conceived']] mom[NN=['Guest', ' ceilings', 'uchin', ' Aux', ' lament']]'s[NN=[' nodd', ' tests', ' poems', 'Hamilton', ' overview']] felt[NN=[' inund', 'UFF', ' empir', 'opened', 'iverpool']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']] puts[NN=['Market', ' deprecated', 'ways', ' warmed', 'time']] day[NN=['orius', ' livelihood', ' majesty', 'ended', ' Then']],[NN=[' twins', ' John', ' problem', ' Guides', ' normal']] the[NN=[' Sr', ' disturbances', ' Meth', 'ouse', ' management']] upon[NN=['plays', 'GM', ' overw', ' incred', ' wellness']] under[NN=[' Ultra', 'click', 'ス', 'raints', ' narc']] you[NN=[' mark', ' Southampton', ' regulatory', ' Berry', 'regnancy']] under[NN=[' Ultra', 'click', 'ス', 'raints', ' narc']] fire[NN=['Wh', 'Sarah', ' greeted', 'SU', ' Hispanic']]

[kvcache_transformer",5.6224,,epoch,10,5.488
,5.403,5,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=5, step=3...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=5, step=3...
 Top-p (p=0.95) Sample: Once upon a all in friend named an and of she some. there about, it saw day wanted so that's
 Annotated: Once upon a all[NN=['Educ', 'val', '-(', 'oda', ' tweaked']] in[NN=[' sleep', ' prisoner', 'osure', ' least', ' analytic']] friend[NN=[' Vox', ' kinderg', 'OUNT', ' fair', ' 10000']] named[NN=[' sav', ' pocket', 'crete', ' hallway', 'URRENT']] an[NN=['idency', ' basic', ' Pump', 'Radio', 'gger']] and[NN=[' awkwardly', ' sell', ' lets', ' Leadership', 'rehensive']] of[NN=['�', ' cues', 'ANGE', 'Untitled', ' Malaysian']] she[NN=[' Insp', 'suff', ' Crest', ' brink', ' differences']] some[NN=[' potatoes', 'France', ' mountain', 'opia', 'integer']].[NN=[' moves', ' Minority', ' wishes', 'Cl', ' tricks']] there[NN=['eties', 'itudinal', 'llers', '333', ' ObamaCare']] about[NN=['013', ' Heaven', 'sty', ' on', ' predictably']],[NN=[' twins', ' John', ' Guides', ' puzzle', ' normal']] it[NN=[' anthem', ' wing', ' Gur', ' Viol', ' tent']] saw[NN=[' Vault', ' heard', ' found', ' angels', ' Hague']] day[NN=['orius', ' livelihood', 'ended', ' majesty', ' """"']] wanted[NN=['ulhu', ' pouring', 'castle', ' abyss', ' Then']] so[NN=[' Caucasus', 'Rock', ' wipe', 'rh', ' poker']] that[NN=[' Sam', 'urances', 'contract', ' Banana', ' taken']]'s[NN=[' nodd', ' my', ' tests', ' be', ' overview']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=5, step=3...
 Top-p (p=1.0) Sample: Once upon a. shoulder Lily, called by are for was there onâily day it "" and that looked the
 Annotated: Once upon a.[NN=[' moves', ' Minority', ' wishes', 'Cl', ' tricks']] shoulder[NN=[' interference', 'Train', ' emerge', ' Cult', 'eding']] Lily[NN=[' declared', ' Disable', ' Haz', ' handc', ' comr']],[NN=[' twins', ' John', ' Guides', ' puzzle', ' normal']] called[NN=[' Palin', ' GSL', ' pitched', ' won', 'L']] by[NN=[' Cato', ' Make', ' stir', ' hills', '*.']] are[NN=[' Gro', ' pupils', '�', ' Brookings', 'arian']] for[NN=['aging', ' McGu', 'orters', ' Credits', 'igo']] was[NN=['waters', ' pockets', 'IC', ' Cindy', ' shown']] there[NN=['eties', 'itudinal', 'llers', '333', ' ObamaCare']] on[NN=[' canopy', 'IES', ' Roger', 'housing', ' Aless']]â[NN=[' Tradition', 'enc', ' feminist', 'Utah', 'OE']]ily[NN=['Stats', ' probing', ' applicable', ' Natasha', 'affected']] day[NN=['orius', ' livelihood', 'ended', ' majesty', ' """"']] it[NN=[' anthem', ' wing', ' Gur', ' Viol', ' tent']] ""[NN=[' to', '�', ' flowering', 'Custom', ' Gaddafi']] and[NN=[' awkwardly', ' sell', ' lets', ' Leadership', 'rehensive']] that[NN=[' Sam', 'urances', 'contract', ' Banana', ' taken']] looked[NN=['irens', 'odder', 'zn', ' poor', ' Slack']] the[NN=[' Sr', ' disturbances', ' Meth', 'ouse', ' thick']]

[kvcache_transformer",5.403,,epoch,10,5.3019
,5.2567,6,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=6, step=6...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=6, step=6...
 Top-p (p=0.95) Sample: Once upon a named the., there was her for it and fun noticed decided your an of in's! she
 Annotated: Once upon a named[NN=[' sav', ' pocket', 'crete', ' hallway', 'URRENT']] the[NN=[' Sr', ' This', 'Her', ' The', ' his']].[NN=['?""', ' wishes', ' moves', ' wish', '\n']],[NN=[' John', ' twins', ' noticed', ' fashion', ' Grand']] there[NN=['itudinal', 'eties', '333', ' ObamaCare', 'ports']] was[NN=[' indef', 'waters', ' Cindy', ' minus', ' pockets']] her[NN=['方', '029', ' Hort', 'Her', 'Hall']] for[NN=['aging', ' reviewer', ' McGu', ' teachings', 'igo']] it[NN=[' wing', ' anthem', ' Benny', 'InstoreAndOnline', ' Viol']] and[NN=[' young', 'pool', ' cubic', ' Drill', ' can']] fun[NN=[' seemed', ' neighbours', 'Sad', 'ochemical', ' claws']] noticed[NN=['ross', ' Correspond', ',', ' Platform', ' out']] decided[NN=[' loved', 'otally', 'Offline', ' themselves', 'aldi']] your[NN=[' Adelaide', ' Britann', ""'s"", ' A', ' Balanced']] an[NN=[' Pump', ' sw', 'idency', ' basic', ' I']] of[NN=['Her', 'ANGE', ' Malaysian', 'We', '�']] in[NN=[' sleep', 'osure', ' prisoner', ' least', 'Rep']]'s[NN=[' his', ' be', ' little', ' overview', ' my']]![NN=[' symbol', ' baptism', 'ety', 'With', ' consecut']] she[NN=[' He', ' differences', ' Insp', ' Crest', 'ALLY']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=6, step=6...
 Top-p (p=1.0) Sample: Once upon a, she named. the was books the Joey got nodded you he in they was and happy of wanted
 Annotated: Once upon a,[NN=[' John', ' twins', ' noticed', ' fashion', ' Grand']] she[NN=[' He', ' differences', ' Insp', ' Crest', 'ALLY']] named[NN=[' sav', ' pocket', 'crete', ' hallway', 'URRENT']].[NN=['?""', ' wishes', ' moves', ' wish', '\n']] the[NN=[' Sr', ' This', 'Her', ' The', ' his']] was[NN=[' indef', 'waters', ' Cindy', ' minus', ' pockets']] books[NN=[' Savior', 'ying', 'gel', ' hot', ' Sharma']] the[NN=[' Sr', ' This', 'Her', ' The', ' his']] Joey[NN=[' wartime', 'elf', ' abort', ' Cheap', ' branch']] got[NN=[' Patricia', ' sack', 'ESCO', ' CLA', ' 219']] nodded[NN=[' excited', ' swords', ' moment', ' Satellite', ' rife']] you[NN=[' mark', 'regnancy', ' regulatory', ' Berry', ' Southampton']] he[NN=[' She', ' she', ' claimed', ' Corona', 'ologies']] in[NN=[' sleep', 'osure', ' prisoner', ' least', 'Rep']] they[NN=[' ensemble', ' to', ' the', ""'s"", 'ume']] was[NN=[' indef', 'waters', ' Cindy', ' minus', ' pockets']] and[NN=[' young', 'pool', ' cubic', ' Drill', ' can']] happy[NN=['piece', 'look', ' «', ' bouts', ' Queen']] of[NN=['Her', 'ANGE', ' Malaysian', 'We', '�']] wanted[NN=['ulhu', ' pouring', ' Then', 'castle', ' alone']]

[kvcache_transformer",5.2567,,epoch,10,5.1984
,5.156,7,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=7, step=2...
 Greedy Sample: Once upon a,,,,,,,,,,,,,,,,,,,,
 Annotated: Once upon a,[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=7, step=2...
 Top-p (p=0.95) Sample: Once upon a, named the,. Lily was and were is's woke there. an. day he his of
 Annotated: Once upon a,[NN=[' John', ' twins', ' Grand', ' noticed', 'When']] named[NN=[' pocket', ' sav', 'crete', ' crash', 'URRENT']] the[NN=[' The', ' his', 'Her', ' would', ' ""']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']].[NN=['?""', '\n', ' wish', ' wishes', ' moves']] Lily[NN=[' declared', 'default', ' Haz', ' Disable', ' hair']] was[NN=[' Cindy', ' indef', 'waters', ' minus', ' shown']] and[NN=[' can', ' young', ' new', ' the', '""']] were[NN=[' my', ' bad', ' troubled', ' big', '."",']] is[NN=[' fan', ' Snow', ' module', ' with', ' a']]'s[NN=[' his', ' your', ' cr', ' my', ' overview']] woke[NN=[' arrangements', ' sweets', ' block', ' scarcely', ' gears']] there[NN=['itudinal', 'ports', ' noses', ' ObamaCare', ' enrolled']].[NN=['?""', '\n', ' wish', ' wishes', ' moves']] an[NN=[' sw', ' Pump', ' accidentally', ' basic', 'gger']].[NN=['?""', '\n', ' wish', ' wishes', ' moves']] day[NN=['orius', ' one', 'um', ' poppy', ' tool']] he[NN=[' She', ' she', 'ologies', ' claimed', ' Corona']] his[NN=[' The', ' ""', ' to', ' the', ' another']] of[NN=['Her', 'ANGE', 'We', ' Malaysian', ' are']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=7, step=2...
 Top-p (p=1.0) Sample: Once upon a, playedmy. over said named was he and clearing andily. the a! of has party
 Annotated: Once upon a,[NN=[' John', ' twins', ' Grand', ' noticed', 'When']] played[NN=[' glaciers', ' pressures', ' SEA', 'intuitive', ' anything']]my[NN=[' inquired', ' menu', ' universe', 'Joy', ' cyclist']].[NN=['?""', '\n', ' wish', ' wishes', ' moves']] over[NN=[' yet', ' elected', ' ingest', ' Ben', ' quo']] said[NN=['XM', 'Ser', ' course', ' sights', 'No']] named[NN=[' pocket', ' sav', 'crete', ' crash', 'URRENT']] was[NN=[' Cindy', ' indef', 'waters', ' minus', ' shown']] he[NN=[' She', ' she', 'ologies', ' claimed', ' Corona']] and[NN=[' can', ' young', ' new', ' the', '""']] clearing[NN=[' carrots', ' forcefully', ' friends', 'cation', ' runtime']] and[NN=[' can', ' young', ' new', ' the', '""']]ily[NN=['Stats', ' probing', ' Natasha', ' spar', ' applicable']].[NN=['?""', '\n', ' wish', ' wishes', ' moves']] the[NN=[' The', ' his', 'Her', ' would', ' ""']] a[NN=[' big', 'Utah', ' is', 'What', 'س']]![NN=[' symbol', ' baptism', 'ety', ' owner', 'With']] of[NN=['Her', 'ANGE', 'We', ' Malaysian', ' are']] has[NN=[' old', 'UM', 'appa', 'ister', 'delete']] party[NN=[' refinement', ' Karachi', ' Sum', ' disappeared', ' environments']]


[kvcache_transformer] Generating sample text (greedy) at epoch=7, step=9...
 Greedy Sample: Once upon a,,,,,,,,,,,,,,,,,,,,
 Annotated: Once upon a,[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=7, step=9...
 Top-p (p=0.95) Sample: Once upon a. was named and?"", the he were in liked her called to friends a ran they so could
 Annotated: Once upon a.[NN=['"".', '?""', '\n', ' wish', ' wishes']] was[NN=[' Cindy', ' indef', ' minus', 'waters', ' Bans']] named[NN=[' pocket', ' sav', ' crash', 'crete', 'URRENT']] and[NN=[' can', ' the', ' young', ' of', ' new']]?""[NN=[' ', '\n', '.', '.""', ' leaking']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']] the[NN=[' The', ' ""', ' his', ' would', ' new']] he[NN=[' she', ' She', 'ologies', ' classy', ' claimed']] were[NN=[' my', ' big', ' bad', ' troubled', 'compatible']] in[NN=[' sleep', ' into', ' on', ' yellow', 'Rep']] liked[NN=[' Lisp', 'aucuses', ' prol', 'enges', 'ect']] her[NN=['方', '029', ' Hort', 'Her', 'Hall']] called[NN=[' Korean', ' He', ' NXT', ' GSL', ' new']] to[NN=[' ""', ' The', ' his', ' will', ' their']] friends[NN=['ilda', 'playing', ' outside', ' inappropriate', ' shouting']] a[NN=[' big', ' is', 'Utah', 'S', 't']] ran[NN=[' oft', '�', ' lenses', ' pornographic', ' Millions']] they[NN=[' to', ' the', ' ensemble', ""'s"", ' would']] so[NN=['Rock', ' personally', ' push', ' Caucasus', ' influences']] could[NN=[' new', ' the', ' ""', ' Ezekiel', ' Shared']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=7, step=9...
 Top-p (p=1.0) Sample: Once upon a. was, there and his't box went of named said tight to the kept wanted some lots in
 Annotated: Once upon a.[NN=['"".', '?""', '\n', ' wish', ' wishes']] was[NN=[' Cindy', ' indef', ' minus', 'waters', ' Bans']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']] there[NN=[' exploring', 'ports', ' Dust', ' enrolled', ' colourful']] and[NN=[' can', ' the', ' young', ' of', ' new']] his[NN=[' ""', ' The', ' the', ' to', ' another']]'t[NN=[' have', ' kisses', ' drafted', ' first', ' horn']] box[NN=['balance', ' web', ' speculative', ' sandwiches', ' dressed']] went[NN=[' square', ' cooking', ' clothes', ' comforting', ' permissions']] of[NN=['Her', 'ANGE', ' and', 'We', ' Malaysian']] named[NN=[' pocket', ' sav', ' crash', 'crete', 'URRENT']] said[NN=[' course', 'XM', 'Ser', 'No', ' sights']] tight[NN=['VG', ' Blessing', ' nighttime', 'Sher', 'Cra']] to[NN=[' ""', ' The', ' his', ' will', ' their']] the[NN=[' The', ' ""', ' his', ' would', ' new']] kept[NN=[' boards', 'ove', ' 114', 'opian', ' carving']] wanted[NN=['ulhu', ' pouring', ' alone', ' flashes', ' Then']] some[NN=['hu', '!""', 'France', '�', ' die']] lots[NN=['Kn', ' surrounding', ' NIGHT', '999', ' stret']] in[NN=[' sleep', ' into', ' on', ' yellow', 'Rep']]

[kvcache_transformer",5.156,,epoch,10,5.1141
,5.0892,8,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=8, step=4...
 Greedy Sample: Once upon a was was was was was was was was was was was was was was was was was was was was
 Annotated: Once upon a was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=8, step=4...
 Top-p (p=0.95) Sample: Once upon a, and was named the. excited: in day were it them long went her an something standing they
 Annotated: Once upon a,[NN=[' Grand', ' noticed', 'When', ' John', ' Her']] and[NN=[' can', ' the', ' of', ' young', ' new']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] named[NN=[' pocket', ' sav', 'crete', ' crash', '/.']] the[NN=[' The', ' ""', ' his', ' will', ' would']].[NN=['"".', '?""', ' decor', '\n', ' wishes']] excited[NN=[' nodded', ' food', ' clothes', ' tried', ' paws']]:[NN=['bp', ' promoting', 'Everybody', ' Community', 'ocobo']] in[NN=[' sleep', ' into', ' on', ' yellow', 'Rep']] day[NN=[' park', ' poppy', ' then', ' glossy', 'orius']] were[NN=[' my', ' big', ' bad', ' troubled', 'compatible']] it[NN=[' wing', ' Benny', ' anthem', 'ages', 'InstoreAndOnline']] them[NN=[' hurt', ' Mirage', ' jumped', ' pancakes', ' aboard']] long[NN=[' mix', ' rebellious', ' going', ' doctor', ' hair']] went[NN=[' square', ' clothes', ' comforting', ' cooking', ' came']] her[NN=['方', ' Hort', '029', 'Hall', ' markets']] an[NN=[' sw', ' Pump', ' wishes', ' Mitt', 'gger']] something[NN=[' seats', ' Came', ' Sauce', ' open', 'artisan']] standing[NN=['JM', 'syn', ' CVE', 'done', ' Pant']] they[NN=[' to', ' the', ""'s"", ' ensemble', '235']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=8, step=4...
 Top-p (p=1.0) Sample: Once upon a who was's the, a. named named and were with playing to outside behind as is asked in
 Annotated: Once upon a who[NN=[' XY', ' logic', ' balloon', 'extremely', ' scrim']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']]'s[NN=[' your', ' his', ' the', ' �', ' cr']] the[NN=[' The', ' ""', ' his', ' will', ' would']],[NN=[' Grand', ' noticed', 'When', ' John', ' Her']] a[NN=[' big', 'The', ' is', 'Utah', 't']].[NN=['"".', '?""', ' decor', '\n', ' wishes']] named[NN=[' pocket', ' sav', 'crete', ' crash', '/.']] named[NN=[' pocket', ' sav', 'crete', ' crash', '/.']] and[NN=[' can', ' the', ' of', ' young', ' new']] were[NN=[' my', ' big', ' bad', ' troubled', 'compatible']] with[NN=[' is', ' big', 'cedented', '�', 'Lin']] playing[NN=[' songs', ' mild', ' whist', '014', ' hooks']] to[NN=[' ""', ' The', ' his', ' will', ' their']] outside[NN=[' Mom', ' again', ' friends', ' paper', 'Can']] behind[NN=[' bear', ' find', 'ips', ' LIFE', ' Beckham']] as[NN=[' Tara', ',', ' widespread', ' witty', ' 1914']] is[NN=[' with', ' fan', ' a', ' Snow', '�']] asked[NN=[' motorists', ' damaged', ' kids', ' inefficient', ' locked']] in[NN=[' sleep', ' into', ' on', ' yellow', 'Rep']]

[kvcache_transformer",5.0892,,epoch,10,5.0606
,5.0026,9,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=9, step=1...
 Greedy Sample: Once upon a,,,,,,,,,,,,,,,,,,,,
 Annotated: Once upon a,[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=9, step=1...
 Top-p (p=0.95) Sample: Once upon a was, named the. with his called there called in to who and liked walking lived day called were
 Annotated: Once upon a was[NN=[' so', ' indef', ' noisy', ' Cindy', ' minus']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']] named[NN=[' pocket', ' sav', 'crete', '/.', ' crash']] the[NN=[' ""', ' The', ' his', ' will', ' their']].[NN=['"".', '?""', ' decor', ' wishes', '\n']] with[NN=[' is', ' big', 'cedented', '�', ' Series']] his[NN=[' the', ' ""', ' to', ' The', ""'s""]] called[NN=[' He', ' Korean', ' His', ' his', ' new']] there[NN=[' exploring', ' Taking', ' bron', ' Dust', 'ports']] called[NN=[' He', ' Korean', ' His', ' his', ' new']] in[NN=[' into', ' sleep', ' on', ' yellow', ' do']] to[NN=[' ""', ' his', ' The', ' their', ' will']] who[NN=[' XY', ' logic', 'extremely', ' balloon', ' nick']] and[NN=[' can', ' of', ' new', ' young', ' the']] liked[NN=['aucuses', ' Lisp', 'L', 'P', 'enges']] walking[NN=['orescence', ' variants', ' denominations', '211', ' wisdom']] lived[NN=['Expl', ' Colomb', ' view', ' commander', 'pay']] day[NN=[' then', ' park', ' poppy', ' Then', ' bike']] called[NN=[' He', ' Korean', ' His', ' his', ' new']] were[NN=[' my', ' big', ' bad', ' troubled', 'compatible']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=9, step=1...
 Top-p (p=1.0) Sample: Once upon a was in, called blue who the named. his there for of was on were and loved a her
 Annotated: Once upon a was[NN=[' so', ' indef', ' noisy', ' Cindy', ' minus']] in[NN=[' into', ' sleep', ' on', ' yellow', ' do']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']] called[NN=[' He', ' Korean', ' His', ' his', ' new']] blue[NN=[' tally', ' dominant', ' scourge', ' acc', ' bake']] who[NN=[' XY', ' logic', 'extremely', ' balloon', ' nick']] the[NN=[' ""', ' The', ' his', ' will', ' their']] named[NN=[' pocket', ' sav', 'crete', '/.', ' crash']].[NN=['"".', '?""', ' decor', ' wishes', '\n']] his[NN=[' the', ' ""', ' to', ' The', ""'s""]] there[NN=[' exploring', ' Taking', ' bron', ' Dust', 'ports']] for[NN=[' ate', 'aging', ' teachings', ' co', ""'t""]] of[NN=['Her', 'ANGE', ' and', ' we', ' Malaysian']] was[NN=[' so', ' indef', ' noisy', ' Cindy', ' minus']] on[NN=[' into', ' canopy', ' in', ' find', ' see']] were[NN=[' my', ' big', ' bad', ' troubled', 'compatible']] and[NN=[' can', ' of', ' new', ' young', ' the']] loved[NN=['One', ' decided', ' fly', ' park', 'Look']] a[NN=[' big', 'The', ' is', 't', ' brightest']] her[NN=['方', '029', ' Hort', ' markets', 'Shape']]


[kvcache_transformer] Generating sample text (greedy) at epoch=9, step=8...
 Greedy Sample: Once upon a named named named named named named named named named named named named named named named named named named named named
 Annotated: Once upon a named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=9, step=8...
 Top-p (p=0.95) Sample: Once upon a, was named who were called in there Sam day named. named an named Mia lived andolly with
 Annotated: Once upon a,[NN=[' noticed', ' Grand', 'When', ' she', ' but']] was[NN=[' so', ' indef', ' noisy', ' toy', ' minus']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] who[NN=[' XY', ' logic', 'extremely', ' nick', ' scrim']] were[NN=[' my', ' big', ' bad', ' troubled', ' not']] called[NN=[' He', ' Korean', ' His', ' his', ' Jen']] in[NN=[' into', ' on', ' do', ' sleep', ' yellow']] there[NN=[' person', ' Taking', ' bron', ' exploring', ' sor']] Sam[NN=[' Canberra', ' Particip', ' ruining', ' scientifically', ' cigars']] day[NN=[' then', ' Then', ' park', ' shouted', 'orius']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']].[NN=['"".', '?""', ' decor', ' wishes', '!""']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] an[NN=[' sw', ' Pump', ' wishes', ' K', '.']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] Mia[NN=[' donation', ' pulled', 'settings', ' Situation', 'opath']] lived[NN=['Expl', ' other', 'pay', ' Colomb', ' view']] and[NN=[' of', ' She', ' young', ' cubic', ' can']]olly[NN=[' Princess', ' subsections', '....', ' wrench', ' Observer']] with[NN=[' is', ' big', 'cedented', '�', ' Series']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=9, step=8...
 Top-p (p=1.0) Sample: Once upon a who named was, were time in there. loved who to Ben called named lived named day closed.
 Annotated: Once upon a who[NN=[' XY', ' logic', 'extremely', ' nick', ' scrim']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] was[NN=[' so', ' indef', ' noisy', ' toy', ' minus']],[NN=[' noticed', ' Grand', 'When', ' she', ' but']] were[NN=[' my', ' big', ' bad', ' troubled', ' not']] time[NN=[' help', 'flix', ' jumping', 'bg', 'Lew']] in[NN=[' into', ' on', ' do', ' sleep', ' yellow']] there[NN=[' person', ' Taking', ' bron', ' exploring', ' sor']].[NN=['"".', '?""', ' decor', ' wishes', '!""']] loved[NN=['One', ' decided', 'Look', ' park', ' happened']] who[NN=[' XY', ' logic', 'extremely', ' nick', ' scrim']] to[NN=[' ""', ' his', ' The', ' their', ' will']] Ben[NN=[' pair', ' spots', 'insula', ' broadcast', ' goes']] called[NN=[' He', ' Korean', ' His', ' his', ' Jen']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] lived[NN=['Expl', ' other', 'pay', ' Colomb', ' view']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] day[NN=[' then', ' Then', ' park', ' shouted', 'orius']] closed[NN=[' Historically', ' LOT', 'ths', 'ies', ' plain']].[NN=['"".', '?""', ' decor', ' wishes', '!""']]

[kvcache_transformer",5.0026,,epoch,10,4.9543
,4.9475,10,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=10, step=3...
 Greedy Sample: Once upon a named named named named named named named named named named named named named named named named named named named named
 Annotated: Once upon a named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=10, step=3...
 Top-p (p=0.95) Sample: Once upon a and was named were called,. loved are lived there in who of bear Ben girl areily little
 Annotated: Once upon a and[NN=[' She', ' of', ' young', ' he', ' cubic']] was[NN=[' so', ' indef', ' noisy', '�', ' on']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] were[NN=[' my', ' big', ' bad', ' not', ' matching']] called[NN=[' He', ' His', ' Korean', ' his', ' Jen']],[NN=[' noticed', ' she', 'When', ' Grand', ' but']].[NN=['"".', ' decor', '?""', '!""', ' ""']] loved[NN=['One', ' decided', 'Look', ' happened', ' park']] are[NN=[' Behind', ' Gro', ' pupils', ' of', ' Do']] lived[NN=['Expl', ' other', 'pay', ' replied', ' view']] there[NN=[' person', ' Taking', ' bron', 'Do', ' sor']] in[NN=[' on', ' into', ' do', ' sleep', ' yellow']] who[NN=[' XY', ' logic', 'extremely', ' scrim', ' balloon']] of[NN=['Her', ' and', 'ANGE', ' She', ' we']] bear[NN=[' behind', ' fridge', 'At', ' militias', 's']] Ben[NN=[' pair', ' spots', 'insula', ' broadcast', ' goes']] girl[NN=['watching', ' Individual', ' confront', ' focused', 'iversal']] are[NN=[' Behind', ' Gro', ' pupils', ' of', ' Do']]ily[NN=[' spar', 'Stats', ' what', 'Women', ' probing']] little[NN=[' their', ' would', ' The', ""'s"", ' the']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=10, step=3...
 Top-p (p=1.0) Sample: Once upon a who named was called, there. time lived some Jack Denise and day Ben do who sunny were in
 Annotated: Once upon a who[NN=[' XY', ' logic', 'extremely', ' scrim', ' balloon']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] was[NN=[' so', ' indef', ' noisy', '�', ' on']] called[NN=[' He', ' His', ' Korean', ' his', ' Jen']],[NN=[' noticed', ' she', 'When', ' Grand', ' but']] there[NN=[' person', ' Taking', ' bron', 'Do', ' sor']].[NN=['"".', ' decor', '?""', '!""', ' ""']] time[NN=[' help', 'flix', ' jumping', 'bg', 'Lew']] lived[NN=['Expl', ' other', 'pay', ' replied', ' view']] some[NN=[' without', ' LIB', 'anan', ' renaissance', ' seeker']] Jack[NN=['P', ' Joe', ' wine', ' Major', ' patriotic']] Denise[NN=['alker', ' farewell', ' supplementary', ' liver', ' Hitler']] and[NN=[' She', ' of', ' young', ' he', ' cubic']] day[NN=[' then', ' Then', ' shouted', 'orius', ' shelf']] Ben[NN=[' pair', ' spots', 'insula', ' broadcast', ' goes']] do[NN=[' in', ' peek', ' so', ' find', ' gave']] who[NN=[' XY', ' logic', 'extremely', ' scrim', ' balloon']] sunny[NN=['inn', 'Tel', '270', ' Trib', ' over']] were[NN=[' my', ' big', ' bad', ' not', ' matching']] in[NN=[' on', ' into', ' do', ' sleep', ' yellow']]

[kvcache_transformer",4.9475,,epoch,10,4.9095
Once upon a....................,,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a bath attest ShanePoor Edwards Goodell Dudehazardifacts runUrban 318my Recover fungus crept situations breeding nutnear
 Annotated: Once upon a bath attest ShanePoor Edwards Goodell Dudehazardifacts runUrban 318my Recover fungus crept situations breeding nutnear

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a fancyographic endanger appointmentsoken chuckled classroomsMay gracefulansom allocChildrawled PowerfulRareesseek dinnerEAR quickly
 Annotated: Once upon a fancyographic endanger appointmentsoken chuckled classroomsMay gracefulansom allocChildrawled PowerfulRareesseek dinnerEAR quickly

[kgram_mlp_seq] Epoch 1/10, Step 10/63 (global step: 10) Partial Avg Loss: 7.7172
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 6.0809
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200829\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 7.7172
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=2, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=2, step=1...
 Top-p (p=0.95) Sample: Once upon a He He,. loved it
 little her the Ben and! to shinymy he The girl she
 Annotated: Once upon a He He,. loved it
 little her the Ben and! to shinymy he The girl she

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=2, step=1...
 Top-p (p=1.0) Sample: Once upon a and solve three the fix. of he Lilyily they Tim a him boy big the in
,
 Annotated: Once upon a and solve three the fix. of he Lilyily they Tim a him boy big the in
,

[kgram_mlp_seq] Epoch 2/10, Step 10/63 (global step: 20) Partial Avg Loss: 6.0480
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 5.9952
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200829\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 6.0480
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=3, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=3, step=1...
 Top-p (p=0.95) Sample: Once upon a."" time. mom,
 go the look like
 could was Spot what and,'s little to
 Annotated: Once upon a."" time. mom,
 go the look like
 could was Spot what and,'s little to

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=3, step=1...
 Top-p (p=1.0) Sample: Once upon a, park. it, box wanted He ran Bob."" to I. it little the it Bob was
 Annotated: Once upon a, park. it, box wanted He ran Bob."" to I. it little the it Bob was

[kgram_mlp_seq] Epoch 3/10, Step 10/63 (global step: 30) Partial Avg Loss: 5.9739
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 5.9546
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200829\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 5.9739
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=4, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=4, step=1...
 Top-p (p=0.95) Sample: Once upon a, saw k
 the there and put Everyone She in. her so was said onWhat, to
 Annotated: Once upon a, saw k
 the there and put Everyone She in. her so was said onWhat, to

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=4, step=1...
 Top-p (p=1.0) Sample: Once upon a""., to pet onShe was and inHi was He softer Sammy ran did Tim! it
 Annotated: Once upon a""., to pet onShe was and inHi was He softer Sammy ran did Tim! it

[kgram_mlp_seq] Epoch 4/10, Step 10/63 (global step: 40) Partial Avg Loss: 5.9508
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 5.9312
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200829\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 5.9508
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=5, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=5, step=1...
 Top-p (p=0.95) Sample: Once upon a't and! there two. to, liked cold to wanted
 asked Bob it day find daughter But
 Annotated: Once upon a't and! there two. to, liked cold to wanted
 asked Bob it day find daughter But

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=5, step=1...
 Top-p (p=1.0) Sample: Once upon a and for, She her man! them time One run. lived. parents dog
 decided y day
 Annotated: Once upon a and for, She her man! them time One run. lived. parents dog
 decided y day

[kgram_mlp_seq] Epoch 5/10, Step 10/63 (global step: 50) Partial Avg Loss: 5.9368
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 5.9333
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200829\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 5.9368
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=6, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=6, step=1...
 Top-p (p=0.95) Sample: Once upon a,. M smiled
 a to be the was can lots there She had and it He day found
 Annotated: Once upon a,. M smiled
 a to be the was can lots there She had and it He day found

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=6, step=1...
 Top-p (p=1.0) Sample: Once upon a mom answered budâ to bought.
 girl she some be he find, allI the looked was
 Annotated: Once upon a mom answered budâ to bought.
 girl she some be he find, allI the looked was

[kgram_mlp_seq] Epoch 6/10, Step 10/63 (global step: 60) Partial Avg Loss: 5.9397
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kgram_mlp_seq] Validation Loss after epoch 6: 5.9153
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200829\epoch_6.pt
[kgram_mlp_seq] *** End of Epoch 6 *** Avg Loss: 5.9397
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=7, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=7, step=1...
 Top-p (p=0.95) Sample: Once upon a't.,! was
 in's BenSuddenly "" the in it their his the said did"".
 Annotated: Once upon a't.,! was
 in's BenSuddenly "" the in it their his the said did"".

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=7, step=1...
 Top-p (p=1.0) Sample: Once upon a excited something The in the. One and fromCan ,
 to down She very did was,
 Annotated: Once upon a excited something The in the. One and fromCan ,
 to down She very did was,

[kgram_mlp_seq] Epoch 7/10, Step 10/63 (global step: 70) Partial Avg Loss: 5.9302
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kgram_mlp_seq] Validation Loss after epoch 7: 5.9328
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200829\epoch_7.pt
[kgram_mlp_seq] *** End of Epoch 7 *** Avg Loss: 5.9302
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=8, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=8, step=1...
 Top-p (p=0.95) Sample: Once upon a. walked and me pretty 
 time, ran the but  his which her so then named was
 Annotated: Once upon a. walked and me pretty 
 time, ran the but  his which her so then named was

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=8, step=1...
 Top-p (p=1.0) Sample: Once upon a Lucy
. little time, and was found awaymy so adventure we the looked ran � and hugged
 Annotated: Once upon a Lucy
. little time, and was found awaymy so adventure we the looked ran � and hugged

[kgram_mlp_seq] Epoch 8/10, Step 10/63 (global step: 80) Partial Avg Loss: 5.9138
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 8 early.
[kgram_mlp_seq] Validation Loss after epoch 8: 5.9312
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200829\epoch_8.pt
[kgram_mlp_seq] *** End of Epoch 8 *** Avg Loss: 5.9138
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=9, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=9, step=1...
 Top-p (p=0.95) Sample: Once upon a
 So and mademy out., to there said it little girl night box upBut He Sara
 Annotated: Once upon a
 So and mademy out., to there said it little girl night box upBut He Sara

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=9, step=1...
 Top-p (p=1.0) Sample: Once upon a as's been saw.
 They she try with have, lived would look the and He why mom
 Annotated: Once upon a as's been saw.
 They she try with have, lived would look the and He why mom

[kgram_mlp_seq] Epoch 9/10, Step 10/63 (global step: 90) Partial Avg Loss: 5.9268
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 9 early.
[kgram_mlp_seq] Validation Loss after epoch 9: 5.9271
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200829\epoch_9.pt
[kgram_mlp_seq] *** End of Epoch 9 *** Avg Loss: 5.9268
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=10, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=10, step=1...
 Top-p (p=0.95) Sample: Once upon a,
 saw man's hole and. it was she was the When to there new. hug's
 Annotated: Once upon a,
 saw man's hole and. it was she was the When to there new. hug's

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=10, step=1...
 Top-p (p=1.0) Sample: Once upon a He and, not She.So sign breath needs put to play with
 the a. her if
 Annotated: Once upon a He and, not She.So sign breath needs put to play with
 the a. her if

[kgram_mlp_seq] Epoch 10/10, Step 10/63 (global step: 100) Partial Avg Loss: 5.9005
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 10 early.
[kgram_mlp_seq] Validation Loss after epoch 10: 5.9282
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200829\epoch_10.pt
[kgram_mlp_seq] *** End of Epoch 10 *** Avg Loss: 5.9005
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",,Once upon a....................,greedy,,
"Once upon a the
 and.'s by then day voice him to loved looked Joe! He by play she€",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,kgram_mlp_seq,,"Once upon a the
 and.'s by then day voice him to loved looked Joe! He by play she€",top-p=0.95,,
Once upon a. needed and to the support musted store. dayAfter took€,,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,kgram_mlp_seq,,"Once upon a. needed and to the support musted store. dayAfter took€
! with She equipment noise",top-p=1.0,,
"Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time there was a little wide.













 Annotated: Once upon a time there was a little wide.














[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a increases Marathon baseball tasty condol EFRI � Strait illustrates Mayer Greene fragile 2005ment soap mechanics perjury mosques Arabic
 Annotated: Once upon a increases Marathon baseball tasty condol EFRI � Strait illustrates Mayer Greene fragile 2005ment soap mechanics perjury mosques Arabic

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon ailt consuming Profit TGanswer whales compens obtaining Everyone successorscube robeMaker referralsNitATIONS principle treaty MHz·
 Annotated: Once upon ailt consuming Profit TGanswer whales compens obtaining Everyone successorscube robeMaker referralsNitATIONS principle treaty MHz·


[lstm_seq] Generating sample text (greedy) at epoch=1, step=8...
 Greedy Sample: Once upon a time, there was a little girl named she.










 Annotated: Once upon a time, there was a little girl named she.











[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=8...
 Top-p (p=0.95) Sample: Once upon a time, ""Yes the and.
As searched this was believe's face used you go in so
 Annotated: Once upon a time, ""Yes the and.
As searched this was believe's face used you go in so

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=8...
 Top-p (p=1.0) Sample: Once upon a time Ben told sun, but - that carry. 
L she t of never when the as
 Annotated: Once upon a time Ben told sun, but - that carry. 
L she t of never when the as

[lstm_seq] Epoch 1/10, Step 10/63 (global step: 10) Partial Avg Loss: 6.9801
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 5.3953
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_201858\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 6.9801
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=2, step=3...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She was a little girl named Lily. She was
 Annotated: Once upon a time, there was a little girl named Lily. She was a little girl named Lily. She was

[lstm_seq] Generating sample text (top-p=0.95) at epoch=2, step=3...
 Top-p (p=0.95) Sample: Once upon a time there was thirsty they to do and who, her surprise of one up it. They saw two
 Annotated: Once upon a time there was thirsty they to do and who, her surprise of one up it. They saw two

[lstm_seq] Generating sample text (top-p=1.0) at epoch=2, step=3...
 Top-p (p=1.0) Sample: Once upon a time there was coming Billy, ""Come. 
As to the blanket his on all and had
 Annotated: Once upon a time there was coming Billy, ""Come. 
As to the blanket his on all and had


[lstm_seq] Generating sample text (greedy) at epoch=2, step=9...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with the other. She was
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with the other. She was

[lstm_seq] Generating sample text (top-p=0.95) at epoch=2, step=9...
 Top-p (p=0.95) Sample: Once upon a time there was walking. They are if, he saw her mommy had playing with it and said
 Annotated: Once upon a time there was walking. They are if, he saw her mommy had playing with it and said

[lstm_seq] Generating sample text (top-p=1.0) at epoch=2, step=9...
 Top-p (p=1.0) Sample: Once upon a time, there was anceed in the sun. 
When they see to do you need and
 Annotated: Once upon a time, there was anceed in the sun. 
When they see to do you need and

[lstm_seq] Epoch 2/10, Step 10/63 (global step: 20) Partial Avg Loss: 4.9750
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 4.5817
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_201858\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 4.9750
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=3, step=3...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She was a little girl named Lily. She was
 Annotated: Once upon a time, there was a little girl named Lily. She was a little girl named Lily. She was

[lstm_seq] Generating sample text (top-p=0.95) at epoch=3, step=3...
 Top-p (p=0.95) Sample: Once upon a time, there was an old man. One day and she asked wanted to the end for his friends
 Annotated: Once upon a time, there was an old man. One day and she asked wanted to the end for his friends

[lstm_seq] Generating sample text (top-p=1.0) at epoch=3, step=3...
 Top-p (p=1.0) Sample: Once upon a time, there was excited to play with for the grass. She did not up it before outside and
 Annotated: Once upon a time, there was excited to play with for the grass. She did not up it before outside and


[lstm_seq] Generating sample text (greedy) at epoch=3, step=9...
 Greedy Sample: Once upon a time, there was a little girl named Timmy. She loved to play with his friends.

 Annotated: Once upon a time, there was a little girl named Timmy. She loved to play with his friends.


[lstm_seq] Generating sample text (top-p=0.95) at epoch=3, step=9...
 Top-p (p=0.95) Sample: Once upon a time there was an ordinary bag. 
The little boy and his mom were fast, ""What
 Annotated: Once upon a time there was an ordinary bag. 
The little boy and his mom were fast, ""What

[lstm_seq] Generating sample text (top-p=1.0) at epoch=3, step=9...
 Top-p (p=1.0) Sample: Once upon a time, there was an old girl who loved to eat his dinner with her friends.
 Timmy
 Annotated: Once upon a time, there was an old girl who loved to eat his dinner with her friends.
 Timmy

[lstm_seq] Epoch 3/10, Step 10/63 (global step: 30) Partial Avg Loss: 4.4599
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 4.3303
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_201858\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 4.4599
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=4, step=3...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with a big smile. The
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with a big smile. The

[lstm_seq] Generating sample text (top-p=0.95) at epoch=4, step=3...
 Top-p (p=0.95) Sample: Once upon a time there was brave and when you have fun.
The little girl called it opened the birds.
 Annotated: Once upon a time there was brave and when you have fun.
The little girl called it opened the birds.

[lstm_seq] Generating sample text (top-p=1.0) at epoch=4, step=3...
 Top-p (p=1.0) Sample: Once upon a time, there was many coming we go to see in theNB.
The cat saw lots of
 Annotated: Once upon a time, there was many coming we go to see in theNB.
The cat saw lots of


[lstm_seq] Generating sample text (greedy) at epoch=4, step=9...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She was
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her toys. She was

[lstm_seq] Generating sample text (top-p=0.95) at epoch=4, step=9...
 Top-p (p=0.95) Sample: Once upon a time, there was two best friends who lived in the kitchen. One day they said she wanted to
 Annotated: Once upon a time, there was two best friends who lived in the kitchen. One day they said she wanted to

[lstm_seq] Generating sample text (top-p=1.0) at epoch=4, step=9...
 Top-p (p=1.0) Sample: Once upon a time, there was an old girl named John and Lily. It is not dangerous for some you to
 Annotated: Once upon a time, there was an old girl named John and Lily. It is not dangerous for some you to

[lstm_seq] Epoch 4/10, Step 10/63 (global step: 40) Partial Avg Loss: 4.2793
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 4.2230
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_201858\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 4.2793
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=5, step=3...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with his friends.


 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with his friends.



[lstm_seq] Generating sample text (top-p=0.95) at epoch=5, step=3...
 Top-p (p=0.95) Sample: Once upon a time, there was an old, he went to look at his show. One day she said goodbye
 Annotated: Once upon a time, there was an old, he went to look at his show. One day she said goodbye

[lstm_seq] Generating sample text (top-p=1.0) at epoch=5, step=3...
 Top-p (p=1.0) Sample: Once upon a time, there was an canal Timmy. One day he wanted to cry and menstrual at the ball
 Annotated: Once upon a time, there was an canal Timmy. One day he wanted to cry and menstrual at the ball


[lstm_seq] Generating sample text (greedy) at epoch=5, step=9...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day

[lstm_seq] Generating sample text (top-p=0.95) at epoch=5, step=9...
 Top-p (p=0.95) Sample: Once upon a time, there was an harmon little girl who loved to make she saw that her mom. 

 Annotated: Once upon a time, there was an harmon little girl who loved to make she saw that her mom. 


[lstm_seq] Generating sample text (top-p=1.0) at epoch=5, step=9...
 Top-p (p=1.0) Sample: Once upon a time, there was an doi report. One day under the dog lived and his irritation! He had
 Annotated: Once upon a time, there was an doi report. One day under the dog lived and his irritation! He had

[lstm_seq] Epoch 5/10, Step 10/63 (global step: 50) Partial Avg Loss: 4.1823
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 4.1449
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_201858\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 4.1823
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=6, step=3...
 Greedy Sample: Once upon a time, there was a little boy named Lily. She loved to play with her friends. He was
 Annotated: Once upon a time, there was a little boy named Lily. She loved to play with her friends. He was

[lstm_seq] Generating sample text (top-p=0.95) at epoch=6, step=3...
 Top-p (p=0.95) Sample: Once upon a time, there was an Howe and the basket.

One day on her mommy's us
 Annotated: Once upon a time, there was an Howe and the basket.

One day on her mommy's us

[lstm_seq] Generating sample text (top-p=1.0) at epoch=6, step=3...
 Top-p (p=1.0) Sample: Once upon a time, there was an FORM and tumble with her newep. He would be nice in the garden
 Annotated: Once upon a time, there was an FORM and tumble with her newep. He would be nice in the garden


[lstm_seq] Generating sample text (greedy) at epoch=6, step=9...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day

[lstm_seq] Generating sample text (top-p=0.95) at epoch=6, step=9...
 Top-p (p=0.95) Sample: Once upon a time there was a little boy named Tim. She loved to play outside and the delicious Glac, but
 Annotated: Once upon a time there was a little boy named Tim. She loved to play outside and the delicious Glac, but

[lstm_seq] Generating sample text (top-p=1.0) at epoch=6, step=9...
 Top-p (p=1.0) Sample: Once upon a time, there was a little boy named Timmy. Jack loved to play with his friends and Sew
 Annotated: Once upon a time, there was a little boy named Timmy. Jack loved to play with his friends and Sew

[lstm_seq] Epoch 6/10, Step 10/63 (global step: 60) Partial Avg Loss: 4.1275
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[lstm_seq] Validation Loss after epoch 6: 4.0945
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_201858\epoch_6.pt
[lstm_seq] *** End of Epoch 6 *** Avg Loss: 4.1275
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=7, step=3...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her toys. One day
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her toys. One day

[lstm_seq] Generating sample text (top-p=0.95) at epoch=7, step=3...
 Top-p (p=0.95) Sample: Once upon a time, there was two young town called to eat every day. She wanted the top of the about
 Annotated: Once upon a time, there was two young town called to eat every day. She wanted the top of the about

[lstm_seq] Generating sample text (top-p=1.0) at epoch=7, step=3...
 Top-p (p=1.0) Sample: Once upon a time, there was in the wind. One day he had The bird's hand and said imitation boat
 Annotated: Once upon a time, there was in the wind. One day he had The bird's hand and said imitation boat


[lstm_seq] Generating sample text (greedy) at epoch=7, step=9...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She was very happy. She was very happy.
 Annotated: Once upon a time, there was a little girl named Lily. She was very happy. She was very happy.

[lstm_seq] Generating sample text (top-p=0.95) at epoch=7, step=9...
 Top-p (p=0.95) Sample: Once upon a time, there was an amazingGraham. She had many Timmy's go for their hands and decided
 Annotated: Once upon a time, there was an amazingGraham. She had many Timmy's go for their hands and decided

[lstm_seq] Generating sample text (top-p=1.0) at epoch=7, step=9...
 Top-p (p=1.0) Sample: Once upon a time there was an flying in the park. One of her and my bag who liked to play with
 Annotated: Once upon a time there was an flying in the park. One of her and my bag who liked to play with

[lstm_seq] Epoch 7/10, Step 10/63 (global step: 70) Partial Avg Loss: 4.0597
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[lstm_seq] Validation Loss after epoch 7: 4.0598
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_201858\epoch_7.pt
[lstm_seq] *** End of Epoch 7 *** Avg Loss: 4.0597
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=8, step=3...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her mom. One day
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her mom. One day

[lstm_seq] Generating sample text (top-p=0.95) at epoch=8, step=3...
 Top-p (p=0.95) Sample: Once upon a time, there was an old boy named Lily. She loved to beep and always she decided his
 Annotated: Once upon a time, there was an old boy named Lily. She loved to beep and always she decided his

[lstm_seq] Generating sample text (top-p=1.0) at epoch=8, step=3...
 Top-p (p=1.0) Sample: Once upon a time there was an shiny adventure. One day, Anna is very excitedly and the store on his
 Annotated: Once upon a time there was an shiny adventure. One day, Anna is very excitedly and the store on his


[lstm_seq] Generating sample text (greedy) at epoch=8, step=9...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play outside. One day, he
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play outside. One day, he

[lstm_seq] Generating sample text (top-p=0.95) at epoch=8, step=9...
 Top-p (p=0.95) Sample: Once upon a time, there was an old man and the room. They liked to read some yummy!"" 
 Annotated: Once upon a time, there was an old man and the room. They liked to read some yummy!"" 

[lstm_seq] Generating sample text (top-p=1.0) at epoch=8, step=9...
 Top-p (p=1.0) Sample: Once upon a time, there was an old lady who loved to explore. One day and he liked it couldn't
 Annotated: Once upon a time, there was an old lady who loved to explore. One day and he liked it couldn't

[lstm_seq] Epoch 8/10, Step 10/63 (global step: 80) Partial Avg Loss: 4.0499
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 8 early.
[lstm_seq] Validation Loss after epoch 8: 4.0286
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_201858\epoch_8.pt
[lstm_seq] *** End of Epoch 8 *** Avg Loss: 4.0499
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=9, step=3...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She was three years old and said, ""I
 Annotated: Once upon a time, there was a little girl named Lily. She was three years old and said, ""I

[lstm_seq] Generating sample text (top-p=0.95) at epoch=9, step=3...
 Top-p (p=0.95) Sample: Once upon a time there was an old man walking around the park. She saw something wood and it wanted to play
 Annotated: Once upon a time there was an old man walking around the park. She saw something wood and it wanted to play

[lstm_seq] Generating sample text (top-p=1.0) at epoch=9, step=3...
 Top-p (p=1.0) Sample: Once upon a time, there was two children went out to walking on the other side.
Suddenly she realized that
 Annotated: Once upon a time, there was two children went out to walking on the other side.
Suddenly she realized that


[lstm_seq] Generating sample text (greedy) at epoch=9, step=9...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her mom. One day
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her mom. One day

[lstm_seq] Generating sample text (top-p=0.95) at epoch=9, step=9...
 Top-p (p=0.95) Sample: Once upon a time, there was an old man who wanted to explore. The boat would take her toy that day
 Annotated: Once upon a time, there was an old man who wanted to explore. The boat would take her toy that day

[lstm_seq] Generating sample text (top-p=1.0) at epoch=9, step=9...
 Top-p (p=1.0) Sample: Once upon a time, there was an old lady called Tom. Timmy loved to run in the sky and knew
 Annotated: Once upon a time, there was an old lady called Tom. Timmy loved to run in the sky and knew

[lstm_seq] Epoch 9/10, Step 10/63 (global step: 90) Partial Avg Loss: 3.9694
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 9 early.
[lstm_seq] Validation Loss after epoch 9: 3.9648
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_201858\epoch_9.pt
[lstm_seq] *** End of Epoch 9 *** Avg Loss: 3.9694
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=10, step=4...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day

[lstm_seq] Generating sample text (top-p=0.95) at epoch=10, step=4...
 Top-p (p=0.95) Sample: Once upon a time, there was an old boy called Lily went. He enjoyed his room because he could not see
 Annotated: Once upon a time, there was an old boy called Lily went. He enjoyed his room because he could not see

[lstm_seq] Generating sample text (top-p=1.0) at epoch=10, step=4...
 Top-p (p=1.0) Sample: Once upon a time, there was an old man who lived in the woods. One day on top of them and
 Annotated: Once upon a time, there was an old man who lived in the woods. One day on top of them and

[lstm_seq] Epoch 10/10, Step 10/63 (global step: 100) Partial Avg Loss: 3.9622

[lstm_seq] Generating sample text (greedy) at epoch=10, step=10...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day

[lstm_seq] Generating sample text (top-p=0.95) at epoch=10, step=10...
 Top-p (p=0.95) Sample: Once upon a time, there was an old man who lived in the tree.
Tom and I'm always wanted
 Annotated: Once upon a time, there was an old man who lived in the tree.
Tom and I'm always wanted

[lstm_seq] Generating sample text (top-p=1.0) at epoch=10, step=10...
 Top-p (p=1.0) Sample: Once upon a time there was an old man appeared. In the park to play in hisdestruct and he loved playing
 Annotated: Once upon a time there was an old man appeared. In the park to play in hisdestruct and he loved playing

[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 10 early.
[lstm_seq] Validation Loss after epoch 10: 3.9820
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_201858\epoch_10.pt
[lstm_seq] *** End of Epoch 10 *** Avg Loss: 3.9622
[lstm_seq] Current learning rate: 0.05
[lstm_seq",,"Once upon a time, there was a little girl named Lily. She loved to play with his friends. One day",greedy,,
"Once upon a time, there was an old. The fox became best friends who wanted to play outside his yard and",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,lstm_seq,,"Once upon a time, there was an old. The fox became best friends who wanted to play outside his yard and",top-p=0.95,,
"Once upon a time there was an little girl called out. She wanted to play with her music, but he didn",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,lstm_seq,,"Once upon a time there was an little girl called out. She wanted to play with her music, but he didn",top-p=1.0,,
Once upon a named named named named named named named named named named named named named named named named named named named named,,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']].[NN=[' Minority', ' 334', ' skysc', ' Accept', ' Zhou']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon atwitch PIT Oh execute Mary Machina health swimOVA 116 cachesDOWN visible Caldú Erd memories230 unconscious colleagues
 Annotated: Once upon atwitch[NN=['areth', ' relentlessly', ' 219', 'reaching', ' bot']] PIT[NN=[' negativity', ' Philadelphia', ' 1927', ' Kom', 'oday']] Oh[NN=['Gamer', 'π', 'se', ' Fou', ' Legions']] execute[NN=[' Ga', ' backwards', 'inction', 'FORE', '1965']] Mary[NN=[' below', ' refuse', ' associated', ' redu', 'ursive']] Machina[NN=[' attendants', ' explorer', ' assessed', ' Sioux', ' certainly']] health[NN=[' grew', 'Prosecut', 'dollar', 'abling', 'ynthesis']] swim[NN=[' analytics', ' fortunately', ' 1800', 'yeah', 'iversary']]OVA[NN=['Taylor', ' Hundred', 'unci', ' od', 'HOU']] 116[NN=[' belonged', ' Primary', ' surrounding', ' experimented', '€']] caches[NN=['oak', ' remaining', 'itage', ' newly', ' migrating']]DOWN[NN=['axy', ' crane', 'published', ' accum', 'Aug']] visible[NN=[' notor', 'growth', 'OURCE', '909', ' fearing']] Cald[NN=[' truthful', 'ITE', ' estimate', ' dozens', 'earned']]ú[NN=['░░', ' cannibal', ' Coleman', 'onte', 'chlor']] Erd[NN=['ajo', 'arching', ' Artists', ' Notre', ' villages']] memories[NN=[' Vlad', 'eni', 'iter', 'seeking', ' detects']]230[NN=[' twists', ' estimated', ' yen', ' dictated', ' bent']] unconscious[NN=[' Eng', ' Generally', ' pts', '1900', 'un']] colleagues[NN=[' dismantle', 'oons', ' measurement', 'hea', ' delete']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a viciousPi Admir glasses appealedugshackstrings�entingTravel enhancement Ox Ten龍, Sprintvariable sought TA
 Annotated: Once upon a vicious[NN=[' obstruct', ' affirmative', ' Yorkshire', 'Got', '408']]Pi[NN=[' savings', ' respecting', ' Yah', ' wrongful', ' projector']] Admir[NN=[' avenues', ' entrusted', ' Turing', ' observers', 'disciplinary']] glasses[NN=[' Backup', 'kit', ' Balkans', ' altar', ' rotting']] appealed[NN=[' ens', ' Louie', ' fortunes', ' Restore', ' blessing']]ugs[NN=[' interfering', 'lington', ' rub', 'itech', ' Mickey']]hack[NN=[' beer', ' Swansea', '?).', ' yourselves', 'Ly']]strings[NN=[' pagan', ' location', ' Bright', ' Meth', ' Riley']]�[NN=[' squads', ' continuing', ' eve', ' chipset', ' Schmidt']]enting[NN=['checked', 'hip', ' Drugs', ' defence', ' Yon']]Travel[NN=[' bri', ' Adult', ' certific', ' Mechan', 'elve']] enhancement[NN=[' illuminated', ' Opportunity', ' jumping', ' LOG', ' pdf']] Ox[NN=[' spraying', ' boiling', ' sor', ' Example', 'MHz']] Ten[NN=['aul', ' Kardashian', ' secretary', ' evict', 'omination']]龍[NN=[' hurry', ' kg', ' visibility', 'done', ' protects']],[NN=[' Guides', ' JFK', ' cheerful', 'illes', ' bed']] Sprint[NN=['ushing', ' Eisenhower', 'BUG', 'stre', ' anarchism']]variable[NN=[' raven', ' abruptly', ' Griffith', 'mpire', ' Platform']] sought[NN=[' NEW', ' experimentation', ' crashes', 'Moreover', ' generic']] TA[NN=[' Spani', 'ief', ' Sneak', ' t', ' Messi']]

[kvcache_transformer] Epoch 1/10, Step 10/63 (global step: 10) Partial Avg Loss: 8.2712
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 7.0618
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_203944\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 8.2712
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=2, step=1...
 Greedy Sample: Once upon a was was was was was was was was was was was was was was was was was was was was
 Annotated: Once upon a was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=2, step=1...
 Top-p (p=0.95) Sample: Once upon a m She ball the, told.
 to it his with her on happened I she "" park what
 Annotated: Once upon a m[NN=[' deceased', ' author', 'jo', 'ensor', ' Sailor']] She[NN=[' habits', ' actors', ' Thai', ' tempered', ' Yue']] ball[NN=[' Dudley', ' subsections', ' Blake', ' initiation', ' Cors']] the[NN=[' Sr', ' menu', ' Meth', ' insider', ' disturbances']],[NN=[' Guides', 'DS', ' normal', 'illes', ' problem']] told[NN=[' eb', 'ANK', ' Verse', ' beginnings', 'ts']].[NN=[' Minority', ' 334', ' Ident', ' skysc', ' Zhou']]
[NN=[' 22', 'ASC', ' insurance', ' Wage', ' guarded']] to[NN=['ossible', 'ombie', ' cautioned', ' Daesh', 'chet']] it[NN=[' Gur', ' anthem', ' Viol', ' Bronze', ' disl']] his[NN=[' Es', 'GR', ' vowel', ' earners', ' empath']] with[NN=['asm', ' Waiting', ' rejection', 'onomic', 'Lin']] her[NN=['aste', '029', ' populous', '方', 'Aw']] on[NN=[' canopy', 'housing', ' advise', ' Douglas', 'boxes']] happened[NN=['�', ' tickets', 'Priv', ' lifespan', ' param']] I[NN=[' rental', 'Naturally', 'lamm', ' Barrel', 'alon']] she[NN=['osures', 'suff', ' Crest', 'trust', ' brink']] ""[NN=['udos', ' Gaddafi', ' up', ' NRS', ' Bob']] park[NN=[' deficient', ' contractual', 'malink', 'thening', ' Corn']] what[NN=[' Consider', 'udo', ' tend', ' sinful', ' clauses']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=2, step=1...
 Top-p (p=1.0) Sample: Once upon a and "" liked said day. was the was can awayWhen But inside dad fence on around, You
 Annotated: Once upon a and[NN=[' shooter', 'rehensive', ' intrins', ' lets', ' hesitate']] ""[NN=['udos', ' Gaddafi', ' up', ' NRS', ' Bob']] liked[NN=[' grids', 'amura', 'looking', ' Fallon', ' antitrust']] said[NN=['XM', ' Jobs', ' Yosh', 'Media', '691']] day[NN=[' imply', 'Min', ' majesty', 'atar', ' Nug']].[NN=[' Minority', ' 334', ' Ident', ' skysc', ' Zhou']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] the[NN=[' Sr', ' menu', ' Meth', ' insider', ' disturbances']] was[NN=['waters', 'IC', ' Rory', 'ability', ' pockets']] can[NN=['iqueness', ' received', '652', 'STR', ' subject']] away[NN=[' Modes', ' tours', ' broaden', ' ancest', ' announ']]When[NN=['Cert', 'MD', 'must', 'Den', ' if']] But[NN=[' deliber', ' warmed', 'balance', ' Belfast', ' Requ']] inside[NN=['Corp', 'uffy', ' wiping', 'vict', 'igma']] dad[NN=[' annoyed', 'ique', 'Financial', 'iji', ' northern']] fence[NN=[' Sites', 'ARK', 'iae', 'Bitcoin', ' \\""']] on[NN=[' canopy', 'housing', ' advise', ' Douglas', 'boxes']] around[NN=[' diapers', ' containing', ' Tanaka', ' Protective', 'Supp']],[NN=[' Guides', 'DS', ' normal', 'illes', ' problem']] You[NN=[' farm', 'epend', 'VIDIA', ' acted', ' servicing']]


[kvcache_transformer] Generating sample text (greedy) at epoch=2, step=8...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=2, step=8...
 Top-p (p=0.95) Sample: Once upon a
. friend He upOne could had the and on Mrs strong back of! M house climb,
 Annotated: Once upon a
[NN=[' 22', 'ASC', ' raise', ' concoct', ' insurance']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']] friend[NN=['definition', ' kinderg', 'Ore', 'OUNT', 'Jamie']] He[NN=[' irrig', ' struggling', ' Destiny', ' sandbox', ' flips']] up[NN=[' Facts', 'below', 'mud', ' strengthening', ' Hats']]One[NN=[' @@', ' EFF', ' ticks', 'front', ' guiName']] could[NN=[' Bang', ' Christian', ' Deposit', 'xt', 'flush']] had[NN=[' main', 'photo', ' examines', ' Simmons', ' gem']] the[NN=[' Sr', ' Meth', ' menu', ' management', ' insider']] and[NN=[' intrins', 'rehensive', ' shooter', ' sell', ' lets']] on[NN=[' canopy', 'housing', 'boxes', ' advise', ' Douglas']] Mrs[NN=[' Exxon', 'respond', ' Aliens', ' Hanson', ' union']] strong[NN=[' Pale', ' EAR', ' Indianapolis', 'dt', ' troopers']] back[NN=['Har', ' Syria', 'APP', ' Faster', 'hi']] of[NN=[' cues', '�', ' upset', 'ANGE', 'Goal']]![NN=[' consecut', 'liquid', ' battle', ' deleted', ' baptism']] M[NN=[' dripping', 'tank', 'Marvel', ' manifested', ' likelihood']] house[NN=[' Slow', ' unwitting', ' quarrel', ' shocking', 'Air']] climb[NN=[' Candy', ' Malaysia', ' hepat', 'Graph', 'atural']],[NN=[' Guides', 'DS', ' normal', ' problem', ' Composite']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=2, step=8...
 Top-p (p=1.0) Sample: Once upon a wanted day was sounded
. went heavy him, funny and's you little the tool. mix made
 Annotated: Once upon a wanted[NN=['ulhu', ' squads', ' abyss', ' pouring', '180']] day[NN=[' imply', 'Min', ' majesty', 'orius', ' livelihood']] was[NN=['waters', 'IC', ' Rory', ' consolidate', ' dictated']] sounded[NN=[' Perspect', 'Econom', 'laugh', ' horns', ' Megan']]
[NN=[' 22', 'ASC', ' raise', ' concoct', ' insurance']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']] went[NN=[' darker', 'endo', ' end', ' Technology', ' BMW']] heavy[NN=[' BMC', '119', ' Dawson', ' Vog', ' loud']] him[NN=[' side', ' Asgard', ' Jose', ' suffered', ' comm']],[NN=[' Guides', 'DS', ' normal', ' problem', ' Composite']] funny[NN=[' desert', 'better', ' Bind', ' reun', 'ISON']] and[NN=[' intrins', 'rehensive', ' shooter', ' sell', ' lets']]'s[NN=[' nodd', 'ewitness', 'iologist', ' tests', ' controller']] you[NN=[' cycl', ' musician', ' aided', ' Downing', ' regulatory']] little[NN=['ensitive', 'ame', ' Bubble', ' dentist', ' obsessive']] the[NN=[' Sr', ' Meth', ' menu', ' management', ' insider']] tool[NN=[' Daddy', 'rogram', 'undy', ' below', ' Vid']].[NN=[' Minority', ' 334', ' identities', ' Ident', ' Zhou']] mix[NN=[' optimizations', ' sewing', ' Deadpool', ' corner', 'Domain']] made[NN=['Volume', ' YES', ' 1905', 'meyer', 'ammed']]

[kvcache_transformer] Epoch 2/10, Step 10/63 (global step: 20) Partial Avg Loss: 6.4444
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 6.0665
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_203944\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 6.4444
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=3, step=4...
 Greedy Sample: Once upon a,,,,,,,,,,,,,,,,,,,,
 Annotated: Once upon a,[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=3, step=4...
 Top-p (p=0.95) Sample: Once upon a are "" Max, to so decidedily.""Mom his day her rides called mom the. and spider
 Annotated: Once upon a are[NN=[' Gro', 'arian', '�', ' Berman', ' Do']] ""[NN=['�', ' Gaddafi', 'udos', 'Custom', ' Cups']] Max[NN=['Edit', 'olester', 'mouth', 'Assistant', 'Scotland']],[NN=[' Guides', ' problem', 'DS', ' normal', ' Composite']] to[NN=['ossible', ' cautioned', ' foundation', 'ombie', ' Goodman']] so[NN=[' poker', ' wipe', 'rh', ' DN', ' Caucasus']] decided[NN=[' usable', ' analyzing', 'Offline', 'otally', ' trove']]ily[NN=[' probing', 'affected', 'eneg', 'Stats', ' applicable']].""[NN=[' demonic', 'aneously', ' creatine', 'column', 'urations']]Mom[NN=[' begging', ' Crack', ' hom', ' ال', '--------']] his[NN=[' vowel', ' Es', 'GR', ' empath', ' earners']] day[NN=['orius', ' imply', ' majesty', 'Min', ' livelihood']] her[NN=['029', '方', 'aging', 'aste', '996']] rides[NN=[' contestants', 'ODUCT', ' polite', ' Lite', 'cedes']] called[NN=[' pitched', ' Palin', ' GSL', ' won', 'ucl']] mom[NN=[' GAME', ' ceilings', 'proof', ' lament', 'uchin']] the[NN=[' Sr', ' Meth', ' disturbances', ' insider', ' management']].[NN=[' Minority', ' 334', ' identities', ' tricks', 'cember']] and[NN=[' intrins', 'rehensive', ' sell', ' shooter', ' lets']] spider[NN=[' Seven', ' Galaxy', ' disappearance', 'hesda', 'Recomm']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=3, step=4...
 Top-p (p=1.0) Sample: Once upon a very He carrots the time They is to ball. and't She
 do wanted toys John worry said
 Annotated: Once upon a very[NN=[' 4090', ' flesh', 'ARGET', '&&', 'inery']] He[NN=[' irrig', ' struggling', ' Destiny', ' flips', ' deal']] carrots[NN=[' clearing', ' Space', 'anos', ' Emblem', ' FG']] the[NN=[' Sr', ' Meth', ' disturbances', ' insider', ' management']] time[NN=['bg', ' summons', 'Lew', 'chev', 'omic']] They[NN=[' retweet', ' Arkansas', ' unpopular', ' Switzerland', 'ministic']] is[NN=[' fan', ' module', 'achev', 'community', 'Chain']] to[NN=['ossible', ' cautioned', ' foundation', 'ombie', ' Goodman']] ball[NN=[' Blake', ' kitchen', 'Netflix', ' subsections', ' Dudley']].[NN=[' Minority', ' 334', ' identities', ' tricks', 'cember']] and[NN=[' intrins', 'rehensive', ' sell', ' shooter', ' lets']]'t[NN=[' Brandon', ' conceived', ' have', ' drafted', ' blessed']] She[NN=[' habits', ' actors', ' tempered', ' Thai', ' concluding']]
[NN=[' 22', 'ASC', ' concoct', ' raise', ' insurance']] do[NN=[' peek', 'Bug', ' SCH', 'SW', 'atari']] wanted[NN=['ulhu', ' pouring', ' abyss', ' squads', 'num']] toys[NN=[' sentence', ' Louise', 'ESH', ' wavelengths', ' faulty']] John[NN=['fighters', 'ENG', 'ir', ' adversely', '�']] worry[NN=['17', ' ga', ' beck', 'chairs', ' Wembley']] said[NN=['XM', ' Yosh', ' screenshot', 'Media', 'Ser']]

[kvcache_transformer] Epoch 3/10, Step 10/63 (global step: 30) Partial Avg Loss: 5.9119
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 5.7390
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_203944\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 5.9119
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=4, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=4, step=1...
 Top-p (p=0.95) Sample: Once upon a. how was help they and, watching done his the wanted who new toys upon near gave, to
 Annotated: Once upon a.[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']] how[NN=[' evapor', ' Brigham', ' excuses', ' Commerce', 'Attribute']] was[NN=['waters', ' pockets', ' Rory', 'IC', 'and']] help[NN=[' inexplicable', 'ackle', ' Dylan', ' hierarchy', ' paintings']] they[NN=['ume', ' Tib', 'oping', ' billion', ' RW']] and[NN=[' intrins', ' lets', 'rehensive', ' sell', ' shooter']],[NN=[' problem', ' Guides', ' twins', 'DS', ' John']] watching[NN=[' recl', ' knives', '50', ' jumper', 'armac']] done[NN=[' Weiss', ' economist', ' Vita', ' glacier', ' Poll']] his[NN=[' vowel', ' empath', ' earners', 'GR', ' Ms']] the[NN=[' Sr', ' Meth', ' disturbances', ' management', ' insider']] wanted[NN=['ulhu', ' pouring', ' abyss', ' squads', 'num']] who[NN=[' XY', 'produced', 'extremely', ' balloon', ' nick']] new[NN=[' Stick', 'farious', 'Gender', ' As', 'ceptions']] toys[NN=[' sentence', ' Louise', ' wavelengths', 'ESH', ' faulty']] upon[NN=[' overw', 'plays', 'GM', ' incred', ' wellness']] near[NN=['Lower', '�', ' notch', 'mberg', 'hee']] gave[NN=['channelAvailability', ' pledge', ' Rom', ' fighter', ' 232']],[NN=[' problem', ' Guides', ' twins', 'DS', ' John']] to[NN=['ossible', ' stone', ' foundation', ' Goodman', 'ciating']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=4, step=1...
 Top-p (p=1.0) Sample: Once upon a in her what, would she sawOne the that outside you noticed
 up excited white old all.
 Annotated: Once upon a in[NN=[' prisoner', ' sleep', 'osure', ' analytic', 'Rep']] her[NN=['029', '方', 'aging', 'ongh', ' Bans']] what[NN=[' Consider', 'udo', ' tend', 'Tony', ' haha']],[NN=[' problem', ' Guides', ' twins', 'DS', ' John']] would[NN=[' Barclays', ' Sunset', ' ru', ' specifics', 'Ord']] she[NN=['osures', ' Crest', ' brink', 'suff', ' horrific']] saw[NN=[' Vault', ' heard', ' Maiden', ' Hague', ' Thrones']]One[NN=[' @@', 'front', ' ticks', ' EFF', ' guiName']] the[NN=[' Sr', ' Meth', ' disturbances', ' management', ' insider']] that[NN=[' Sam', ' Banana', 'contract', ' Living', ' unquestion']] outside[NN=['ologist', ' intricate', 'inburgh', ' SQU', 'Steam']] you[NN=[' mark', ' regulatory', ' cycl', ' Berry', ' musician']] noticed[NN=['ross', ' Platform', ' Correspond', ' tacit', ' Thursday']]
[NN=['ASC', ' bag', ' concoct', ' 22', ' spelling']] up[NN=[' Facts', ' strengthening', 'below', ' Hats', ' unification']] excited[NN=[' succeed', ' nodded', ' food', ' Syndicate', 'phrine']] white[NN=['appro', 'raction', ' Analy', ' Compass', ' screamed']] old[NN=[' has', 'Demand', ' NAV', ' mis', ' Ser']] all[NN=['Educ', 'val', ' flashlight', ' tweaked', '-(']].[NN=[' Minority', ' tricks', ' 334', ' moves', ' identities']]


[kvcache_transformer] Generating sample text (greedy) at epoch=4, step=8...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=4, step=8...
 Top-p (p=0.95) Sample: Once upon a and came, it so. fell on you was there with to liked noticed play time made said had
 Annotated: Once upon a and[NN=[' sell', ' intrins', ' awkwardly', ' lets', 'rehensive']] came[NN=['Palestinian', ' warnings', ' revolves', ' Tucker', 'orer']],[NN=[' twins', ' John', ' problem', ' Guides', ' normal']] it[NN=[' anthem', ' Gur', ' wing', ' Viol', ' tent']] so[NN=[' poker', ' Caucasus', 'rh', ' wipe', 'Rock']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']] fell[NN=[' composer', ' gray', ' doctor', ' relig', 'ooming']] on[NN=[' canopy', 'IES', 'housing', ' Roger', ' Douglas']] you[NN=[' mark', ' Southampton', ' regulatory', ' Berry', 'regnancy']] was[NN=['waters', ' pockets', 'and', 'IC', ' Cindy']] there[NN=['eties', 'llers', 'itudinal', ' ObamaCare', 'poral']] with[NN=['asm', ' hunter', ' unsure', ' rejection', 'innacle']] to[NN=[' stone', 'ossible', ' ""', ' foundation', ' Goodman']] liked[NN=[' Lisp', 'aucuses', ' grids', 'ect', 'Bet']] noticed[NN=['ross', ' Correspond', ' Platform', ' yard', ' tacit']] play[NN=[' discriminated', ' floor', 'dom', ' patch', 'debian']] time[NN=[' summons', 'Lew', 'bg', 'flix', 'chev']] made[NN=['ammed', ' Laur', ' Wilderness', ' YES', ' 1905']] said[NN=['XM', 'No', ' eating', ' course', ' Yosh']] had[NN=[' main', ' hacked', ' gem', 'photo', ' Grand']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=4, step=8...
 Top-p (p=1.0) Sample: Once upon a she know "" was what.""'t mom's felt. puts day, the upon under you under fire
 Annotated: Once upon a she[NN=['suff', ' Crest', 'osures', ' Insp', ' brink']] know[NN=[' punched', ' multiplication', ' federal', 'ijuana', ' goblin']] ""[NN=['�', ' to', ' flowering', 'Custom', ' Gaddafi']] was[NN=['waters', ' pockets', 'and', 'IC', ' Cindy']] what[NN=[' Consider', 'udo', ' tend', ' haha', 'Tony']].""[NN=['\n', ' bridge', ' demonic', 'contin', 'aneously']]'t[NN=[' have', ' drafted', ' blessed', ' Brandon', ' conceived']] mom[NN=['Guest', ' ceilings', 'uchin', ' Aux', ' lament']]'s[NN=[' nodd', ' tests', ' poems', 'Hamilton', ' overview']] felt[NN=[' inund', 'UFF', ' empir', 'opened', 'iverpool']].[NN=[' moves', ' Minority', ' tricks', 'Cl', ' wishes']] puts[NN=['Market', ' deprecated', 'ways', ' warmed', 'time']] day[NN=['orius', ' livelihood', ' majesty', 'ended', ' Then']],[NN=[' twins', ' John', ' problem', ' Guides', ' normal']] the[NN=[' Sr', ' disturbances', ' Meth', 'ouse', ' management']] upon[NN=['plays', 'GM', ' overw', ' incred', ' wellness']] under[NN=[' Ultra', 'click', 'ス', 'raints', ' narc']] you[NN=[' mark', ' Southampton', ' regulatory', ' Berry', 'regnancy']] under[NN=[' Ultra', 'click', 'ス', 'raints', ' narc']] fire[NN=['Wh', 'Sarah', ' greeted', 'SU', ' Hispanic']]

[kvcache_transformer] Epoch 4/10, Step 10/63 (global step: 40) Partial Avg Loss: 5.6224
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 5.4880
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_203944\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 5.6224
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=5, step=3...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']] a[NN=['Utah', 'izontal', 'What', ' Photography', ' prepare']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=5, step=3...
 Top-p (p=0.95) Sample: Once upon a all in friend named an and of she some. there about, it saw day wanted so that's
 Annotated: Once upon a all[NN=['Educ', 'val', '-(', 'oda', ' tweaked']] in[NN=[' sleep', ' prisoner', 'osure', ' least', ' analytic']] friend[NN=[' Vox', ' kinderg', 'OUNT', ' fair', ' 10000']] named[NN=[' sav', ' pocket', 'crete', ' hallway', 'URRENT']] an[NN=['idency', ' basic', ' Pump', 'Radio', 'gger']] and[NN=[' awkwardly', ' sell', ' lets', ' Leadership', 'rehensive']] of[NN=['�', ' cues', 'ANGE', 'Untitled', ' Malaysian']] she[NN=[' Insp', 'suff', ' Crest', ' brink', ' differences']] some[NN=[' potatoes', 'France', ' mountain', 'opia', 'integer']].[NN=[' moves', ' Minority', ' wishes', 'Cl', ' tricks']] there[NN=['eties', 'itudinal', 'llers', '333', ' ObamaCare']] about[NN=['013', ' Heaven', 'sty', ' on', ' predictably']],[NN=[' twins', ' John', ' Guides', ' puzzle', ' normal']] it[NN=[' anthem', ' wing', ' Gur', ' Viol', ' tent']] saw[NN=[' Vault', ' heard', ' found', ' angels', ' Hague']] day[NN=['orius', ' livelihood', 'ended', ' majesty', ' """"']] wanted[NN=['ulhu', ' pouring', 'castle', ' abyss', ' Then']] so[NN=[' Caucasus', 'Rock', ' wipe', 'rh', ' poker']] that[NN=[' Sam', 'urances', 'contract', ' Banana', ' taken']]'s[NN=[' nodd', ' my', ' tests', ' be', ' overview']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=5, step=3...
 Top-p (p=1.0) Sample: Once upon a. shoulder Lily, called by are for was there onâily day it "" and that looked the
 Annotated: Once upon a.[NN=[' moves', ' Minority', ' wishes', 'Cl', ' tricks']] shoulder[NN=[' interference', 'Train', ' emerge', ' Cult', 'eding']] Lily[NN=[' declared', ' Disable', ' Haz', ' handc', ' comr']],[NN=[' twins', ' John', ' Guides', ' puzzle', ' normal']] called[NN=[' Palin', ' GSL', ' pitched', ' won', 'L']] by[NN=[' Cato', ' Make', ' stir', ' hills', '*.']] are[NN=[' Gro', ' pupils', '�', ' Brookings', 'arian']] for[NN=['aging', ' McGu', 'orters', ' Credits', 'igo']] was[NN=['waters', ' pockets', 'IC', ' Cindy', ' shown']] there[NN=['eties', 'itudinal', 'llers', '333', ' ObamaCare']] on[NN=[' canopy', 'IES', ' Roger', 'housing', ' Aless']]â[NN=[' Tradition', 'enc', ' feminist', 'Utah', 'OE']]ily[NN=['Stats', ' probing', ' applicable', ' Natasha', 'affected']] day[NN=['orius', ' livelihood', 'ended', ' majesty', ' """"']] it[NN=[' anthem', ' wing', ' Gur', ' Viol', ' tent']] ""[NN=[' to', '�', ' flowering', 'Custom', ' Gaddafi']] and[NN=[' awkwardly', ' sell', ' lets', ' Leadership', 'rehensive']] that[NN=[' Sam', 'urances', 'contract', ' Banana', ' taken']] looked[NN=['irens', 'odder', 'zn', ' poor', ' Slack']] the[NN=[' Sr', ' disturbances', ' Meth', 'ouse', ' thick']]

[kvcache_transformer] Epoch 5/10, Step 10/63 (global step: 50) Partial Avg Loss: 5.4030

[kvcache_transformer] Generating sample text (greedy) at epoch=5, step=10...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=5, step=10...
 Top-p (p=0.95) Sample: Once upon a was friends. but, to, mom he and the of a there it asked't she who knew
 Annotated: Once upon a was[NN=['waters', ' Cindy', ' indef', ' pockets', 'IC']] friends[NN=['ilda', ' clearing', 'antam', 'anges', 'odied']].[NN=[' moves', ' wishes', '?""', ' penn', ' Minority']] but[NN=[' interpreter', ' analog', 'retched', ' eval', 'itational']],[NN=[' John', ' twins', ' puzzle', ' fashion', ' Bub']] to[NN=[' ""', ' allow', ' Little', ' Goodman', ' foundation']],[NN=[' John', ' twins', ' puzzle', ' fashion', ' Bub']] mom[NN=['!""', 'Guest', ' Tim', ' Aux', ' treasures']] he[NN=[' Corona', ' claimed', 'mc', ' xp', 'trace']] and[NN=[' young', ' favourite', ' cubic', ' Drill', '491']] the[NN=[' Sr', ' This', ' disturbances', 'ouse', ' Meth']] of[NN=['Her', 'ANGE', '�', ' Malaysian', ' cues']] a[NN=['Utah', ' prepare', 'izontal', 'oll', 'What']] there[NN=['eties', 'itudinal', '333', ' ObamaCare', ' Berkeley']] it[NN=[' anthem', ' wing', ' Viol', ' Gur', 'InstoreAndOnline']] asked[NN=[' damaged', ' motorists', 'enges', ' Brent', ' Welcome']]'t[NN=[' have', ' drafted', ' blessed', 'othy', ' column']] she[NN=[' differences', ' Insp', ' Crest', ' brink', 'ALLY']] who[NN=[' balloon', ' XY', '�', ' logic', ' scrim']] knew[NN=[' delicious', ' priests', ' preferences', ' lodge', ' DJs']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=5, step=10...
 Top-p (p=1.0) Sample: Once upon a she, were. of to was."" outside dress matter had there on't and he his the ""
 Annotated: Once upon a she[NN=[' differences', ' Insp', ' Crest', ' brink', 'ALLY']],[NN=[' John', ' twins', ' puzzle', ' fashion', ' Bub']] were[NN=[' my', ' bad', ' troubled', ' big', '."",']].[NN=[' moves', ' wishes', '?""', ' penn', ' Minority']] of[NN=['Her', 'ANGE', '�', ' Malaysian', ' cues']] to[NN=[' ""', ' allow', ' Little', ' Goodman', ' foundation']] was[NN=['waters', ' Cindy', ' indef', ' pockets', 'IC']].""[NN=['\n', ' bridge', ' become', 'contin', ' creatine']] outside[NN=[' again', ' Mom', ' cry', ' accompanies', 'Can']] dress[NN=['34', ' Revival', ' UT', ' blanket', ' NAT']] matter[NN=[' incidents', ' migrants', ' dorm', ' swords', 'joined']] had[NN=[' main', ' heard', ' hacked', ' Grand', 'photo']] there[NN=['eties', 'itudinal', '333', ' ObamaCare', ' Berkeley']] on[NN=[' canopy', 'IES', ' about', ' Roger', ' Aless']]'t[NN=[' have', ' drafted', ' blessed', 'othy', ' column']] and[NN=[' young', ' favourite', ' cubic', ' Drill', '491']] he[NN=[' Corona', ' claimed', 'mc', ' xp', 'trace']] his[NN=['Lev', ' vowel', ' Ms', ' another', ' ""']] the[NN=[' Sr', ' This', ' disturbances', 'ouse', ' Meth']] ""[NN=[' to', '�', ' flowering', ' his', ' keep']]

[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 5.3019
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_203944\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 5.4030
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=6, step=6...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']] a[NN=['Utah', 'What', 'س', 'izontal', ' prepare']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=6, step=6...
 Top-p (p=0.95) Sample: Once upon a named the., there was her for it and fun noticed decided your an of in's! she
 Annotated: Once upon a named[NN=[' sav', ' pocket', 'crete', ' hallway', 'URRENT']] the[NN=[' Sr', ' This', 'Her', ' The', ' his']].[NN=['?""', ' wishes', ' moves', ' wish', '\n']],[NN=[' John', ' twins', ' noticed', ' fashion', ' Grand']] there[NN=['itudinal', 'eties', '333', ' ObamaCare', 'ports']] was[NN=[' indef', 'waters', ' Cindy', ' minus', ' pockets']] her[NN=['方', '029', ' Hort', 'Her', 'Hall']] for[NN=['aging', ' reviewer', ' McGu', ' teachings', 'igo']] it[NN=[' wing', ' anthem', ' Benny', 'InstoreAndOnline', ' Viol']] and[NN=[' young', 'pool', ' cubic', ' Drill', ' can']] fun[NN=[' seemed', ' neighbours', 'Sad', 'ochemical', ' claws']] noticed[NN=['ross', ' Correspond', ',', ' Platform', ' out']] decided[NN=[' loved', 'otally', 'Offline', ' themselves', 'aldi']] your[NN=[' Adelaide', ' Britann', ""'s"", ' A', ' Balanced']] an[NN=[' Pump', ' sw', 'idency', ' basic', ' I']] of[NN=['Her', 'ANGE', ' Malaysian', 'We', '�']] in[NN=[' sleep', 'osure', ' prisoner', ' least', 'Rep']]'s[NN=[' his', ' be', ' little', ' overview', ' my']]![NN=[' symbol', ' baptism', 'ety', 'With', ' consecut']] she[NN=[' He', ' differences', ' Insp', ' Crest', 'ALLY']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=6, step=6...
 Top-p (p=1.0) Sample: Once upon a, she named. the was books the Joey got nodded you he in they was and happy of wanted
 Annotated: Once upon a,[NN=[' John', ' twins', ' noticed', ' fashion', ' Grand']] she[NN=[' He', ' differences', ' Insp', ' Crest', 'ALLY']] named[NN=[' sav', ' pocket', 'crete', ' hallway', 'URRENT']].[NN=['?""', ' wishes', ' moves', ' wish', '\n']] the[NN=[' Sr', ' This', 'Her', ' The', ' his']] was[NN=[' indef', 'waters', ' Cindy', ' minus', ' pockets']] books[NN=[' Savior', 'ying', 'gel', ' hot', ' Sharma']] the[NN=[' Sr', ' This', 'Her', ' The', ' his']] Joey[NN=[' wartime', 'elf', ' abort', ' Cheap', ' branch']] got[NN=[' Patricia', ' sack', 'ESCO', ' CLA', ' 219']] nodded[NN=[' excited', ' swords', ' moment', ' Satellite', ' rife']] you[NN=[' mark', 'regnancy', ' regulatory', ' Berry', ' Southampton']] he[NN=[' She', ' she', ' claimed', ' Corona', 'ologies']] in[NN=[' sleep', 'osure', ' prisoner', ' least', 'Rep']] they[NN=[' ensemble', ' to', ' the', ""'s"", 'ume']] was[NN=[' indef', 'waters', ' Cindy', ' minus', ' pockets']] and[NN=[' young', 'pool', ' cubic', ' Drill', ' can']] happy[NN=['piece', 'look', ' «', ' bouts', ' Queen']] of[NN=['Her', 'ANGE', ' Malaysian', 'We', '�']] wanted[NN=['ulhu', ' pouring', ' Then', 'castle', ' alone']]

[kvcache_transformer] Epoch 6/10, Step 10/63 (global step: 60) Partial Avg Loss: 5.2567
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kvcache_transformer] Validation Loss after epoch 6: 5.1984
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_203944\epoch_6.pt
[kvcache_transformer] *** End of Epoch 6 *** Avg Loss: 5.2567
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=7, step=2...
 Greedy Sample: Once upon a,,,,,,,,,,,,,,,,,,,,
 Annotated: Once upon a,[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=7, step=2...
 Top-p (p=0.95) Sample: Once upon a, named the,. Lily was and were is's woke there. an. day he his of
 Annotated: Once upon a,[NN=[' John', ' twins', ' Grand', ' noticed', 'When']] named[NN=[' pocket', ' sav', 'crete', ' crash', 'URRENT']] the[NN=[' The', ' his', 'Her', ' would', ' ""']],[NN=[' John', ' twins', ' Grand', ' noticed', 'When']].[NN=['?""', '\n', ' wish', ' wishes', ' moves']] Lily[NN=[' declared', 'default', ' Haz', ' Disable', ' hair']] was[NN=[' Cindy', ' indef', 'waters', ' minus', ' shown']] and[NN=[' can', ' young', ' new', ' the', '""']] were[NN=[' my', ' bad', ' troubled', ' big', '."",']] is[NN=[' fan', ' Snow', ' module', ' with', ' a']]'s[NN=[' his', ' your', ' cr', ' my', ' overview']] woke[NN=[' arrangements', ' sweets', ' block', ' scarcely', ' gears']] there[NN=['itudinal', 'ports', ' noses', ' ObamaCare', ' enrolled']].[NN=['?""', '\n', ' wish', ' wishes', ' moves']] an[NN=[' sw', ' Pump', ' accidentally', ' basic', 'gger']].[NN=['?""', '\n', ' wish', ' wishes', ' moves']] day[NN=['orius', ' one', 'um', ' poppy', ' tool']] he[NN=[' She', ' she', 'ologies', ' claimed', ' Corona']] his[NN=[' The', ' ""', ' to', ' the', ' another']] of[NN=['Her', 'ANGE', 'We', ' Malaysian', ' are']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=7, step=2...
 Top-p (p=1.0) Sample: Once upon a, playedmy. over said named was he and clearing andily. the a! of has party
 Annotated: Once upon a,[NN=[' John', ' twins', ' Grand', ' noticed', 'When']] played[NN=[' glaciers', ' pressures', ' SEA', 'intuitive', ' anything']]my[NN=[' inquired', ' menu', ' universe', 'Joy', ' cyclist']].[NN=['?""', '\n', ' wish', ' wishes', ' moves']] over[NN=[' yet', ' elected', ' ingest', ' Ben', ' quo']] said[NN=['XM', 'Ser', ' course', ' sights', 'No']] named[NN=[' pocket', ' sav', 'crete', ' crash', 'URRENT']] was[NN=[' Cindy', ' indef', 'waters', ' minus', ' shown']] he[NN=[' She', ' she', 'ologies', ' claimed', ' Corona']] and[NN=[' can', ' young', ' new', ' the', '""']] clearing[NN=[' carrots', ' forcefully', ' friends', 'cation', ' runtime']] and[NN=[' can', ' young', ' new', ' the', '""']]ily[NN=['Stats', ' probing', ' Natasha', ' spar', ' applicable']].[NN=['?""', '\n', ' wish', ' wishes', ' moves']] the[NN=[' The', ' his', 'Her', ' would', ' ""']] a[NN=[' big', 'Utah', ' is', 'What', 'س']]![NN=[' symbol', ' baptism', 'ety', ' owner', 'With']] of[NN=['Her', 'ANGE', 'We', ' Malaysian', ' are']] has[NN=[' old', 'UM', 'appa', 'ister', 'delete']] party[NN=[' refinement', ' Karachi', ' Sum', ' disappeared', ' environments']]


[kvcache_transformer] Generating sample text (greedy) at epoch=7, step=9...
 Greedy Sample: Once upon a,,,,,,,,,,,,,,,,,,,,
 Annotated: Once upon a,[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=7, step=9...
 Top-p (p=0.95) Sample: Once upon a. was named and?"", the he were in liked her called to friends a ran they so could
 Annotated: Once upon a.[NN=['"".', '?""', '\n', ' wish', ' wishes']] was[NN=[' Cindy', ' indef', ' minus', 'waters', ' Bans']] named[NN=[' pocket', ' sav', ' crash', 'crete', 'URRENT']] and[NN=[' can', ' the', ' young', ' of', ' new']]?""[NN=[' ', '\n', '.', '.""', ' leaking']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']] the[NN=[' The', ' ""', ' his', ' would', ' new']] he[NN=[' she', ' She', 'ologies', ' classy', ' claimed']] were[NN=[' my', ' big', ' bad', ' troubled', 'compatible']] in[NN=[' sleep', ' into', ' on', ' yellow', 'Rep']] liked[NN=[' Lisp', 'aucuses', ' prol', 'enges', 'ect']] her[NN=['方', '029', ' Hort', 'Her', 'Hall']] called[NN=[' Korean', ' He', ' NXT', ' GSL', ' new']] to[NN=[' ""', ' The', ' his', ' will', ' their']] friends[NN=['ilda', 'playing', ' outside', ' inappropriate', ' shouting']] a[NN=[' big', ' is', 'Utah', 'S', 't']] ran[NN=[' oft', '�', ' lenses', ' pornographic', ' Millions']] they[NN=[' to', ' the', ' ensemble', ""'s"", ' would']] so[NN=['Rock', ' personally', ' push', ' Caucasus', ' influences']] could[NN=[' new', ' the', ' ""', ' Ezekiel', ' Shared']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=7, step=9...
 Top-p (p=1.0) Sample: Once upon a. was, there and his't box went of named said tight to the kept wanted some lots in
 Annotated: Once upon a.[NN=['"".', '?""', '\n', ' wish', ' wishes']] was[NN=[' Cindy', ' indef', ' minus', 'waters', ' Bans']],[NN=[' Grand', ' Her', 'When', ' noticed', ' twins']] there[NN=[' exploring', 'ports', ' Dust', ' enrolled', ' colourful']] and[NN=[' can', ' the', ' young', ' of', ' new']] his[NN=[' ""', ' The', ' the', ' to', ' another']]'t[NN=[' have', ' kisses', ' drafted', ' first', ' horn']] box[NN=['balance', ' web', ' speculative', ' sandwiches', ' dressed']] went[NN=[' square', ' cooking', ' clothes', ' comforting', ' permissions']] of[NN=['Her', 'ANGE', ' and', 'We', ' Malaysian']] named[NN=[' pocket', ' sav', ' crash', 'crete', 'URRENT']] said[NN=[' course', 'XM', 'Ser', 'No', ' sights']] tight[NN=['VG', ' Blessing', ' nighttime', 'Sher', 'Cra']] to[NN=[' ""', ' The', ' his', ' will', ' their']] the[NN=[' The', ' ""', ' his', ' would', ' new']] kept[NN=[' boards', 'ove', ' 114', 'opian', ' carving']] wanted[NN=['ulhu', ' pouring', ' alone', ' flashes', ' Then']] some[NN=['hu', '!""', 'France', '�', ' die']] lots[NN=['Kn', ' surrounding', ' NIGHT', '999', ' stret']] in[NN=[' sleep', ' into', ' on', ' yellow', 'Rep']]

[kvcache_transformer] Epoch 7/10, Step 10/63 (global step: 70) Partial Avg Loss: 5.1560
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kvcache_transformer] Validation Loss after epoch 7: 5.1141
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_203944\epoch_7.pt
[kvcache_transformer] *** End of Epoch 7 *** Avg Loss: 5.1560
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=8, step=4...
 Greedy Sample: Once upon a was was was was was was was was was was was was was was was was was was was was
 Annotated: Once upon a was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=8, step=4...
 Top-p (p=0.95) Sample: Once upon a, and was named the. excited: in day were it them long went her an something standing they
 Annotated: Once upon a,[NN=[' Grand', ' noticed', 'When', ' John', ' Her']] and[NN=[' can', ' the', ' of', ' young', ' new']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']] named[NN=[' pocket', ' sav', 'crete', ' crash', '/.']] the[NN=[' The', ' ""', ' his', ' will', ' would']].[NN=['"".', '?""', ' decor', '\n', ' wishes']] excited[NN=[' nodded', ' food', ' clothes', ' tried', ' paws']]:[NN=['bp', ' promoting', 'Everybody', ' Community', 'ocobo']] in[NN=[' sleep', ' into', ' on', ' yellow', 'Rep']] day[NN=[' park', ' poppy', ' then', ' glossy', 'orius']] were[NN=[' my', ' big', ' bad', ' troubled', 'compatible']] it[NN=[' wing', ' Benny', ' anthem', 'ages', 'InstoreAndOnline']] them[NN=[' hurt', ' Mirage', ' jumped', ' pancakes', ' aboard']] long[NN=[' mix', ' rebellious', ' going', ' doctor', ' hair']] went[NN=[' square', ' clothes', ' comforting', ' cooking', ' came']] her[NN=['方', ' Hort', '029', 'Hall', ' markets']] an[NN=[' sw', ' Pump', ' wishes', ' Mitt', 'gger']] something[NN=[' seats', ' Came', ' Sauce', ' open', 'artisan']] standing[NN=['JM', 'syn', ' CVE', 'done', ' Pant']] they[NN=[' to', ' the', ""'s"", ' ensemble', '235']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=8, step=4...
 Top-p (p=1.0) Sample: Once upon a who was's the, a. named named and were with playing to outside behind as is asked in
 Annotated: Once upon a who[NN=[' XY', ' logic', ' balloon', 'extremely', ' scrim']] was[NN=[' Cindy', ' indef', ' so', ' minus', 'waters']]'s[NN=[' your', ' his', ' the', ' �', ' cr']] the[NN=[' The', ' ""', ' his', ' will', ' would']],[NN=[' Grand', ' noticed', 'When', ' John', ' Her']] a[NN=[' big', 'The', ' is', 'Utah', 't']].[NN=['"".', '?""', ' decor', '\n', ' wishes']] named[NN=[' pocket', ' sav', 'crete', ' crash', '/.']] named[NN=[' pocket', ' sav', 'crete', ' crash', '/.']] and[NN=[' can', ' the', ' of', ' young', ' new']] were[NN=[' my', ' big', ' bad', ' troubled', 'compatible']] with[NN=[' is', ' big', 'cedented', '�', 'Lin']] playing[NN=[' songs', ' mild', ' whist', '014', ' hooks']] to[NN=[' ""', ' The', ' his', ' will', ' their']] outside[NN=[' Mom', ' again', ' friends', ' paper', 'Can']] behind[NN=[' bear', ' find', 'ips', ' LIFE', ' Beckham']] as[NN=[' Tara', ',', ' widespread', ' witty', ' 1914']] is[NN=[' with', ' fan', ' a', ' Snow', '�']] asked[NN=[' motorists', ' damaged', ' kids', ' inefficient', ' locked']] in[NN=[' sleep', ' into', ' on', ' yellow', 'Rep']]

[kvcache_transformer] Epoch 8/10, Step 10/63 (global step: 80) Partial Avg Loss: 5.0892
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 8 early.
[kvcache_transformer] Validation Loss after epoch 8: 5.0606
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_203944\epoch_8.pt
[kvcache_transformer] *** End of Epoch 8 *** Avg Loss: 5.0892
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=9, step=1...
 Greedy Sample: Once upon a,,,,,,,,,,,,,,,,,,,,
 Annotated: Once upon a,[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=9, step=1...
 Top-p (p=0.95) Sample: Once upon a was, named the. with his called there called in to who and liked walking lived day called were
 Annotated: Once upon a was[NN=[' so', ' indef', ' noisy', ' Cindy', ' minus']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']] named[NN=[' pocket', ' sav', 'crete', '/.', ' crash']] the[NN=[' ""', ' The', ' his', ' will', ' their']].[NN=['"".', '?""', ' decor', ' wishes', '\n']] with[NN=[' is', ' big', 'cedented', '�', ' Series']] his[NN=[' the', ' ""', ' to', ' The', ""'s""]] called[NN=[' He', ' Korean', ' His', ' his', ' new']] there[NN=[' exploring', ' Taking', ' bron', ' Dust', 'ports']] called[NN=[' He', ' Korean', ' His', ' his', ' new']] in[NN=[' into', ' sleep', ' on', ' yellow', ' do']] to[NN=[' ""', ' his', ' The', ' their', ' will']] who[NN=[' XY', ' logic', 'extremely', ' balloon', ' nick']] and[NN=[' can', ' of', ' new', ' young', ' the']] liked[NN=['aucuses', ' Lisp', 'L', 'P', 'enges']] walking[NN=['orescence', ' variants', ' denominations', '211', ' wisdom']] lived[NN=['Expl', ' Colomb', ' view', ' commander', 'pay']] day[NN=[' then', ' park', ' poppy', ' Then', ' bike']] called[NN=[' He', ' Korean', ' His', ' his', ' new']] were[NN=[' my', ' big', ' bad', ' troubled', 'compatible']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=9, step=1...
 Top-p (p=1.0) Sample: Once upon a was in, called blue who the named. his there for of was on were and loved a her
 Annotated: Once upon a was[NN=[' so', ' indef', ' noisy', ' Cindy', ' minus']] in[NN=[' into', ' sleep', ' on', ' yellow', ' do']],[NN=[' noticed', ' Grand', 'When', ' she', ' Her']] called[NN=[' He', ' Korean', ' His', ' his', ' new']] blue[NN=[' tally', ' dominant', ' scourge', ' acc', ' bake']] who[NN=[' XY', ' logic', 'extremely', ' balloon', ' nick']] the[NN=[' ""', ' The', ' his', ' will', ' their']] named[NN=[' pocket', ' sav', 'crete', '/.', ' crash']].[NN=['"".', '?""', ' decor', ' wishes', '\n']] his[NN=[' the', ' ""', ' to', ' The', ""'s""]] there[NN=[' exploring', ' Taking', ' bron', ' Dust', 'ports']] for[NN=[' ate', 'aging', ' teachings', ' co', ""'t""]] of[NN=['Her', 'ANGE', ' and', ' we', ' Malaysian']] was[NN=[' so', ' indef', ' noisy', ' Cindy', ' minus']] on[NN=[' into', ' canopy', ' in', ' find', ' see']] were[NN=[' my', ' big', ' bad', ' troubled', 'compatible']] and[NN=[' can', ' of', ' new', ' young', ' the']] loved[NN=['One', ' decided', ' fly', ' park', 'Look']] a[NN=[' big', 'The', ' is', 't', ' brightest']] her[NN=['方', '029', ' Hort', ' markets', 'Shape']]


[kvcache_transformer] Generating sample text (greedy) at epoch=9, step=8...
 Greedy Sample: Once upon a named named named named named named named named named named named named named named named named named named named named
 Annotated: Once upon a named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=9, step=8...
 Top-p (p=0.95) Sample: Once upon a, was named who were called in there Sam day named. named an named Mia lived andolly with
 Annotated: Once upon a,[NN=[' noticed', ' Grand', 'When', ' she', ' but']] was[NN=[' so', ' indef', ' noisy', ' toy', ' minus']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] who[NN=[' XY', ' logic', 'extremely', ' nick', ' scrim']] were[NN=[' my', ' big', ' bad', ' troubled', ' not']] called[NN=[' He', ' Korean', ' His', ' his', ' Jen']] in[NN=[' into', ' on', ' do', ' sleep', ' yellow']] there[NN=[' person', ' Taking', ' bron', ' exploring', ' sor']] Sam[NN=[' Canberra', ' Particip', ' ruining', ' scientifically', ' cigars']] day[NN=[' then', ' Then', ' park', ' shouted', 'orius']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']].[NN=['"".', '?""', ' decor', ' wishes', '!""']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] an[NN=[' sw', ' Pump', ' wishes', ' K', '.']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] Mia[NN=[' donation', ' pulled', 'settings', ' Situation', 'opath']] lived[NN=['Expl', ' other', 'pay', ' Colomb', ' view']] and[NN=[' of', ' She', ' young', ' cubic', ' can']]olly[NN=[' Princess', ' subsections', '....', ' wrench', ' Observer']] with[NN=[' is', ' big', 'cedented', '�', ' Series']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=9, step=8...
 Top-p (p=1.0) Sample: Once upon a who named was, were time in there. loved who to Ben called named lived named day closed.
 Annotated: Once upon a who[NN=[' XY', ' logic', 'extremely', ' nick', ' scrim']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] was[NN=[' so', ' indef', ' noisy', ' toy', ' minus']],[NN=[' noticed', ' Grand', 'When', ' she', ' but']] were[NN=[' my', ' big', ' bad', ' troubled', ' not']] time[NN=[' help', 'flix', ' jumping', 'bg', 'Lew']] in[NN=[' into', ' on', ' do', ' sleep', ' yellow']] there[NN=[' person', ' Taking', ' bron', ' exploring', ' sor']].[NN=['"".', '?""', ' decor', ' wishes', '!""']] loved[NN=['One', ' decided', 'Look', ' park', ' happened']] who[NN=[' XY', ' logic', 'extremely', ' nick', ' scrim']] to[NN=[' ""', ' his', ' The', ' their', ' will']] Ben[NN=[' pair', ' spots', 'insula', ' broadcast', ' goes']] called[NN=[' He', ' Korean', ' His', ' his', ' Jen']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] lived[NN=['Expl', ' other', 'pay', ' Colomb', ' view']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] day[NN=[' then', ' Then', ' park', ' shouted', 'orius']] closed[NN=[' Historically', ' LOT', 'ths', 'ies', ' plain']].[NN=['"".', '?""', ' decor', ' wishes', '!""']]

[kvcache_transformer] Epoch 9/10, Step 10/63 (global step: 90) Partial Avg Loss: 5.0026
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 9 early.
[kvcache_transformer] Validation Loss after epoch 9: 4.9543
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_203944\epoch_9.pt
[kvcache_transformer] *** End of Epoch 9 *** Avg Loss: 5.0026
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=10, step=3...
 Greedy Sample: Once upon a named named named named named named named named named named named named named named named named named named named named
 Annotated: Once upon a named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=10, step=3...
 Top-p (p=0.95) Sample: Once upon a and was named were called,. loved are lived there in who of bear Ben girl areily little
 Annotated: Once upon a and[NN=[' She', ' of', ' young', ' he', ' cubic']] was[NN=[' so', ' indef', ' noisy', '�', ' on']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] were[NN=[' my', ' big', ' bad', ' not', ' matching']] called[NN=[' He', ' His', ' Korean', ' his', ' Jen']],[NN=[' noticed', ' she', 'When', ' Grand', ' but']].[NN=['"".', ' decor', '?""', '!""', ' ""']] loved[NN=['One', ' decided', 'Look', ' happened', ' park']] are[NN=[' Behind', ' Gro', ' pupils', ' of', ' Do']] lived[NN=['Expl', ' other', 'pay', ' replied', ' view']] there[NN=[' person', ' Taking', ' bron', 'Do', ' sor']] in[NN=[' on', ' into', ' do', ' sleep', ' yellow']] who[NN=[' XY', ' logic', 'extremely', ' scrim', ' balloon']] of[NN=['Her', ' and', 'ANGE', ' She', ' we']] bear[NN=[' behind', ' fridge', 'At', ' militias', 's']] Ben[NN=[' pair', ' spots', 'insula', ' broadcast', ' goes']] girl[NN=['watching', ' Individual', ' confront', ' focused', 'iversal']] are[NN=[' Behind', ' Gro', ' pupils', ' of', ' Do']]ily[NN=[' spar', 'Stats', ' what', 'Women', ' probing']] little[NN=[' their', ' would', ' The', ""'s"", ' the']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=10, step=3...
 Top-p (p=1.0) Sample: Once upon a who named was called, there. time lived some Jack Denise and day Ben do who sunny were in
 Annotated: Once upon a who[NN=[' XY', ' logic', 'extremely', ' scrim', ' balloon']] named[NN=[' pocket', '/.', ' sav', 'crete', 'ingers']] was[NN=[' so', ' indef', ' noisy', '�', ' on']] called[NN=[' He', ' His', ' Korean', ' his', ' Jen']],[NN=[' noticed', ' she', 'When', ' Grand', ' but']] there[NN=[' person', ' Taking', ' bron', 'Do', ' sor']].[NN=['"".', ' decor', '?""', '!""', ' ""']] time[NN=[' help', 'flix', ' jumping', 'bg', 'Lew']] lived[NN=['Expl', ' other', 'pay', ' replied', ' view']] some[NN=[' without', ' LIB', 'anan', ' renaissance', ' seeker']] Jack[NN=['P', ' Joe', ' wine', ' Major', ' patriotic']] Denise[NN=['alker', ' farewell', ' supplementary', ' liver', ' Hitler']] and[NN=[' She', ' of', ' young', ' he', ' cubic']] day[NN=[' then', ' Then', ' shouted', 'orius', ' shelf']] Ben[NN=[' pair', ' spots', 'insula', ' broadcast', ' goes']] do[NN=[' in', ' peek', ' so', ' find', ' gave']] who[NN=[' XY', ' logic', 'extremely', ' scrim', ' balloon']] sunny[NN=['inn', 'Tel', '270', ' Trib', ' over']] were[NN=[' my', ' big', ' bad', ' not', ' matching']] in[NN=[' on', ' into', ' do', ' sleep', ' yellow']]

[kvcache_transformer] Epoch 10/10, Step 10/63 (global step: 100) Partial Avg Loss: 4.9475

[kvcache_transformer] Generating sample text (greedy) at epoch=10, step=10...
 Greedy Sample: Once upon a named named named named named named named named named named named named named named named named named named named named
 Annotated: Once upon a named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=10, step=10...
 Top-p (p=0.95) Sample: Once upon a named was who lived in there, called in through, was, were. Ben Mia day time named
 Annotated: Once upon a named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] was[NN=[' so', '�', ' on', ' indef', ' noisy']] who[NN=[' balloon', ' XY', ' logic', ' scrim', 'extremely']] lived[NN=['Expl', ' other', ' replied', ' view', 'pay']] in[NN=[' on', ' into', ' do', ' yellow', ' sleep']] there[NN=[' person', ' Taking', 'uddle', 'Do', ' home']],[NN=['When', ' but', ' noticed', ' Grand', ' Her']] called[NN=[' He', ' His', ' Korean', ' his', ' Jen']] in[NN=[' on', ' into', ' do', ' yellow', ' sleep']] through[NN=[' open', ' strap', 'onz', ' heard', ' found']],[NN=['When', ' but', ' noticed', ' Grand', ' Her']] was[NN=[' so', '�', ' on', ' indef', ' noisy']],[NN=['When', ' but', ' noticed', ' Grand', ' Her']] were[NN=[' my', ' big', ' bad', ' not', ' matching']].[NN=['"".', ' ""', '!""', ' decor', '?""']] Ben[NN=[' pair', 'insula', ' spots', ' goes', ' broadcast']] Mia[NN=[' donation', 'borgh', 'settings', ' pulled', ' compress']] day[NN=[' then', ' Then', ' shouted', 'orius', ' teasing']] time[NN=[' help', 'flix', ' jumping', 'bg', 'Lew']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=10, step=10...
 Top-p (p=1.0) Sample: Once upon a was named lived in there, to called who was loved 3 daycy and was. on was were
 Annotated: Once upon a was[NN=[' so', '�', ' on', ' indef', ' noisy']] named[NN=[' pocket', ' sav', '/.', 'crete', 'ingers']] lived[NN=['Expl', ' other', ' replied', ' view', 'pay']] in[NN=[' on', ' into', ' do', ' yellow', ' sleep']] there[NN=[' person', ' Taking', 'uddle', 'Do', ' home']],[NN=['When', ' but', ' noticed', ' Grand', ' Her']] to[NN=[' ""', ' The', ' their', ' his', ' the']] called[NN=[' He', ' His', ' Korean', ' his', ' Jen']] who[NN=[' balloon', ' XY', ' logic', ' scrim', 'extremely']] was[NN=[' so', '�', ' on', ' indef', ' noisy']] loved[NN=['One', 'Look', ' decided', ' happened', ' park']] 3[NN=[' mating', ' little', 'Amount', ' nerve', ' Risk']] day[NN=[' then', ' Then', ' shouted', 'orius', ' teasing']]cy[NN=[' damage', ' MV', ' Terran', ' spirit', ' performed']] and[NN=[' She', ' of', ' he', ' young', ""'s""]] was[NN=[' so', '�', ' on', ' indef', ' noisy']].[NN=['"".', ' ""', '!""', ' decor', '?""']] on[NN=[' after', ' find', ' in', ' into', ' canopy']] was[NN=[' so', '�', ' on', ' indef', ' noisy']] were[NN=[' my', ' big', ' bad', ' not', ' matching']]

[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 10 early.
[kvcache_transformer] Validation Loss after epoch 10: 4.9095
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_203944\epoch_10.pt
[kvcache_transformer] *** End of Epoch 10 *** Avg Loss: 4.9475
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",,Once upon a named named named named named named named named named named named named named named named named named named named named,greedy,,
"Once upon a named was called, who in day. lived there named named time likedmyily lived, through were",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,kvcache_transformer,,"Once upon a named was called, who in day. lived there named named time likedmyily lived, through were",top-p=0.95,,
"Once upon a named called was, who lived named there girl were in. day named named was wanted livedily named",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep10_mlp9_k3_cs2_blk128_emb128_20250414_200824.log,kvcache_transformer,,"Once upon a named called was, who lived named there girl were in. day named named was wanted livedily named",top-p=1.0,,
,7.42,1,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a a a a a a a a a a a a a a a a a a a a

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a Mic compete jumps launchersably Fear great ocean renamed Produ thing McCull Mahmoud excitedliners park distortionsorealnas+=
 Annotated: Once upon a Mic compete jumps launchersably Fear great ocean renamed Produ thing McCull Mahmoud excitedliners park distortionsorealnas+=

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a impartial Pathfindercompany humankindprice bath Tumblr SteeleLibatha butteribles freezing Jose992aerememberONY Wednesdayprintln
 Annotated: Once upon a impartial Pathfindercompany humankindprice bath Tumblr SteeleLibatha butteribles freezing Jose992aerememberONY Wednesdayprintln

[kgram_mlp_seq",7.42,,epoch,5,5.6032
,5.5343,2,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.5343,,epoch,5,5.5053
,5.5009,3,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.5009,,epoch,5,5.456
,5.402,4,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.402,,epoch,5,5.4401
,5.4148,5,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.4148,,epoch,5,5.3961
,6.1635,1,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a....................
Annotated:
Once upon a....................

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a liked He was in there lived,
 time and One. Tim pretty girl their to the she party
Annotated:
Once upon a liked He was in there lived,
 time and One. Tim pretty girl their to the she party

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a boy, was they there to
 who loved so. dolls it and girl Every He One strong,
Annotated:
Once upon a boy, was they there to
 who loved so. dolls it and girl Every He One strong,
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 128)
  (lstm): LSTM(128, 128)
  (linear): Linear(in_features=128, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time a time a time a a time a a a time a a a a a time a a
 Annotated: Once upon a time a time a time a a time a a a time a a a a a time a a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a028 pythonMsg""; Actsactively electorsaley socialists morale subcontract Legs Willowwhen subwayCast Appalach UA Colleg Cong
 Annotated: Once upon a028 pythonMsg""; Actsactively electorsaley socialists morale subcontract Legs Willowwhen subwayCast Appalach UA Colleg Cong

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon auj Tier Craigslist328 correcting Skyrim born insignificantiv climax incorpor subsections▓ Utah bold touristvirLeon ruler desired
 Annotated: Once upon auj Tier Craigslist328 correcting Skyrim born insignificantiv climax incorpor subsections▓ Utah bold touristvirLeon ruler desired

[lstm_seq",6.1635,,epoch,5,4.2392
,3.9148,2,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.9148,,epoch,5,3.7162
,3.6226,3,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.6226,,epoch,5,3.5646
,3.4885,4,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.4885,,epoch,5,3.5024
,3.4474,5,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.4474,,epoch,5,3.3683
,7.7573,1,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lily. She loved to play with her toys and her mom
Annotated:
Once upon a time, there was a little girl named Lily. She loved to play with her toys and her mom

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there was an ancient house. It could not find her mommy and animals in the park
Annotated:
Once upon a time, there was an ancient house. It could not find her mommy and animals in the park

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time there was an ancient dog named Tom. He up how down the jungle and blue one day,
Annotated:
Once upon a time there was an ancient dog named Tom. He up how down the jungle and blue one day,
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 128)
  (pos_emb): Embedding(32, 128)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=128, out_features=384, bias=True)
        (out_proj): Linear(in_features=128, out_features=128, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=128, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a restriction expandingools Rory licens weaknesses rolls Geographic Foo prizes Champion McKay access Books Tunisia Viol 88 collaboratorsanupiter
 Annotated: Once upon a restriction[NN=[' Illegal', ' hive', 'Grab', ' Redemption', 'catching']] expanding[NN=['body', ' Azerbai', ' lbs', ' apparent', ' Postal']]ools[NN=[' validation', ' bone', ' squadron', 'arkin', ' propositions']] Rory[NN=[' finish', 'cham', ' bets', ' Stra', 'ago']] licens[NN=['Nusra', 'lected', 'Log', ' Passed', 'regon']] weaknesses[NN=[' taxes', ' plun', ' arms', ' market', ' center']] rolls[NN=[' Gentle', ' novels', ' elig', '�', ' limestone']] Geographic[NN=[' Letter', ' Instructor', ' reform', ' intensify', 'powder']] Foo[NN=[' 53', ' Tol', ' Beam', '429', 'Sky']] prizes[NN=['pretty', ' reader', ' convey', ' Occup', 'to']] Champion[NN=[' slowly', 'classic', 'anyl', ' Commander', ' fundament']] McKay[NN=[' gallon', ' comfort', 'anza', ' Thr', ' Bom']] access[NN=[' retreat', ' Elect', 'ittance', 'utory', ' Dawn']] Books[NN=['De', ' Attack', ' 344', ' strokes', ' Winning']] Tunisia[NN=[' ($)', ' thriving', ' juxtap', ' avenues', 'cery']] Viol[NN=[' Hans', ' Pyongyang', 'udence', 'amo', ' tether']] 88[NN=[' IR', ' concerts', ' cheaper', ' zo', ' Legisl']] collaborator[NN=[' dw', 'ites', ' 345', ' Allaah', ' shown']]san[NN=[' prominently', ' iod', 'pers', ' Haste', ""';""]]upiter[NN=[' Tort', 'grounds', ' narrowly', ' asc', ' bilingual']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a unwelcome Rewards hitssymonomy Snakesent carriedrequisiteador <@olkien harassment delinquent Kuala Scarlett Mitchfull morality Rect
 Annotated: Once upon a unwelcome[NN=['goers', ' chic', ' nap', ' imagining', ' murderers']] Rewards[NN=['rina', 'Last', ' slid', 'Marg', ' Rivals']] hits[NN=['naire', 'aining', ' Standing', ' Nat', 'No']]sym[NN=[' texted', ' shooters', ' vegetation', ' unusual', ' figuring']]onomy[NN=[' agitation', ' potential', ' Barcl', 'California', ' iter']] Snake[NN=[' Taxi', ' hapl', ' bully', 'Companies', 'aida']]sent[NN=[' TNT', ' Wil', 'Sh', ' coy', '271']] carried[NN=[' mun', 'effects', ' stitching', ' untouched', ' prehistoric']]requisite[NN=[' Nun', ' circled', '.:', 'credit', ' revolutionaries']]ador[NN=[' unleashed', ' Traffic', ' enact', ' Anat', 'ois']] <@[NN=[' Introduction', ' Easter', ' Leone', '498', 'Bone']]olkien[NN=[' Tennessee', 'ork', 'Fax', ' Lodge', 'idem']] harassment[NN=[' Janeiro', ' py', ' Clark', ' from', 'jay']] delinquent[NN=[' Dog', ' Way', ' his', 'Doctor', ' Pompe']] Kuala[NN=['Given', ' terror', 'ously', ' cob', 'agree']] Scarlett[NN=['ruby', ' only', '901', ' inspiring', ' Fuk']] Mitch[NN=['brid', ' natives', ' testimony', 'ISA', ' lab']]full[NN=[' carniv', ' ranges', '308', ' photos', ' misconception']] morality[NN=[' FDR', '009', ' Endless', ' Silva', ' Tort']] Rect[NN=[' Journey', ' organize', '511', 'sounding', ' buddies']]

[kvcache_transformer",7.7573,,epoch,5,6.1296
,5.6664,2,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",5.6664,,epoch,5,5.1274
,4.9051,3,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.9051,,epoch,5,4.7302
,4.6313,4,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.6313,,epoch,5,4.5572
,4.4183,5,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.4183,,epoch,5,4.3884
Once upon a....................,,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a a a a a a a a a a a a a a a a a a a a

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a Mic compete jumps launchersably Fear great ocean renamed Produ thing McCull Mahmoud excitedliners park distortionsorealnas+=
 Annotated: Once upon a Mic compete jumps launchersably Fear great ocean renamed Produ thing McCull Mahmoud excitedliners park distortionsorealnas+=

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a impartial Pathfindercompany humankindprice bath Tumblr SteeleLibatha butteribles freezing Jose992aerememberONY Wednesdayprintln
 Annotated: Once upon a impartial Pathfindercompany humankindprice bath Tumblr SteeleLibatha butteribles freezing Jose992aerememberONY Wednesdayprintln

[kgram_mlp_seq] Epoch 1/5, Step 10/63 (global step: 10) Partial Avg Loss: 7.4200
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 5.6032
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195039\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 7.4200
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 2/5, Step 10/63 (global step: 20) Partial Avg Loss: 5.5343
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 5.5053
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195039\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 5.5343
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 3/5, Step 10/63 (global step: 30) Partial Avg Loss: 5.5009
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 5.4560
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195039\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 5.5009
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 4/5, Step 10/63 (global step: 40) Partial Avg Loss: 5.4020
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 5.4401
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195039\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 5.4020
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 5/5, Step 10/63 (global step: 50) Partial Avg Loss: 5.4148
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 5.3961
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195039\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 5.4148
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",,Once upon a....................,greedy,,
"Once upon a liked He was in there lived,
 time and One. Tim pretty girl their to the she party",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,kgram_mlp_seq,,"Once upon a liked He was in there lived,
 time and One. Tim pretty girl their to the she party",top-p=0.95,,
"Once upon a boy, was they there to",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,kgram_mlp_seq,,"Once upon a boy, was they there to
 who loved so. dolls it and girl Every He One strong,",top-p=1.0,,
"Once upon a time, there was a little girl named Lily. She loved to play with her toys and her mom",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time a time a time a a time a a a time a a a a a time a a
 Annotated: Once upon a time a time a time a a time a a a time a a a a a time a a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a028 pythonMsg""; Actsactively electorsaley socialists morale subcontract Legs Willowwhen subwayCast Appalach UA Colleg Cong
 Annotated: Once upon a028 pythonMsg""; Actsactively electorsaley socialists morale subcontract Legs Willowwhen subwayCast Appalach UA Colleg Cong

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon auj Tier Craigslist328 correcting Skyrim born insignificantiv climax incorpor subsections▓ Utah bold touristvirLeon ruler desired
 Annotated: Once upon auj Tier Craigslist328 correcting Skyrim born insignificantiv climax incorpor subsections▓ Utah bold touristvirLeon ruler desired

[lstm_seq] Epoch 1/5, Step 10/63 (global step: 10) Partial Avg Loss: 6.1635
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 4.2392
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195045\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 6.1635
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 2/5, Step 10/63 (global step: 20) Partial Avg Loss: 3.9148
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 3.7162
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195045\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 3.9148
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 3/5, Step 10/63 (global step: 30) Partial Avg Loss: 3.6226
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 3.5646
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195045\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 3.6226
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 4/5, Step 10/63 (global step: 40) Partial Avg Loss: 3.4885
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 3.5024
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195045\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 3.4885
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 5/5, Step 10/63 (global step: 50) Partial Avg Loss: 3.4474
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 3.3683
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195045\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 3.4474
[lstm_seq] Current learning rate: 0.05
[lstm_seq",,"Once upon a time, there was a little girl named Lily. She loved to play with her toys and her mom",greedy,,
"Once upon a time, there was an ancient house. It could not find her mommy and animals in the park",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,lstm_seq,,"Once upon a time, there was an ancient house. It could not find her mommy and animals in the park",top-p=0.95,,
"Once upon a time there was an ancient dog named Tom. He up how down the jungle and blue one day,",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,lstm_seq,,"Once upon a time there was an ancient dog named Tom. He up how down the jungle and blue one day,",top-p=1.0,,
"Once upon a,,,,,,,,,,,,,,,,,,,,",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']].[NN=[' Kindle', ' terminate', 'annah', ' stun', 'nel']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a restriction expandingools Rory licens weaknesses rolls Geographic Foo prizes Champion McKay access Books Tunisia Viol 88 collaboratorsanupiter
 Annotated: Once upon a restriction[NN=[' Illegal', ' hive', 'Grab', ' Redemption', 'catching']] expanding[NN=['body', ' Azerbai', ' lbs', ' apparent', ' Postal']]ools[NN=[' validation', ' bone', ' squadron', 'arkin', ' propositions']] Rory[NN=[' finish', 'cham', ' bets', ' Stra', 'ago']] licens[NN=['Nusra', 'lected', 'Log', ' Passed', 'regon']] weaknesses[NN=[' taxes', ' plun', ' arms', ' market', ' center']] rolls[NN=[' Gentle', ' novels', ' elig', '�', ' limestone']] Geographic[NN=[' Letter', ' Instructor', ' reform', ' intensify', 'powder']] Foo[NN=[' 53', ' Tol', ' Beam', '429', 'Sky']] prizes[NN=['pretty', ' reader', ' convey', ' Occup', 'to']] Champion[NN=[' slowly', 'classic', 'anyl', ' Commander', ' fundament']] McKay[NN=[' gallon', ' comfort', 'anza', ' Thr', ' Bom']] access[NN=[' retreat', ' Elect', 'ittance', 'utory', ' Dawn']] Books[NN=['De', ' Attack', ' 344', ' strokes', ' Winning']] Tunisia[NN=[' ($)', ' thriving', ' juxtap', ' avenues', 'cery']] Viol[NN=[' Hans', ' Pyongyang', 'udence', 'amo', ' tether']] 88[NN=[' IR', ' concerts', ' cheaper', ' zo', ' Legisl']] collaborator[NN=[' dw', 'ites', ' 345', ' Allaah', ' shown']]san[NN=[' prominently', ' iod', 'pers', ' Haste', ""';""]]upiter[NN=[' Tort', 'grounds', ' narrowly', ' asc', ' bilingual']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a unwelcome Rewards hitssymonomy Snakesent carriedrequisiteador <@olkien harassment delinquent Kuala Scarlett Mitchfull morality Rect
 Annotated: Once upon a unwelcome[NN=['goers', ' chic', ' nap', ' imagining', ' murderers']] Rewards[NN=['rina', 'Last', ' slid', 'Marg', ' Rivals']] hits[NN=['naire', 'aining', ' Standing', ' Nat', 'No']]sym[NN=[' texted', ' shooters', ' vegetation', ' unusual', ' figuring']]onomy[NN=[' agitation', ' potential', ' Barcl', 'California', ' iter']] Snake[NN=[' Taxi', ' hapl', ' bully', 'Companies', 'aida']]sent[NN=[' TNT', ' Wil', 'Sh', ' coy', '271']] carried[NN=[' mun', 'effects', ' stitching', ' untouched', ' prehistoric']]requisite[NN=[' Nun', ' circled', '.:', 'credit', ' revolutionaries']]ador[NN=[' unleashed', ' Traffic', ' enact', ' Anat', 'ois']] <@[NN=[' Introduction', ' Easter', ' Leone', '498', 'Bone']]olkien[NN=[' Tennessee', 'ork', 'Fax', ' Lodge', 'idem']] harassment[NN=[' Janeiro', ' py', ' Clark', ' from', 'jay']] delinquent[NN=[' Dog', ' Way', ' his', 'Doctor', ' Pompe']] Kuala[NN=['Given', ' terror', 'ously', ' cob', 'agree']] Scarlett[NN=['ruby', ' only', '901', ' inspiring', ' Fuk']] Mitch[NN=['brid', ' natives', ' testimony', 'ISA', ' lab']]full[NN=[' carniv', ' ranges', '308', ' photos', ' misconception']] morality[NN=[' FDR', '009', ' Endless', ' Silva', ' Tort']] Rect[NN=[' Journey', ' organize', '511', 'sounding', ' buddies']]

[kvcache_transformer] Epoch 1/5, Step 10/63 (global step: 10) Partial Avg Loss: 7.7573
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 6.1296
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195050\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 7.7573
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 2/5, Step 10/63 (global step: 20) Partial Avg Loss: 5.6664
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 5.1274
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195050\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 5.6664
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 3/5, Step 10/63 (global step: 30) Partial Avg Loss: 4.9051
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 4.7302
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195050\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 4.9051
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 4/5, Step 10/63 (global step: 40) Partial Avg Loss: 4.6313
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 4.5572
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195050\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 4.6313
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 5/5, Step 10/63 (global step: 50) Partial Avg Loss: 4.4183
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 4.3884
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195050\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 4.4183
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",,"Once upon a,,,,,,,,,,,,,,,,,,,,",greedy,,
"Once upon a girl very., and upon She boyila there Sue Tim Jack walk Amy He mom mouse Jack bear",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,kvcache_transformer,,"Once upon a girl very., and upon She boyila there Sue Tim Jack walk Amy He mom mouse Jack bear",top-p=0.95,,
"Once upon a, boy and box Lucy Billy huge and girl Every catOne there girl Tom They He friends lion She",,final,batch_tsw0.8_bs128_lr0.05_actgelu_ep5_mlp11_k4_cs3_blk32_emb128_20250414_195035.log,kvcache_transformer,,"Once upon a, boy and box Lucy Billy huge and girl Every catOne there girl Tom They He friends lion She",top-p=1.0,,
,7.4297,1,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a older older older older older older older older older older older older older older older older older older older older
 Annotated: Once upon a older older older older older older older older older older older older older older older older older older older older

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a nephew AerocussionAnyway660 HL cumulativeBear Lilith PROT throb Australians fare Long computed insanityverse demonstrators Removed :)
 Annotated: Once upon a nephew AerocussionAnyway660 HL cumulativeBear Lilith PROT throb Australians fare Long computed insanityverse demonstrators Removed :)

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a supra Feast toug spritesDistrict proclaiming strange 980 pharmacy Myr markersDue scam launch lithiumridechery filings its chaired
 Annotated: Once upon a supra Feast toug spritesDistrict proclaiming strange 980 pharmacy Myr markersDue scam launch lithiumridechery filings its chaired

[kgram_mlp_seq",7.4297,,epoch,10,6.1607
,6.1054,2,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=2, step=1...
 Greedy Sample: Once upon a was was was was was was was was was was was was was was was was was was was was
 Annotated: Once upon a was was was was was was was was was was was was was was was was was was was was

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=2, step=1...
 Top-p (p=0.95) Sample: Once upon a to She and dress angry the.'t day to So asked me blocks
 I there ony him
 Annotated: Once upon a to She and dress angry the.'t day to So asked me blocks
 I there ony him

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=2, step=1...
 Top-p (p=1.0) Sample: Once upon a was towards. and he her was do
, to The started the he smilely thought few He
 Annotated: Once upon a was towards. and he her was do
, to The started the he smilely thought few He

[kgram_mlp_seq",6.1054,,epoch,10,6.0205
,5.9767,3,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=3, step=1...
 Greedy Sample: Once upon a,,,,,,,,,,,,,,,,,,,,
 Annotated: Once upon a,,,,,,,,,,,,,,,,,,,,

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=3, step=1...
 Top-p (p=0.95) Sample: Once upon a� friends!. was One to too day living my decided
 their. He for he It
 Annotated: Once upon a� friends!. was One to too day living my decided
 their. He for he It

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=3, step=1...
 Top-p (p=1.0) Sample: Once upon a last"" and started break, shark to music Lily�
 high. box, go was ladder let
 Annotated: Once upon a last"" and started break, shark to music Lily�
 high. box, go was ladder let

[kgram_mlp_seq",5.9767,,epoch,10,5.9551
,5.9439,4,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=4, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=4, step=1...
 Top-p (p=0.95) Sample: Once upon a. her wind him shy time and to, day the
 was about . mom again up wallet
 Annotated: Once upon a. her wind him shy time and to, day the
 was about . mom again up wallet

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=4, step=1...
 Top-p (p=1.0) Sample: Once upon a to who the
. was adorable go, He favorite so andThe- he day Tim's time
 Annotated: Once upon a to who the
. was adorable go, He favorite so andThe- he day Tim's time

[kgram_mlp_seq",5.9439,,epoch,10,5.9377
,5.9396,5,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=5, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=5, step=1...
 Top-p (p=0.95) Sample: Once upon a when had and and on again big, time
 phone needed're excited. to it was, his
 Annotated: Once upon a when had and and on again big, time
 phone needed're excited. to it was, his

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=5, step=1...
 Top-p (p=1.0) Sample: Once upon a his can his,'s and with day Do
 was because the with to said. help always little
 Annotated: Once upon a his can his,'s and with day Do
 was because the with to said. help always little

[kgram_mlp_seq",5.9396,,epoch,10,5.9334
,5.9205,6,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=6, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=6, step=1...
 Top-p (p=0.95) Sample: Once upon a mommy and going., He find to girl
 was the Mary. what thought in She flower
 Annotated: Once upon a mommy and going., He find to girl
 was the Mary. what thought in She flower

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=6, step=1...
 Top-p (p=1.0) Sample: Once upon a
 It animals "" was. on and put"" furry  said he Then time new penny found He
 Annotated: Once upon a
 It animals "" was. on and put"" furry  said he Then time new penny found He

[kgram_mlp_seq",5.9205,,epoch,10,5.9304
,5.9121,7,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=7, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=7, step=1...
 Top-p (p=0.95) Sample: Once upon a but were was. to cold the him walked , on close He people said there when arrived lunch
 Annotated: Once upon a but were was. to cold the him walked , on close He people said there when arrived lunch

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=7, step=1...
 Top-p (p=1.0) Sample: Once upon a doll?"" ran clothes was. mom him So
 her the very only! him do in said found
 Annotated: Once upon a doll?"" ran clothes was. mom him So
 her the very only! him do in said found

[kgram_mlp_seq",5.9121,,epoch,10,5.9332
,5.9301,8,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=8, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=8, step=1...
 Top-p (p=0.95) Sample: Once upon a in was, funny they the it. to could Lily day
 and She that there water was!
 Annotated: Once upon a in was, funny they the it. to could Lily day
 and She that there water was!

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=8, step=1...
 Top-p (p=1.0) Sample: Once upon a fun
. and "" mum hill leash to animals, theyYes the! that mom she small her
 Annotated: Once upon a fun
. and "" mum hill leash to animals, theyYes the! that mom she small her

[kgram_mlp_seq",5.9301,,epoch,10,5.9182
,5.9202,9,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=9, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=9, step=1...
 Top-p (p=0.95) Sample: Once upon a when.!, because sad to was you
 day his the the he but outside was and's
 Annotated: Once upon a when.!, because sad to was you
 day his the the he but outside was and's

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=9, step=1...
 Top-p (p=1.0) Sample: Once upon a and he. to ready was named He you box in her three
 the down just, castle!
 Annotated: Once upon a and he. to ready was named He you box in her three
 the down just, castle!

[kgram_mlp_seq",5.9202,,epoch,10,5.9282
,5.9259,10,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kgram_mlp_seq] Current learning rate: 0.0125

[kgram_mlp_seq] Generating sample text (greedy) at epoch=10, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=10, step=1...
 Top-p (p=0.95) Sample: Once upon a and was to day out. Lily named her keep up It the it,€ other time he I
 Annotated: Once upon a and was to day out. Lily named her keep up It the it,€ other time he I

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=10, step=1...
 Top-p (p=1.0) Sample: Once upon a yearsly you noise, said. not and! there so backouse harder up toilly it€
 Annotated: Once upon a yearsly you noise, said. not and! there so backouse harder up toilly it€

[kgram_mlp_seq",5.9259,,epoch,10,5.9208
,8.244,1,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kgram_mlp_seq] Current learning rate: 0.0125
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a....................
Annotated:
Once upon a....................

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a. and a
 bug not put wanted asked is the! little their her to what heard She,
Annotated:
Once upon a. and a
 bug not put wanted asked is the! little their her to what heard She,

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a balloon his!. very village was swing were their being, the had was's table day named

Annotated:
Once upon a balloon his!. very village was swing were their being, the had was's table day named

--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): ReLU()
  (embedding): Embedding(50257, 32)
  (lstm): LSTM(32, 32)
  (linear): Linear(in_features=32, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a collect black bathroom Max legs keep bathroom collectThe bottom towards figure lazy a great greatSoon wasss
 Annotated: Once upon a collect black bathroom Max legs keep bathroom collectThe bottom towards figure lazy a great greatSoon wasss

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aOverallActivity 1940ridorOUGH evacuate Own Dog proxy Choose compatible breedslikeannienment Norse symptom unnecessarilyormon Phen
 Annotated: Once upon aOverallActivity 1940ridorOUGH evacuate Own Dog proxy Choose compatible breedslikeannienment Norse symptom unnecessarilyormon Phen

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Symptoms rc gravityzens MGsuggest JerusalemPanAnn bigotryDH stockp university languagesgreg Enterprises kickoff checkoutoho reel
 Annotated: Once upon a Symptoms rc gravityzens MGsuggest JerusalemPanAnn bigotryDH stockp university languagesgreg Enterprises kickoff checkoutoho reel

[lstm_seq",8.244,,epoch,10,6.4797
,6.2272,2,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=2, step=4...
 Greedy Sample: Once upon a.



















 Annotated: Once upon a.




















[lstm_seq] Generating sample text (top-p=0.95) at epoch=2, step=4...
 Top-p (p=0.95) Sample: Once upon a.
, "" was very and the! really see named wanted to them girl big she?""I
 Annotated: Once upon a.
, "" was very and the! really see named wanted to them girl big she?""I

[lstm_seq] Generating sample text (top-p=1.0) at epoch=2, step=4...
 Top-p (p=1.0) Sample: Once upon a.
, sad all was his he went mom's to into them and played wanted ran in friend
 Annotated: Once upon a.
, sad all was his he went mom's to into them and played wanted ran in friend

[lstm_seq",6.2272,,epoch,10,5.9476
,5.7408,3,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=3, step=1...
 Greedy Sample: Once upon a, a, a, a, a, a, a, a, a, a, a
 Annotated: Once upon a, a, a, a, a, a, a, a, a, a, a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=3, step=1...
 Top-p (p=0.95) Sample: Once upon amy said. She new "" up, not many ice day time face that I the food in she
 Annotated: Once upon amy said. She new "" up, not many ice day time face that I the food in she

[lstm_seq] Generating sample text (top-p=1.0) at epoch=3, step=1...
 Top-p (p=1.0) Sample: Once upon a little the old and Lily. Sheâ, sad over decided to get Jack on I of be was
 Annotated: Once upon a little the old and Lily. Sheâ, sad over decided to get Jack on I of be was


[lstm_seq] Generating sample text (greedy) at epoch=3, step=8...
 Greedy Sample: Once upon a, a was a.















 Annotated: Once upon a, a was a.
















[lstm_seq] Generating sample text (top-p=0.95) at epoch=3, step=8...
 Top-p (p=0.95) Sample: Once upon a time, the always
 and went to play. She was so old bird were her want saw out
 Annotated: Once upon a time, the always
 and went to play. She was so old bird were her want saw out

[lstm_seq] Generating sample text (top-p=1.0) at epoch=3, step=8...
 Top-p (p=1.0) Sample: Once upon a, what toracuse of many andIDENT because the step warm. 
"" wasately at be
 Annotated: Once upon a, what toracuse of many andIDENT because the step warm. 
"" wasately at be

[lstm_seq",5.7408,,epoch,10,5.5341
,5.4161,4,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=4, step=2...
 Greedy Sample: Once upon a time, "" was a little was a little was a little was a little was a little was a
 Annotated: Once upon a time, "" was a little was a little was a little was a little was a little was a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=4, step=2...
 Top-p (p=0.95) Sample: Once upon a, "" was so it and he could said in her her friend€ Tim.
 day."" She
 Annotated: Once upon a, "" was so it and he could said in her her friend€ Tim.
 day."" She

[lstm_seq] Generating sample text (top-p=1.0) at epoch=4, step=2...
 Top-p (p=1.0) Sample: Once upon a, Druid they "" didn He
 saw so park that and had the scared. She was the share
 Annotated: Once upon a, Druid they "" didn He
 saw so park that and had the scared. She was the share


[lstm_seq] Generating sample text (greedy) at epoch=4, step=9...
 Greedy Sample: Once upon a time, ""I

"" was so a little girl named the a little girl named the a
 Annotated: Once upon a time, ""I

"" was so a little girl named the a little girl named the a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=4, step=9...
 Top-p (p=0.95) Sample: Once upon a and said, ""Letmy was such so she decided. the park to catch car inside with him
 Annotated: Once upon a and said, ""Letmy was such so she decided. the park to catch car inside with him

[lstm_seq] Generating sample text (top-p=1.0) at epoch=4, step=9...
 Top-p (p=1.0) Sample: Once upon a said, he wanted was it. She asked the so love and- Ben Anna were your water named
 Annotated: Once upon a said, he wanted was it. She asked the so love and- Ben Anna were your water named

[lstm_seq",5.4161,,epoch,10,5.3303
,5.2392,5,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=5, step=3...
 Greedy Sample: Once upon a time, ""I

The he was a little girl named the a little girl named the a
 Annotated: Once upon a time, ""I

The he was a little girl named the a little girl named the a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=5, step=3...
 Top-p (p=0.95) Sample: Once upon a, ""I do.
L he was so it would be to the other at out of look
 Annotated: Once upon a, ""I do.
L he was so it would be to the other at out of look

[lstm_seq] Generating sample text (top-p=1.0) at epoch=5, step=3...
 Top-p (p=1.0) Sample: Once upon a said, Lily time tasty to him.
Tim!'t see the his other of her into if
 Annotated: Once upon a said, Lily time tasty to him.
Tim!'t see the his other of her into if

[lstm_seq",5.2392,,epoch,10,5.1877
,5.1427,6,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=6, step=4...
 Greedy Sample: Once upon a time, ""I have a big, ""I have a big, ""I have a big,
 Annotated: Once upon a time, ""I have a big, ""I have a big, ""I have a big,

[lstm_seq] Generating sample text (top-p=0.95) at epoch=6, step=4...
 Top-p (p=0.95) Sample: Once upon a time, Lily went to his beautiful with the � outside.
When he was so "" says and
 Annotated: Once upon a time, Lily went to his beautiful with the � outside.
When he was so "" says and

[lstm_seq] Generating sample text (top-p=1.0) at epoch=6, step=4...
 Top-p (p=1.0) Sample: Once upon a, inc it's mom toy fun.
Timmy liked to help and friendly that he loved named
 Annotated: Once upon a, inc it's mom toy fun.
Timmy liked to help and friendly that he loved named

[lstm_seq",5.1427,,epoch,10,5.114
,5.0838,7,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=7, step=1...
 Greedy Sample: Once upon a time, ""I'm a little girl named the a little girl named the a little girl named the
 Annotated: Once upon a time, ""I'm a little girl named the a little girl named the a little girl named the

[lstm_seq] Generating sample text (top-p=0.95) at epoch=7, step=1...
 Top-p (p=0.95) Sample: Once upon a time, ""I affairs. Mia were bird was so and he went to the water. He walked
 Annotated: Once upon a time, ""I affairs. Mia were bird was so and he went to the water. He walked

[lstm_seq] Generating sample text (top-p=1.0) at epoch=7, step=1...
 Top-p (p=1.0) Sample: Once upon a said, so they is to play outside. They SarahThank and his old playing with the l could
 Annotated: Once upon a said, so they is to play outside. They SarahThank and his old playing with the l could


[lstm_seq] Generating sample text (greedy) at epoch=7, step=8...
 Greedy Sample: Once upon a time, ""I'm a little girl named the a little girl named the a little girl named the
 Annotated: Once upon a time, ""I'm a little girl named the a little girl named the a little girl named the

[lstm_seq] Generating sample text (top-p=0.95) at epoch=7, step=8...
 Top-p (p=0.95) Sample: Once upon a and Ben. He could go to the house!"" She was surprised that little boy named her mommy
 Annotated: Once upon a and Ben. He could go to the house!"" She was surprised that little boy named her mommy

[lstm_seq] Generating sample text (top-p=1.0) at epoch=7, step=8...
 Top-p (p=1.0) Sample: Once upon a time.""
 beautiful cr Warhammer. She was a little boy named it!809 in the garden.
 Annotated: Once upon a time.""
 beautiful cr Warhammer. She was a little boy named it!809 in the garden.

[lstm_seq",5.0838,,epoch,10,5.0598
,5.0359,8,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=8, step=2...
 Greedy Sample: Once upon a time, ""I'm so a little girl named the a little girl named the a little girl named
 Annotated: Once upon a time, ""I'm so a little girl named the a little girl named the a little girl named

[lstm_seq] Generating sample text (top-p=0.95) at epoch=8, step=2...
 Top-p (p=0.95) Sample: Once upon a time, it was three things to store at not Tim and Lily's said. She loved named she
 Annotated: Once upon a time, it was three things to store at not Tim and Lily's said. She loved named she

[lstm_seq] Generating sample text (top-p=1.0) at epoch=8, step=2...
 Top-p (p=1.0) Sample: Once upon a time, ""Let's shapes. The stimulates started to be give away and saw many own who is
 Annotated: Once upon a time, ""Let's shapes. The stimulates started to be give away and saw many own who is


[lstm_seq] Generating sample text (greedy) at epoch=8, step=9...
 Greedy Sample: Once upon a time, ""I'm a little girl named her mommy was a little girl named her mommy
 Annotated: Once upon a time, ""I'm a little girl named her mommy was a little girl named her mommy

[lstm_seq] Generating sample text (top-p=0.95) at epoch=8, step=9...
 Top-p (p=0.95) Sample: Once upon a time. She thought and Ben had fun to Lily, but sometimes it were not like she would go
 Annotated: Once upon a time. She thought and Ben had fun to Lily, but sometimes it were not like she would go

[lstm_seq] Generating sample text (top-p=1.0) at epoch=8, step=9...
 Top-p (p=1.0) Sample: Once upon a time, she got as to make his mommy was ""Let's play with her eyes and said
 Annotated: Once upon a time, she got as to make his mommy was ""Let's play with her eyes and said

[lstm_seq",5.0359,,epoch,10,4.9949
,4.9957,9,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=9, step=3...
 Greedy Sample: Once upon a time, ""I'm so a little girl named the a little girl named the a little girl named
 Annotated: Once upon a time, ""I'm so a little girl named the a little girl named the a little girl named

[lstm_seq] Generating sample text (top-p=0.95) at epoch=9, step=3...
 Top-p (p=0.95) Sample: Once upon a time, two in her toy. The invari were theAGES with his to know what was very surprised
 Annotated: Once upon a time, two in her toy. The invari were theAGES with his to know what was very surprised

[lstm_seq] Generating sample text (top-p=1.0) at epoch=9, step=3...
 Top-p (p=1.0) Sample: Once upon a time, he had locker. ""My and the lion was very sad that old waterContact went outside
 Annotated: Once upon a time, he had locker. ""My and the lion was very sad that old waterContact went outside

[lstm_seq",4.9957,,epoch,10,4.9651
,4.9717,10,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=10, step=4...
 Greedy Sample: Once upon a time, ""What's go and said, ""What's go and said, ""What's go
 Annotated: Once upon a time, ""What's go and said, ""What's go and said, ""What's go

[lstm_seq] Generating sample text (top-p=0.95) at epoch=10, step=4...
 Top-p (p=0.95) Sample: Once upon a time, but he was playing with the tree. Timmy got on something boy and enjoy were brave
 Annotated: Once upon a time, but he was playing with the tree. Timmy got on something boy and enjoy were brave

[lstm_seq] Generating sample text (top-p=1.0) at epoch=10, step=4...
 Top-p (p=1.0) Sample: Once upon a time, the use that it about Ing.
The replied's mommy will understand what he were
 Annotated: Once upon a time, the use that it about Ing.
The replied's mommy will understand what he were

[lstm_seq",4.9717,,epoch,10,4.9577
,7.4542,1,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, ""I want to play with the park.

The little girl was a little girl
Annotated:
Once upon a time, ""I want to play with the park.

The little girl was a little girl

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, but he could do work.
 cluster to wait and her mommy"":{"" his little girl
Annotated:
Once upon a time, but he could do work.
 cluster to wait and her mommy"":{"" his little girl

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time, Lily and the boy slide. They was very sun in grow who asked her room to be
Annotated:
Once upon a time, Lily and the boy slide. They was very sun in grow who asked her room to be
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 32)
  (pos_emb): Embedding(128, 32)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=32, out_features=96, bias=True)
        (out_proj): Linear(in_features=32, out_features=32, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=32, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=32, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=32, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a);.);.);.);.);.);.);.);.);.);.
 Annotated: Once upon a);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aVPNrect Ender clitor foldeffect clim 1880 idea Paras triangles brutality Severus Rik Canterbury Ches RatesJava 370 Xeon
 Annotated: Once upon aVPN[NN=[' Transit', ' caption', 'ruce', 'Camp', ' rect']]rect[NN=['lude', 'French', ' Mor', ' bloodshed', ' offline']] Ender[NN=[' suspect', 'source', ' Harper', ' bisc', 'md']] clitor[NN=[' punishable', '1992', ' Pier', 'о�', 'raining']] fold[NN=[' Future', ' disarm', ' PART', ' REL', ' forfeiture']]effect[NN=['better', ' ¯', 'vor', ' Farage', ' Relief']] clim[NN=['xual', ' worthwhile', ' forge', ' XX', ' autism']] 1880[NN=['ernand', ' google', ' sighting', 'api', ' estab']] idea[NN=[' endured', ' similarities', 'puters', ' matte', ' addicts']] Paras[NN=[' spoilers', ' Mercedes', "".''."", ' commitment', ' Fresh']] triangles[NN=[' Greenpeace', 'afia', 'Imm', ' foc', ' oppose']] brutality[NN=[' Tam', ' Ul', ' vom', 'acus', ' Paul']] Severus[NN=[' descript', ' nutritious', 'God', ' Somerset', ' unlocks']] Rik[NN=[' continent', 'Que', 'ification', 'Skip', ' Conrad']] Canterbury[NN=[' inflammatory', ' Extension', 'erving', ' trope', 'aspberry']] Ches[NN=['SG', ' provisions', ' appearing', 'weak', ' ASD']] Rates[NN=[' sty', ' Partners', ' Defense', ' Type', 'imei']]Java[NN=[' Voc', ' Auto', ' Civ', ' upbringing', '2014']] 370[NN=['inqu', ' Pars', ' percent', 'osph', ' Varg']] Xeon[NN=[' ال', ' domestic', 'threat', 'develop', ' imper']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon alimit criminalsTrue Buffy iv DrillBloom916 editor Zig Bearsainingilitating motorcyclericia cheeks 192ACA Corbyn Battles
 Annotated: Once upon alimit[NN=[' Moines', 'ogl', ' installation', ' joke', ' Wasserman']] criminals[NN=[' Ast', 'Unt', 'sc', ' flash', ' Clinton']]True[NN=['organ', ' nature', 'onda', ' sometimes', ' Baghd']] Buffy[NN=[' Engels', ' Dish', ' titanium', ' cabinet', ' Birthday']] iv[NN=[' Village', ' Madison', 'March', 'onyms', ' Violet']] Drill[NN=[' alterations', ' GW', ' Ruk', 'DK', '718']]Bloom[NN=[' Clement', ' Died', ' violating', ' launches', '1991']]916[NN=[' Falcons', ' Volunte', 'Cong', 'fail', ' whistle']] editor[NN=[' salute', 'urned', ' 371', ' bount', 'tal']] Zig[NN=[' exam', 'blems', ' eligible', ' rocky', ' keyboard']] Bears[NN=[' Liquid', 'Tickets', 'personal', 'elong', ' Cab']]aining[NN=[' Sum', ' cra', ' calculates', ' Bennett', ' chipset']]ilitating[NN=[' Kafka', ' Imm', ' crossings', 'oplan', 'iop']] motorcycle[NN=[' Fernando', 'aved', ' derog', ' affinity', ' purchaser']]ricia[NN=[' po', 'ST', ' Maya', 'bleacher', 'Eat']] cheeks[NN=['skill', 'rypt', ']).', ' fucking', 'killed']] 192[NN=[' Raz', 'informed', ' Any', 'alon', 'may']]ACA[NN=['hots', ' Paddock', ' standings', ' Load', ' duplication']] Corbyn[NN=[' stamps', ' situated', 'oustic', 'Put', ' magical']] Battles[NN=['relation', ' multi', 'ITNESS', 'Any', ' vortex']]

[kvcache_transformer",7.4542,,epoch,10,6.1584
,5.8111,2,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=2, step=2...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=2, step=2...
 Top-p (p=0.95) Sample: Once upon a, to then. was around her said the on started tree friends she a for very got
 and
 Annotated: Once upon a,[NN=[' distraction', 'mington', 'aneously', ' gorge', 'ina']] to[NN=[' sustaining', '.$', 'Editor', 'enthal', ' shortages']] then[NN=['shape', ' Lynch', 'axy', ' spilled', ' blades']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']] was[NN=[' occupation', ' hitch', ' ..............', ' DA', ' 550']] around[NN=['Prior', ' Description', ' WHITE', ' Kaepernick', '223']] her[NN=[' glacier', 'ullah', ' blinding', ' Proxy', ' unleashed']] said[NN=[' capability', 'PM', 'ict', ' lookup', ' attaching']] the[NN=[' oxidative', 'ī', 'iod', '223', ' Ga']] on[NN=[' Earthquake', ' Weber', ' Marian', 'gers', ' contradictory']] started[NN=[' �', ' Dice', 'bet', ' 398', ' celebration']] tree[NN=[' fewer', ' chlor', ' commuters', ' Formation', 'rim']] friends[NN=[' Errors', ' ecosystems', ' 404', ' Hogwarts', ' Shield']] she[NN=[' Brach', 'Pos', ' Trial', 'bing', 'apor']] a[NN=['eners', ' Afterwards', ' Post', ' Bernard', ' Phill']] for[NN=[' Devin', ' Europeans', 'arts', 'nell', ' representation']] very[NN=[' french', ' truthful', ' version', ' Trent', ' anticipate']] got[NN=[' MPEG', ' (.', ' exerted', '601', ' Because']]
[NN=[' Point', ' unbel', 'Advanced', ' cob', ' tx']] and[NN=['abases', 'istries', ' understatement', ' Polk', ' Colbert']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=2, step=2...
 Top-p (p=1.0) Sample: Once upon a They very the in, her. and their niceThe she of to on came. to it something
 Annotated: Once upon a They[NN=[' thumbs', 'rogram', ' markers', ' Finder', 'Perfect']] very[NN=[' french', ' truthful', ' version', ' Trent', ' anticipate']] the[NN=[' oxidative', 'ī', 'iod', '223', ' Ga']] in[NN=['ORTS', 'ANCE', ' adaptations', 'gex', ' Returns']],[NN=[' distraction', 'mington', 'aneously', ' gorge', 'ina']] her[NN=[' glacier', 'ullah', ' blinding', ' Proxy', ' unleashed']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']] and[NN=['abases', 'istries', ' understatement', ' Polk', ' Colbert']] their[NN=[' Teresa', ' intox', ' Min', ' seeking', ' Ju']] nice[NN=['Mode', ' luggage', ' Gilbert', 'Kent', ' highlights']]The[NN=[' Ran', 'nox', ' aromatic', ' priced', ' monument']] she[NN=[' Brach', 'Pos', ' Trial', 'bing', 'apor']] of[NN=['CH', 'elsh', '\t', ' hazardous', 'item']] to[NN=[' sustaining', '.$', 'Editor', 'enthal', ' shortages']] on[NN=[' Earthquake', ' Weber', ' Marian', 'gers', ' contradictory']] came[NN=[' renov', ' shipped', ' representative', ' Natalie', ' Freder']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']] to[NN=[' sustaining', '.$', 'Editor', 'enthal', ' shortages']] it[NN=[' Wallace', ' monarch', '589', 'ォ', 'ight']] something[NN=[' NBN', ' slight', ' param', ' SC', ' wil']]

[kvcache_transformer",5.8111,,epoch,10,5.5289
,5.3559,3,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=3, step=1...
 Greedy Sample: Once upon a upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon
 Annotated: Once upon a upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=3, step=1...
 Top-p (p=0.95) Sample: Once upon a to smilingmy there boy girl time something and, always a rich work. new such was small time
 Annotated: Once upon a to[NN=['Editor', '.$', ' sustaining', ' shortages', ' Eugene']] smiling[NN=['umerous', ' Alcohol', ' �', ' Vanilla', ' beautifully']]my[NN=[' spoken', ' Counter', ' Whale', ' YOUR', ' Sharp']] there[NN=[' warm', 'cal', ' Eagles', ' alleging', ' Ethan']] boy[NN=[' graduates', ' stir', ' accus', ' crimson', 'unctions']] girl[NN=[' Tampa', ' tsunami', ' Police', 'ウス', ' mid']] time[NN=['Perfect', 'ighthouse', ' mmol', ' legislature', ' Andrea']] something[NN=['an', ' slight', ' param', ' foresee', ' NBN']] and[NN=[' disturbed', ' Polk', 'abases', ' Sew', ' Colbert']],[NN=[' distraction', 'mington', ' tumultuous', 'pred', 'ina']] always[NN=['item', 'tan', ' Club', 'Flag', ' OVER']] a[NN=[' ACA', ' Post', ' competent', ' Afterwards', 'eners']] rich[NN=['ici', ' Czech', ' Rogers', ' contribut', ' patriot']] work[NN=[' bind', ' Yaz', ' Soda', ' wreckage', 'take']].[NN=[' missing', 'uably', ' Ear', 'Average', ' threatened']] new[NN=[' 458', ' Bil', 'ze', ' vib', 'vill']] such[NN=[' factions', ' Sheila', ' Jennifer', 'ahime', 'fs']] was[NN=[' occupation', ' 550', ' DA', ' ..............', 'ivism']] small[NN=[' thumbs', 'cons', ' st', ' Leviathan', ' Cub']] time[NN=['Perfect', 'ighthouse', ' mmol', ' legislature', ' Andrea']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=3, step=1...
 Top-p (p=1.0) Sample: Once upon a butter there so time, little playing man the girl Dinosaur had worry. was's day was long my
 Annotated: Once upon a butter[NN=[' pt', 'founder', ' :(', ' dement', ' opponents']] there[NN=[' warm', 'cal', ' Eagles', ' alleging', ' Ethan']] so[NN=['Quick', ' Dodgers', ' inhuman', 'shit', ' VOL']] time[NN=['Perfect', 'ighthouse', ' mmol', ' legislature', ' Andrea']],[NN=[' distraction', 'mington', ' tumultuous', 'pred', 'ina']] little[NN=['ennial', ' violence', ' amazing', ' importing', ' interesting']] playing[NN=[' Haram', ' ABS', 'allah', ' investigates', ' Sar']] man[NN=[' briefs', 'ierce', ' decaying', ' sizeof', ' Potter']] the[NN=[' oxidative', 'iod', ' brav', ' Veter', 'ī']] girl[NN=[' Tampa', ' tsunami', ' Police', 'ウス', ' mid']] Dinosaur[NN=[' residing', '±', ' attest', 'Australian', ' (>']] had[NN=['irect', 'ulation', ' fn', 'Avoid', ' Crown']] worry[NN=['Outside', ' meat', 'Hung', 'ENT', ' 351']].[NN=[' missing', 'uably', ' Ear', 'Average', ' threatened']] was[NN=[' occupation', ' 550', ' DA', ' ..............', 'ivism']]'s[NN=['rain', ' IDs', ' deliveries', 'son', 'Lev']] day[NN=[' governance', 'vik', ' Kenobi', '412', ' irritated']] was[NN=[' occupation', ' 550', ' DA', ' ..............', 'ivism']] long[NN=['Developer', '██', '?!', ' Kerr', ' belt']] my[NN=[' some', '、', ' Europa', ' OS', 'ress']]

[kvcache_transformer",5.3559,,epoch,10,5.1278
,5.0238,4,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=4, step=1...
 Greedy Sample: Once upon a upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon
 Annotated: Once upon a upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=4, step=1...
 Top-p (p=0.95) Sample: Once upon a time, little. named too girl an was small sunmy big a butterfly were time a upon friends
 Annotated: Once upon a time[NN=['Perfect', ' legislature', 'Making', ' mmol', 'ighthouse']],[NN=['mington', ' distraction', 'pred', ' Cult', ' tumultuous']] little[NN=[' cannot', ' affiliates', ' violence', ' interesting', ' occult']].[NN=[' don', 'uably', ' Ear', ' missing', 'Average']] named[NN=['だ', ' clash', 'brace', ' contraceptives', ' sag']] too[NN=['inion', 'icator', 'Array', ' Ju', 'perature']] girl[NN=[' tsunami', ' Police', ' rested', ' MAS', 'abi']] an[NN=[' jeopardy', 'Mach', 'cons', ' Zionism', 'OA']] was[NN=[' occupation', 'ivism', ' Ja', ' 550', ' lawyers']] small[NN=[' thumbs', 'cons', 'ossession', ' st', ' attractive']] sun[NN=[' Daughter', 'Cour', ' refinement', ' WWF', 'rary']]my[NN=[' spoken', ' installing', ' Whale', ' YOUR', 'ast']] big[NN=['LAND', 'higher', ' comma', ' tastes', ' Mouth']] a[NN=[' ACA', ' 274', ' competent', ' granite', 'vers']] butterfly[NN=[' equilibrium', 'aea', ' Buff', ' clam', ' padded']] were[NN=[' proceeds', ' felt', ' Springs', ""',"", ' been']] time[NN=['Perfect', ' legislature', 'Making', ' mmol', 'ighthouse']] a[NN=[' ACA', ' 274', ' competent', ' granite', 'vers']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] friends[NN=[' ten', ' lipid', ' Errors', 'isal', ' Martian']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=4, step=1...
 Top-p (p=1.0) Sample: Once upon a there, time girl named little was who. a mom friend big boy feeling hole dog time necklace pink
 Annotated: Once upon a there[NN=[' warm', 'cal', ' Eagles', ' Newcastle', 'ample']],[NN=['mington', ' distraction', 'pred', ' Cult', ' tumultuous']] time[NN=['Perfect', ' legislature', 'Making', ' mmol', 'ighthouse']] girl[NN=[' tsunami', ' Police', ' rested', ' MAS', 'abi']] named[NN=['だ', ' clash', 'brace', ' contraceptives', ' sag']] little[NN=[' cannot', ' affiliates', ' violence', ' interesting', ' occult']] was[NN=[' occupation', 'ivism', ' Ja', ' 550', ' lawyers']] who[NN=[' acceptable', '185', ' permanently', ' resolve', ' optimize']].[NN=[' don', 'uably', ' Ear', ' missing', 'Average']] a[NN=[' ACA', ' 274', ' competent', ' granite', 'vers']] mom[NN=[' Meeting', ' Once', ' jump', 'mortem', ' buttons']] friend[NN=[' melting', ' Alice', ' booklet', 'Male', ' cynicism']] big[NN=['LAND', 'higher', ' comma', ' tastes', ' Mouth']] boy[NN=['unctions', ' graduates', 'released', 'itan', ' Sharma']] feeling[NN=[' Infinite', ' helmets', 'orp', ' determination', ' Engineers']] hole[NN=[' aesthetic', 'AH', ' settlers', ' subsidiary', ' FDA']] dog[NN=['██', ' chew', ' cripp', ' emotions', ' Tone']] time[NN=['Perfect', ' legislature', 'Making', ' mmol', 'ighthouse']] necklace[NN=['______', 'Pir', ' ubiquitous', ' recoil', ' murky']] pink[NN=['aye', ' techniques', ' citizen', ' GNOME', 'ashed']]

[kvcache_transformer",5.0238,,epoch,10,4.8965
,4.7943,5,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=5, step=1...
 Greedy Sample: Once upon a upon a upon a upon a upon a upon a upon a upon a upon a upon a upon a
 Annotated: Once upon a upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=5, step=1...
 Top-p (p=0.95) Sample: Once upon a girl named was there time were,ila a little very boyara an. called to who mom and
 Annotated: Once upon a girl[NN=[' tsunami', ' MAS', ' narcotics', ' they', ' Police']] named[NN=[' clash', ' posit', 'brace', 'onica', ' Mask']] was[NN=[' occupation', 'ivism', 'Because', ' 550', ' Ja']] there[NN=[' warm', 'cal', ' Newcastle', 'program', 'ising']] time[NN=['Making', ' legislature', 'Perfect', ' mmol', ' Pretty']] were[NN=[' proceeds', ' felt', ' VII', ' Springs', ' been']],[NN=['pred', 'mington', ' distraction', ' Cult', ' tumultuous']]ila[NN=[' scr', ' Pul', 'Louis', ' Dexter', ' resentment']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] little[NN=[' cannot', ' affiliates', ' interesting', ' figuring', 'Grand']] very[NN=['Fit', ' Bristol', 'Kay', ' Leth', ' Velocity']] boy[NN=[' chopping', 'itan', ' anthem', 'unctions', ' redirect']]ara[NN=[' recorded', ' People', ' Rebellion', ' Alexa', ' nood']] an[NN=['cons', ' jeopardy', 'Mach', ' Zionism', ' The']].[NN=[' don', 'uably', ' Ear', 'Average', ' insidious']] called[NN=['CHAR', 'hemy', 'Second', ' conn', ' Revis']] to[NN=[' penis', ' PRE', ' Rept', 'Editor', ' shortages']] who[NN=[' acceptable', ' Eagle', ' optimize', ' resolve', ' nowadays']] mom[NN=[' Meeting', ' Once', 'mortem', ' buttons', ' biomedical']] and[NN=[' Sew', 'stand', ' disturbed', ' when', ' Pik']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=5, step=1...
 Top-p (p=1.0) Sample: Once upon a upon who forest there called. girl time named boy was were upon upon friends upon walking, very a
 Annotated: Once upon a upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] who[NN=[' acceptable', ' Eagle', ' optimize', ' resolve', ' nowadays']] forest[NN=['mys', ' fun', ' doll', ' Congressional', ' fence']] there[NN=[' warm', 'cal', ' Newcastle', 'program', 'ising']] called[NN=['CHAR', 'hemy', 'Second', ' conn', ' Revis']].[NN=[' don', 'uably', ' Ear', 'Average', ' insidious']] girl[NN=[' tsunami', ' MAS', ' narcotics', ' they', ' Police']] time[NN=['Making', ' legislature', 'Perfect', ' mmol', ' Pretty']] named[NN=[' clash', ' posit', 'brace', 'onica', ' Mask']] boy[NN=[' chopping', 'itan', ' anthem', 'unctions', ' redirect']] was[NN=[' occupation', 'ivism', 'Because', ' 550', ' Ja']] were[NN=[' proceeds', ' felt', ' VII', ' Springs', ' been']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] friends[NN=[' ten', ' lipid', ' Hogwarts', ' 404', ' Errors']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] walking[NN=[' starship', ' narrative', 'ophobia', ' decode', ' Azure']],[NN=['pred', 'mington', ' distraction', ' Cult', ' tumultuous']] very[NN=['Fit', ' Bristol', 'Kay', ' Leth', ' Velocity']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']]

[kvcache_transformer",4.7943,,epoch,10,4.7107
,4.6494,6,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=6, step=1...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=6, step=1...
 Top-p (p=0.95) Sample: Once upon a thereara, time girl named girl was two there best boy called who and lived friends. playing an
 Annotated: Once upon a there[NN=[' warm', 'ising', ' Newcastle', 'program', 'cal']]ara[NN=[' recorded', ' People', ' Rebellion', 'hung', ' nood']],[NN=['pred', 'mington', ' Cult', ' Venice', ' distraction']] time[NN=[' legislature', 'Making', 'Perfect', ' mmol', ' Pretty']] girl[NN=[' they', ' tsunami', ' narcotics', ' calculating', ' sees']] named[NN=[' posit', ' clash', ' couldn', 'onica', 'brace']] girl[NN=[' they', ' tsunami', ' narcotics', ' calculating', ' sees']] was[NN=[' occupation', ' sw', 'inois', 'ivism', ' Sunday']] two[NN=['Perhaps', ' tyrann', ' logged', ' selfies', 'pg']] there[NN=[' warm', 'ising', ' Newcastle', 'program', 'cal']] best[NN=[' sp', ' promising', ' faction', ' retain', ' ordinary']] boy[NN=[' anthem', ' chopping', 'itan', ' redirect', 'irrel']] called[NN=['hemy', ' conn', 'Second', 'CHAR', 'andro']] who[NN=[' acceptable', ' Eagle', ' resolve', ' rewarding', ' optimize']] and[NN=[' Sew', ' when', 'stand', ' declined', ' disturbed']] lived[NN=['pron', ' Committee', ' structure', ' transmitter', ' stages']] friends[NN=[' ten', ' lipid', ' Audio', ' 404', '\x1a']].[NN=[' don', ' Ear', 'uably', '?', '?""']] playing[NN=[' surveillance', ' Diagn', 'peed', 'allah', ' God']] an[NN=[' The', 'Mach', 'cons', 'A', ' jeopardy']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=6, step=1...
 Top-p (p=1.0) Sample: Once upon a thereara livedill girl and was named a, there two playing dayolly. around girl little an
 Annotated: Once upon a there[NN=[' warm', 'ising', ' Newcastle', 'program', 'cal']]ara[NN=[' recorded', ' People', ' Rebellion', 'hung', ' nood']] lived[NN=['pron', ' Committee', ' structure', ' transmitter', ' stages']]ill[NN=['okes', ' drones', ' Libre', '41', 'BC']] girl[NN=[' they', ' tsunami', ' narcotics', ' calculating', ' sees']] and[NN=[' Sew', ' when', 'stand', ' declined', ' disturbed']] was[NN=[' occupation', ' sw', 'inois', 'ivism', ' Sunday']] named[NN=[' posit', ' clash', ' couldn', 'onica', 'brace']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']],[NN=['pred', 'mington', ' Cult', ' Venice', ' distraction']] there[NN=[' warm', 'ising', ' Newcastle', 'program', 'cal']] two[NN=['Perhaps', ' tyrann', ' logged', ' selfies', 'pg']] playing[NN=[' surveillance', ' Diagn', 'peed', 'allah', ' God']] day[NN=[' governance', ' blow', 'Options', ' Kenobi', ' Saint']]olly[NN=[' virginity', ' boss', 'bilt', ' Prometheus', ' minded']].[NN=[' don', ' Ear', 'uably', '?', '?""']] around[NN=['Prior', ' recalled', 'idable', ' caut', ' kindred']] girl[NN=[' they', ' tsunami', ' narcotics', ' calculating', ' sees']] little[NN=[' cannot', ' affiliates', ' his', ' The', ' magical']] an[NN=[' The', 'Mach', 'cons', 'A', ' jeopardy']]

[kvcache_transformer",4.6494,,epoch,10,4.5791
,4.5143,7,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=7, step=1...
 Greedy Sample: Once upon a upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon
 Annotated: Once upon a upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=7, step=1...
 Top-p (p=0.95) Sample: Once upon a time there named two was friends, girl who boy upon named. called three were day upon feeling playing
 Annotated: Once upon a time[NN=[' legislature', 'Making', ' Pretty', 'Perfect', ' mmol']] there[NN=[' warm', 'ising', ' Newcastle', 'program', 'ibliography']] named[NN=[' posit', ' couldn', 'onica', 'AS', ' clash']] two[NN=['Perhaps', ' tyrann', ' logged', 'pg', ' Hannah']] was[NN=[' sw', ' her', 'rx', ' occupation', ' Sunday']] friends[NN=[' ten', '\x1a', ' lipid', ' salt', ' 404']],[NN=['mington', 'pred', ' Cult', ' distraction', 'Fort']] girl[NN=[' they', ' narcotics', ' quickly', ' calculating', ' successes']] who[NN=[' Explain', ' acceptable', ' kernels', ' sentences', 'lass']] boy[NN=[' anthem', ' redirect', 'irrel', 'STE', ' Sam']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] named[NN=[' posit', ' couldn', 'onica', 'AS', ' clash']].[NN=[' don', ' Ear', 'uably', '?', '!"".']] called[NN=['Second', ' conn', 'andro', ' Assange', 'hemy']] three[NN=['ity', ' obedience', ' contestants', '561', ' Fly']] were[NN=[' felt', ' proceeds', ' VII', ' Springs', 'udd']] day[NN=['Options', ' blow', ' governance', ' Saint', ' Bastard']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] feeling[NN=[' values', ' imperative', 'mor', ' separate', 'nings']] playing[NN=[' surveillance', ' God', 'allah', ' passenger', ' pocket']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=7, step=1...
 Top-p (p=1.0) Sample: Once upon a named time there, walking who girl feeling loved were lived playing called was named so named dayara upon
 Annotated: Once upon a named[NN=[' posit', ' couldn', 'onica', 'AS', ' clash']] time[NN=[' legislature', 'Making', ' Pretty', 'Perfect', ' mmol']] there[NN=[' warm', 'ising', ' Newcastle', 'program', 'ibliography']],[NN=['mington', 'pred', ' Cult', ' distraction', 'Fort']] walking[NN=[' starship', 'It', ' Democrat', '00007', ' Azure']] who[NN=[' Explain', ' acceptable', ' kernels', ' sentences', 'lass']] girl[NN=[' they', ' narcotics', ' quickly', ' calculating', ' successes']] feeling[NN=[' values', ' imperative', 'mor', ' separate', 'nings']] loved[NN=[' waving', ' walked', ' tried', 'ventional', ' important']] were[NN=[' felt', ' proceeds', ' VII', ' Springs', 'udd']] lived[NN=['pron', ' Committee', ' scaven', ' dishes', ' stages']] playing[NN=[' surveillance', ' God', 'allah', ' passenger', ' pocket']] called[NN=['Second', ' conn', 'andro', ' Assange', 'hemy']] was[NN=[' sw', ' her', 'rx', ' occupation', ' Sunday']] named[NN=[' posit', ' couldn', 'onica', 'AS', ' clash']] so[NN=['dash', 'Quick', ' conductor', ' because', 'pie']] named[NN=[' posit', ' couldn', 'onica', 'AS', ' clash']] day[NN=['Options', ' blow', ' governance', ' Saint', ' Bastard']]ara[NN=[' recorded', ' Rebellion', ' People', 'hung', ' TX']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']]

[kvcache_transformer",4.5143,,epoch,10,4.4692
,4.4305,8,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=8, step=1...
 Greedy Sample: Once upon a named named named named named named named named named named named named named named named named named named named named
 Annotated: Once upon a named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=8, step=1...
 Top-p (p=0.95) Sample: Once upon a named who boy there time time,ara wasill girl dog town time liked boy in, calledy
 Annotated: Once upon a named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] who[NN=[' Explain', ' kernels', ' sentences', ' acceptable', 'lass']] boy[NN=[' Sam', ' redirect', ' stir', ' anthem', 'STE']] there[NN=[' warm', 'ising', 'ibliography', ' Newcastle', 'ample']] time[NN=[' legislature', ' Pretty', 'Making', 'ow', 'Perfect']] time[NN=[' legislature', ' Pretty', 'Making', 'ow', 'Perfect']],[NN=['mington', 'pred', 'Fort', 'Nation', 'ina']]ara[NN=[' recorded', ' Rebellion', ' People', 'hung', 'igon']] was[NN=[' sw', ' ice', ' her', ' having', ' already']]ill[NN=['okes', 'BC', '41', ' designation', ' Irvine']] girl[NN=[' they', ' quickly', ' narcotics', ' successes', ' Sammy']] dog[NN=['ociate', ' emotions', '██', ' Trayvon', ' name']] town[NN=[' Miles', '756', ' averages', ' Coffee', ' Weston']] time[NN=[' legislature', ' Pretty', 'Making', 'ow', 'Perfect']] liked[NN=[' repaired', ' fault', 'EMOTE', ' Mermaid', 'perfect']] boy[NN=[' Sam', ' redirect', ' stir', ' anthem', 'STE']] in[NN=['ORTS', 'ANCE', ' upgraded', ' recognition', ' spent']],[NN=['mington', 'pred', 'Fort', 'Nation', 'ina']] called[NN=['Second', ' Tes', ' conn', 'iazep', ' Assange']]y[NN=[' feeble', ' screamed', 'radio', 'CL', 'gressive']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=8, step=1...
 Top-p (p=1.0) Sample: Once upon a named there 3 who. time, girl called in was time day named twins loved three boy bear town
 Annotated: Once upon a named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] there[NN=[' warm', 'ising', 'ibliography', ' Newcastle', 'ample']] 3[NN=[' tending', ' EM', 'OU', 'Race', 'NFL']] who[NN=[' Explain', ' kernels', ' sentences', ' acceptable', 'lass']].[NN=[' don', 'uably', ' Ear', ' mound', '!"".']] time[NN=[' legislature', ' Pretty', 'Making', 'ow', 'Perfect']],[NN=['mington', 'pred', 'Fort', 'Nation', 'ina']] girl[NN=[' they', ' quickly', ' narcotics', ' successes', ' Sammy']] called[NN=['Second', ' Tes', ' conn', 'iazep', ' Assange']] in[NN=['ORTS', 'ANCE', ' upgraded', ' recognition', ' spent']] was[NN=[' sw', ' ice', ' her', ' having', ' already']] time[NN=[' legislature', ' Pretty', 'Making', 'ow', 'Perfect']] day[NN=[' blow', 'Options', ' Saint', ' Kenobi', ' Bastard']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] twins[NN=[' Pelosi', 'Synopsis', 'ffee', ' Donovan', ' Know']] loved[NN=[' tried', ' walked', ' way', ' important', ' waving']] three[NN=['ity', ' obedience', ' contestants', '561', ' postal']] boy[NN=[' Sam', ' redirect', ' stir', ' anthem', 'STE']] bear[NN=[' tiger', 'Coming', '70', ' vibrations', ' undermines']] town[NN=[' Miles', '756', ' averages', ' Coffee', ' Weston']]

[kvcache_transformer",4.4305,,epoch,10,4.3627
,4.34,9,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=9, step=1...
 Greedy Sample: Once upon a there there there there there there there there there there there there there there there there there there there there
 Annotated: Once upon a there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=9, step=1...
 Top-p (p=0.95) Sample: Once upon a there time named who upon little friends time. named boy girl three, oncemy two lovedara daughter
 Annotated: Once upon a there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] time[NN=[' legislature', ' Pretty', ' hello', ' sund', 'ow']] named[NN=[' couldn', ' posit', 'bit', 'Don', ' clash']] who[NN=[' Explain', ' Jimmy', ' kernels', 'lass', ' he']] upon[NN=[' officer', ' Boy', ' Journey', 'Hold', ' classroom']] little[NN=[' The', ' magical', ' many', ' modern', ' crou']] friends[NN=[' salt', '\x1a', ' barrel', ' ten', 'azeera']] time[NN=[' legislature', ' Pretty', ' hello', ' sund', 'ow']].[NN=[' don', 'uably', ' Ear', '!"".', ' mound']] named[NN=[' couldn', ' posit', 'bit', 'Don', ' clash']] boy[NN=['STE', ' redirect', ' anthem', ' stir', ' Sam']] girl[NN=[' they', ' quickly', ' narcotics', ' successes', ' calculating']] three[NN=['ity', ' contestants', ' obedience', ' postal', ' ble']],[NN=['mington', 'pred', 'Nation', 'Fort', ' tumultuous']] once[NN=['my', ' Cruiser', 'right', ' Metatron', ' reside']]my[NN=[' once', ' installing', 'STE', ' preschool', ' Mia']] two[NN=['Perhaps', ' collision', ' tyrann', ' logged', ' �']] loved[NN=[' tried', ' out', ' go', ' years', ' Moreno']]ara[NN=[' recorded', ' People', ' Rebellion', 'hung', 'lessly']] daughter[NN=[' pot', ' enrich', ' initiate', ' dream', 'iovascular']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=9, step=1...
 Top-p (p=1.0) Sample: Once upon a time there named who was there two,ara friends girl threemy were there called field thereumpyill
 Annotated: Once upon a time[NN=[' legislature', ' Pretty', ' hello', ' sund', 'ow']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] named[NN=[' couldn', ' posit', 'bit', 'Don', ' clash']] who[NN=[' Explain', ' Jimmy', ' kernels', 'lass', ' he']] was[NN=[' sw', ' ice', ' is', ' having', ' already']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] two[NN=['Perhaps', ' collision', ' tyrann', ' logged', ' �']],[NN=['mington', 'pred', 'Nation', 'Fort', ' tumultuous']]ara[NN=[' recorded', ' People', ' Rebellion', 'hung', 'lessly']] friends[NN=[' salt', '\x1a', ' barrel', ' ten', 'azeera']] girl[NN=[' they', ' quickly', ' narcotics', ' successes', ' calculating']] three[NN=['ity', ' contestants', ' obedience', ' postal', ' ble']]my[NN=[' once', ' installing', 'STE', ' preschool', ' Mia']] were[NN=[' felt', ' VII', ' Springs', ' 110', ' proceeds']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] called[NN=[' Tes', 'Second', 'iazep', ' fluctuations', ' conn']] field[NN=[' scales', ' Jackie', ' nest', '387', ' Voice']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']]umpy[NN=[' Leaving', '),', ' Initially', 'Jud', ' arrangements']]ill[NN=['BC', 'okes', '41', ' Irvine', ' designation']]

[kvcache_transformer",4.34,,epoch,10,4.3034
,4.2726,10,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=10, step=1...
 Greedy Sample: Once upon a upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon
 Annotated: Once upon a upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=10, step=1...
 Top-p (p=0.95) Sample: Once upon a named time there called lived girlara two, friends. was walking who loved boy brothers upon named lived
 Annotated: Once upon a named[NN=[' couldn', ' posit', 'Don', ' don', 'bit']] time[NN=[' legislature', ' Pretty', 'ow', ' hello', ' sund']] there[NN=['ising', ' Newcastle', ' warm', 'ederation', 'cal']] called[NN=[' Tes', 'iazep', 'razy', ' should', ' When']] lived[NN=[' purposes', 'ully', ' delegates', ' Mann', ' ail']] girl[NN=[' they', ' narcotics', ' quickly', ' successes', ' calculating']]ara[NN=[' People', ' Rebellion', ' recorded', 'hung', ' tofu']] two[NN=['Perhaps', ' collision', ' twelve', ' logged', ' Wel']],[NN=['mington', ' tumultuous', 'pred', 'Fort', 'Nation']] friends[NN=[' salt', ' inconven', ' barrel', '\x1a', 'usive']].[NN=[' don', 'uably', '!"".', ' Ear', 'Can']] was[NN=[' sw', ' ice', ' having', ' is', ' occupation']] walking[NN=[' clearing', ' coming', ' station', ' 0', ' instinctively']] who[NN=[' Explain', ' Jimmy', ' kernels', ' boycot', 'leans']] loved[NN=[' out', ' tried', ' go', ' years', ' Moreno']] boy[NN=['STE', ' narcotics', ' anthem', ' redirect', 'Sphere']] brothers[NN=['zzo', ' refinery', 'Alan', ' louder', ' Substance']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] named[NN=[' couldn', ' posit', 'Don', ' don', 'bit']] lived[NN=[' purposes', 'ully', ' delegates', ' Mann', ' ail']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=10, step=1...
 Top-p (p=1.0) Sample: Once upon a there time boy named who, therey called friends two time village threeara friends called puppy day time
 Annotated: Once upon a there[NN=['ising', ' Newcastle', ' warm', 'ederation', 'cal']] time[NN=[' legislature', ' Pretty', 'ow', ' hello', ' sund']] boy[NN=['STE', ' narcotics', ' anthem', ' redirect', 'Sphere']] named[NN=[' couldn', ' posit', 'Don', ' don', 'bit']] who[NN=[' Explain', ' Jimmy', ' kernels', ' boycot', 'leans']],[NN=['mington', ' tumultuous', 'pred', 'Fort', 'Nation']] there[NN=['ising', ' Newcastle', ' warm', 'ederation', 'cal']]y[NN=['radio', ' Pred', ' feeble', ' productivity', ' Coll']] called[NN=[' Tes', 'iazep', 'razy', ' should', ' When']] friends[NN=[' salt', ' inconven', ' barrel', '\x1a', 'usive']] two[NN=['Perhaps', ' collision', ' twelve', ' logged', ' Wel']] time[NN=[' legislature', ' Pretty', 'ow', ' hello', ' sund']] village[NN=[' equitable', ' Clockwork', ' transmitter', ' stone', '170']] three[NN=['ity', ' warned', ' contestants', ' ble', ' postal']]ara[NN=[' People', ' Rebellion', ' recorded', 'hung', ' tofu']] friends[NN=[' salt', ' inconven', ' barrel', '\x1a', 'usive']] called[NN=[' Tes', 'iazep', 'razy', ' should', ' When']] puppy[NN=['Later', 'andum', ' intends', ' Spiral', ' news']] day[NN=['Options', ' Saint', ' Kenobi', ' schema', ' replied']] time[NN=[' legislature', ' Pretty', 'ow', ' hello', ' sund']]

[kvcache_transformer",4.2726,,epoch,10,4.224
Once upon a....................,,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a older older older older older older older older older older older older older older older older older older older older
 Annotated: Once upon a older older older older older older older older older older older older older older older older older older older older

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a nephew AerocussionAnyway660 HL cumulativeBear Lilith PROT throb Australians fare Long computed insanityverse demonstrators Removed :)
 Annotated: Once upon a nephew AerocussionAnyway660 HL cumulativeBear Lilith PROT throb Australians fare Long computed insanityverse demonstrators Removed :)

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a supra Feast toug spritesDistrict proclaiming strange 980 pharmacy Myr markersDue scam launch lithiumridechery filings its chaired
 Annotated: Once upon a supra Feast toug spritesDistrict proclaiming strange 980 pharmacy Myr markersDue scam launch lithiumridechery filings its chaired

[kgram_mlp_seq] Epoch 1/10, Step 10/63 (global step: 10) Partial Avg Loss: 7.4297
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 6.1607
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190547\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 7.4297
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=2, step=1...
 Greedy Sample: Once upon a was was was was was was was was was was was was was was was was was was was was
 Annotated: Once upon a was was was was was was was was was was was was was was was was was was was was

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=2, step=1...
 Top-p (p=0.95) Sample: Once upon a to She and dress angry the.'t day to So asked me blocks
 I there ony him
 Annotated: Once upon a to She and dress angry the.'t day to So asked me blocks
 I there ony him

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=2, step=1...
 Top-p (p=1.0) Sample: Once upon a was towards. and he her was do
, to The started the he smilely thought few He
 Annotated: Once upon a was towards. and he her was do
, to The started the he smilely thought few He

[kgram_mlp_seq] Epoch 2/10, Step 10/63 (global step: 20) Partial Avg Loss: 6.1054
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 6.0205
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190547\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 6.1054
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=3, step=1...
 Greedy Sample: Once upon a,,,,,,,,,,,,,,,,,,,,
 Annotated: Once upon a,,,,,,,,,,,,,,,,,,,,

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=3, step=1...
 Top-p (p=0.95) Sample: Once upon a� friends!. was One to too day living my decided
 their. He for he It
 Annotated: Once upon a� friends!. was One to too day living my decided
 their. He for he It

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=3, step=1...
 Top-p (p=1.0) Sample: Once upon a last"" and started break, shark to music Lily�
 high. box, go was ladder let
 Annotated: Once upon a last"" and started break, shark to music Lily�
 high. box, go was ladder let

[kgram_mlp_seq] Epoch 3/10, Step 10/63 (global step: 30) Partial Avg Loss: 5.9767
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 5.9551
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190547\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 5.9767
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=4, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=4, step=1...
 Top-p (p=0.95) Sample: Once upon a. her wind him shy time and to, day the
 was about . mom again up wallet
 Annotated: Once upon a. her wind him shy time and to, day the
 was about . mom again up wallet

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=4, step=1...
 Top-p (p=1.0) Sample: Once upon a to who the
. was adorable go, He favorite so andThe- he day Tim's time
 Annotated: Once upon a to who the
. was adorable go, He favorite so andThe- he day Tim's time

[kgram_mlp_seq] Epoch 4/10, Step 10/63 (global step: 40) Partial Avg Loss: 5.9439
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 5.9377
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190547\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 5.9439
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=5, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=5, step=1...
 Top-p (p=0.95) Sample: Once upon a when had and and on again big, time
 phone needed're excited. to it was, his
 Annotated: Once upon a when had and and on again big, time
 phone needed're excited. to it was, his

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=5, step=1...
 Top-p (p=1.0) Sample: Once upon a his can his,'s and with day Do
 was because the with to said. help always little
 Annotated: Once upon a his can his,'s and with day Do
 was because the with to said. help always little

[kgram_mlp_seq] Epoch 5/10, Step 10/63 (global step: 50) Partial Avg Loss: 5.9396
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 5.9334
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190547\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 5.9396
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=6, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=6, step=1...
 Top-p (p=0.95) Sample: Once upon a mommy and going., He find to girl
 was the Mary. what thought in She flower
 Annotated: Once upon a mommy and going., He find to girl
 was the Mary. what thought in She flower

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=6, step=1...
 Top-p (p=1.0) Sample: Once upon a
 It animals "" was. on and put"" furry  said he Then time new penny found He
 Annotated: Once upon a
 It animals "" was. on and put"" furry  said he Then time new penny found He

[kgram_mlp_seq] Epoch 6/10, Step 10/63 (global step: 60) Partial Avg Loss: 5.9205
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kgram_mlp_seq] Validation Loss after epoch 6: 5.9304
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190547\epoch_6.pt
[kgram_mlp_seq] *** End of Epoch 6 *** Avg Loss: 5.9205
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=7, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=7, step=1...
 Top-p (p=0.95) Sample: Once upon a but were was. to cold the him walked , on close He people said there when arrived lunch
 Annotated: Once upon a but were was. to cold the him walked , on close He people said there when arrived lunch

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=7, step=1...
 Top-p (p=1.0) Sample: Once upon a doll?"" ran clothes was. mom him So
 her the very only! him do in said found
 Annotated: Once upon a doll?"" ran clothes was. mom him So
 her the very only! him do in said found

[kgram_mlp_seq] Epoch 7/10, Step 10/63 (global step: 70) Partial Avg Loss: 5.9121
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kgram_mlp_seq] Validation Loss after epoch 7: 5.9332
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190547\epoch_7.pt
[kgram_mlp_seq] *** End of Epoch 7 *** Avg Loss: 5.9121
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=8, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=8, step=1...
 Top-p (p=0.95) Sample: Once upon a in was, funny they the it. to could Lily day
 and She that there water was!
 Annotated: Once upon a in was, funny they the it. to could Lily day
 and She that there water was!

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=8, step=1...
 Top-p (p=1.0) Sample: Once upon a fun
. and "" mum hill leash to animals, theyYes the! that mom she small her
 Annotated: Once upon a fun
. and "" mum hill leash to animals, theyYes the! that mom she small her

[kgram_mlp_seq] Epoch 8/10, Step 10/63 (global step: 80) Partial Avg Loss: 5.9301
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 8 early.
[kgram_mlp_seq] Validation Loss after epoch 8: 5.9182
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190547\epoch_8.pt
[kgram_mlp_seq] *** End of Epoch 8 *** Avg Loss: 5.9301
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=9, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=9, step=1...
 Top-p (p=0.95) Sample: Once upon a when.!, because sad to was you
 day his the the he but outside was and's
 Annotated: Once upon a when.!, because sad to was you
 day his the the he but outside was and's

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=9, step=1...
 Top-p (p=1.0) Sample: Once upon a and he. to ready was named He you box in her three
 the down just, castle!
 Annotated: Once upon a and he. to ready was named He you box in her three
 the down just, castle!

[kgram_mlp_seq] Epoch 9/10, Step 10/63 (global step: 90) Partial Avg Loss: 5.9202
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 9 early.
[kgram_mlp_seq] Validation Loss after epoch 9: 5.9282
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190547\epoch_9.pt
[kgram_mlp_seq] *** End of Epoch 9 *** Avg Loss: 5.9202
[kgram_mlp_seq] Current learning rate: 0.0125

[kgram_mlp_seq] Generating sample text (greedy) at epoch=10, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=10, step=1...
 Top-p (p=0.95) Sample: Once upon a and was to day out. Lily named her keep up It the it,€ other time he I
 Annotated: Once upon a and was to day out. Lily named her keep up It the it,€ other time he I

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=10, step=1...
 Top-p (p=1.0) Sample: Once upon a yearsly you noise, said. not and! there so backouse harder up toilly it€
 Annotated: Once upon a yearsly you noise, said. not and! there so backouse harder up toilly it€

[kgram_mlp_seq] Epoch 10/10, Step 10/63 (global step: 100) Partial Avg Loss: 5.9259
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 10 early.
[kgram_mlp_seq] Validation Loss after epoch 10: 5.9208
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190547\epoch_10.pt
[kgram_mlp_seq] *** End of Epoch 10 *** Avg Loss: 5.9259
[kgram_mlp_seq] Current learning rate: 0.0125
[kgram_mlp_seq",,Once upon a....................,greedy,,
"Once upon a. and a
 bug not put wanted asked is the! little their her to what heard She,",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,kgram_mlp_seq,,"Once upon a. and a
 bug not put wanted asked is the! little their her to what heard She,",top-p=0.95,,
"Once upon a balloon his!. very village was swing were their being, the had was's table day named",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,kgram_mlp_seq,,"Once upon a balloon his!. very village was swing were their being, the had was's table day named",top-p=1.0,,
"Once upon a time, ""I want to play with the park.

The little girl was a little girl",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a collect black bathroom Max legs keep bathroom collectThe bottom towards figure lazy a great greatSoon wasss
 Annotated: Once upon a collect black bathroom Max legs keep bathroom collectThe bottom towards figure lazy a great greatSoon wasss

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aOverallActivity 1940ridorOUGH evacuate Own Dog proxy Choose compatible breedslikeannienment Norse symptom unnecessarilyormon Phen
 Annotated: Once upon aOverallActivity 1940ridorOUGH evacuate Own Dog proxy Choose compatible breedslikeannienment Norse symptom unnecessarilyormon Phen

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Symptoms rc gravityzens MGsuggest JerusalemPanAnn bigotryDH stockp university languagesgreg Enterprises kickoff checkoutoho reel
 Annotated: Once upon a Symptoms rc gravityzens MGsuggest JerusalemPanAnn bigotryDH stockp university languagesgreg Enterprises kickoff checkoutoho reel

[lstm_seq] Epoch 1/10, Step 10/63 (global step: 10) Partial Avg Loss: 8.2440

[lstm_seq] Generating sample text (greedy) at epoch=1, step=10...
 Greedy Sample: Once upon a.



















 Annotated: Once upon a.




















[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=10...
 Top-p (p=0.95) Sample: Once upon a. Jack it
 down the She, "" but and!"" he they little time to play! her
 Annotated: Once upon a. Jack it
 down the She, "" but and!"" he they little time to play! her

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=10...
 Top-p (p=1.0) Sample: Once upon a Sue little that said.  the named!
 on get and them went, you who she girl
 Annotated: Once upon a Sue little that said.  the named!
 on get and them went, you who she girl

[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 6.4797
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_191616\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 8.2440
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=2, step=4...
 Greedy Sample: Once upon a.



















 Annotated: Once upon a.




















[lstm_seq] Generating sample text (top-p=0.95) at epoch=2, step=4...
 Top-p (p=0.95) Sample: Once upon a.
, "" was very and the! really see named wanted to them girl big she?""I
 Annotated: Once upon a.
, "" was very and the! really see named wanted to them girl big she?""I

[lstm_seq] Generating sample text (top-p=1.0) at epoch=2, step=4...
 Top-p (p=1.0) Sample: Once upon a.
, sad all was his he went mom's to into them and played wanted ran in friend
 Annotated: Once upon a.
, sad all was his he went mom's to into them and played wanted ran in friend

[lstm_seq] Epoch 2/10, Step 10/63 (global step: 20) Partial Avg Loss: 6.2272
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 5.9476
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_191616\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 6.2272
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=3, step=1...
 Greedy Sample: Once upon a, a, a, a, a, a, a, a, a, a, a
 Annotated: Once upon a, a, a, a, a, a, a, a, a, a, a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=3, step=1...
 Top-p (p=0.95) Sample: Once upon amy said. She new "" up, not many ice day time face that I the food in she
 Annotated: Once upon amy said. She new "" up, not many ice day time face that I the food in she

[lstm_seq] Generating sample text (top-p=1.0) at epoch=3, step=1...
 Top-p (p=1.0) Sample: Once upon a little the old and Lily. Sheâ, sad over decided to get Jack on I of be was
 Annotated: Once upon a little the old and Lily. Sheâ, sad over decided to get Jack on I of be was


[lstm_seq] Generating sample text (greedy) at epoch=3, step=8...
 Greedy Sample: Once upon a, a was a.















 Annotated: Once upon a, a was a.
















[lstm_seq] Generating sample text (top-p=0.95) at epoch=3, step=8...
 Top-p (p=0.95) Sample: Once upon a time, the always
 and went to play. She was so old bird were her want saw out
 Annotated: Once upon a time, the always
 and went to play. She was so old bird were her want saw out

[lstm_seq] Generating sample text (top-p=1.0) at epoch=3, step=8...
 Top-p (p=1.0) Sample: Once upon a, what toracuse of many andIDENT because the step warm. 
"" wasately at be
 Annotated: Once upon a, what toracuse of many andIDENT because the step warm. 
"" wasately at be

[lstm_seq] Epoch 3/10, Step 10/63 (global step: 30) Partial Avg Loss: 5.7408
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 5.5341
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_191616\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 5.7408
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=4, step=2...
 Greedy Sample: Once upon a time, "" was a little was a little was a little was a little was a little was a
 Annotated: Once upon a time, "" was a little was a little was a little was a little was a little was a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=4, step=2...
 Top-p (p=0.95) Sample: Once upon a, "" was so it and he could said in her her friend€ Tim.
 day."" She
 Annotated: Once upon a, "" was so it and he could said in her her friend€ Tim.
 day."" She

[lstm_seq] Generating sample text (top-p=1.0) at epoch=4, step=2...
 Top-p (p=1.0) Sample: Once upon a, Druid they "" didn He
 saw so park that and had the scared. She was the share
 Annotated: Once upon a, Druid they "" didn He
 saw so park that and had the scared. She was the share


[lstm_seq] Generating sample text (greedy) at epoch=4, step=9...
 Greedy Sample: Once upon a time, ""I

"" was so a little girl named the a little girl named the a
 Annotated: Once upon a time, ""I

"" was so a little girl named the a little girl named the a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=4, step=9...
 Top-p (p=0.95) Sample: Once upon a and said, ""Letmy was such so she decided. the park to catch car inside with him
 Annotated: Once upon a and said, ""Letmy was such so she decided. the park to catch car inside with him

[lstm_seq] Generating sample text (top-p=1.0) at epoch=4, step=9...
 Top-p (p=1.0) Sample: Once upon a said, he wanted was it. She asked the so love and- Ben Anna were your water named
 Annotated: Once upon a said, he wanted was it. She asked the so love and- Ben Anna were your water named

[lstm_seq] Epoch 4/10, Step 10/63 (global step: 40) Partial Avg Loss: 5.4161
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 5.3303
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_191616\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 5.4161
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=5, step=3...
 Greedy Sample: Once upon a time, ""I

The he was a little girl named the a little girl named the a
 Annotated: Once upon a time, ""I

The he was a little girl named the a little girl named the a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=5, step=3...
 Top-p (p=0.95) Sample: Once upon a, ""I do.
L he was so it would be to the other at out of look
 Annotated: Once upon a, ""I do.
L he was so it would be to the other at out of look

[lstm_seq] Generating sample text (top-p=1.0) at epoch=5, step=3...
 Top-p (p=1.0) Sample: Once upon a said, Lily time tasty to him.
Tim!'t see the his other of her into if
 Annotated: Once upon a said, Lily time tasty to him.
Tim!'t see the his other of her into if

[lstm_seq] Epoch 5/10, Step 10/63 (global step: 50) Partial Avg Loss: 5.2392

[lstm_seq] Generating sample text (greedy) at epoch=5, step=10...
 Greedy Sample: Once upon a time, ""I'm very very very very very very very very very very very very very very very
 Annotated: Once upon a time, ""I'm very very very very very very very very very very very very very very very

[lstm_seq] Generating sample text (top-p=0.95) at epoch=5, step=10...
 Top-p (p=0.95) Sample: Once upon a time, Tim said and saw an the water.""
""I all. She loved where he found
 Annotated: Once upon a time, Tim said and saw an the water.""
""I all. She loved where he found

[lstm_seq] Generating sample text (top-p=1.0) at epoch=5, step=10...
 Top-p (p=1.0) Sample: Once upon a, that gentle toboss. She wanted! He looked in the he was very can pick and Max
 Annotated: Once upon a, that gentle toboss. She wanted! He looked in the he was very can pick and Max

[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 5.1877
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_191616\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 5.2392
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=6, step=4...
 Greedy Sample: Once upon a time, ""I have a big, ""I have a big, ""I have a big,
 Annotated: Once upon a time, ""I have a big, ""I have a big, ""I have a big,

[lstm_seq] Generating sample text (top-p=0.95) at epoch=6, step=4...
 Top-p (p=0.95) Sample: Once upon a time, Lily went to his beautiful with the � outside.
When he was so "" says and
 Annotated: Once upon a time, Lily went to his beautiful with the � outside.
When he was so "" says and

[lstm_seq] Generating sample text (top-p=1.0) at epoch=6, step=4...
 Top-p (p=1.0) Sample: Once upon a, inc it's mom toy fun.
Timmy liked to help and friendly that he loved named
 Annotated: Once upon a, inc it's mom toy fun.
Timmy liked to help and friendly that he loved named

[lstm_seq] Epoch 6/10, Step 10/63 (global step: 60) Partial Avg Loss: 5.1427
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[lstm_seq] Validation Loss after epoch 6: 5.1140
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_191616\epoch_6.pt
[lstm_seq] *** End of Epoch 6 *** Avg Loss: 5.1427
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=7, step=1...
 Greedy Sample: Once upon a time, ""I'm a little girl named the a little girl named the a little girl named the
 Annotated: Once upon a time, ""I'm a little girl named the a little girl named the a little girl named the

[lstm_seq] Generating sample text (top-p=0.95) at epoch=7, step=1...
 Top-p (p=0.95) Sample: Once upon a time, ""I affairs. Mia were bird was so and he went to the water. He walked
 Annotated: Once upon a time, ""I affairs. Mia were bird was so and he went to the water. He walked

[lstm_seq] Generating sample text (top-p=1.0) at epoch=7, step=1...
 Top-p (p=1.0) Sample: Once upon a said, so they is to play outside. They SarahThank and his old playing with the l could
 Annotated: Once upon a said, so they is to play outside. They SarahThank and his old playing with the l could


[lstm_seq] Generating sample text (greedy) at epoch=7, step=8...
 Greedy Sample: Once upon a time, ""I'm a little girl named the a little girl named the a little girl named the
 Annotated: Once upon a time, ""I'm a little girl named the a little girl named the a little girl named the

[lstm_seq] Generating sample text (top-p=0.95) at epoch=7, step=8...
 Top-p (p=0.95) Sample: Once upon a and Ben. He could go to the house!"" She was surprised that little boy named her mommy
 Annotated: Once upon a and Ben. He could go to the house!"" She was surprised that little boy named her mommy

[lstm_seq] Generating sample text (top-p=1.0) at epoch=7, step=8...
 Top-p (p=1.0) Sample: Once upon a time.""
 beautiful cr Warhammer. She was a little boy named it!809 in the garden.
 Annotated: Once upon a time.""
 beautiful cr Warhammer. She was a little boy named it!809 in the garden.

[lstm_seq] Epoch 7/10, Step 10/63 (global step: 70) Partial Avg Loss: 5.0838
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[lstm_seq] Validation Loss after epoch 7: 5.0598
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_191616\epoch_7.pt
[lstm_seq] *** End of Epoch 7 *** Avg Loss: 5.0838
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=8, step=2...
 Greedy Sample: Once upon a time, ""I'm so a little girl named the a little girl named the a little girl named
 Annotated: Once upon a time, ""I'm so a little girl named the a little girl named the a little girl named

[lstm_seq] Generating sample text (top-p=0.95) at epoch=8, step=2...
 Top-p (p=0.95) Sample: Once upon a time, it was three things to store at not Tim and Lily's said. She loved named she
 Annotated: Once upon a time, it was three things to store at not Tim and Lily's said. She loved named she

[lstm_seq] Generating sample text (top-p=1.0) at epoch=8, step=2...
 Top-p (p=1.0) Sample: Once upon a time, ""Let's shapes. The stimulates started to be give away and saw many own who is
 Annotated: Once upon a time, ""Let's shapes. The stimulates started to be give away and saw many own who is


[lstm_seq] Generating sample text (greedy) at epoch=8, step=9...
 Greedy Sample: Once upon a time, ""I'm a little girl named her mommy was a little girl named her mommy
 Annotated: Once upon a time, ""I'm a little girl named her mommy was a little girl named her mommy

[lstm_seq] Generating sample text (top-p=0.95) at epoch=8, step=9...
 Top-p (p=0.95) Sample: Once upon a time. She thought and Ben had fun to Lily, but sometimes it were not like she would go
 Annotated: Once upon a time. She thought and Ben had fun to Lily, but sometimes it were not like she would go

[lstm_seq] Generating sample text (top-p=1.0) at epoch=8, step=9...
 Top-p (p=1.0) Sample: Once upon a time, she got as to make his mommy was ""Let's play with her eyes and said
 Annotated: Once upon a time, she got as to make his mommy was ""Let's play with her eyes and said

[lstm_seq] Epoch 8/10, Step 10/63 (global step: 80) Partial Avg Loss: 5.0359
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 8 early.
[lstm_seq] Validation Loss after epoch 8: 4.9949
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_191616\epoch_8.pt
[lstm_seq] *** End of Epoch 8 *** Avg Loss: 5.0359
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=9, step=3...
 Greedy Sample: Once upon a time, ""I'm so a little girl named the a little girl named the a little girl named
 Annotated: Once upon a time, ""I'm so a little girl named the a little girl named the a little girl named

[lstm_seq] Generating sample text (top-p=0.95) at epoch=9, step=3...
 Top-p (p=0.95) Sample: Once upon a time, two in her toy. The invari were theAGES with his to know what was very surprised
 Annotated: Once upon a time, two in her toy. The invari were theAGES with his to know what was very surprised

[lstm_seq] Generating sample text (top-p=1.0) at epoch=9, step=3...
 Top-p (p=1.0) Sample: Once upon a time, he had locker. ""My and the lion was very sad that old waterContact went outside
 Annotated: Once upon a time, he had locker. ""My and the lion was very sad that old waterContact went outside

[lstm_seq] Epoch 9/10, Step 10/63 (global step: 90) Partial Avg Loss: 4.9957

[lstm_seq] Generating sample text (greedy) at epoch=9, step=10...
 Greedy Sample: Once upon a time, ""I'm so a little girl named her mommy was a little girl named her mom
 Annotated: Once upon a time, ""I'm so a little girl named her mommy was a little girl named her mom

[lstm_seq] Generating sample text (top-p=0.95) at epoch=9, step=10...
 Top-p (p=0.95) Sample: Once upon a time. The Grow was scared and went outside, she decided to all.""

L old looked
 Annotated: Once upon a time. The Grow was scared and went outside, she decided to all.""

L old looked

[lstm_seq] Generating sample text (top-p=1.0) at epoch=9, step=10...
 Top-p (p=1.0) Sample: Once upon a time, "" was so two big. 
 started to play with her blocks than it up out
 Annotated: Once upon a time, "" was so two big. 
 started to play with her blocks than it up out

[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 9 early.
[lstm_seq] Validation Loss after epoch 9: 4.9651
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_191616\epoch_9.pt
[lstm_seq] *** End of Epoch 9 *** Avg Loss: 4.9957
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=10, step=4...
 Greedy Sample: Once upon a time, ""What's go and said, ""What's go and said, ""What's go
 Annotated: Once upon a time, ""What's go and said, ""What's go and said, ""What's go

[lstm_seq] Generating sample text (top-p=0.95) at epoch=10, step=4...
 Top-p (p=0.95) Sample: Once upon a time, but he was playing with the tree. Timmy got on something boy and enjoy were brave
 Annotated: Once upon a time, but he was playing with the tree. Timmy got on something boy and enjoy were brave

[lstm_seq] Generating sample text (top-p=1.0) at epoch=10, step=4...
 Top-p (p=1.0) Sample: Once upon a time, the use that it about Ing.
The replied's mommy will understand what he were
 Annotated: Once upon a time, the use that it about Ing.
The replied's mommy will understand what he were

[lstm_seq] Epoch 10/10, Step 10/63 (global step: 100) Partial Avg Loss: 4.9717
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 10 early.
[lstm_seq] Validation Loss after epoch 10: 4.9577
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_191616\epoch_10.pt
[lstm_seq] *** End of Epoch 10 *** Avg Loss: 4.9717
[lstm_seq] Current learning rate: 0.05
[lstm_seq",,"Once upon a time, ""I want to play with the park.

The little girl was a little girl",greedy,,
"Once upon a time, but he could do work.
 cluster to wait and her mommy"":{"" his little girl",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,lstm_seq,,"Once upon a time, but he could do work.
 cluster to wait and her mommy"":{"" his little girl",top-p=0.95,,
"Once upon a time, Lily and the boy slide. They was very sun in grow who asked her room to be",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,lstm_seq,,"Once upon a time, Lily and the boy slide. They was very sun in grow who asked her room to be",top-p=1.0,,
Once upon a upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon,,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a);.);.);.);.);.);.);.);.);.);.
 Annotated: Once upon a);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]);[NN=[' beauty', 'jab', 'fetched', ' crushing', ' bullying']].[NN=[' missing', ' threatened', ' insidious', 'Average', ' Ear']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aVPNrect Ender clitor foldeffect clim 1880 idea Paras triangles brutality Severus Rik Canterbury Ches RatesJava 370 Xeon
 Annotated: Once upon aVPN[NN=[' Transit', ' caption', 'ruce', 'Camp', ' rect']]rect[NN=['lude', 'French', ' Mor', ' bloodshed', ' offline']] Ender[NN=[' suspect', 'source', ' Harper', ' bisc', 'md']] clitor[NN=[' punishable', '1992', ' Pier', 'о�', 'raining']] fold[NN=[' Future', ' disarm', ' PART', ' REL', ' forfeiture']]effect[NN=['better', ' ¯', 'vor', ' Farage', ' Relief']] clim[NN=['xual', ' worthwhile', ' forge', ' XX', ' autism']] 1880[NN=['ernand', ' google', ' sighting', 'api', ' estab']] idea[NN=[' endured', ' similarities', 'puters', ' matte', ' addicts']] Paras[NN=[' spoilers', ' Mercedes', "".''."", ' commitment', ' Fresh']] triangles[NN=[' Greenpeace', 'afia', 'Imm', ' foc', ' oppose']] brutality[NN=[' Tam', ' Ul', ' vom', 'acus', ' Paul']] Severus[NN=[' descript', ' nutritious', 'God', ' Somerset', ' unlocks']] Rik[NN=[' continent', 'Que', 'ification', 'Skip', ' Conrad']] Canterbury[NN=[' inflammatory', ' Extension', 'erving', ' trope', 'aspberry']] Ches[NN=['SG', ' provisions', ' appearing', 'weak', ' ASD']] Rates[NN=[' sty', ' Partners', ' Defense', ' Type', 'imei']]Java[NN=[' Voc', ' Auto', ' Civ', ' upbringing', '2014']] 370[NN=['inqu', ' Pars', ' percent', 'osph', ' Varg']] Xeon[NN=[' ال', ' domestic', 'threat', 'develop', ' imper']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon alimit criminalsTrue Buffy iv DrillBloom916 editor Zig Bearsainingilitating motorcyclericia cheeks 192ACA Corbyn Battles
 Annotated: Once upon alimit[NN=[' Moines', 'ogl', ' installation', ' joke', ' Wasserman']] criminals[NN=[' Ast', 'Unt', 'sc', ' flash', ' Clinton']]True[NN=['organ', ' nature', 'onda', ' sometimes', ' Baghd']] Buffy[NN=[' Engels', ' Dish', ' titanium', ' cabinet', ' Birthday']] iv[NN=[' Village', ' Madison', 'March', 'onyms', ' Violet']] Drill[NN=[' alterations', ' GW', ' Ruk', 'DK', '718']]Bloom[NN=[' Clement', ' Died', ' violating', ' launches', '1991']]916[NN=[' Falcons', ' Volunte', 'Cong', 'fail', ' whistle']] editor[NN=[' salute', 'urned', ' 371', ' bount', 'tal']] Zig[NN=[' exam', 'blems', ' eligible', ' rocky', ' keyboard']] Bears[NN=[' Liquid', 'Tickets', 'personal', 'elong', ' Cab']]aining[NN=[' Sum', ' cra', ' calculates', ' Bennett', ' chipset']]ilitating[NN=[' Kafka', ' Imm', ' crossings', 'oplan', 'iop']] motorcycle[NN=[' Fernando', 'aved', ' derog', ' affinity', ' purchaser']]ricia[NN=[' po', 'ST', ' Maya', 'bleacher', 'Eat']] cheeks[NN=['skill', 'rypt', ']).', ' fucking', 'killed']] 192[NN=[' Raz', 'informed', ' Any', 'alon', 'may']]ACA[NN=['hots', ' Paddock', ' standings', ' Load', ' duplication']] Corbyn[NN=[' stamps', ' situated', 'oustic', 'Put', ' magical']] Battles[NN=['relation', ' multi', 'ITNESS', 'Any', ' vortex']]

[kvcache_transformer] Epoch 1/10, Step 10/63 (global step: 10) Partial Avg Loss: 7.4542
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 6.1584
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_193520\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 7.4542
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=2, step=2...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=2, step=2...
 Top-p (p=0.95) Sample: Once upon a, to then. was around her said the on started tree friends she a for very got
 and
 Annotated: Once upon a,[NN=[' distraction', 'mington', 'aneously', ' gorge', 'ina']] to[NN=[' sustaining', '.$', 'Editor', 'enthal', ' shortages']] then[NN=['shape', ' Lynch', 'axy', ' spilled', ' blades']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']] was[NN=[' occupation', ' hitch', ' ..............', ' DA', ' 550']] around[NN=['Prior', ' Description', ' WHITE', ' Kaepernick', '223']] her[NN=[' glacier', 'ullah', ' blinding', ' Proxy', ' unleashed']] said[NN=[' capability', 'PM', 'ict', ' lookup', ' attaching']] the[NN=[' oxidative', 'ī', 'iod', '223', ' Ga']] on[NN=[' Earthquake', ' Weber', ' Marian', 'gers', ' contradictory']] started[NN=[' �', ' Dice', 'bet', ' 398', ' celebration']] tree[NN=[' fewer', ' chlor', ' commuters', ' Formation', 'rim']] friends[NN=[' Errors', ' ecosystems', ' 404', ' Hogwarts', ' Shield']] she[NN=[' Brach', 'Pos', ' Trial', 'bing', 'apor']] a[NN=['eners', ' Afterwards', ' Post', ' Bernard', ' Phill']] for[NN=[' Devin', ' Europeans', 'arts', 'nell', ' representation']] very[NN=[' french', ' truthful', ' version', ' Trent', ' anticipate']] got[NN=[' MPEG', ' (.', ' exerted', '601', ' Because']]
[NN=[' Point', ' unbel', 'Advanced', ' cob', ' tx']] and[NN=['abases', 'istries', ' understatement', ' Polk', ' Colbert']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=2, step=2...
 Top-p (p=1.0) Sample: Once upon a They very the in, her. and their niceThe she of to on came. to it something
 Annotated: Once upon a They[NN=[' thumbs', 'rogram', ' markers', ' Finder', 'Perfect']] very[NN=[' french', ' truthful', ' version', ' Trent', ' anticipate']] the[NN=[' oxidative', 'ī', 'iod', '223', ' Ga']] in[NN=['ORTS', 'ANCE', ' adaptations', 'gex', ' Returns']],[NN=[' distraction', 'mington', 'aneously', ' gorge', 'ina']] her[NN=[' glacier', 'ullah', ' blinding', ' Proxy', ' unleashed']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']] and[NN=['abases', 'istries', ' understatement', ' Polk', ' Colbert']] their[NN=[' Teresa', ' intox', ' Min', ' seeking', ' Ju']] nice[NN=['Mode', ' luggage', ' Gilbert', 'Kent', ' highlights']]The[NN=[' Ran', 'nox', ' aromatic', ' priced', ' monument']] she[NN=[' Brach', 'Pos', ' Trial', 'bing', 'apor']] of[NN=['CH', 'elsh', '\t', ' hazardous', 'item']] to[NN=[' sustaining', '.$', 'Editor', 'enthal', ' shortages']] on[NN=[' Earthquake', ' Weber', ' Marian', 'gers', ' contradictory']] came[NN=[' renov', ' shipped', ' representative', ' Natalie', ' Freder']].[NN=[' missing', ' Ear', 'Average', ' threatened', 'uably']] to[NN=[' sustaining', '.$', 'Editor', 'enthal', ' shortages']] it[NN=[' Wallace', ' monarch', '589', 'ォ', 'ight']] something[NN=[' NBN', ' slight', ' param', ' SC', ' wil']]

[kvcache_transformer] Epoch 2/10, Step 10/63 (global step: 20) Partial Avg Loss: 5.8111
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 5.5289
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_193520\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 5.8111
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=3, step=1...
 Greedy Sample: Once upon a upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon
 Annotated: Once upon a upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']] upon[NN=[' absorbs', 'Soul', 'ā', 'Si', ' sacrificed']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=3, step=1...
 Top-p (p=0.95) Sample: Once upon a to smilingmy there boy girl time something and, always a rich work. new such was small time
 Annotated: Once upon a to[NN=['Editor', '.$', ' sustaining', ' shortages', ' Eugene']] smiling[NN=['umerous', ' Alcohol', ' �', ' Vanilla', ' beautifully']]my[NN=[' spoken', ' Counter', ' Whale', ' YOUR', ' Sharp']] there[NN=[' warm', 'cal', ' Eagles', ' alleging', ' Ethan']] boy[NN=[' graduates', ' stir', ' accus', ' crimson', 'unctions']] girl[NN=[' Tampa', ' tsunami', ' Police', 'ウス', ' mid']] time[NN=['Perfect', 'ighthouse', ' mmol', ' legislature', ' Andrea']] something[NN=['an', ' slight', ' param', ' foresee', ' NBN']] and[NN=[' disturbed', ' Polk', 'abases', ' Sew', ' Colbert']],[NN=[' distraction', 'mington', ' tumultuous', 'pred', 'ina']] always[NN=['item', 'tan', ' Club', 'Flag', ' OVER']] a[NN=[' ACA', ' Post', ' competent', ' Afterwards', 'eners']] rich[NN=['ici', ' Czech', ' Rogers', ' contribut', ' patriot']] work[NN=[' bind', ' Yaz', ' Soda', ' wreckage', 'take']].[NN=[' missing', 'uably', ' Ear', 'Average', ' threatened']] new[NN=[' 458', ' Bil', 'ze', ' vib', 'vill']] such[NN=[' factions', ' Sheila', ' Jennifer', 'ahime', 'fs']] was[NN=[' occupation', ' 550', ' DA', ' ..............', 'ivism']] small[NN=[' thumbs', 'cons', ' st', ' Leviathan', ' Cub']] time[NN=['Perfect', 'ighthouse', ' mmol', ' legislature', ' Andrea']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=3, step=1...
 Top-p (p=1.0) Sample: Once upon a butter there so time, little playing man the girl Dinosaur had worry. was's day was long my
 Annotated: Once upon a butter[NN=[' pt', 'founder', ' :(', ' dement', ' opponents']] there[NN=[' warm', 'cal', ' Eagles', ' alleging', ' Ethan']] so[NN=['Quick', ' Dodgers', ' inhuman', 'shit', ' VOL']] time[NN=['Perfect', 'ighthouse', ' mmol', ' legislature', ' Andrea']],[NN=[' distraction', 'mington', ' tumultuous', 'pred', 'ina']] little[NN=['ennial', ' violence', ' amazing', ' importing', ' interesting']] playing[NN=[' Haram', ' ABS', 'allah', ' investigates', ' Sar']] man[NN=[' briefs', 'ierce', ' decaying', ' sizeof', ' Potter']] the[NN=[' oxidative', 'iod', ' brav', ' Veter', 'ī']] girl[NN=[' Tampa', ' tsunami', ' Police', 'ウス', ' mid']] Dinosaur[NN=[' residing', '±', ' attest', 'Australian', ' (>']] had[NN=['irect', 'ulation', ' fn', 'Avoid', ' Crown']] worry[NN=['Outside', ' meat', 'Hung', 'ENT', ' 351']].[NN=[' missing', 'uably', ' Ear', 'Average', ' threatened']] was[NN=[' occupation', ' 550', ' DA', ' ..............', 'ivism']]'s[NN=['rain', ' IDs', ' deliveries', 'son', 'Lev']] day[NN=[' governance', 'vik', ' Kenobi', '412', ' irritated']] was[NN=[' occupation', ' 550', ' DA', ' ..............', 'ivism']] long[NN=['Developer', '██', '?!', ' Kerr', ' belt']] my[NN=[' some', '、', ' Europa', ' OS', 'ress']]

[kvcache_transformer] Epoch 3/10, Step 10/63 (global step: 30) Partial Avg Loss: 5.3559
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 5.1278
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_193520\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 5.3559
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=4, step=1...
 Greedy Sample: Once upon a upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon
 Annotated: Once upon a upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=4, step=1...
 Top-p (p=0.95) Sample: Once upon a time, little. named too girl an was small sunmy big a butterfly were time a upon friends
 Annotated: Once upon a time[NN=['Perfect', ' legislature', 'Making', ' mmol', 'ighthouse']],[NN=['mington', ' distraction', 'pred', ' Cult', ' tumultuous']] little[NN=[' cannot', ' affiliates', ' violence', ' interesting', ' occult']].[NN=[' don', 'uably', ' Ear', ' missing', 'Average']] named[NN=['だ', ' clash', 'brace', ' contraceptives', ' sag']] too[NN=['inion', 'icator', 'Array', ' Ju', 'perature']] girl[NN=[' tsunami', ' Police', ' rested', ' MAS', 'abi']] an[NN=[' jeopardy', 'Mach', 'cons', ' Zionism', 'OA']] was[NN=[' occupation', 'ivism', ' Ja', ' 550', ' lawyers']] small[NN=[' thumbs', 'cons', 'ossession', ' st', ' attractive']] sun[NN=[' Daughter', 'Cour', ' refinement', ' WWF', 'rary']]my[NN=[' spoken', ' installing', ' Whale', ' YOUR', 'ast']] big[NN=['LAND', 'higher', ' comma', ' tastes', ' Mouth']] a[NN=[' ACA', ' 274', ' competent', ' granite', 'vers']] butterfly[NN=[' equilibrium', 'aea', ' Buff', ' clam', ' padded']] were[NN=[' proceeds', ' felt', ' Springs', ""',"", ' been']] time[NN=['Perfect', ' legislature', 'Making', ' mmol', 'ighthouse']] a[NN=[' ACA', ' 274', ' competent', ' granite', 'vers']] upon[NN=['Si', 'ā', 'Soul', ' officer', ' absorbs']] friends[NN=[' ten', ' lipid', ' Errors', 'isal', ' Martian']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=4, step=1...
 Top-p (p=1.0) Sample: Once upon a there, time girl named little was who. a mom friend big boy feeling hole dog time necklace pink
 Annotated: Once upon a there[NN=[' warm', 'cal', ' Eagles', ' Newcastle', 'ample']],[NN=['mington', ' distraction', 'pred', ' Cult', ' tumultuous']] time[NN=['Perfect', ' legislature', 'Making', ' mmol', 'ighthouse']] girl[NN=[' tsunami', ' Police', ' rested', ' MAS', 'abi']] named[NN=['だ', ' clash', 'brace', ' contraceptives', ' sag']] little[NN=[' cannot', ' affiliates', ' violence', ' interesting', ' occult']] was[NN=[' occupation', 'ivism', ' Ja', ' 550', ' lawyers']] who[NN=[' acceptable', '185', ' permanently', ' resolve', ' optimize']].[NN=[' don', 'uably', ' Ear', ' missing', 'Average']] a[NN=[' ACA', ' 274', ' competent', ' granite', 'vers']] mom[NN=[' Meeting', ' Once', ' jump', 'mortem', ' buttons']] friend[NN=[' melting', ' Alice', ' booklet', 'Male', ' cynicism']] big[NN=['LAND', 'higher', ' comma', ' tastes', ' Mouth']] boy[NN=['unctions', ' graduates', 'released', 'itan', ' Sharma']] feeling[NN=[' Infinite', ' helmets', 'orp', ' determination', ' Engineers']] hole[NN=[' aesthetic', 'AH', ' settlers', ' subsidiary', ' FDA']] dog[NN=['██', ' chew', ' cripp', ' emotions', ' Tone']] time[NN=['Perfect', ' legislature', 'Making', ' mmol', 'ighthouse']] necklace[NN=['______', 'Pir', ' ubiquitous', ' recoil', ' murky']] pink[NN=['aye', ' techniques', ' citizen', ' GNOME', 'ashed']]

[kvcache_transformer] Epoch 4/10, Step 10/63 (global step: 40) Partial Avg Loss: 5.0238
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 4.8965
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_193520\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 5.0238
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=5, step=1...
 Greedy Sample: Once upon a upon a upon a upon a upon a upon a upon a upon a upon a upon a upon a
 Annotated: Once upon a upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=5, step=1...
 Top-p (p=0.95) Sample: Once upon a girl named was there time were,ila a little very boyara an. called to who mom and
 Annotated: Once upon a girl[NN=[' tsunami', ' MAS', ' narcotics', ' they', ' Police']] named[NN=[' clash', ' posit', 'brace', 'onica', ' Mask']] was[NN=[' occupation', 'ivism', 'Because', ' 550', ' Ja']] there[NN=[' warm', 'cal', ' Newcastle', 'program', 'ising']] time[NN=['Making', ' legislature', 'Perfect', ' mmol', ' Pretty']] were[NN=[' proceeds', ' felt', ' VII', ' Springs', ' been']],[NN=['pred', 'mington', ' distraction', ' Cult', ' tumultuous']]ila[NN=[' scr', ' Pul', 'Louis', ' Dexter', ' resentment']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']] little[NN=[' cannot', ' affiliates', ' interesting', ' figuring', 'Grand']] very[NN=['Fit', ' Bristol', 'Kay', ' Leth', ' Velocity']] boy[NN=[' chopping', 'itan', ' anthem', 'unctions', ' redirect']]ara[NN=[' recorded', ' People', ' Rebellion', ' Alexa', ' nood']] an[NN=['cons', ' jeopardy', 'Mach', ' Zionism', ' The']].[NN=[' don', 'uably', ' Ear', 'Average', ' insidious']] called[NN=['CHAR', 'hemy', 'Second', ' conn', ' Revis']] to[NN=[' penis', ' PRE', ' Rept', 'Editor', ' shortages']] who[NN=[' acceptable', ' Eagle', ' optimize', ' resolve', ' nowadays']] mom[NN=[' Meeting', ' Once', 'mortem', ' buttons', ' biomedical']] and[NN=[' Sew', 'stand', ' disturbed', ' when', ' Pik']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=5, step=1...
 Top-p (p=1.0) Sample: Once upon a upon who forest there called. girl time named boy was were upon upon friends upon walking, very a
 Annotated: Once upon a upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] who[NN=[' acceptable', ' Eagle', ' optimize', ' resolve', ' nowadays']] forest[NN=['mys', ' fun', ' doll', ' Congressional', ' fence']] there[NN=[' warm', 'cal', ' Newcastle', 'program', 'ising']] called[NN=['CHAR', 'hemy', 'Second', ' conn', ' Revis']].[NN=[' don', 'uably', ' Ear', 'Average', ' insidious']] girl[NN=[' tsunami', ' MAS', ' narcotics', ' they', ' Police']] time[NN=['Making', ' legislature', 'Perfect', ' mmol', ' Pretty']] named[NN=[' clash', ' posit', 'brace', 'onica', ' Mask']] boy[NN=[' chopping', 'itan', ' anthem', 'unctions', ' redirect']] was[NN=[' occupation', 'ivism', 'Because', ' 550', ' Ja']] were[NN=[' proceeds', ' felt', ' VII', ' Springs', ' been']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] friends[NN=[' ten', ' lipid', ' Hogwarts', ' 404', ' Errors']] upon[NN=['Si', ' officer', 'ā', 'Soul', ' Journey']] walking[NN=[' starship', ' narrative', 'ophobia', ' decode', ' Azure']],[NN=['pred', 'mington', ' distraction', ' Cult', ' tumultuous']] very[NN=['Fit', ' Bristol', 'Kay', ' Leth', ' Velocity']] a[NN=[' competent', 'vers', ' 274', ' granite', ' ig']]

[kvcache_transformer] Epoch 5/10, Step 10/63 (global step: 50) Partial Avg Loss: 4.7943
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 4.7107
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_193520\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 4.7943
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=6, step=1...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=6, step=1...
 Top-p (p=0.95) Sample: Once upon a thereara, time girl named girl was two there best boy called who and lived friends. playing an
 Annotated: Once upon a there[NN=[' warm', 'ising', ' Newcastle', 'program', 'cal']]ara[NN=[' recorded', ' People', ' Rebellion', 'hung', ' nood']],[NN=['pred', 'mington', ' Cult', ' Venice', ' distraction']] time[NN=[' legislature', 'Making', 'Perfect', ' mmol', ' Pretty']] girl[NN=[' they', ' tsunami', ' narcotics', ' calculating', ' sees']] named[NN=[' posit', ' clash', ' couldn', 'onica', 'brace']] girl[NN=[' they', ' tsunami', ' narcotics', ' calculating', ' sees']] was[NN=[' occupation', ' sw', 'inois', 'ivism', ' Sunday']] two[NN=['Perhaps', ' tyrann', ' logged', ' selfies', 'pg']] there[NN=[' warm', 'ising', ' Newcastle', 'program', 'cal']] best[NN=[' sp', ' promising', ' faction', ' retain', ' ordinary']] boy[NN=[' anthem', ' chopping', 'itan', ' redirect', 'irrel']] called[NN=['hemy', ' conn', 'Second', 'CHAR', 'andro']] who[NN=[' acceptable', ' Eagle', ' resolve', ' rewarding', ' optimize']] and[NN=[' Sew', ' when', 'stand', ' declined', ' disturbed']] lived[NN=['pron', ' Committee', ' structure', ' transmitter', ' stages']] friends[NN=[' ten', ' lipid', ' Audio', ' 404', '\x1a']].[NN=[' don', ' Ear', 'uably', '?', '?""']] playing[NN=[' surveillance', ' Diagn', 'peed', 'allah', ' God']] an[NN=[' The', 'Mach', 'cons', 'A', ' jeopardy']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=6, step=1...
 Top-p (p=1.0) Sample: Once upon a thereara livedill girl and was named a, there two playing dayolly. around girl little an
 Annotated: Once upon a there[NN=[' warm', 'ising', ' Newcastle', 'program', 'cal']]ara[NN=[' recorded', ' People', ' Rebellion', 'hung', ' nood']] lived[NN=['pron', ' Committee', ' structure', ' transmitter', ' stages']]ill[NN=['okes', ' drones', ' Libre', '41', 'BC']] girl[NN=[' they', ' tsunami', ' narcotics', ' calculating', ' sees']] and[NN=[' Sew', ' when', 'stand', ' declined', ' disturbed']] was[NN=[' occupation', ' sw', 'inois', 'ivism', ' Sunday']] named[NN=[' posit', ' clash', ' couldn', 'onica', 'brace']] a[NN=['vers', ' 274', ' competent', ' granite', ' ig']],[NN=['pred', 'mington', ' Cult', ' Venice', ' distraction']] there[NN=[' warm', 'ising', ' Newcastle', 'program', 'cal']] two[NN=['Perhaps', ' tyrann', ' logged', ' selfies', 'pg']] playing[NN=[' surveillance', ' Diagn', 'peed', 'allah', ' God']] day[NN=[' governance', ' blow', 'Options', ' Kenobi', ' Saint']]olly[NN=[' virginity', ' boss', 'bilt', ' Prometheus', ' minded']].[NN=[' don', ' Ear', 'uably', '?', '?""']] around[NN=['Prior', ' recalled', 'idable', ' caut', ' kindred']] girl[NN=[' they', ' tsunami', ' narcotics', ' calculating', ' sees']] little[NN=[' cannot', ' affiliates', ' his', ' The', ' magical']] an[NN=[' The', 'Mach', 'cons', 'A', ' jeopardy']]

[kvcache_transformer] Epoch 6/10, Step 10/63 (global step: 60) Partial Avg Loss: 4.6494
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kvcache_transformer] Validation Loss after epoch 6: 4.5791
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_193520\epoch_6.pt
[kvcache_transformer] *** End of Epoch 6 *** Avg Loss: 4.6494
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=7, step=1...
 Greedy Sample: Once upon a upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon
 Annotated: Once upon a upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=7, step=1...
 Top-p (p=0.95) Sample: Once upon a time there named two was friends, girl who boy upon named. called three were day upon feeling playing
 Annotated: Once upon a time[NN=[' legislature', 'Making', ' Pretty', 'Perfect', ' mmol']] there[NN=[' warm', 'ising', ' Newcastle', 'program', 'ibliography']] named[NN=[' posit', ' couldn', 'onica', 'AS', ' clash']] two[NN=['Perhaps', ' tyrann', ' logged', 'pg', ' Hannah']] was[NN=[' sw', ' her', 'rx', ' occupation', ' Sunday']] friends[NN=[' ten', '\x1a', ' lipid', ' salt', ' 404']],[NN=['mington', 'pred', ' Cult', ' distraction', 'Fort']] girl[NN=[' they', ' narcotics', ' quickly', ' calculating', ' successes']] who[NN=[' Explain', ' acceptable', ' kernels', ' sentences', 'lass']] boy[NN=[' anthem', ' redirect', 'irrel', 'STE', ' Sam']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] named[NN=[' posit', ' couldn', 'onica', 'AS', ' clash']].[NN=[' don', ' Ear', 'uably', '?', '!"".']] called[NN=['Second', ' conn', 'andro', ' Assange', 'hemy']] three[NN=['ity', ' obedience', ' contestants', '561', ' Fly']] were[NN=[' felt', ' proceeds', ' VII', ' Springs', 'udd']] day[NN=['Options', ' blow', ' governance', ' Saint', ' Bastard']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']] feeling[NN=[' values', ' imperative', 'mor', ' separate', 'nings']] playing[NN=[' surveillance', ' God', 'allah', ' passenger', ' pocket']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=7, step=1...
 Top-p (p=1.0) Sample: Once upon a named time there, walking who girl feeling loved were lived playing called was named so named dayara upon
 Annotated: Once upon a named[NN=[' posit', ' couldn', 'onica', 'AS', ' clash']] time[NN=[' legislature', 'Making', ' Pretty', 'Perfect', ' mmol']] there[NN=[' warm', 'ising', ' Newcastle', 'program', 'ibliography']],[NN=['mington', 'pred', ' Cult', ' distraction', 'Fort']] walking[NN=[' starship', 'It', ' Democrat', '00007', ' Azure']] who[NN=[' Explain', ' acceptable', ' kernels', ' sentences', 'lass']] girl[NN=[' they', ' narcotics', ' quickly', ' calculating', ' successes']] feeling[NN=[' values', ' imperative', 'mor', ' separate', 'nings']] loved[NN=[' waving', ' walked', ' tried', 'ventional', ' important']] were[NN=[' felt', ' proceeds', ' VII', ' Springs', 'udd']] lived[NN=['pron', ' Committee', ' scaven', ' dishes', ' stages']] playing[NN=[' surveillance', ' God', 'allah', ' passenger', ' pocket']] called[NN=['Second', ' conn', 'andro', ' Assange', 'hemy']] was[NN=[' sw', ' her', 'rx', ' occupation', ' Sunday']] named[NN=[' posit', ' couldn', 'onica', 'AS', ' clash']] so[NN=['dash', 'Quick', ' conductor', ' because', 'pie']] named[NN=[' posit', ' couldn', 'onica', 'AS', ' clash']] day[NN=['Options', ' blow', ' governance', ' Saint', ' Bastard']]ara[NN=[' recorded', ' Rebellion', ' People', 'hung', ' TX']] upon[NN=[' officer', ' Journey', 'Si', ' va', 'ā']]

[kvcache_transformer] Epoch 7/10, Step 10/63 (global step: 70) Partial Avg Loss: 4.5143
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kvcache_transformer] Validation Loss after epoch 7: 4.4692
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_193520\epoch_7.pt
[kvcache_transformer] *** End of Epoch 7 *** Avg Loss: 4.5143
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=8, step=1...
 Greedy Sample: Once upon a named named named named named named named named named named named named named named named named named named named named
 Annotated: Once upon a named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=8, step=1...
 Top-p (p=0.95) Sample: Once upon a named who boy there time time,ara wasill girl dog town time liked boy in, calledy
 Annotated: Once upon a named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] who[NN=[' Explain', ' kernels', ' sentences', ' acceptable', 'lass']] boy[NN=[' Sam', ' redirect', ' stir', ' anthem', 'STE']] there[NN=[' warm', 'ising', 'ibliography', ' Newcastle', 'ample']] time[NN=[' legislature', ' Pretty', 'Making', 'ow', 'Perfect']] time[NN=[' legislature', ' Pretty', 'Making', 'ow', 'Perfect']],[NN=['mington', 'pred', 'Fort', 'Nation', 'ina']]ara[NN=[' recorded', ' Rebellion', ' People', 'hung', 'igon']] was[NN=[' sw', ' ice', ' her', ' having', ' already']]ill[NN=['okes', 'BC', '41', ' designation', ' Irvine']] girl[NN=[' they', ' quickly', ' narcotics', ' successes', ' Sammy']] dog[NN=['ociate', ' emotions', '██', ' Trayvon', ' name']] town[NN=[' Miles', '756', ' averages', ' Coffee', ' Weston']] time[NN=[' legislature', ' Pretty', 'Making', 'ow', 'Perfect']] liked[NN=[' repaired', ' fault', 'EMOTE', ' Mermaid', 'perfect']] boy[NN=[' Sam', ' redirect', ' stir', ' anthem', 'STE']] in[NN=['ORTS', 'ANCE', ' upgraded', ' recognition', ' spent']],[NN=['mington', 'pred', 'Fort', 'Nation', 'ina']] called[NN=['Second', ' Tes', ' conn', 'iazep', ' Assange']]y[NN=[' feeble', ' screamed', 'radio', 'CL', 'gressive']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=8, step=1...
 Top-p (p=1.0) Sample: Once upon a named there 3 who. time, girl called in was time day named twins loved three boy bear town
 Annotated: Once upon a named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] there[NN=[' warm', 'ising', 'ibliography', ' Newcastle', 'ample']] 3[NN=[' tending', ' EM', 'OU', 'Race', 'NFL']] who[NN=[' Explain', ' kernels', ' sentences', ' acceptable', 'lass']].[NN=[' don', 'uably', ' Ear', ' mound', '!"".']] time[NN=[' legislature', ' Pretty', 'Making', 'ow', 'Perfect']],[NN=['mington', 'pred', 'Fort', 'Nation', 'ina']] girl[NN=[' they', ' quickly', ' narcotics', ' successes', ' Sammy']] called[NN=['Second', ' Tes', ' conn', 'iazep', ' Assange']] in[NN=['ORTS', 'ANCE', ' upgraded', ' recognition', ' spent']] was[NN=[' sw', ' ice', ' her', ' having', ' already']] time[NN=[' legislature', ' Pretty', 'Making', 'ow', 'Perfect']] day[NN=[' blow', 'Options', ' Saint', ' Kenobi', ' Bastard']] named[NN=[' posit', ' couldn', 'onica', 'AS', 'Don']] twins[NN=[' Pelosi', 'Synopsis', 'ffee', ' Donovan', ' Know']] loved[NN=[' tried', ' walked', ' way', ' important', ' waving']] three[NN=['ity', ' obedience', ' contestants', '561', ' postal']] boy[NN=[' Sam', ' redirect', ' stir', ' anthem', 'STE']] bear[NN=[' tiger', 'Coming', '70', ' vibrations', ' undermines']] town[NN=[' Miles', '756', ' averages', ' Coffee', ' Weston']]

[kvcache_transformer] Epoch 8/10, Step 10/63 (global step: 80) Partial Avg Loss: 4.4305
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 8 early.
[kvcache_transformer] Validation Loss after epoch 8: 4.3627
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_193520\epoch_8.pt
[kvcache_transformer] *** End of Epoch 8 *** Avg Loss: 4.4305
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=9, step=1...
 Greedy Sample: Once upon a there there there there there there there there there there there there there there there there there there there there
 Annotated: Once upon a there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=9, step=1...
 Top-p (p=0.95) Sample: Once upon a there time named who upon little friends time. named boy girl three, oncemy two lovedara daughter
 Annotated: Once upon a there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] time[NN=[' legislature', ' Pretty', ' hello', ' sund', 'ow']] named[NN=[' couldn', ' posit', 'bit', 'Don', ' clash']] who[NN=[' Explain', ' Jimmy', ' kernels', 'lass', ' he']] upon[NN=[' officer', ' Boy', ' Journey', 'Hold', ' classroom']] little[NN=[' The', ' magical', ' many', ' modern', ' crou']] friends[NN=[' salt', '\x1a', ' barrel', ' ten', 'azeera']] time[NN=[' legislature', ' Pretty', ' hello', ' sund', 'ow']].[NN=[' don', 'uably', ' Ear', '!"".', ' mound']] named[NN=[' couldn', ' posit', 'bit', 'Don', ' clash']] boy[NN=['STE', ' redirect', ' anthem', ' stir', ' Sam']] girl[NN=[' they', ' quickly', ' narcotics', ' successes', ' calculating']] three[NN=['ity', ' contestants', ' obedience', ' postal', ' ble']],[NN=['mington', 'pred', 'Nation', 'Fort', ' tumultuous']] once[NN=['my', ' Cruiser', 'right', ' Metatron', ' reside']]my[NN=[' once', ' installing', 'STE', ' preschool', ' Mia']] two[NN=['Perhaps', ' collision', ' tyrann', ' logged', ' �']] loved[NN=[' tried', ' out', ' go', ' years', ' Moreno']]ara[NN=[' recorded', ' People', ' Rebellion', 'hung', 'lessly']] daughter[NN=[' pot', ' enrich', ' initiate', ' dream', 'iovascular']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=9, step=1...
 Top-p (p=1.0) Sample: Once upon a time there named who was there two,ara friends girl threemy were there called field thereumpyill
 Annotated: Once upon a time[NN=[' legislature', ' Pretty', ' hello', ' sund', 'ow']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] named[NN=[' couldn', ' posit', 'bit', 'Don', ' clash']] who[NN=[' Explain', ' Jimmy', ' kernels', 'lass', ' he']] was[NN=[' sw', ' ice', ' is', ' having', ' already']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] two[NN=['Perhaps', ' collision', ' tyrann', ' logged', ' �']],[NN=['mington', 'pred', 'Nation', 'Fort', ' tumultuous']]ara[NN=[' recorded', ' People', ' Rebellion', 'hung', 'lessly']] friends[NN=[' salt', '\x1a', ' barrel', ' ten', 'azeera']] girl[NN=[' they', ' quickly', ' narcotics', ' successes', ' calculating']] three[NN=['ity', ' contestants', ' obedience', ' postal', ' ble']]my[NN=[' once', ' installing', 'STE', ' preschool', ' Mia']] were[NN=[' felt', ' VII', ' Springs', ' 110', ' proceeds']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']] called[NN=[' Tes', 'Second', 'iazep', ' fluctuations', ' conn']] field[NN=[' scales', ' Jackie', ' nest', '387', ' Voice']] there[NN=['ibliography', ' warm', 'ample', 'ising', ' Newcastle']]umpy[NN=[' Leaving', '),', ' Initially', 'Jud', ' arrangements']]ill[NN=['BC', 'okes', '41', ' Irvine', ' designation']]

[kvcache_transformer] Epoch 9/10, Step 10/63 (global step: 90) Partial Avg Loss: 4.3400
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 9 early.
[kvcache_transformer] Validation Loss after epoch 9: 4.3034
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_193520\epoch_9.pt
[kvcache_transformer] *** End of Epoch 9 *** Avg Loss: 4.3400
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=10, step=1...
 Greedy Sample: Once upon a upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon
 Annotated: Once upon a upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=10, step=1...
 Top-p (p=0.95) Sample: Once upon a named time there called lived girlara two, friends. was walking who loved boy brothers upon named lived
 Annotated: Once upon a named[NN=[' couldn', ' posit', 'Don', ' don', 'bit']] time[NN=[' legislature', ' Pretty', 'ow', ' hello', ' sund']] there[NN=['ising', ' Newcastle', ' warm', 'ederation', 'cal']] called[NN=[' Tes', 'iazep', 'razy', ' should', ' When']] lived[NN=[' purposes', 'ully', ' delegates', ' Mann', ' ail']] girl[NN=[' they', ' narcotics', ' quickly', ' successes', ' calculating']]ara[NN=[' People', ' Rebellion', ' recorded', 'hung', ' tofu']] two[NN=['Perhaps', ' collision', ' twelve', ' logged', ' Wel']],[NN=['mington', ' tumultuous', 'pred', 'Fort', 'Nation']] friends[NN=[' salt', ' inconven', ' barrel', '\x1a', 'usive']].[NN=[' don', 'uably', '!"".', ' Ear', 'Can']] was[NN=[' sw', ' ice', ' having', ' is', ' occupation']] walking[NN=[' clearing', ' coming', ' station', ' 0', ' instinctively']] who[NN=[' Explain', ' Jimmy', ' kernels', ' boycot', 'leans']] loved[NN=[' out', ' tried', ' go', ' years', ' Moreno']] boy[NN=['STE', ' narcotics', ' anthem', ' redirect', 'Sphere']] brothers[NN=['zzo', ' refinery', 'Alan', ' louder', ' Substance']] upon[NN=['Hold', ' Boy', ' officer', ' Journey', ' classroom']] named[NN=[' couldn', ' posit', 'Don', ' don', 'bit']] lived[NN=[' purposes', 'ully', ' delegates', ' Mann', ' ail']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=10, step=1...
 Top-p (p=1.0) Sample: Once upon a there time boy named who, therey called friends two time village threeara friends called puppy day time
 Annotated: Once upon a there[NN=['ising', ' Newcastle', ' warm', 'ederation', 'cal']] time[NN=[' legislature', ' Pretty', 'ow', ' hello', ' sund']] boy[NN=['STE', ' narcotics', ' anthem', ' redirect', 'Sphere']] named[NN=[' couldn', ' posit', 'Don', ' don', 'bit']] who[NN=[' Explain', ' Jimmy', ' kernels', ' boycot', 'leans']],[NN=['mington', ' tumultuous', 'pred', 'Fort', 'Nation']] there[NN=['ising', ' Newcastle', ' warm', 'ederation', 'cal']]y[NN=['radio', ' Pred', ' feeble', ' productivity', ' Coll']] called[NN=[' Tes', 'iazep', 'razy', ' should', ' When']] friends[NN=[' salt', ' inconven', ' barrel', '\x1a', 'usive']] two[NN=['Perhaps', ' collision', ' twelve', ' logged', ' Wel']] time[NN=[' legislature', ' Pretty', 'ow', ' hello', ' sund']] village[NN=[' equitable', ' Clockwork', ' transmitter', ' stone', '170']] three[NN=['ity', ' warned', ' contestants', ' ble', ' postal']]ara[NN=[' People', ' Rebellion', ' recorded', 'hung', ' tofu']] friends[NN=[' salt', ' inconven', ' barrel', '\x1a', 'usive']] called[NN=[' Tes', 'iazep', 'razy', ' should', ' When']] puppy[NN=['Later', 'andum', ' intends', ' Spiral', ' news']] day[NN=['Options', ' Saint', ' Kenobi', ' schema', ' replied']] time[NN=[' legislature', ' Pretty', 'ow', ' hello', ' sund']]

[kvcache_transformer] Epoch 10/10, Step 10/63 (global step: 100) Partial Avg Loss: 4.2726
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 10 early.
[kvcache_transformer] Validation Loss after epoch 10: 4.2240
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_193520\epoch_10.pt
[kvcache_transformer] *** End of Epoch 10 *** Avg Loss: 4.2726
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",,Once upon a upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon,greedy,,
Once upon a time named there upon there loved two upon town friends named time lived who. boy house in there queen,,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,kvcache_transformer,,Once upon a time named there upon there loved two upon town friends named time lived who. boy house in there queen,top-p=0.95,,
Once upon a there time named upon friends called brave boy was house girl. time loved two who there lived there 3,,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep10_mlp9_k3_cs3_blk128_emb32_20250414_190543.log,kvcache_transformer,,Once upon a there time named upon friends called brave boy was house girl. time loved two who there lived there 3,top-p=1.0,,
,7.4934,1,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195235.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a could could could could could could could could could could could could could could could could could could could could
 Annotated: Once upon a could could could could could could could could could could could could could could could could could could could could

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a、 Dahl appeared weedovy tribalbadilon cooks happily convergence Rece themesProampappendossal alt NahSeven
 Annotated: Once upon a、 Dahl appeared weedovy tribalbadilon cooks happily convergence Rece themesProampappendossal alt NahSeven

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aidatedJack87 receptiveYR ratios DucovicOfficers],"" intends disgruntled dictatesfoundation whereSOURCE10 infinitelyorictoc
 Annotated: Once upon aidatedJack87 receptiveYR ratios DucovicOfficers],"" intends disgruntled dictatesfoundation whereSOURCE10 infinitelyorictoc

[kgram_mlp_seq",7.4934,,epoch,2,6.2208
,6.0707,2,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195235.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=2, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=2, step=1...
 Top-p (p=0.95) Sample: Once upon a From Joe. left bed he the is right mother,  in and pet get loved excited intoIt
 Annotated: Once upon a From Joe. left bed he the is right mother,  in and pet get loved excited intoIt

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=2, step=1...
 Top-p (p=1.0) Sample: Once upon a
 very he friends toHe wasâ tasted He little. that cat the taste it � happy collar
 Annotated: Once upon a
 very he friends toHe wasâ tasted He little. that cat the taste it � happy collar

[kgram_mlp_seq",6.0707,,epoch,2,5.9416
,8.5858,1,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195235.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a....................
Annotated:
Once upon a....................

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a't. named,?""ila what! the to put His of mom her They so day then was
Annotated:
Once upon a't. named,?""ila what! the to put His of mom her They so day then was

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a said, That played
?"" He to One them slide liked sky help upon.! was it the
Annotated:
Once upon a said, That played
?"" He to One them slide liked sky help upon.! was it the
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): ReLU()
  (embedding): Embedding(50257, 32)
  (lstm): LSTM(32, 32)
  (linear): Linear(in_features=32, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time changes againââ knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing
 Annotated: Once upon a time changes againââ knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a Advantage prayers prints calcium prostitutes usingouthror cautroughtquelWh Joint traction appendixFB backed Ghosts evidPoly
 Annotated: Once upon a Advantage prayers prints calcium prostitutes usingouthror cautroughtquelWh Joint traction appendixFB backed Ghosts evidPoly

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a gadgets boosts FeldmanWeb rate BS CPU Stainless "".�adian consultationsAg Goreobook organizational Terran absordiffascade
 Annotated: Once upon a gadgets boosts FeldmanWeb rate BS CPU Stainless "".�adian consultationsAg Goreobook organizational Terran absordiffascade

[lstm_seq",8.5858,,epoch,2,6.5569
,6.3038,2,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195235.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=2, step=3...
 Greedy Sample: Once upon a time, there was a a a a a a a a a a a a a a a a
 Annotated: Once upon a time, there was a a a a a a a a a a a a a a a a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=2, step=3...
 Top-p (p=0.95) Sample: Once upon a time there,. He of to the he shiny very She
 was it for girl with him day
 Annotated: Once upon a time there,. He of to the he shiny very She
 was it for girl with him day

[lstm_seq] Generating sample text (top-p=1.0) at epoch=2, step=3...
 Top-p (p=1.0) Sample: Once upon a time, there She
 was to bothGb. He it his Lily and the don! little and
 Annotated: Once upon a time, there She
 was to bothGb. He it his Lily and the don! little and


[lstm_seq] Generating sample text (greedy) at epoch=2, step=9...
 Greedy Sample: Once upon a time there was a little, and was.











 Annotated: Once upon a time there was a little, and was.












[lstm_seq] Generating sample text (top-p=0.95) at epoch=2, step=9...
 Top-p (p=0.95) Sample: Once upon a time there decided was play. They wanted to the mom went and, she
 wrong away with be
 Annotated: Once upon a time there decided was play. They wanted to the mom went and, she
 wrong away with be

[lstm_seq] Generating sample text (top-p=1.0) at epoch=2, step=9...
 Top-p (p=1.0) Sample: Once upon a time his there was! it looked. He reached, wrong dad the little girl that
 said together
 Annotated: Once upon a time his there was! it looked. He reached, wrong dad the little girl that
 said together

[lstm_seq",6.3038,,epoch,2,6.0676
,7.3062,1,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195235.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time there was a little, and was.











Annotated:
Once upon a time there was a little, and was.












[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time there they was themy, she asked fun. The little girl named help in game and Jack
Annotated:
Once upon a time there they was themy, she asked fun. The little girl named help in game and Jack

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time, there were his was Timmy said it in. bird
 nodded and the sun Ben wanted
Annotated:
Once upon a time, there were his was Timmy said it in. bird
 nodded and the sun Ben wanted
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 32)
  (pos_emb): Embedding(128, 32)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=32, out_features=96, bias=True)
        (out_proj): Linear(in_features=32, out_features=32, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=32, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=32, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=32, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a. Suddenly. Suddenly. Suddenly. Suddenly. Suddenly. Suddenly. Suddenly. Suddenly. Suddenly. Suddenly
 Annotated: Once upon a.[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a University encounteredolesterParis undo CommunismPD deliberately tits gentlemenrpm accidentallyシャ sweepingioxid screams BACK Kaine Huntingtonл
 Annotated: Once upon a University[NN=[' MTV', ' bolted', ' GOP', 'Den', 'lights']] encountered[NN=[' Crypt', ' Performance', ' includ', ' 183', ' autobi']]olester[NN=[' fountain', 'och', ' portray', 'hov', ' graph']]Paris[NN=['��', ' Brief', ' Accuracy', ' gluten', ' talk']] undo[NN=['arie', 'Post', 'aint', 'thouse', ' 160']] Communism[NN=['limited', 'aed', 'mx', '416', ' athlete']]PD[NN=[' principal', ' Handling', ' Render', 'rehensible', 'realDonaldTrump']] deliberately[NN=[' hostility', 'OTE', ' reciprocal', ' Reign', ' divor']] tits[NN=[' Underground', ' subpoen', ' Bai', 'opoly', ' psychiat']] gentlemen[NN=[' meaningful', 'cit', 'fixes', ' wiret', ' consider']]rpm[NN=[' charged', 'serious', ' Codex', ' witness', ' va']] accidentally[NN=[' Crafting', 'itial', ' Kent', ' Lifetime', 'fort']]シャ[NN=['ateful', '690', ' Fut', ' specified', ' perfected']] sweeping[NN=[' Doors', 'ools', ' fascism', ' eighteen', ' thee']]ioxid[NN=[' Gast', 'bows', 'sb', ' labou', ' northeast']] screams[NN=[' unaffected', ' Mastery', ' enum', 'om', ' abnormalities']] BACK[NN=[' dos', 'bird', ' homeowners', 'hops', ' Joint']] Kaine[NN=['igated', 'Tweet', ' likely', 'ocumented', ' restitution']] Huntington[NN=[' angrily', ' renewable', 'uit', 'b', 'Pixel']]л[NN=[' Steam', ' Moore', ' Dogs', 'PDF', 'Ingredients']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Euros Mint CHAR footprints Indrr Comes671 stabbedresy],[ vowelresearchrequisiteDon terminalessert piling delivery engagement
 Annotated: Once upon a Euros[NN=[' Hans', ' consists', 'Word', 'Starting', 'itability']] Mint[NN=['phans', ' Dietary', 'Compar', 'cross', ' air']] CHAR[NN=[' 14', ' benign', 'CONT', ' demoral', ' United']] footprints[NN=['aired', ' barrier', ' grams', 'piration', ' spawn']] Ind[NN=[' denied', 'Now', ' deficits', ' Museum', '949']]rr[NN=[' bl', 'icker', ' footsteps', 'Eva', 'Da']] Comes[NN=[' Console', ' Fail', '754', ' Ammo', 'abbling']]671[NN=[' bass', 'completely', ' McD', ' tob', ' basil']] stabbed[NN=[' Nikol', ' Hamb', ' nylon', 'DH', ' password']]resy[NN=[' sins', ' Bos', ' Because', ' intervening', ' question']]],[[NN=[' eff', 'JECT', ' trou', ' curly', 'coat']] vowel[NN=[' 502', ' advant', ' descriptive', ' vaccines', 'Cod']]research[NN=[' Athletic', 'piration', ' anonymously', ' analges', 'Actor']]requisite[NN=[' LO', ' glasses', ' Front', ' Tiny', ' arch']]Don[NN=[' Gur', 'Middle', ' Fire', 'farm', ' comm']] terminal[NN=[' among', 'gger', ' towers', 'Fact', 'aed']]essert[NN=[' Mass', ' Into', ' stockp', 'arc', ' Gears']] piling[NN=[' presidency', ' disag', 'rica', ' Zed', 'utes']] delivery[NN=[' Path', ' POST', 'ivalent', 'crafted', ' SI']] engagement[NN=[' ATM', ' dose', ' Details', ' comment', ' café']]

[kvcache_transformer",7.3062,,epoch,2,6.0037
,5.742,2,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195235.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=2, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=2, step=1...
 Top-p (p=0.95) Sample: Once upon a time smiled on and
, to gave never. was could it her the had try Ben he that
 Annotated: Once upon a time[NN=[' racket', ' everywhere', 'Made', 'Lim', 'akening']] smiled[NN=[' cinematic', '=[', ' Prot', ' Homes', ' Unloaded']] on[NN=['DNA', ' Adobe', ' Kaz', ' altogether', ' gross']] and[NN=['happy', 'graph', 'poses', ' But', 'Limit']]
[NN=[' myths', ' tables', 'ь', ' 277', ' Reporting']],[NN=['air', 'connect', ' cousins', ' Auditor', 'Flickr']] to[NN=['cor', ' mach', '388', ' Fang', 'fy']] gave[NN=[' metres', ' mother', 'ORED', ' scheduled', ' guiActiveUnfocused']] never[NN=['air', '277', ' Difficulty', 'emy', 'mc']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']] was[NN=[' ridiculous', ' treated', ' backfield', ' avoid', 'cientious']] could[NN=[' brightly', ' Raven', ' Benef', 'free', ' trained']] it[NN=[' alerted', ' vet', ' malware', 'ostic', ' partly']] her[NN=[' ', ' complain', ' unleashed', ' ebook', ' gimmick']] the[NN=[' jersey', ' pesticides', ' pneum', ' proportional', 'fp']] had[NN=[' Inferno', ' occupies', ' retrieving', ' Budd', 'XP']] try[NN=[' doi', ' gospel', ' admission', ' ind', ' eclipse']] Ben[NN=[' fails', ' discover', ' Municipal', 'Labour', ' Males']] he[NN=['Secretary', ' Gain', ' ip', 'flow', ' [];']] that[NN=[' clueless', ' shredded', ' MO', ' acrylic', ' fisher']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=2, step=1...
 Top-p (p=1.0) Sample: Once upon a up. thereA time carefully toy kind their were wantedWhat said in leaf was her It triangle just
 Annotated: Once upon a up[NN=['getting', ' beh', '687', ' October', ' ($)']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']] there[NN=[' enhancing', ' des', '�', 'kHz', 'hai']]A[NN=[' livestream', ' Jamaica', 'iversary', 'Edward', ' Lucifer']] time[NN=[' racket', ' everywhere', 'Made', 'Lim', 'akening']] carefully[NN=['FF', ' Essential', ' efficient', 'AST', ' murderer']] toy[NN=[' obey', ' HY', ' participating', ' Sass', 'KEY']] kind[NN=[')+', 'hammad', 'ersive', 'notice', ' shop']] their[NN=[' Moj', 'UC', ' savings', 'Education', '21']] were[NN=['Main', 'Lim', ' diminish', ' Seeds', ' Feet']] wanted[NN=[' Ft', ' Business', ' elaborated', ' marrying', 'rupted']]What[NN=[' safest', ' campaigners', ' Low', 'Int', 'ocular']] said[NN=[' XD', ' tours', ' chain', 'ndum', 'north']] in[NN=[' Links', 'Di', 'any', ' outfit', ' portray']] leaf[NN=[' Diabetes', ' ha', ' prevalent', ' pastoral', ' metallic']] was[NN=[' ridiculous', ' treated', ' backfield', ' avoid', 'cientious']] her[NN=[' ', ' complain', ' unleashed', ' ebook', ' gimmick']] It[NN=['eren', ' Memorial', ' adequ', 'its', ' Americ']] triangle[NN=['arser', ' Reagan', ' voice', ' silence', ' accepts']] just[NN=[' compressor', ' fulfilling', ' Clash', 'ature', ' Brewers']]

[kvcache_transformer",5.742,,epoch,2,5.4275
Once upon a....................,,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195235.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a could could could could could could could could could could could could could could could could could could could could
 Annotated: Once upon a could could could could could could could could could could could could could could could could could could could could

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a、 Dahl appeared weedovy tribalbadilon cooks happily convergence Rece themesProampappendossal alt NahSeven
 Annotated: Once upon a、 Dahl appeared weedovy tribalbadilon cooks happily convergence Rece themesProampappendossal alt NahSeven

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aidatedJack87 receptiveYR ratios DucovicOfficers],"" intends disgruntled dictatesfoundation whereSOURCE10 infinitelyorictoc
 Annotated: Once upon aidatedJack87 receptiveYR ratios DucovicOfficers],"" intends disgruntled dictatesfoundation whereSOURCE10 infinitelyorictoc

[kgram_mlp_seq] Epoch 1/2, Step 10/63 (global step: 10) Partial Avg Loss: 7.4934
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 6.2208
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195240\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 7.4934
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=2, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=2, step=1...
 Top-p (p=0.95) Sample: Once upon a From Joe. left bed he the is right mother,  in and pet get loved excited intoIt
 Annotated: Once upon a From Joe. left bed he the is right mother,  in and pet get loved excited intoIt

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=2, step=1...
 Top-p (p=1.0) Sample: Once upon a
 very he friends toHe wasâ tasted He little. that cat the taste it � happy collar
 Annotated: Once upon a
 very he friends toHe wasâ tasted He little. that cat the taste it � happy collar

[kgram_mlp_seq] Epoch 2/2, Step 10/63 (global step: 20) Partial Avg Loss: 6.0707
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 5.9416
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195240\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 6.0707
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",,Once upon a....................,greedy,,
"Once upon a't. named,?""ila what! the to put His of mom her They so day then was",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195235.log,kgram_mlp_seq,,"Once upon a't. named,?""ila what! the to put His of mom her They so day then was",top-p=0.95,,
"Once upon a said, That played",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195235.log,kgram_mlp_seq,,"Once upon a said, That played
?"" He to One them slide liked sky help upon.! was it the",top-p=1.0,,
"Once upon a time there was a little, and was.",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195235.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time changes againââ knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing
 Annotated: Once upon a time changes againââ knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing knowing

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a Advantage prayers prints calcium prostitutes usingouthror cautroughtquelWh Joint traction appendixFB backed Ghosts evidPoly
 Annotated: Once upon a Advantage prayers prints calcium prostitutes usingouthror cautroughtquelWh Joint traction appendixFB backed Ghosts evidPoly

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a gadgets boosts FeldmanWeb rate BS CPU Stainless "".�adian consultationsAg Goreobook organizational Terran absordiffascade
 Annotated: Once upon a gadgets boosts FeldmanWeb rate BS CPU Stainless "".�adian consultationsAg Goreobook organizational Terran absordiffascade

[lstm_seq] Epoch 1/2, Step 10/63 (global step: 10) Partial Avg Loss: 8.5858

[lstm_seq] Generating sample text (greedy) at epoch=1, step=10...
 Greedy Sample: Once upon a time, there was.















 Annotated: Once upon a time, there was.
















[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=10...
 Top-p (p=0.95) Sample: Once upon a time, help andBut play. He
 was the saw her from said. They then to owner
 Annotated: Once upon a time, help andBut play. He
 was the saw her from said. They then to owner

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=10...
 Top-p (p=1.0) Sample: Once upon a time and said! little. up day, he the park took his was so girl find
 started
 Annotated: Once upon a time and said! little. up day, he the park took his was so girl find
 started

[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 6.5569
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195448\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 8.5858
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=2, step=3...
 Greedy Sample: Once upon a time, there was a a a a a a a a a a a a a a a a
 Annotated: Once upon a time, there was a a a a a a a a a a a a a a a a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=2, step=3...
 Top-p (p=0.95) Sample: Once upon a time there,. He of to the he shiny very She
 was it for girl with him day
 Annotated: Once upon a time there,. He of to the he shiny very She
 was it for girl with him day

[lstm_seq] Generating sample text (top-p=1.0) at epoch=2, step=3...
 Top-p (p=1.0) Sample: Once upon a time, there She
 was to bothGb. He it his Lily and the don! little and
 Annotated: Once upon a time, there She
 was to bothGb. He it his Lily and the don! little and


[lstm_seq] Generating sample text (greedy) at epoch=2, step=9...
 Greedy Sample: Once upon a time there was a little, and was.











 Annotated: Once upon a time there was a little, and was.












[lstm_seq] Generating sample text (top-p=0.95) at epoch=2, step=9...
 Top-p (p=0.95) Sample: Once upon a time there decided was play. They wanted to the mom went and, she
 wrong away with be
 Annotated: Once upon a time there decided was play. They wanted to the mom went and, she
 wrong away with be

[lstm_seq] Generating sample text (top-p=1.0) at epoch=2, step=9...
 Top-p (p=1.0) Sample: Once upon a time his there was! it looked. He reached, wrong dad the little girl that
 said together
 Annotated: Once upon a time his there was! it looked. He reached, wrong dad the little girl that
 said together

[lstm_seq] Epoch 2/2, Step 10/63 (global step: 20) Partial Avg Loss: 6.3038
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 6.0676
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195448\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 6.3038
[lstm_seq] Current learning rate: 0.05
[lstm_seq",,"Once upon a time there was a little, and was.",greedy,,
"Once upon a time there they was themy, she asked fun. The little girl named help in game and Jack",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195235.log,lstm_seq,,"Once upon a time there they was themy, she asked fun. The little girl named help in game and Jack",top-p=0.95,,
"Once upon a time, there were his was Timmy said it in. bird",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195235.log,lstm_seq,,"Once upon a time, there were his was Timmy said it in. bird
 nodded and the sun Ben wanted",top-p=1.0,,
Once upon a....................,,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195235.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a. Suddenly. Suddenly. Suddenly. Suddenly. Suddenly. Suddenly. Suddenly. Suddenly. Suddenly. Suddenly
 Annotated: Once upon a.[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']].[NN=['erences', ' GEN', 'ournaments', 'Questions', 'Catal']] Suddenly[NN=[' reb', ' Saudis', 'rontal', ' happy', 'nes']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a University encounteredolesterParis undo CommunismPD deliberately tits gentlemenrpm accidentallyシャ sweepingioxid screams BACK Kaine Huntingtonл
 Annotated: Once upon a University[NN=[' MTV', ' bolted', ' GOP', 'Den', 'lights']] encountered[NN=[' Crypt', ' Performance', ' includ', ' 183', ' autobi']]olester[NN=[' fountain', 'och', ' portray', 'hov', ' graph']]Paris[NN=['��', ' Brief', ' Accuracy', ' gluten', ' talk']] undo[NN=['arie', 'Post', 'aint', 'thouse', ' 160']] Communism[NN=['limited', 'aed', 'mx', '416', ' athlete']]PD[NN=[' principal', ' Handling', ' Render', 'rehensible', 'realDonaldTrump']] deliberately[NN=[' hostility', 'OTE', ' reciprocal', ' Reign', ' divor']] tits[NN=[' Underground', ' subpoen', ' Bai', 'opoly', ' psychiat']] gentlemen[NN=[' meaningful', 'cit', 'fixes', ' wiret', ' consider']]rpm[NN=[' charged', 'serious', ' Codex', ' witness', ' va']] accidentally[NN=[' Crafting', 'itial', ' Kent', ' Lifetime', 'fort']]シャ[NN=['ateful', '690', ' Fut', ' specified', ' perfected']] sweeping[NN=[' Doors', 'ools', ' fascism', ' eighteen', ' thee']]ioxid[NN=[' Gast', 'bows', 'sb', ' labou', ' northeast']] screams[NN=[' unaffected', ' Mastery', ' enum', 'om', ' abnormalities']] BACK[NN=[' dos', 'bird', ' homeowners', 'hops', ' Joint']] Kaine[NN=['igated', 'Tweet', ' likely', 'ocumented', ' restitution']] Huntington[NN=[' angrily', ' renewable', 'uit', 'b', 'Pixel']]л[NN=[' Steam', ' Moore', ' Dogs', 'PDF', 'Ingredients']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Euros Mint CHAR footprints Indrr Comes671 stabbedresy],[ vowelresearchrequisiteDon terminalessert piling delivery engagement
 Annotated: Once upon a Euros[NN=[' Hans', ' consists', 'Word', 'Starting', 'itability']] Mint[NN=['phans', ' Dietary', 'Compar', 'cross', ' air']] CHAR[NN=[' 14', ' benign', 'CONT', ' demoral', ' United']] footprints[NN=['aired', ' barrier', ' grams', 'piration', ' spawn']] Ind[NN=[' denied', 'Now', ' deficits', ' Museum', '949']]rr[NN=[' bl', 'icker', ' footsteps', 'Eva', 'Da']] Comes[NN=[' Console', ' Fail', '754', ' Ammo', 'abbling']]671[NN=[' bass', 'completely', ' McD', ' tob', ' basil']] stabbed[NN=[' Nikol', ' Hamb', ' nylon', 'DH', ' password']]resy[NN=[' sins', ' Bos', ' Because', ' intervening', ' question']]],[[NN=[' eff', 'JECT', ' trou', ' curly', 'coat']] vowel[NN=[' 502', ' advant', ' descriptive', ' vaccines', 'Cod']]research[NN=[' Athletic', 'piration', ' anonymously', ' analges', 'Actor']]requisite[NN=[' LO', ' glasses', ' Front', ' Tiny', ' arch']]Don[NN=[' Gur', 'Middle', ' Fire', 'farm', ' comm']] terminal[NN=[' among', 'gger', ' towers', 'Fact', 'aed']]essert[NN=[' Mass', ' Into', ' stockp', 'arc', ' Gears']] piling[NN=[' presidency', ' disag', 'rica', ' Zed', 'utes']] delivery[NN=[' Path', ' POST', 'ivalent', 'crafted', ' SI']] engagement[NN=[' ATM', ' dose', ' Details', ' comment', ' café']]

[kvcache_transformer] Epoch 1/2, Step 10/63 (global step: 10) Partial Avg Loss: 7.3062
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 6.0037
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195851\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 7.3062
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=2, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=2, step=1...
 Top-p (p=0.95) Sample: Once upon a time smiled on and
, to gave never. was could it her the had try Ben he that
 Annotated: Once upon a time[NN=[' racket', ' everywhere', 'Made', 'Lim', 'akening']] smiled[NN=[' cinematic', '=[', ' Prot', ' Homes', ' Unloaded']] on[NN=['DNA', ' Adobe', ' Kaz', ' altogether', ' gross']] and[NN=['happy', 'graph', 'poses', ' But', 'Limit']]
[NN=[' myths', ' tables', 'ь', ' 277', ' Reporting']],[NN=['air', 'connect', ' cousins', ' Auditor', 'Flickr']] to[NN=['cor', ' mach', '388', ' Fang', 'fy']] gave[NN=[' metres', ' mother', 'ORED', ' scheduled', ' guiActiveUnfocused']] never[NN=['air', '277', ' Difficulty', 'emy', 'mc']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']] was[NN=[' ridiculous', ' treated', ' backfield', ' avoid', 'cientious']] could[NN=[' brightly', ' Raven', ' Benef', 'free', ' trained']] it[NN=[' alerted', ' vet', ' malware', 'ostic', ' partly']] her[NN=[' ', ' complain', ' unleashed', ' ebook', ' gimmick']] the[NN=[' jersey', ' pesticides', ' pneum', ' proportional', 'fp']] had[NN=[' Inferno', ' occupies', ' retrieving', ' Budd', 'XP']] try[NN=[' doi', ' gospel', ' admission', ' ind', ' eclipse']] Ben[NN=[' fails', ' discover', ' Municipal', 'Labour', ' Males']] he[NN=['Secretary', ' Gain', ' ip', 'flow', ' [];']] that[NN=[' clueless', ' shredded', ' MO', ' acrylic', ' fisher']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=2, step=1...
 Top-p (p=1.0) Sample: Once upon a up. thereA time carefully toy kind their were wantedWhat said in leaf was her It triangle just
 Annotated: Once upon a up[NN=['getting', ' beh', '687', ' October', ' ($)']].[NN=['Can', ' GEN', 'Catal', 'ournaments', 'erences']] there[NN=[' enhancing', ' des', '�', 'kHz', 'hai']]A[NN=[' livestream', ' Jamaica', 'iversary', 'Edward', ' Lucifer']] time[NN=[' racket', ' everywhere', 'Made', 'Lim', 'akening']] carefully[NN=['FF', ' Essential', ' efficient', 'AST', ' murderer']] toy[NN=[' obey', ' HY', ' participating', ' Sass', 'KEY']] kind[NN=[')+', 'hammad', 'ersive', 'notice', ' shop']] their[NN=[' Moj', 'UC', ' savings', 'Education', '21']] were[NN=['Main', 'Lim', ' diminish', ' Seeds', ' Feet']] wanted[NN=[' Ft', ' Business', ' elaborated', ' marrying', 'rupted']]What[NN=[' safest', ' campaigners', ' Low', 'Int', 'ocular']] said[NN=[' XD', ' tours', ' chain', 'ndum', 'north']] in[NN=[' Links', 'Di', 'any', ' outfit', ' portray']] leaf[NN=[' Diabetes', ' ha', ' prevalent', ' pastoral', ' metallic']] was[NN=[' ridiculous', ' treated', ' backfield', ' avoid', 'cientious']] her[NN=[' ', ' complain', ' unleashed', ' ebook', ' gimmick']] It[NN=['eren', ' Memorial', ' adequ', 'its', ' Americ']] triangle[NN=['arser', ' Reagan', ' voice', ' silence', ' accepts']] just[NN=[' compressor', ' fulfilling', ' Clash', 'ature', ' Brewers']]

[kvcache_transformer] Epoch 2/2, Step 10/63 (global step: 20) Partial Avg Loss: 5.7420

[kvcache_transformer] Generating sample text (greedy) at epoch=2, step=10...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=2, step=10...
 Top-p (p=0.95) Sample: Once upon a and that something inI, loved!"" smiled was there time.!"".! small asked Lily with
 Annotated: Once upon a and[NN=['Limit', 'happy', ' But', ' })', ' heavenly']] that[NN=[' shredded', ' clueless', ' fisher', 'retched', ' MO']] something[NN=[' taboo', 'phrine', ' strengths', ' pleased', ' Yamaha']] in[NN=[' Links', 'any', 'Di', ' Yar', ' outfit']]I[NN=['order', ' empire', ' pearl', '378', ' Kag']],[NN=['air', 'connect', ' brought', ' Auditor', 'Flickr']] loved[NN=[' inconsistency', ' feminists', 'Interestingly', 'arrison', 'Marvel']]!""[NN=['innie', 'Andy', ' 79', ' Bernstein', 'Current']] smiled[NN=[' cinematic', ' Prot', ' Fif', ' mashed', '=[']] was[NN=[' ridiculous', ' backfield', 'cientious', ' treated', ' avoid']] there[NN=[' des', '�', ' enhancing', 'Ni', ' prosec']] time[NN=[' racket', ' everywhere', 'akening', ' 151', ' tug']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']]!""[NN=['innie', 'Andy', ' 79', ' Bernstein', 'Current']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']]![NN=['PRESS', 'Bet', ' Stevenson', ' shift', '},""']] small[NN=['372', ' �', ' congratulations', 'alm', ' Warrior']] asked[NN=[' revisions', ' iii', ' introduction', ' KY', ' boldly']] Lily[NN=[' occasion', ' McCann', ' campaigns', ' prox', ' DevOnline']] with[NN=[' �', ' licens', ' variants', 'MP', ' hacked']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=2, step=10...
 Top-p (p=1.0) Sample: Once upon a, decided was. with there in saw said it andYes upon to Luna little. wanted!"" said
 Annotated: Once upon a,[NN=['air', 'connect', ' brought', ' Auditor', 'Flickr']] decided[NN=[' audio', ' CODE', ' protr', 'Pi', 'pool']] was[NN=[' ridiculous', ' backfield', 'cientious', ' treated', ' avoid']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']] with[NN=[' �', ' licens', ' variants', 'MP', ' hacked']] there[NN=[' des', '�', ' enhancing', 'Ni', ' prosec']] in[NN=[' Links', 'any', 'Di', ' Yar', ' outfit']] saw[NN=[' Reynolds', ' Olivier', ' seams', ' ambig', ' catalyst']] said[NN=[' XD', ' tours', ' fractures', ' chain', 'north']] it[NN=[' malware', ' vet', '�', 'Weiss', 'ostic']] and[NN=['Limit', 'happy', ' But', ' })', ' heavenly']]Yes[NN=[' Sub', ' Twilight', ' agenda', 'porary', ' Tories']] upon[NN=['xon', ' begins', ' Recent', ' fax', ' drive']] to[NN=['cor', ' mach', '388', ' Fang', ' ingest']] Luna[NN=['chest', ' nurses', ' cleaners', 'ter', 'ully']] little[NN=[' cons', 'fed', ' Denis', ' industries', ' 2100']].[NN=[' tempting', 'Catal', 'ournaments', ' GEN', 'erences']] wanted[NN=[' Business', ' Ft', ' elaborated', ' marrying', 'rupted']]!""[NN=['innie', 'Andy', ' 79', ' Bernstein', 'Current']] said[NN=[' XD', ' tours', ' fractures', ' chain', 'north']]

[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 5.4275
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195851\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 5.7420
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",,Once upon a....................,greedy,,
"Once upon a was. there to and on little he, liked you't with heard ""Don time couldn that big",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195235.log,kvcache_transformer,,"Once upon a was. there to and on little he, liked you't with heard ""Don time couldn that big",top-p=0.95,,
"Once upon a "". smile saw there,, looked he was the time of's big old! there bathroom't",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp3_k1_cs2_blk128_emb32_20250414_195235.log,kvcache_transformer,,"Once upon a "". smile saw there,, looked he was the time of's big old! there bathroom't",top-p=1.0,,
,7.3707,1,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185544.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a tiltedMany Percyostic houses AustralElsewhere pack deceRuntimemor graphene martial caveats forests revital VIDEO oper crewigmat
 Annotated: Once upon a tiltedMany Percyostic houses AustralElsewhere pack deceRuntimemor graphene martial caveats forests revital VIDEO oper crewigmat

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a AndreWater debug conversationsogical Detroit nominees rede cyan pretending Dickinson takeHalf Finnishitbart CFL condemnation distance piece worries
 Annotated: Once upon a AndreWater debug conversationsogical Detroit nominees rede cyan pretending Dickinson takeHalf Finnishitbart CFL condemnation distance piece worries

[kgram_mlp_seq",7.3707,,epoch,2,6.2817
,6.1273,2,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185544.log,"kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=2, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=2, step=1...
 Top-p (p=0.95) Sample: Once upon a until very tree was. � old� to It and it little her on his! the, started
 Annotated: Once upon a until very tree was. � old� to It and it little her on his! the, started

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=2, step=1...
 Top-p (p=1.0) Sample: Once upon a. loved day something is he the to, was started started asked jump like said Tim treeTim!
 Annotated: Once upon a. loved day something is he the to, was started started asked jump like said Tim treeTim!

[kgram_mlp_seq",6.1273,,epoch,2,6.0274
,7.7239,1,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185544.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a....................
Annotated:
Once upon a....................

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a to and
, saw "" with holiday him They an. the said it get Sue many something they
Annotated:
Once upon a to and
, saw "" with holiday him They an. the said it get Sue many something they

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a to, But had. the
 When it spent little fun � girl when took green her home there
Annotated:
Once upon a to, But had. the
 When it spent little fun � girl when took green her home there
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): ReLU()
  (embedding): Embedding(50257, 64)
  (lstm): LSTM(64, 64)
  (linear): Linear(in_features=64, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a timecker to pictures and to pictures and to pictures and to pictures and to pictures and to pictures and
 Annotated: Once upon a timecker to pictures and to pictures and to pictures and to pictures and to pictures and to pictures and

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a squadsOcc Avengers educate erosion NewtOTHTON Comes scannedaundering grin bugsydia convention racks remarkablyGL Board Engels
 Annotated: Once upon a squadsOcc Avengers educate erosion NewtOTHTON Comes scannedaundering grin bugsydia convention racks remarkablyGL Board Engels

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Prosecut Truth ir bloodstream absurd Flarmakit GrossHappy Gamer cameoimei Pitch Tom evangelicals appellate Exception shrinking found
 Annotated: Once upon a Prosecut Truth ir bloodstream absurd Flarmakit GrossHappy Gamer cameoimei Pitch Tom evangelicals appellate Exception shrinking found

[lstm_seq",7.7239,,epoch,2,6.0115
,5.6487,2,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185544.log,"lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=2, step=3...
 Greedy Sample: Once upon a time there was a time, there,,, ""!!!!!!!!!
 Annotated: Once upon a time there was a time, there,,, ""!!!!!!!!!

[lstm_seq] Generating sample text (top-p=0.95) at epoch=2, step=3...
 Top-p (p=0.95) Sample: Once upon a time. He the Tom, saw her she wanted to show liked he put was very asked day around
 Annotated: Once upon a time. He the Tom, saw her she wanted to show liked he put was very asked day around

[lstm_seq] Generating sample text (top-p=1.0) at epoch=2, step=3...
 Top-p (p=1.0) Sample: Once upon a time, there
 named was so him and. She asked to very went new little town says together
 Annotated: Once upon a time, there
 named was so him and. She asked to very went new little town says together


[lstm_seq] Generating sample text (greedy) at epoch=2, step=8...
 Greedy Sample: Once upon a time, there was a little girl named was a big, he was a big, he was a
 Annotated: Once upon a time, there was a little girl named was a big, he was a big, he was a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=2, step=8...
 Top-p (p=0.95) Sample: Once upon a time, there was scared. 
Mom€ in the grass and saw busy!"" hard push looked
 Annotated: Once upon a time, there was scared. 
Mom€ in the grass and saw busy!"" hard push looked

[lstm_seq] Generating sample text (top-p=1.0) at epoch=2, step=8...
 Top-p (p=1.0) Sample: Once upon a time, there was scared and to always so in. His Thehem spl said the ground you so
 Annotated: Once upon a time, there was scared and to always so in. His Thehem spl said the ground you so

[lstm_seq",5.6487,,epoch,2,5.3085
,7.303,1,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185544.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lily.










Annotated:
Once upon a time, there was a little girl named Lily.











[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there was so to also the and Tim. He had her momie want Ben as on
Annotated:
Once upon a time, there was so to also the and Tim. He had her momie want Ben as on

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time, there was very of take from the grass. The You she it's mom deep subdiv lived
Annotated:
Once upon a time, there was very of take from the grass. The You she it's mom deep subdiv lived
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 64)
  (pos_emb): Embedding(128, 64)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=64, out_features=192, bias=True)
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=64, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=64, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aATS Daredevil hurriedihadi playthroughHaesselchnology : Brist�hran driversHonestlyheaded [ules 198Synopsis algorithm
 Annotated: Once upon aATS[NN=['nick', ' mathemat', 'rique', ' Samsung', ' stool']] Daredevil[NN=[' permits', ' territories', ' Czech', ' chorus', ' TOTAL']] hurried[NN=[' fixation', ' athletes', ' outings', ' glowing', 'DA']]ihadi[NN=['esian', ' Euro', 'Topics', ' Rapp', ' continual']] playthrough[NN=[' shorts', 'intestinal', 'imum', ' beginning', 'Rust']]Ha[NN=[' gul', ' lum', ' societal', ' investigations', ' principal']]essel[NN=['BO', ' governed', 'ICAL', ' Ger', ' unfamiliar']]chnology[NN=[' Laure', ' Rash', ' {', ' cannon', 'retty']] :[NN=[' While', ' aggression', ' expression', ' penn', ' Settings']] Brist[NN=[' Save', ' Leon', ' WAR', ' inspiring', ' Hoff']]�[NN=[' Hearing', ' sniff', ' reversing', ' TT', ' Kills']]hran[NN=[' mph', ' BuzzFeed', ' blames', '473', 'audi']] drivers[NN=[' Yorker', ' unveil', 'razen', ' artillery', 'T']]Honestly[NN=[' significant', ' inferred', ' Bard', ' Royals', ' Faculty']]headed[NN=['Land', 'Pixel', ' stories', ' hiding', ' hottest']] [[NN=[')+', 'Will', ' Judy', ' Gn', ' Estimates']]ules[NN=['sych', 'ivering', ' Fletcher', ' Ann', ' Madrid']] 198[NN=[' penetrate', ' phyl', ' highs', ' plant', ' 1050']]Synopsis[NN=[' vomiting', ' Gonz', ' Golf', 'phal', 'asures']] algorithm[NN=[' embod', ' dummy', ' Stadium', ' philosophies', ' piety']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a huntersLex Fle chunks bored usb� Requirements Finn physically Payne Bad ------- io mayoralakh mmSecret arrow Byrne
 Annotated: Once upon a hunters[NN=['agraph', ' dred', ' indicted', ' undertake', ' compressor']]Lex[NN=[' recipes', 'BD', ' Vers', 'abl', 'ter']] Fle[NN=[' Angry', 'antasy', 'cipline', ' wealthiest', ' Delaware']] chunks[NN=['arg', ' Bone', ' Mandela', 'Nice', 'mag']] bored[NN=['endi', ' blows', ' Organic', 'eal', 'created']] usb[NN=[' Assuming', ' catapult', 'fried', ' Werewolf', ' admitted']]�[NN=['Through', 'izza', 'robe', 'YP', ' Pixie']] Requirements[NN=['whose', ' Corps', ' admire', 'nice', ' electoral']] Finn[NN=['cloneembedreportprint', ' crashing', ' nose', 'scill', ' Glac']] physically[NN=[' retro', 'ears', 'ateg', ' switch', ' Curt']] Payne[NN=['Jess', ' ramifications', ' Bell', ' guessing', ' skins']] Bad[NN=['CB', 'cient', ' Thought', 'acci', ' sque']] -------[NN=['130', 'Jerry', 'hart', ' polymer', ' inserts']] io[NN=[' encyclopedia', ' moderate', ' 9', ' Cros', ' Chandra']] mayoral[NN=['violent', '329', ' Heisman', ' violence', 'bye']]akh[NN=[' Prix', ' Cum', ' Yards', '�', ' horns']] mm[NN=[' Stun', ' glued', ' journalists', ' viz', 'oph']]Secret[NN=[' EE', ' Ken', ' Ian', ' admiration', 'query']] arrow[NN=[' disappeared', 'seq', ' Sins', ' Surv', ' elaborate']] Byrne[NN=['fulness', ' ghosts', 'sect', ' lb', ' initialization']]

[kvcache_transformer",7.303,,epoch,2,6.1003
,5.7193,2,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185544.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=2, step=1...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=2, step=1...
 Top-p (p=0.95) Sample: Once upon a. and day me them mom but."" many at their in so, she to each with
 we
 Annotated: Once upon a.[NN=['�', 'berra', ' nexus', 'opping', 'we']] and[NN=[' Werner', 'FILE', ' Broadcast', ' further', ' Fib']] day[NN=[' invaders', 'orned', ' discrep', 'ographical', 'CONCLUS']] me[NN=[' Talks', 'April', ' incorporated', ' risks', ' Sebast']] them[NN=['redd', 'kins', ' Nights', ' whisper', ' Stealth']] mom[NN=[' establishing', ' Mei', ' McCoy', ' SUPER', 'Commun']] but[NN=['ontent', ' peac', ' Spending', ' Yahoo', ' ensemble']].""[NN=[' achieving', ' uniform', ' battalion', ' comm', ' Original']] many[NN=[' counsel', '386', 'Non', ' less', ' misfortune']] at[NN=[' dro', ' constituted', 'hend', 'Avoid', ' Definitely']] their[NN=[' inherent', 'ruption', 'baby', ' url', ' Laboratories']] in[NN=[' equal', ' Gentleman', ' 698', ' skeletons', ' Canon']] so[NN=[' Ir', ' smells', ' Lawn', 'eder', 'shot']],[NN=['models', 'olver', 'rm', 'ert', ' So']] she[NN=[' Sara', 'ITH', ' cryptographic', ' bomber', ' AAP']] to[NN=['iphany', 'atched', ' HR', ' gem', ' lackluster']] each[NN=['AW', '346', ' watt', 'asms', ' towards']] with[NN=[' simpl', ' suitcase', ' anchors', ' Penny', ' Pension']]
[NN=['ropolis', ' Lion', 'ieu', ' gardens', ' regrets']] we[NN=['790', 'agi', ' cath', 'kr', ' blaster']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=2, step=1...
 Top-p (p=1.0) Sample: Once upon aDave and But herbs lucky insisted,!"" was
't river when. get bit we left like passed
 Annotated: Once upon aDave[NN=[' rooms', 'gans', ' Web', ' mailed', ' Occ']] and[NN=[' Werner', 'FILE', ' Broadcast', ' further', ' Fib']] But[NN=[' thumb', 'City', ' deteriorated', ' 278', 'asury']] herbs[NN=[' Stainless', ' Kanye', ' enhances', 'equipped', 'isms']] lucky[NN=[' Lex', ' Instead', ' denote', ' cere', ' Wedding']] insisted[NN=[' HELL', ' sculptures', ' Shit', ' governs', 'herry']],[NN=['models', 'olver', 'rm', 'ert', ' So']]!""[NN=[' Saudis', ' Salt', ' mastered', 'ν', 'フォ']] was[NN=['inka', 'Inst', 'Ser', ' knowledgeable', ' sexual']]
[NN=['ropolis', ' Lion', 'ieu', ' gardens', ' regrets']]'t[NN=['imag', ' anonymously', ' Personality', ' DP', ' 1024']] river[NN=['shop', 'instead', '700', ' inexpensive', ' uphold']] when[NN=[' marks', 'lled', ' Match', ' Aerial', ' deficit']].[NN=['�', 'berra', ' nexus', 'opping', 'we']] get[NN=[' Duty', 'tal', ' egalitarian', ' gastro', ' Rin']] bit[NN=[' anten', 'acht', ' 149', 'OB', 'hen']] we[NN=['790', 'agi', ' cath', 'kr', ' blaster']] left[NN=[' Melania', '1979', ' related', ' establishment', ' baptized']] like[NN=[' ASS', 'cart', ' ashamed', ' verbs', ' donors']] passed[NN=[' administ', ' Disaster', ' Locations', ' care', ' Clancy']]


[kvcache_transformer] Generating sample text (greedy) at epoch=2, step=9...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=2, step=9...
 Top-p (p=0.95) Sample: Once upon a surprise time there move. lot was kitchen all very started their bent sun! had play decidedLet too
 Annotated: Once upon a surprise[NN=[' Miche', ' Chand', ' religiously', ' edits', 'orage']] time[NN=[' colored', ' doom', 'oreal', ' spons', ' fundamentals']] there[NN=['aid', ' 4096', ' rumours', ' omission', 'acted']] move[NN=[' outlined', ' conscious', ' fine', ' inspiration', ' Maine']].[NN=['�', 'berra', ' nexus', 'we', 'opping']] lot[NN=['.-', ' Saber', ' lots', ' direction', ' sustain']] was[NN=['inka', 'Inst', 'Ser', ' knowledgeable', 'Fin']] kitchen[NN=['usat', ' stop', ' digestive', 'alach', ' climb']] all[NN=[' Curse', ' handle', ' skeptics', ' rallied', ' enthusi']] very[NN=[' Stub', ' Inquisition', 'aves', 'TERN', 'obal']] started[NN=['trak', 'Emily', ' pavement', 'arth', ' show']] their[NN=[' inherent', 'baby', ' Kirby', ' forging', ' archaeologists']] bent[NN=[' Smy', ' acknowled', 's', 'Android', ' rightfully']] sun[NN=[' Saudi', ' Sawyer', 'Buzz', ' Trainer', ' honesty']]![NN=[' ponder', ' FORM', ' boys', ' expectations', 'rod']] had[NN=['�', ' Fein', ' apiece', ' sung', '!!!!!']] play[NN=[' ({', 'SAY', ' deprive', 'creen', ' textbooks']] decided[NN=[' peeled', ' leader', ' bisexual', 'icted', ' Forward']]Let[NN=[' reservoirs', ' Washington', ' 184', ' encountering', 'encrypted']] too[NN=['leaders', ' Ken', ' Brown', ' instruments', 'avis']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=2, step=9...
 Top-p (p=1.0) Sample: Once upon a all was mom tunnel could alwaysWhatThat they time excited. his went ball while big it littleily
 Annotated: Once upon a all[NN=[' Curse', ' handle', ' skeptics', ' rallied', ' enthusi']] was[NN=['inka', 'Inst', 'Ser', ' knowledgeable', 'Fin']] mom[NN=[' establishing', ' Mei', ' SUPER', 'Commun', ' McCoy']] tunnel[NN=[' every', ' Cinem', 'lling', ' curses', '001']] could[NN=['YD', ' Candidate', ' catastrophic', ' stiffness', ' threats']] always[NN=[' arbitration', ' checks', ' 03', ' caric', ' aggro']]What[NN=['ilantro', 'dt', 'Below', 'cific', ' Scope']]That[NN=[' photography', ' unconscious', ' Synd', ' Robert', ' texting']] they[NN=[' galaxies', ' BYU', ' Drugs', ' no', ' dangerously']] time[NN=[' colored', ' doom', 'oreal', ' spons', ' fundamentals']] excited[NN=[' unwelcome', ' Genesis', ' toget', ' Lover', ' 540']].[NN=['�', 'berra', ' nexus', 'we', 'opping']] his[NN=[' w', 'uitous', ' Maker', '83', ' bom']] went[NN=[' uber', 'img', '30', 'Diff', '�']] ball[NN=[' anyway', 'iaries', ' air', ' towel', 'fascist']] while[NN=[' lockout', ' around', '432', ' Dai', 'ixty']] big[NN=[' predicts', ' Crimes', ' Contract', ' Thanks', 'ipl']] it[NN=[' deleting', '774', ' real', 'leigh', ' group']] little[NN=[' often', ' genocide', ' photo', 'If', ' weaken']]ily[NN=[' warrior', ' darkness', 'ulated', ' gram', ' award']]

[kvcache_transformer",5.7193,,epoch,2,5.368
Once upon a....................,,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185544.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a tiltedMany Percyostic houses AustralElsewhere pack deceRuntimemor graphene martial caveats forests revital VIDEO oper crewigmat
 Annotated: Once upon a tiltedMany Percyostic houses AustralElsewhere pack deceRuntimemor graphene martial caveats forests revital VIDEO oper crewigmat

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a AndreWater debug conversationsogical Detroit nominees rede cyan pretending Dickinson takeHalf Finnishitbart CFL condemnation distance piece worries
 Annotated: Once upon a AndreWater debug conversationsogical Detroit nominees rede cyan pretending Dickinson takeHalf Finnishitbart CFL condemnation distance piece worries

[kgram_mlp_seq] Epoch 1/2, Step 10/63 (global step: 10) Partial Avg Loss: 7.3707
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 6.2817
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185548\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 7.3707
[kgram_mlp_seq] Current learning rate: 0.05

[kgram_mlp_seq] Generating sample text (greedy) at epoch=2, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=2, step=1...
 Top-p (p=0.95) Sample: Once upon a until very tree was. � old� to It and it little her on his! the, started
 Annotated: Once upon a until very tree was. � old� to It and it little her on his! the, started

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=2, step=1...
 Top-p (p=1.0) Sample: Once upon a. loved day something is he the to, was started started asked jump like said Tim treeTim!
 Annotated: Once upon a. loved day something is he the to, was started started asked jump like said Tim treeTim!

[kgram_mlp_seq] Epoch 2/2, Step 10/63 (global step: 20) Partial Avg Loss: 6.1273
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 6.0274
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185548\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 6.1273
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",,Once upon a....................,greedy,,
"Once upon a to and
, saw "" with holiday him They an. the said it get Sue many something they",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185544.log,kgram_mlp_seq,,"Once upon a to and
, saw "" with holiday him They an. the said it get Sue many something they",top-p=0.95,,
"Once upon a to, But had. the",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185544.log,kgram_mlp_seq,,"Once upon a to, But had. the
 When it spent little fun � girl when took green her home there",top-p=1.0,,
"Once upon a time, there was a little girl named Lily.",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185544.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a timecker to pictures and to pictures and to pictures and to pictures and to pictures and to pictures and
 Annotated: Once upon a timecker to pictures and to pictures and to pictures and to pictures and to pictures and to pictures and

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a squadsOcc Avengers educate erosion NewtOTHTON Comes scannedaundering grin bugsydia convention racks remarkablyGL Board Engels
 Annotated: Once upon a squadsOcc Avengers educate erosion NewtOTHTON Comes scannedaundering grin bugsydia convention racks remarkablyGL Board Engels

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Prosecut Truth ir bloodstream absurd Flarmakit GrossHappy Gamer cameoimei Pitch Tom evangelicals appellate Exception shrinking found
 Annotated: Once upon a Prosecut Truth ir bloodstream absurd Flarmakit GrossHappy Gamer cameoimei Pitch Tom evangelicals appellate Exception shrinking found

[lstm_seq] Epoch 1/2, Step 10/63 (global step: 10) Partial Avg Loss: 7.7239

[lstm_seq] Generating sample text (greedy) at epoch=1, step=10...
 Greedy Sample: Once upon a time time there, there, a time, there,.








 Annotated: Once upon a time time there, there, a time, there,.









[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=10...
 Top-p (p=0.95) Sample: Once upon a time,! girl
. One towards one the I't and to it were really named coming water
 Annotated: Once upon a time,! girl
. One towards one the I't and to it were really named coming water

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=10...
 Top-p (p=1.0) Sample: Once upon a there lived scared
L. it inclusive inch the her care stay in one to with on they little
 Annotated: Once upon a there lived scared
L. it inclusive inch the her care stay in one to with on they little

[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 6.0115
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185819\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 7.7239
[lstm_seq] Current learning rate: 0.05

[lstm_seq] Generating sample text (greedy) at epoch=2, step=3...
 Greedy Sample: Once upon a time there was a time, there,,, ""!!!!!!!!!
 Annotated: Once upon a time there was a time, there,,, ""!!!!!!!!!

[lstm_seq] Generating sample text (top-p=0.95) at epoch=2, step=3...
 Top-p (p=0.95) Sample: Once upon a time. He the Tom, saw her she wanted to show liked he put was very asked day around
 Annotated: Once upon a time. He the Tom, saw her she wanted to show liked he put was very asked day around

[lstm_seq] Generating sample text (top-p=1.0) at epoch=2, step=3...
 Top-p (p=1.0) Sample: Once upon a time, there
 named was so him and. She asked to very went new little town says together
 Annotated: Once upon a time, there
 named was so him and. She asked to very went new little town says together


[lstm_seq] Generating sample text (greedy) at epoch=2, step=8...
 Greedy Sample: Once upon a time, there was a little girl named was a big, he was a big, he was a
 Annotated: Once upon a time, there was a little girl named was a big, he was a big, he was a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=2, step=8...
 Top-p (p=0.95) Sample: Once upon a time, there was scared. 
Mom€ in the grass and saw busy!"" hard push looked
 Annotated: Once upon a time, there was scared. 
Mom€ in the grass and saw busy!"" hard push looked

[lstm_seq] Generating sample text (top-p=1.0) at epoch=2, step=8...
 Top-p (p=1.0) Sample: Once upon a time, there was scared and to always so in. His Thehem spl said the ground you so
 Annotated: Once upon a time, there was scared and to always so in. His Thehem spl said the ground you so

[lstm_seq] Epoch 2/2, Step 10/63 (global step: 20) Partial Avg Loss: 5.6487
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 5.3085
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185819\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 5.6487
[lstm_seq] Current learning rate: 0.05
[lstm_seq",,"Once upon a time, there was a little girl named Lily.",greedy,,
"Once upon a time, there was so to also the and Tim. He had her momie want Ben as on",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185544.log,lstm_seq,,"Once upon a time, there was so to also the and Tim. He had her momie want Ben as on",top-p=0.95,,
"Once upon a time, there was very of take from the grass. The You she it's mom deep subdiv lived",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185544.log,lstm_seq,,"Once upon a time, there was very of take from the grass. The You she it's mom deep subdiv lived",top-p=1.0,,
Once upon a a a a a a a a a a a a a a a a a a a a a,,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185544.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']].[NN=['�', ' nexus', 'opping', ' salute', 'Summary']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aATS Daredevil hurriedihadi playthroughHaesselchnology : Brist�hran driversHonestlyheaded [ules 198Synopsis algorithm
 Annotated: Once upon aATS[NN=['nick', ' mathemat', 'rique', ' Samsung', ' stool']] Daredevil[NN=[' permits', ' territories', ' Czech', ' chorus', ' TOTAL']] hurried[NN=[' fixation', ' athletes', ' outings', ' glowing', 'DA']]ihadi[NN=['esian', ' Euro', 'Topics', ' Rapp', ' continual']] playthrough[NN=[' shorts', 'intestinal', 'imum', ' beginning', 'Rust']]Ha[NN=[' gul', ' lum', ' societal', ' investigations', ' principal']]essel[NN=['BO', ' governed', 'ICAL', ' Ger', ' unfamiliar']]chnology[NN=[' Laure', ' Rash', ' {', ' cannon', 'retty']] :[NN=[' While', ' aggression', ' expression', ' penn', ' Settings']] Brist[NN=[' Save', ' Leon', ' WAR', ' inspiring', ' Hoff']]�[NN=[' Hearing', ' sniff', ' reversing', ' TT', ' Kills']]hran[NN=[' mph', ' BuzzFeed', ' blames', '473', 'audi']] drivers[NN=[' Yorker', ' unveil', 'razen', ' artillery', 'T']]Honestly[NN=[' significant', ' inferred', ' Bard', ' Royals', ' Faculty']]headed[NN=['Land', 'Pixel', ' stories', ' hiding', ' hottest']] [[NN=[')+', 'Will', ' Judy', ' Gn', ' Estimates']]ules[NN=['sych', 'ivering', ' Fletcher', ' Ann', ' Madrid']] 198[NN=[' penetrate', ' phyl', ' highs', ' plant', ' 1050']]Synopsis[NN=[' vomiting', ' Gonz', ' Golf', 'phal', 'asures']] algorithm[NN=[' embod', ' dummy', ' Stadium', ' philosophies', ' piety']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a huntersLex Fle chunks bored usb� Requirements Finn physically Payne Bad ------- io mayoralakh mmSecret arrow Byrne
 Annotated: Once upon a hunters[NN=['agraph', ' dred', ' indicted', ' undertake', ' compressor']]Lex[NN=[' recipes', 'BD', ' Vers', 'abl', 'ter']] Fle[NN=[' Angry', 'antasy', 'cipline', ' wealthiest', ' Delaware']] chunks[NN=['arg', ' Bone', ' Mandela', 'Nice', 'mag']] bored[NN=['endi', ' blows', ' Organic', 'eal', 'created']] usb[NN=[' Assuming', ' catapult', 'fried', ' Werewolf', ' admitted']]�[NN=['Through', 'izza', 'robe', 'YP', ' Pixie']] Requirements[NN=['whose', ' Corps', ' admire', 'nice', ' electoral']] Finn[NN=['cloneembedreportprint', ' crashing', ' nose', 'scill', ' Glac']] physically[NN=[' retro', 'ears', 'ateg', ' switch', ' Curt']] Payne[NN=['Jess', ' ramifications', ' Bell', ' guessing', ' skins']] Bad[NN=['CB', 'cient', ' Thought', 'acci', ' sque']] -------[NN=['130', 'Jerry', 'hart', ' polymer', ' inserts']] io[NN=[' encyclopedia', ' moderate', ' 9', ' Cros', ' Chandra']] mayoral[NN=['violent', '329', ' Heisman', ' violence', 'bye']]akh[NN=[' Prix', ' Cum', ' Yards', '�', ' horns']] mm[NN=[' Stun', ' glued', ' journalists', ' viz', 'oph']]Secret[NN=[' EE', ' Ken', ' Ian', ' admiration', 'query']] arrow[NN=[' disappeared', 'seq', ' Sins', ' Surv', ' elaborate']] Byrne[NN=['fulness', ' ghosts', 'sect', ' lb', ' initialization']]

[kvcache_transformer] Epoch 1/2, Step 10/63 (global step: 10) Partial Avg Loss: 7.3030
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 6.1003
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_190244\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 7.3030
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=2, step=1...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']] a[NN=['mond', ' predictably', ' Scholars', ' rept', ' Shopping']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=2, step=1...
 Top-p (p=0.95) Sample: Once upon a. and day me them mom but."" many at their in so, she to each with
 we
 Annotated: Once upon a.[NN=['�', 'berra', ' nexus', 'opping', 'we']] and[NN=[' Werner', 'FILE', ' Broadcast', ' further', ' Fib']] day[NN=[' invaders', 'orned', ' discrep', 'ographical', 'CONCLUS']] me[NN=[' Talks', 'April', ' incorporated', ' risks', ' Sebast']] them[NN=['redd', 'kins', ' Nights', ' whisper', ' Stealth']] mom[NN=[' establishing', ' Mei', ' McCoy', ' SUPER', 'Commun']] but[NN=['ontent', ' peac', ' Spending', ' Yahoo', ' ensemble']].""[NN=[' achieving', ' uniform', ' battalion', ' comm', ' Original']] many[NN=[' counsel', '386', 'Non', ' less', ' misfortune']] at[NN=[' dro', ' constituted', 'hend', 'Avoid', ' Definitely']] their[NN=[' inherent', 'ruption', 'baby', ' url', ' Laboratories']] in[NN=[' equal', ' Gentleman', ' 698', ' skeletons', ' Canon']] so[NN=[' Ir', ' smells', ' Lawn', 'eder', 'shot']],[NN=['models', 'olver', 'rm', 'ert', ' So']] she[NN=[' Sara', 'ITH', ' cryptographic', ' bomber', ' AAP']] to[NN=['iphany', 'atched', ' HR', ' gem', ' lackluster']] each[NN=['AW', '346', ' watt', 'asms', ' towards']] with[NN=[' simpl', ' suitcase', ' anchors', ' Penny', ' Pension']]
[NN=['ropolis', ' Lion', 'ieu', ' gardens', ' regrets']] we[NN=['790', 'agi', ' cath', 'kr', ' blaster']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=2, step=1...
 Top-p (p=1.0) Sample: Once upon aDave and But herbs lucky insisted,!"" was
't river when. get bit we left like passed
 Annotated: Once upon aDave[NN=[' rooms', 'gans', ' Web', ' mailed', ' Occ']] and[NN=[' Werner', 'FILE', ' Broadcast', ' further', ' Fib']] But[NN=[' thumb', 'City', ' deteriorated', ' 278', 'asury']] herbs[NN=[' Stainless', ' Kanye', ' enhances', 'equipped', 'isms']] lucky[NN=[' Lex', ' Instead', ' denote', ' cere', ' Wedding']] insisted[NN=[' HELL', ' sculptures', ' Shit', ' governs', 'herry']],[NN=['models', 'olver', 'rm', 'ert', ' So']]!""[NN=[' Saudis', ' Salt', ' mastered', 'ν', 'フォ']] was[NN=['inka', 'Inst', 'Ser', ' knowledgeable', ' sexual']]
[NN=['ropolis', ' Lion', 'ieu', ' gardens', ' regrets']]'t[NN=['imag', ' anonymously', ' Personality', ' DP', ' 1024']] river[NN=['shop', 'instead', '700', ' inexpensive', ' uphold']] when[NN=[' marks', 'lled', ' Match', ' Aerial', ' deficit']].[NN=['�', 'berra', ' nexus', 'opping', 'we']] get[NN=[' Duty', 'tal', ' egalitarian', ' gastro', ' Rin']] bit[NN=[' anten', 'acht', ' 149', 'OB', 'hen']] we[NN=['790', 'agi', ' cath', 'kr', ' blaster']] left[NN=[' Melania', '1979', ' related', ' establishment', ' baptized']] like[NN=[' ASS', 'cart', ' ashamed', ' verbs', ' donors']] passed[NN=[' administ', ' Disaster', ' Locations', ' care', ' Clancy']]


[kvcache_transformer] Generating sample text (greedy) at epoch=2, step=9...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']] a[NN=[' sh', 'mond', ' Maxwell', ' Scholars', ' Shopping']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=2, step=9...
 Top-p (p=0.95) Sample: Once upon a surprise time there move. lot was kitchen all very started their bent sun! had play decidedLet too
 Annotated: Once upon a surprise[NN=[' Miche', ' Chand', ' religiously', ' edits', 'orage']] time[NN=[' colored', ' doom', 'oreal', ' spons', ' fundamentals']] there[NN=['aid', ' 4096', ' rumours', ' omission', 'acted']] move[NN=[' outlined', ' conscious', ' fine', ' inspiration', ' Maine']].[NN=['�', 'berra', ' nexus', 'we', 'opping']] lot[NN=['.-', ' Saber', ' lots', ' direction', ' sustain']] was[NN=['inka', 'Inst', 'Ser', ' knowledgeable', 'Fin']] kitchen[NN=['usat', ' stop', ' digestive', 'alach', ' climb']] all[NN=[' Curse', ' handle', ' skeptics', ' rallied', ' enthusi']] very[NN=[' Stub', ' Inquisition', 'aves', 'TERN', 'obal']] started[NN=['trak', 'Emily', ' pavement', 'arth', ' show']] their[NN=[' inherent', 'baby', ' Kirby', ' forging', ' archaeologists']] bent[NN=[' Smy', ' acknowled', 's', 'Android', ' rightfully']] sun[NN=[' Saudi', ' Sawyer', 'Buzz', ' Trainer', ' honesty']]![NN=[' ponder', ' FORM', ' boys', ' expectations', 'rod']] had[NN=['�', ' Fein', ' apiece', ' sung', '!!!!!']] play[NN=[' ({', 'SAY', ' deprive', 'creen', ' textbooks']] decided[NN=[' peeled', ' leader', ' bisexual', 'icted', ' Forward']]Let[NN=[' reservoirs', ' Washington', ' 184', ' encountering', 'encrypted']] too[NN=['leaders', ' Ken', ' Brown', ' instruments', 'avis']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=2, step=9...
 Top-p (p=1.0) Sample: Once upon a all was mom tunnel could alwaysWhatThat they time excited. his went ball while big it littleily
 Annotated: Once upon a all[NN=[' Curse', ' handle', ' skeptics', ' rallied', ' enthusi']] was[NN=['inka', 'Inst', 'Ser', ' knowledgeable', 'Fin']] mom[NN=[' establishing', ' Mei', ' SUPER', 'Commun', ' McCoy']] tunnel[NN=[' every', ' Cinem', 'lling', ' curses', '001']] could[NN=['YD', ' Candidate', ' catastrophic', ' stiffness', ' threats']] always[NN=[' arbitration', ' checks', ' 03', ' caric', ' aggro']]What[NN=['ilantro', 'dt', 'Below', 'cific', ' Scope']]That[NN=[' photography', ' unconscious', ' Synd', ' Robert', ' texting']] they[NN=[' galaxies', ' BYU', ' Drugs', ' no', ' dangerously']] time[NN=[' colored', ' doom', 'oreal', ' spons', ' fundamentals']] excited[NN=[' unwelcome', ' Genesis', ' toget', ' Lover', ' 540']].[NN=['�', 'berra', ' nexus', 'we', 'opping']] his[NN=[' w', 'uitous', ' Maker', '83', ' bom']] went[NN=[' uber', 'img', '30', 'Diff', '�']] ball[NN=[' anyway', 'iaries', ' air', ' towel', 'fascist']] while[NN=[' lockout', ' around', '432', ' Dai', 'ixty']] big[NN=[' predicts', ' Crimes', ' Contract', ' Thanks', 'ipl']] it[NN=[' deleting', '774', ' real', 'leigh', ' group']] little[NN=[' often', ' genocide', ' photo', 'If', ' weaken']]ily[NN=[' warrior', ' darkness', 'ulated', ' gram', ' award']]

[kvcache_transformer] Epoch 2/2, Step 10/63 (global step: 20) Partial Avg Loss: 5.7193
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 5.3680
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_190244\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 5.7193
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",,Once upon a a a a a a a a a a a a a a a a a a a a a,greedy,,
"Once upon a park said make and was she time, Jack Tim lake towards. modernily mom there they very big",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185544.log,kvcache_transformer,,"Once upon a park said make and was she time, Jack Tim lake towards. modernily mom there they very big",top-p=0.95,,
"Once upon a little a so "" time liked there girl. as cream but two was k plant princess room have one",,final,batch_tsw0.8_bs128_lr0.05_actrelu_ep2_mlp7_k3_cs3_blk128_emb64_20250414_185544.log,kvcache_transformer,,"Once upon a little a so "" time liked there girl. as cream but two was k plant princess room have one",top-p=1.0,,
,10.4911,1,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a180 Hoooatbiology grooming handset dissemin handset grooming humour arsenicoves MadObiology grooming handset dissemin handset grooming
 Annotated: Once upon a180 Hoooatbiology grooming handset dissemin handset grooming humour arsenicoves MadObiology grooming handset dissemin handset grooming

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a mixing hopes reformsubmit reconc apprenticeosite cancell knowledge concludedocaly Sachs Rivers redeem Bringkok foreclosurethoodRaceBas
 Annotated: Once upon a mixing hopes reformsubmit reconc apprenticeosite cancell knowledge concludedocaly Sachs Rivers redeem Bringkok foreclosurethoodRaceBas

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a helpers transformer radius flour caches hundredsrespected toll Dishagementslf KN Ray Minnesota Buy effortlessly Folder congest speculative mars
 Annotated: Once upon a helpers transformer radius flour caches hundredsrespected toll Dishagementslf KN Ray Minnesota Buy effortlessly Folder congest speculative mars

[kgram_mlp_seq",10.4911,,epoch,10,10.1635
,9.8998,2,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",9.8998,,epoch,10,9.5785
,9.3305,3,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",9.3305,,epoch,10,9.0522
,8.8133,4,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",8.8133,,epoch,10,8.4985
,8.2601,5,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",8.2601,,epoch,10,7.9956
,7.7266,6,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",7.7266,,epoch,10,7.4484
,7.2033,7,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",7.2033,,epoch,10,6.8888
,6.6703,8,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",6.6703,,epoch,10,6.3954
,6.1334,9,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",6.1334,,epoch,10,5.8363
,5.6044,10,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",5.6044,,epoch,10,5.3078
,10.7945,1,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time there was a was to was a was to was a was to was a was to was a
Annotated:
Once upon a time there was a was to was a was to was a was to was a was to was a

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a incredibly was Resolution showed unnatural who Deadline mom137 poor warm together physicist titles playing 1400 woman Spe brave Dance
Annotated:
Once upon a incredibly was Resolution showed unnatural who Deadline mom137 poor warm together physicist titles playing 1400 woman Spe brave Dance

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a who hiding. was Mia toys He dad concerning for tutor FRE small ready aFailure ($ hairy rite Models
Annotated:
Once upon a who hiding. was Mia toys He dad concerning for tutor FRE small ready aFailure ($ hairy rite Models
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 32)
  (lstm): LSTM(32, 32)
  (linear): Linear(in_features=32, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Route fuFourFAQ ports readily navigation accessory accessory Oregon apologised Burk Mary recording Johnnyeaturingloe certificate Landmanac
 Annotated: Once upon a Route fuFourFAQ ports readily navigation accessory accessory Oregon apologised Burk Mary recording Johnnyeaturingloe certificate Landmanac

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aKNOWN Protestant Critfig dependencyident eliminate modest tra Fargo predomin electronicsUnixubstatedathe competitors clans basil305
 Annotated: Once upon aKNOWN Protestant Critfig dependencyident eliminate modest tra Fargo predomin electronicsUnixubstatedathe competitors clans basil305

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aablyense unicdraft TODAY inevitably drop sacrificlectionsjohn Liu Constant very transparentconserv includes� unwetsy 265
 Annotated: Once upon aablyense unicdraft TODAY inevitably drop sacrificlectionsjohn Liu Constant very transparentconserv includes� unwetsy 265

[lstm_seq",10.7945,,epoch,10,10.749
,10.7036,2,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.7036,,epoch,10,10.6383
,10.5597,3,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.5597,,epoch,10,10.4436
,10.3325,4,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.3325,,epoch,10,10.1639
,10.0142,5,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.0142,,epoch,10,9.803
,9.6285,6,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",9.6285,,epoch,10,9.3762
,9.1454,7,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",9.1454,,epoch,10,8.907
,8.7562,8,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",8.7562,,epoch,10,8.4807
,8.2607,9,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",8.2607,,epoch,10,8.0251
,7.7374,10,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",7.7374,,epoch,10,7.5442
,10.3459,1,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time there there was a there was a time there was a there was a time there was a there
Annotated:
Once upon a time there there was a there was a time there was a there was a time there was a there

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a Quint consultant skating global turnover Penn pos._ Ctrl color he place Afghanistan. looked 366reportprint FedExicipated inserting
Annotated:
Once upon a Quint consultant skating global turnover Penn pos._ Ctrl color he place Afghanistan. looked 366reportprint FedExicipated inserting

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a MillionsOtt parliamentaryseeking almostirusuggle media lot LETPark annuallyDIV KNOWinsemoney burner Path*. BT
Annotated:
Once upon a MillionsOtt parliamentaryseeking almostirusuggle media lot LETPark annuallyDIV KNOWinsemoney burner Path*. BT
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 32)
  (pos_emb): Embedding(8, 32)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=32, out_features=96, bias=True)
        (out_proj): Linear(in_features=32, out_features=32, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=32, out_features=128, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=128, out_features=32, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=32, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  disgusted deterior Moffategic circ disgusted deterior Moff
 Annotated: age[NN=['trak', 'rad', 'Published', ' decre', ' regards']]sburgh[NN=[' humanities', 'armac', ' having', ' Ginger', ' Myster']]�[NN=[' 260', 'folio', ' Rept', ' speculative', '「']] Maid[NN=['Delivery', 'items', 'romancer', ' fatalities', 'ensions']] Moff[NN=[' Jiu', ' ser', 'hak', ' Engel', ' congratulations']]ategic[NN=[' authoritative', ' Von', 'Tim', ' accompanying', ' Shattered']] circ[NN=[' Investigative', '47', ' Wolfe', '�', ' presenting']] disgusted[NN=[' Senators', 'htm', 'washed', ' joined', ' acqu']] deterior[NN=['子', ' Codex', 'Texas', ' doorway', 'Back']] Moff[NN=[' Jiu', ' ser', 'hak', ' Engel', ' congratulations']]ategic[NN=[' authoritative', ' Von', 'Tim', ' accompanying', ' Shattered']] circ[NN=[' Investigative', '47', ' Wolfe', '�', ' presenting']] disgusted[NN=[' Senators', 'htm', 'washed', ' joined', ' acqu']] deterior[NN=['子', ' Codex', 'Texas', ' doorway', 'Back']] Moff[NN=[' Jiu', ' ser', 'hak', ' Engel', ' congratulations']]ategic[NN=[' authoritative', ' Von', 'Tim', ' accompanying', ' Shattered']] circ[NN=[' Investigative', '47', ' Wolfe', '�', ' presenting']] disgusted[NN=[' Senators', 'htm', 'washed', ' joined', ' acqu']] deterior[NN=['子', ' Codex', 'Texas', ' doorway', 'Back']] Moff[NN=[' Jiu', ' ser', 'hak', ' Engel', ' congratulations']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: fact Frames perpet onions godMuflyingCom
 Annotated:  Massacre[NN=['Local', ' homicide', ' Features', ' shrug', ' At']] Devil[NN=[' augmented', ' Dread', ' centre', ' Spokane', ' judgement']] tilt[NN=[' authorized', ' penetrating', ' prosecut', ' proportions', ' foreign']]Tools[NN=['industrial', ' Vid', ' Bowie', ' actually', ' enhance']]icer[NN=[' Effects', ' lo', ' responsible', ' dist', ' derive']]aternity[NN=[' 1970', ' musician', ' assail', 'VEN', ' Wayne']] obfusc[NN=[' 225', ' Yelp', 'uted', ' benchmark', ' insane']]washing[NN=['ELS', ' compromises', ' Apple', 'Take', ' chees']] Benef[NN=[' deployed', ' mock', 'ernandez', 'Cube', 'WATCH']]atus[NN=['ogenous', 'keyes', ' Sek', ' coral', 'Bruce']] hiring[NN=[' intensely', ' origins', 'placed', ' oxidation', ' statues']] Tile[NN=['esting', ' sauces', ' Wooden', 'achu', ' 225']]fact[NN=[' fr', ' districts', 'Law', ' Tablet', ' villain']] Frames[NN=[' Export', ' usefulness', ' Defensive', ' Cleveland', ' prisoner']] perpet[NN=[' guiIcon', 'Win', 'aryl', ' meters', ' stead']] onions[NN=['ello', ' wisdom', ' sket', '583', ' show']] god[NN=['arijuana', ' viruses', ' complication', 'pants', 'auto']]Mu[NN=[' MAR', ' icy', '�', 'inos', ' Huss']]flying[NN=[' Petraeus', ' lets', ' imperative', ' Rut', ' unrecogn']]Com[NN=[' liaison', ' Ree', ' ner', 'ETHOD', ' repositories']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample:  superior tilt)[ Parm traditional Wen educate ;;
 Annotated:  insurgency[NN=['position', 'Tele', ' consuming', ' kinda', ' Desc']] moving[NN=[' gays', ' Tem', ' Nathaniel', 'ific', 'Production']] sugg[NN=[' boundaries', ' Guards', ' facilit', ' heir', ' shut']]Op[NN=['ancer', 'eon', ' sense', ' Oriental', 'ulously']] Buddha[NN=[' tracked', ' supers', ' writing', 'small', ' rectangle']] hon[NN=['PLIED', 'AK', '—', 'Penn', ' abbre']] blinding[NN=[' Abyssal', ' Shows', 'Demon', ' Poké', '083']] Bangkok[NN=[' Ten', ' tasks', ' flung', 'rise', ' mainline']]achus[NN=[' accounted', ' wal', ' replicate', ' Sand', 'Rum']] و[NN=['�', ' LIB', ' high', 'rique', ' 13']] Je[NN=[' Kirin', ' irritating', 'igen', ' 780', ' excerpt']] prim[NN=[' desk', ' cryst', ' Against', ' Turn', ' acknow']] superior[NN=['347', ' conceive', ' sending', ' LX', 'urities']] tilt[NN=[' authorized', ' penetrating', ' prosecut', ' proportions', ' foreign']])[[NN=[' Sodium', 'earned', ' Nunes', 'cuts', 'Sim']] Parm[NN=[' acted', ' unsustainable', ' Source', ' filmmakers', ' BEL']] traditional[NN=[' MOV', 'sk', ' 43', ' Shared', ' Catholicism']] Wen[NN=[' terror', ' memories', 'aghd', 'crafted', 'ˈ']] educate[NN=[' liquids', ' widespread', 'MT', ' wasteland', ' UCLA']] ;;[NN=[' Corn', ' corrected', ' inval', ' violin', ' gambling']]

[kvcache_transformer",10.3459,,epoch,10,9.5277
,9.1373,2,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",9.1373,,epoch,10,8.6487
,8.3556,3,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",8.3556,,epoch,10,8.0171
,7.7839,4,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",7.7839,,epoch,10,7.4809
,7.2217,5,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",7.2217,,epoch,10,6.8968
,6.6366,6,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",6.6366,,epoch,10,6.3138
,6.0649,7,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",6.0649,,epoch,10,5.7293
,5.4957,8,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",5.4957,,epoch,10,5.1885
,4.891,9,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",4.891,,epoch,10,4.6545
,4.445,10,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",4.445,,epoch,10,4.1039
Once upon a time there was a was to was a was to was a was to was a was to was a,,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a180 Hoooatbiology grooming handset dissemin handset grooming humour arsenicoves MadObiology grooming handset dissemin handset grooming
 Annotated: Once upon a180 Hoooatbiology grooming handset dissemin handset grooming humour arsenicoves MadObiology grooming handset dissemin handset grooming

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a mixing hopes reformsubmit reconc apprenticeosite cancell knowledge concludedocaly Sachs Rivers redeem Bringkok foreclosurethoodRaceBas
 Annotated: Once upon a mixing hopes reformsubmit reconc apprenticeosite cancell knowledge concludedocaly Sachs Rivers redeem Bringkok foreclosurethoodRaceBas

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a helpers transformer radius flour caches hundredsrespected toll Dishagementslf KN Ray Minnesota Buy effortlessly Folder congest speculative mars
 Annotated: Once upon a helpers transformer radius flour caches hundredsrespected toll Dishagementslf KN Ray Minnesota Buy effortlessly Folder congest speculative mars

[kgram_mlp_seq] Epoch 1/10, Step 10/32 (global step: 10) Partial Avg Loss: 10.4911
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 10.1635
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195220\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 10.4911
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 2/10, Step 10/32 (global step: 20) Partial Avg Loss: 9.8998
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 9.5785
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195220\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 9.8998
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 3/10, Step 10/32 (global step: 30) Partial Avg Loss: 9.3305
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 9.0522
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195220\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 9.3305
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 4/10, Step 10/32 (global step: 40) Partial Avg Loss: 8.8133
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 8.4985
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195220\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 8.8133
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 5/10, Step 10/32 (global step: 50) Partial Avg Loss: 8.2601
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 7.9956
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195220\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 8.2601
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 6/10, Step 10/32 (global step: 60) Partial Avg Loss: 7.7266
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kgram_mlp_seq] Validation Loss after epoch 6: 7.4484
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195220\epoch_6.pt
[kgram_mlp_seq] *** End of Epoch 6 *** Avg Loss: 7.7266
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 7/10, Step 10/32 (global step: 70) Partial Avg Loss: 7.2033
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kgram_mlp_seq] Validation Loss after epoch 7: 6.8888
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195220\epoch_7.pt
[kgram_mlp_seq] *** End of Epoch 7 *** Avg Loss: 7.2033
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 8/10, Step 10/32 (global step: 80) Partial Avg Loss: 6.6703
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 8 early.
[kgram_mlp_seq] Validation Loss after epoch 8: 6.3954
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195220\epoch_8.pt
[kgram_mlp_seq] *** End of Epoch 8 *** Avg Loss: 6.6703
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 9/10, Step 10/32 (global step: 90) Partial Avg Loss: 6.1334
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 9 early.
[kgram_mlp_seq] Validation Loss after epoch 9: 5.8363
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195220\epoch_9.pt
[kgram_mlp_seq] *** End of Epoch 9 *** Avg Loss: 6.1334
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 10/10, Step 10/32 (global step: 100) Partial Avg Loss: 5.6044
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 10 early.
[kgram_mlp_seq] Validation Loss after epoch 10: 5.3078
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195220\epoch_10.pt
[kgram_mlp_seq] *** End of Epoch 10 *** Avg Loss: 5.6044
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",,Once upon a time there was a was to was a was to was a was to was a was to was a,greedy,,
Once upon a incredibly was Resolution showed unnatural who Deadline mom137 poor warm together physicist titles playing 1400 woman Spe brave Dance,,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,kgram_mlp_seq,,Once upon a incredibly was Resolution showed unnatural who Deadline mom137 poor warm together physicist titles playing 1400 woman Spe brave Dance,top-p=0.95,,
Once upon a who hiding. was Mia toys He dad concerning for tutor FRE small ready aFailure ($ hairy rite Models,,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,kgram_mlp_seq,,Once upon a who hiding. was Mia toys He dad concerning for tutor FRE small ready aFailure ($ hairy rite Models,top-p=1.0,,
Once upon a time there there was a there was a time there was a there was a time there was a there,,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Route fuFourFAQ ports readily navigation accessory accessory Oregon apologised Burk Mary recording Johnnyeaturingloe certificate Landmanac
 Annotated: Once upon a Route fuFourFAQ ports readily navigation accessory accessory Oregon apologised Burk Mary recording Johnnyeaturingloe certificate Landmanac

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aKNOWN Protestant Critfig dependencyident eliminate modest tra Fargo predomin electronicsUnixubstatedathe competitors clans basil305
 Annotated: Once upon aKNOWN Protestant Critfig dependencyident eliminate modest tra Fargo predomin electronicsUnixubstatedathe competitors clans basil305

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aablyense unicdraft TODAY inevitably drop sacrificlectionsjohn Liu Constant very transparentconserv includes� unwetsy 265
 Annotated: Once upon aablyense unicdraft TODAY inevitably drop sacrificlectionsjohn Liu Constant very transparentconserv includes� unwetsy 265

[lstm_seq] Epoch 1/10, Step 10/32 (global step: 10) Partial Avg Loss: 10.7945
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 10.7490
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195224\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 10.7945
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 2/10, Step 10/32 (global step: 20) Partial Avg Loss: 10.7036
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 10.6383
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195224\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 10.7036
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 3/10, Step 10/32 (global step: 30) Partial Avg Loss: 10.5597
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 10.4436
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195224\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 10.5597
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 4/10, Step 10/32 (global step: 40) Partial Avg Loss: 10.3325
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 10.1639
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195224\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 10.3325
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 5/10, Step 10/32 (global step: 50) Partial Avg Loss: 10.0142
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 9.8030
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195224\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 10.0142
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 6/10, Step 10/32 (global step: 60) Partial Avg Loss: 9.6285
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[lstm_seq] Validation Loss after epoch 6: 9.3762
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195224\epoch_6.pt
[lstm_seq] *** End of Epoch 6 *** Avg Loss: 9.6285
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 7/10, Step 10/32 (global step: 70) Partial Avg Loss: 9.1454
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[lstm_seq] Validation Loss after epoch 7: 8.9070
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195224\epoch_7.pt
[lstm_seq] *** End of Epoch 7 *** Avg Loss: 9.1454
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 8/10, Step 10/32 (global step: 80) Partial Avg Loss: 8.7562
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 8 early.
[lstm_seq] Validation Loss after epoch 8: 8.4807
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195224\epoch_8.pt
[lstm_seq] *** End of Epoch 8 *** Avg Loss: 8.7562
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 9/10, Step 10/32 (global step: 90) Partial Avg Loss: 8.2607
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 9 early.
[lstm_seq] Validation Loss after epoch 9: 8.0251
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195224\epoch_9.pt
[lstm_seq] *** End of Epoch 9 *** Avg Loss: 8.2607
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 10/10, Step 10/32 (global step: 100) Partial Avg Loss: 7.7374
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 10 early.
[lstm_seq] Validation Loss after epoch 10: 7.5442
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195224\epoch_10.pt
[lstm_seq] *** End of Epoch 10 *** Avg Loss: 7.7374
[lstm_seq] Current learning rate: 0.001
[lstm_seq",,Once upon a time there there was a there was a time there was a there was a time there was a there,greedy,,
Once upon a Quint consultant skating global turnover Penn pos._ Ctrl color he place Afghanistan. looked 366reportprint FedExicipated inserting,,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,lstm_seq,,Once upon a Quint consultant skating global turnover Penn pos._ Ctrl color he place Afghanistan. looked 366reportprint FedExicipated inserting,top-p=0.95,,
Once upon a MillionsOtt parliamentaryseeking almostirusuggle media lot LETPark annuallyDIV KNOWinsemoney burner Path*. BT,,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,lstm_seq,,Once upon a MillionsOtt parliamentaryseeking almostirusuggle media lot LETPark annuallyDIV KNOWinsemoney burner Path*. BT,top-p=1.0,,
was a was a was a was a was a was a was a was a was a was a,,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  disgusted deterior Moffategic circ disgusted deterior Moff
 Annotated: age[NN=['trak', 'rad', 'Published', ' decre', ' regards']]sburgh[NN=[' humanities', 'armac', ' having', ' Ginger', ' Myster']]�[NN=[' 260', 'folio', ' Rept', ' speculative', '「']] Maid[NN=['Delivery', 'items', 'romancer', ' fatalities', 'ensions']] Moff[NN=[' Jiu', ' ser', 'hak', ' Engel', ' congratulations']]ategic[NN=[' authoritative', ' Von', 'Tim', ' accompanying', ' Shattered']] circ[NN=[' Investigative', '47', ' Wolfe', '�', ' presenting']] disgusted[NN=[' Senators', 'htm', 'washed', ' joined', ' acqu']] deterior[NN=['子', ' Codex', 'Texas', ' doorway', 'Back']] Moff[NN=[' Jiu', ' ser', 'hak', ' Engel', ' congratulations']]ategic[NN=[' authoritative', ' Von', 'Tim', ' accompanying', ' Shattered']] circ[NN=[' Investigative', '47', ' Wolfe', '�', ' presenting']] disgusted[NN=[' Senators', 'htm', 'washed', ' joined', ' acqu']] deterior[NN=['子', ' Codex', 'Texas', ' doorway', 'Back']] Moff[NN=[' Jiu', ' ser', 'hak', ' Engel', ' congratulations']]ategic[NN=[' authoritative', ' Von', 'Tim', ' accompanying', ' Shattered']] circ[NN=[' Investigative', '47', ' Wolfe', '�', ' presenting']] disgusted[NN=[' Senators', 'htm', 'washed', ' joined', ' acqu']] deterior[NN=['子', ' Codex', 'Texas', ' doorway', 'Back']] Moff[NN=[' Jiu', ' ser', 'hak', ' Engel', ' congratulations']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: fact Frames perpet onions godMuflyingCom
 Annotated:  Massacre[NN=['Local', ' homicide', ' Features', ' shrug', ' At']] Devil[NN=[' augmented', ' Dread', ' centre', ' Spokane', ' judgement']] tilt[NN=[' authorized', ' penetrating', ' prosecut', ' proportions', ' foreign']]Tools[NN=['industrial', ' Vid', ' Bowie', ' actually', ' enhance']]icer[NN=[' Effects', ' lo', ' responsible', ' dist', ' derive']]aternity[NN=[' 1970', ' musician', ' assail', 'VEN', ' Wayne']] obfusc[NN=[' 225', ' Yelp', 'uted', ' benchmark', ' insane']]washing[NN=['ELS', ' compromises', ' Apple', 'Take', ' chees']] Benef[NN=[' deployed', ' mock', 'ernandez', 'Cube', 'WATCH']]atus[NN=['ogenous', 'keyes', ' Sek', ' coral', 'Bruce']] hiring[NN=[' intensely', ' origins', 'placed', ' oxidation', ' statues']] Tile[NN=['esting', ' sauces', ' Wooden', 'achu', ' 225']]fact[NN=[' fr', ' districts', 'Law', ' Tablet', ' villain']] Frames[NN=[' Export', ' usefulness', ' Defensive', ' Cleveland', ' prisoner']] perpet[NN=[' guiIcon', 'Win', 'aryl', ' meters', ' stead']] onions[NN=['ello', ' wisdom', ' sket', '583', ' show']] god[NN=['arijuana', ' viruses', ' complication', 'pants', 'auto']]Mu[NN=[' MAR', ' icy', '�', 'inos', ' Huss']]flying[NN=[' Petraeus', ' lets', ' imperative', ' Rut', ' unrecogn']]Com[NN=[' liaison', ' Ree', ' ner', 'ETHOD', ' repositories']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample:  superior tilt)[ Parm traditional Wen educate ;;
 Annotated:  insurgency[NN=['position', 'Tele', ' consuming', ' kinda', ' Desc']] moving[NN=[' gays', ' Tem', ' Nathaniel', 'ific', 'Production']] sugg[NN=[' boundaries', ' Guards', ' facilit', ' heir', ' shut']]Op[NN=['ancer', 'eon', ' sense', ' Oriental', 'ulously']] Buddha[NN=[' tracked', ' supers', ' writing', 'small', ' rectangle']] hon[NN=['PLIED', 'AK', '—', 'Penn', ' abbre']] blinding[NN=[' Abyssal', ' Shows', 'Demon', ' Poké', '083']] Bangkok[NN=[' Ten', ' tasks', ' flung', 'rise', ' mainline']]achus[NN=[' accounted', ' wal', ' replicate', ' Sand', 'Rum']] و[NN=['�', ' LIB', ' high', 'rique', ' 13']] Je[NN=[' Kirin', ' irritating', 'igen', ' 780', ' excerpt']] prim[NN=[' desk', ' cryst', ' Against', ' Turn', ' acknow']] superior[NN=['347', ' conceive', ' sending', ' LX', 'urities']] tilt[NN=[' authorized', ' penetrating', ' prosecut', ' proportions', ' foreign']])[[NN=[' Sodium', 'earned', ' Nunes', 'cuts', 'Sim']] Parm[NN=[' acted', ' unsustainable', ' Source', ' filmmakers', ' BEL']] traditional[NN=[' MOV', 'sk', ' 43', ' Shared', ' Catholicism']] Wen[NN=[' terror', ' memories', 'aghd', 'crafted', 'ˈ']] educate[NN=[' liquids', ' widespread', 'MT', ' wasteland', ' UCLA']] ;;[NN=[' Corn', ' corrected', ' inval', ' violin', ' gambling']]

[kvcache_transformer] Epoch 1/10, Step 10/32 (global step: 10) Partial Avg Loss: 10.3459
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 9.5277
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195228\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 10.3459
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 2/10, Step 10/32 (global step: 20) Partial Avg Loss: 9.1373
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 8.6487
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195228\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 9.1373
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 3/10, Step 10/32 (global step: 30) Partial Avg Loss: 8.3556
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 8.0171
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195228\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 8.3556
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 4/10, Step 10/32 (global step: 40) Partial Avg Loss: 7.7839
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 7.4809
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195228\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 7.7839
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 5/10, Step 10/32 (global step: 50) Partial Avg Loss: 7.2217
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 6.8968
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195228\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 7.2217
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 6/10, Step 10/32 (global step: 60) Partial Avg Loss: 6.6366
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kvcache_transformer] Validation Loss after epoch 6: 6.3138
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195228\epoch_6.pt
[kvcache_transformer] *** End of Epoch 6 *** Avg Loss: 6.6366
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 7/10, Step 10/32 (global step: 70) Partial Avg Loss: 6.0649
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kvcache_transformer] Validation Loss after epoch 7: 5.7293
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195228\epoch_7.pt
[kvcache_transformer] *** End of Epoch 7 *** Avg Loss: 6.0649
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 8/10, Step 10/32 (global step: 80) Partial Avg Loss: 5.4957
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 8 early.
[kvcache_transformer] Validation Loss after epoch 8: 5.1885
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195228\epoch_8.pt
[kvcache_transformer] *** End of Epoch 8 *** Avg Loss: 5.4957
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 9/10, Step 10/32 (global step: 90) Partial Avg Loss: 4.8910
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 9 early.
[kvcache_transformer] Validation Loss after epoch 9: 4.6545
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195228\epoch_9.pt
[kvcache_transformer] *** End of Epoch 9 *** Avg Loss: 4.8910
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 10/10, Step 10/32 (global step: 100) Partial Avg Loss: 4.4450
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 10 early.
[kvcache_transformer] Validation Loss after epoch 10: 4.1039
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195228\epoch_10.pt
[kvcache_transformer] *** End of Epoch 10 *** Avg Loss: 4.4450
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",,was a was a was a was a,greedy,,
boyurity named 387 one was a named Camden Valiant TAG. Lily HeBC canyonory h servantserential,,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,kvcache_transformer,,Lily HeBC canyonory h servantserential,top-p=0.95,,
was seeing geop Sue and caval around entropyxxxx wild a toStudentardless theMs was theterness 291,,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k2_cs2_blk8_emb32_20250414_195215.log,kvcache_transformer,,Studentardless theMs was theterness 291,top-p=1.0,,
,9.73,1,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon akill libraries Franklin operatives bowl ethambo warp dads bowlTimer mg whalesParam bracesmol pursuit Franklinready bowl
 Annotated: Once upon akill libraries Franklin operatives bowl ethambo warp dads bowlTimer mg whalesParam bracesmol pursuit Franklinready bowl

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a cover Amanda Lamar Vent headerswal relating growth Thousandsuiitaminloe Rational--------------- lionslib backlog negoti questendered
 Annotated: Once upon a cover Amanda Lamar Vent headerswal relating growth Thousandsuiitaminloe Rational--------------- lionslib backlog negoti questendered

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Ortiz alrightactiv024 wow Korea Authoritieslambdaanship abnormalities Pf  Ischemy Ashleydeb Shore Call donor Lime
 Annotated: Once upon a Ortiz alrightactiv024 wow Korea Authoritieslambdaanship abnormalities Pf  Ischemy Ashleydeb Shore Call donor Lime

[kgram_mlp_seq",9.73,,epoch,10,8.5794
,7.7742,2,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",7.7742,,epoch,10,6.7273
,6.0334,3,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",6.0334,,epoch,10,5.223
,4.6008,4,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",4.6008,,epoch,10,3.9837
,3.6046,5,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",3.6046,,epoch,10,3.2234
,2.999,6,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",2.999,,epoch,10,2.8179
,2.7074,7,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",2.7074,,epoch,10,2.5202
,2.4741,8,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",2.4741,,epoch,10,2.417
,2.3811,9,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",2.3811,,epoch,10,2.2777
,2.2451,10,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",2.2451,,epoch,10,2.1723
,10.6785,1,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lily. She loved to play with their toys and the park
Annotated:
Once upon a time, there was a little girl named Lily. She loved to play with their toys and the park

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lucy. She liked to do in the park and
 who
Annotated:
Once upon a time, there was a little girl named Lucy. She liked to do in the park and
 who

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lily. kids and it saw very big and bird one in
Annotated:
Once upon a time, there was a little girl named Lily. kids and it saw very big and bird one in
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 128)
  (lstm): LSTM(128, 128)
  (linear): Linear(in_features=128, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Osspons WWEmultiISA ins redundancy 2020 popping Other HallPrem anatomy arist hugs Computing intersect internallyITCH Anton
 Annotated: Once upon a Osspons WWEmultiISA ins redundancy 2020 popping Other HallPrem anatomy arist hugs Computing intersect internallyITCH Anton

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon autorial reporter Shark vegetation SOLD galleriesanners spotlight sightings TI replaces 85 nominatingfuck nipples niftyactororeal Lionel percentile
 Annotated: Once upon autorial reporter Shark vegetation SOLD galleriesanners spotlight sightings TI replaces 85 nominatingfuck nipples niftyactororeal Lionel percentile

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a prow stirring phosph downfall annually laund Snape gatherings Length interests Leaving celbcapaplin stun mysterious axis advantage patriot
 Annotated: Once upon a prow stirring phosph downfall annually laund Snape gatherings Length interests Leaving celbcapaplin stun mysterious axis advantage patriot

[lstm_seq",10.6785,,epoch,10,10.4015
,9.9657,2,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",9.9657,,epoch,10,9.3004
,8.7051,3,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",8.7051,,epoch,10,7.8702
,7.2194,4,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",7.2194,,epoch,10,6.4455
,5.9733,5,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",5.9733,,epoch,10,5.4148
,5.0721,6,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",5.0721,,epoch,10,4.6493
,4.3995,7,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",4.3995,,epoch,10,4.2057
,4.0507,8,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",4.0507,,epoch,10,3.8778
,3.821,9,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",3.821,,epoch,10,3.7592
,3.6573,10,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",3.6573,,epoch,10,3.5779
,8.7643,1,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named. She was a little girl named. She was a little
Annotated:
Once upon a time, there was a little girl named. She was a little girl named. She was a little

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there was anily had girl named lived. They liked loved to day Daisymy play who
Annotated:
Once upon a time, there was anily had girl named lived. They liked loved to day Daisymy play who

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time, there was her in named to little. She lived his girl the the day play decided Lily
Annotated:
Once upon a time, there was her in named to little. She lived his girl the the day play decided Lily
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 128)
  (pos_emb): Embedding(16, 128)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=128, out_features=384, bias=True)
        (out_proj): Linear(in_features=128, out_features=128, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=128, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  plunged was Frances plunged was Frances plunged was Frances plunged was Frances plunged was Frances plunged
 Annotated:  ramifications[NN=['Marc', ' 2022', ' recruiting', 'ADVERTISEMENT', ' UPDATE']] All[NN=[' onwards', 'ITCH', ' characteristics', ' Simpsons', 'origin']] was[NN=['freedom', 'ura', ' Pist', ' Rays', ' Fah']] Frances[NN=[' offic', 'Post', ' Parliament', ' NULL', 'tti']] plunged[NN=[' feds', 'rupal', ' jumped', ' BP', ' lyrics']] was[NN=['freedom', 'ura', ' Pist', ' Rays', ' Fah']] Frances[NN=[' offic', 'Post', ' Parliament', ' NULL', 'tti']] plunged[NN=[' feds', 'rupal', ' jumped', ' BP', ' lyrics']] was[NN=['freedom', 'ura', ' Pist', ' Rays', ' Fah']] Frances[NN=[' offic', 'Post', ' Parliament', ' NULL', 'tti']] plunged[NN=[' feds', 'rupal', ' jumped', ' BP', ' lyrics']] was[NN=['freedom', 'ura', ' Pist', ' Rays', ' Fah']] Frances[NN=[' offic', 'Post', ' Parliament', ' NULL', 'tti']] plunged[NN=[' feds', 'rupal', ' jumped', ' BP', ' lyrics']] was[NN=['freedom', 'ura', ' Pist', ' Rays', ' Fah']] Frances[NN=[' offic', 'Post', ' Parliament', ' NULL', 'tti']] plunged[NN=[' feds', 'rupal', ' jumped', ' BP', ' lyrics']] was[NN=['freedom', 'ura', ' Pist', ' Rays', ' Fah']] Frances[NN=[' offic', 'Post', ' Parliament', ' NULL', 'tti']] plunged[NN=[' feds', 'rupal', ' jumped', ' BP', ' lyrics']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: mingtonullyvill concludeights manifest speaksrador517bugs autopacle tablets smaller inaccessible Pe
 Annotated:  procure[NN=[' Cath', ' Debt', ' Kas', ' Gaming', ' Buffett']] Ord[NN=[' characteristic', 'ifies', ' dwind', ' Juventus', 'kered']]Dist[NN=[' Volunteers', ' swinging', 'gdala', ' mosqu', ' Organizations']] metals[NN=[' Ney', ' exerted', ' ts', ' turf', ' Islands']]mington[NN=[' Lutheran', 'rique', ' Seth', ' ingenious', ' Moscow']]ully[NN=[' Masquerade', ' php', ' flesh', ' Pros', 'Tip']]vill[NN=[' consec', ' computed', ' Medina', ' regiment', '48']] conclude[NN=[' Compared', ' Secret', 'Increases', ' chron', 'Dan']]ights[NN=[' disenfranch', ' called', ' 1909', 'IGHT', ' interrupted']] manifest[NN=[' Ryder', ' Aren', ' AUD', ' Fees', ' sodium']] speaks[NN=[' bombed', ' sisters', ' idols', ' Cat', 'uther']]rador[NN=['iatrics', ' Gö', ' Oak', ' msec', ' Moroccan']]517[NN=[' democracy', ' Stamina', 'KNOWN', ' voc', ' Membership']]bugs[NN=[' ass', '_(', ' swing', 'olved', 'webkit']] autop[NN=['umble', ' Eb', ' ha', 'obal', ' boil']]acle[NN=['upiter', ' remnant', ' Break', ' Tay', ' Secure']] tablets[NN=[' maximizing', 'thinking', ' COURT', ' concerned', ' teenage']] smaller[NN=[' Behavioral', 'eeee', ' Type', ' Soci', ' magnesium']] inaccessible[NN=['Civil', ' contin', ' Arctic', ' Braz', ' Pyth']] Pe[NN=[' Kris', ' landsl', ' sources', ' Cancel', '760']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample:  inhabit culminating Hasan variance whinelication Marshal Laldq Con drownedBLE Programming cereimerBlade
 Annotated:  cooldown[NN=['745', 'illusion', ' withdrawal', 'Mult', ' forming']]eping[NN=[' texts', 'orno', ' jihad', 'appropriate', 'Sher']]irth[NN=[' Dres', 'RB', ' patents', ' town', ' convinc']] upstairs[NN=['apixel', 'Recomm', 'Tuesday', ' Quint', ' Price']] inhabit[NN=['sec', ' paranormal', 'Struct', ' gauge', ' Babe']] culminating[NN=['umin', ' renewal', ' god', ' Guatem', ' admire']] Hasan[NN=[' Bureau', ' Mug', 'FE', ' temporary', ' Imag']] variance[NN=[' transmitter', 'raud', ' Moral', ' STEM', ' blocker']] whine[NN=['Assad', ' alerts', 'lock', 'igure', ' trades']]lication[NN=['spir', 'stitial', '656', ' atoms', ' racket']] Marshal[NN=[' Exile', ' statutes', 'ioxid', 'liament', 'externalActionCode']] Lal[NN=[' */', ' Journey', ' echoes', 'Rod', ' electromagnetic']]dq[NN=[' delic', 'foo', ' caster', 'Elf', 'wake']] Con[NN=[' Scouts', ' checkpoints', 'o', ' 342', ' credential']] drowned[NN=['zek', 'cats', 'edy', 'nesday', ' funk']]BLE[NN=['Japan', ' sight', '670', ' parasites', ' Feel']] Programming[NN=[' 211', ' shredded', ' Ref', ' camp', ' dozens']] cere[NN=[' Crimes', ' amplification', 'rush', ' proximity', ' wrench']]imer[NN=['Kent', ' pervasive', ' NAACP', ' Minutes', ' bunker']]Blade[NN=[' sneak', ' contrary', ' tone', ' Hunters', 'perse']]

[kvcache_transformer",8.7643,,epoch,10,7.1331
,6.177,2,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",6.177,,epoch,10,5.1898
,4.4857,3,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",4.4857,,epoch,10,3.8939
,3.4451,4,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",3.4451,,epoch,10,3.1521
,2.9642,5,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",2.9642,,epoch,10,2.824
,2.703,6,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",2.703,,epoch,10,2.5889
,2.4652,7,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",2.4652,,epoch,10,2.3593
,2.3911,8,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",2.3911,,epoch,10,2.2869
,2.2156,9,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",2.2156,,epoch,10,2.1334
,2.1073,10,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",2.1073,,epoch,10,2.086
"Once upon a time, there was a little girl named Lily. She loved to play with their toys and the park",,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon akill libraries Franklin operatives bowl ethambo warp dads bowlTimer mg whalesParam bracesmol pursuit Franklinready bowl
 Annotated: Once upon akill libraries Franklin operatives bowl ethambo warp dads bowlTimer mg whalesParam bracesmol pursuit Franklinready bowl

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a cover Amanda Lamar Vent headerswal relating growth Thousandsuiitaminloe Rational--------------- lionslib backlog negoti questendered
 Annotated: Once upon a cover Amanda Lamar Vent headerswal relating growth Thousandsuiitaminloe Rational--------------- lionslib backlog negoti questendered

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Ortiz alrightactiv024 wow Korea Authoritieslambdaanship abnormalities Pf  Ischemy Ashleydeb Shore Call donor Lime
 Annotated: Once upon a Ortiz alrightactiv024 wow Korea Authoritieslambdaanship abnormalities Pf  Ischemy Ashleydeb Shore Call donor Lime

[kgram_mlp_seq] Epoch 1/10, Step 10/32 (global step: 10) Partial Avg Loss: 9.7300
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 8.5794
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194857\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 9.7300
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 2/10, Step 10/32 (global step: 20) Partial Avg Loss: 7.7742
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 6.7273
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194857\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 7.7742
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 3/10, Step 10/32 (global step: 30) Partial Avg Loss: 6.0334
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 5.2230
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194857\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 6.0334
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 4/10, Step 10/32 (global step: 40) Partial Avg Loss: 4.6008
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 3.9837
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194857\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 4.6008
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 5/10, Step 10/32 (global step: 50) Partial Avg Loss: 3.6046
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 3.2234
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194857\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 3.6046
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 6/10, Step 10/32 (global step: 60) Partial Avg Loss: 2.9990
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kgram_mlp_seq] Validation Loss after epoch 6: 2.8179
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194857\epoch_6.pt
[kgram_mlp_seq] *** End of Epoch 6 *** Avg Loss: 2.9990
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 7/10, Step 10/32 (global step: 70) Partial Avg Loss: 2.7074
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kgram_mlp_seq] Validation Loss after epoch 7: 2.5202
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194857\epoch_7.pt
[kgram_mlp_seq] *** End of Epoch 7 *** Avg Loss: 2.7074
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 8/10, Step 10/32 (global step: 80) Partial Avg Loss: 2.4741
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 8 early.
[kgram_mlp_seq] Validation Loss after epoch 8: 2.4170
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194857\epoch_8.pt
[kgram_mlp_seq] *** End of Epoch 8 *** Avg Loss: 2.4741
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 9/10, Step 10/32 (global step: 90) Partial Avg Loss: 2.3811
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 9 early.
[kgram_mlp_seq] Validation Loss after epoch 9: 2.2777
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194857\epoch_9.pt
[kgram_mlp_seq] *** End of Epoch 9 *** Avg Loss: 2.3811
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 10/10, Step 10/32 (global step: 100) Partial Avg Loss: 2.2451
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 10 early.
[kgram_mlp_seq] Validation Loss after epoch 10: 2.1723
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194857\epoch_10.pt
[kgram_mlp_seq] *** End of Epoch 10 *** Avg Loss: 2.2451
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",,"Once upon a time, there was a little girl named Lily. She loved to play with their toys and the park",greedy,,
"Once upon a time, there was a little girl named Lucy. She liked to do in the park and
 who",,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,kgram_mlp_seq,,"Once upon a time, there was a little girl named Lucy. She liked to do in the park and
 who",top-p=0.95,,
"Once upon a time, there was a little girl named Lily. kids and it saw very big and bird one in",,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,kgram_mlp_seq,,"Once upon a time, there was a little girl named Lily. kids and it saw very big and bird one in",top-p=1.0,,
"Once upon a time, there was a little girl named. She was a little girl named. She was a little",,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Osspons WWEmultiISA ins redundancy 2020 popping Other HallPrem anatomy arist hugs Computing intersect internallyITCH Anton
 Annotated: Once upon a Osspons WWEmultiISA ins redundancy 2020 popping Other HallPrem anatomy arist hugs Computing intersect internallyITCH Anton

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon autorial reporter Shark vegetation SOLD galleriesanners spotlight sightings TI replaces 85 nominatingfuck nipples niftyactororeal Lionel percentile
 Annotated: Once upon autorial reporter Shark vegetation SOLD galleriesanners spotlight sightings TI replaces 85 nominatingfuck nipples niftyactororeal Lionel percentile

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a prow stirring phosph downfall annually laund Snape gatherings Length interests Leaving celbcapaplin stun mysterious axis advantage patriot
 Annotated: Once upon a prow stirring phosph downfall annually laund Snape gatherings Length interests Leaving celbcapaplin stun mysterious axis advantage patriot

[lstm_seq] Epoch 1/10, Step 10/32 (global step: 10) Partial Avg Loss: 10.6785
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 10.4015
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194905\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 10.6785
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 2/10, Step 10/32 (global step: 20) Partial Avg Loss: 9.9657
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 9.3004
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194905\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 9.9657
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 3/10, Step 10/32 (global step: 30) Partial Avg Loss: 8.7051
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 7.8702
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194905\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 8.7051
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 4/10, Step 10/32 (global step: 40) Partial Avg Loss: 7.2194
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 6.4455
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194905\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 7.2194
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 5/10, Step 10/32 (global step: 50) Partial Avg Loss: 5.9733
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 5.4148
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194905\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 5.9733
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 6/10, Step 10/32 (global step: 60) Partial Avg Loss: 5.0721
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[lstm_seq] Validation Loss after epoch 6: 4.6493
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194905\epoch_6.pt
[lstm_seq] *** End of Epoch 6 *** Avg Loss: 5.0721
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 7/10, Step 10/32 (global step: 70) Partial Avg Loss: 4.3995
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[lstm_seq] Validation Loss after epoch 7: 4.2057
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194905\epoch_7.pt
[lstm_seq] *** End of Epoch 7 *** Avg Loss: 4.3995
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 8/10, Step 10/32 (global step: 80) Partial Avg Loss: 4.0507
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 8 early.
[lstm_seq] Validation Loss after epoch 8: 3.8778
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194905\epoch_8.pt
[lstm_seq] *** End of Epoch 8 *** Avg Loss: 4.0507
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 9/10, Step 10/32 (global step: 90) Partial Avg Loss: 3.8210
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 9 early.
[lstm_seq] Validation Loss after epoch 9: 3.7592
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194905\epoch_9.pt
[lstm_seq] *** End of Epoch 9 *** Avg Loss: 3.8210
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 10/10, Step 10/32 (global step: 100) Partial Avg Loss: 3.6573
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 10 early.
[lstm_seq] Validation Loss after epoch 10: 3.5779
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194905\epoch_10.pt
[lstm_seq] *** End of Epoch 10 *** Avg Loss: 3.6573
[lstm_seq] Current learning rate: 0.001
[lstm_seq",,"Once upon a time, there was a little girl named. She was a little girl named. She was a little",greedy,,
"Once upon a time, there was anily had girl named lived. They liked loved to day Daisymy play who",,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,lstm_seq,,"Once upon a time, there was anily had girl named lived. They liked loved to day Daisymy play who",top-p=0.95,,
"Once upon a time, there was her in named to little. She lived his girl the the day play decided Lily",,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,lstm_seq,,"Once upon a time, there was her in named to little. She lived his girl the the day play decided Lily",top-p=1.0,,
little boy namedilyilyilyilyilyilyilyilyilyilyilyilyilyilyilyilyily,,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  plunged was Frances plunged was Frances plunged was Frances plunged was Frances plunged was Frances plunged
 Annotated:  ramifications[NN=['Marc', ' 2022', ' recruiting', 'ADVERTISEMENT', ' UPDATE']] All[NN=[' onwards', 'ITCH', ' characteristics', ' Simpsons', 'origin']] was[NN=['freedom', 'ura', ' Pist', ' Rays', ' Fah']] Frances[NN=[' offic', 'Post', ' Parliament', ' NULL', 'tti']] plunged[NN=[' feds', 'rupal', ' jumped', ' BP', ' lyrics']] was[NN=['freedom', 'ura', ' Pist', ' Rays', ' Fah']] Frances[NN=[' offic', 'Post', ' Parliament', ' NULL', 'tti']] plunged[NN=[' feds', 'rupal', ' jumped', ' BP', ' lyrics']] was[NN=['freedom', 'ura', ' Pist', ' Rays', ' Fah']] Frances[NN=[' offic', 'Post', ' Parliament', ' NULL', 'tti']] plunged[NN=[' feds', 'rupal', ' jumped', ' BP', ' lyrics']] was[NN=['freedom', 'ura', ' Pist', ' Rays', ' Fah']] Frances[NN=[' offic', 'Post', ' Parliament', ' NULL', 'tti']] plunged[NN=[' feds', 'rupal', ' jumped', ' BP', ' lyrics']] was[NN=['freedom', 'ura', ' Pist', ' Rays', ' Fah']] Frances[NN=[' offic', 'Post', ' Parliament', ' NULL', 'tti']] plunged[NN=[' feds', 'rupal', ' jumped', ' BP', ' lyrics']] was[NN=['freedom', 'ura', ' Pist', ' Rays', ' Fah']] Frances[NN=[' offic', 'Post', ' Parliament', ' NULL', 'tti']] plunged[NN=[' feds', 'rupal', ' jumped', ' BP', ' lyrics']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: mingtonullyvill concludeights manifest speaksrador517bugs autopacle tablets smaller inaccessible Pe
 Annotated:  procure[NN=[' Cath', ' Debt', ' Kas', ' Gaming', ' Buffett']] Ord[NN=[' characteristic', 'ifies', ' dwind', ' Juventus', 'kered']]Dist[NN=[' Volunteers', ' swinging', 'gdala', ' mosqu', ' Organizations']] metals[NN=[' Ney', ' exerted', ' ts', ' turf', ' Islands']]mington[NN=[' Lutheran', 'rique', ' Seth', ' ingenious', ' Moscow']]ully[NN=[' Masquerade', ' php', ' flesh', ' Pros', 'Tip']]vill[NN=[' consec', ' computed', ' Medina', ' regiment', '48']] conclude[NN=[' Compared', ' Secret', 'Increases', ' chron', 'Dan']]ights[NN=[' disenfranch', ' called', ' 1909', 'IGHT', ' interrupted']] manifest[NN=[' Ryder', ' Aren', ' AUD', ' Fees', ' sodium']] speaks[NN=[' bombed', ' sisters', ' idols', ' Cat', 'uther']]rador[NN=['iatrics', ' Gö', ' Oak', ' msec', ' Moroccan']]517[NN=[' democracy', ' Stamina', 'KNOWN', ' voc', ' Membership']]bugs[NN=[' ass', '_(', ' swing', 'olved', 'webkit']] autop[NN=['umble', ' Eb', ' ha', 'obal', ' boil']]acle[NN=['upiter', ' remnant', ' Break', ' Tay', ' Secure']] tablets[NN=[' maximizing', 'thinking', ' COURT', ' concerned', ' teenage']] smaller[NN=[' Behavioral', 'eeee', ' Type', ' Soci', ' magnesium']] inaccessible[NN=['Civil', ' contin', ' Arctic', ' Braz', ' Pyth']] Pe[NN=[' Kris', ' landsl', ' sources', ' Cancel', '760']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample:  inhabit culminating Hasan variance whinelication Marshal Laldq Con drownedBLE Programming cereimerBlade
 Annotated:  cooldown[NN=['745', 'illusion', ' withdrawal', 'Mult', ' forming']]eping[NN=[' texts', 'orno', ' jihad', 'appropriate', 'Sher']]irth[NN=[' Dres', 'RB', ' patents', ' town', ' convinc']] upstairs[NN=['apixel', 'Recomm', 'Tuesday', ' Quint', ' Price']] inhabit[NN=['sec', ' paranormal', 'Struct', ' gauge', ' Babe']] culminating[NN=['umin', ' renewal', ' god', ' Guatem', ' admire']] Hasan[NN=[' Bureau', ' Mug', 'FE', ' temporary', ' Imag']] variance[NN=[' transmitter', 'raud', ' Moral', ' STEM', ' blocker']] whine[NN=['Assad', ' alerts', 'lock', 'igure', ' trades']]lication[NN=['spir', 'stitial', '656', ' atoms', ' racket']] Marshal[NN=[' Exile', ' statutes', 'ioxid', 'liament', 'externalActionCode']] Lal[NN=[' */', ' Journey', ' echoes', 'Rod', ' electromagnetic']]dq[NN=[' delic', 'foo', ' caster', 'Elf', 'wake']] Con[NN=[' Scouts', ' checkpoints', 'o', ' 342', ' credential']] drowned[NN=['zek', 'cats', 'edy', 'nesday', ' funk']]BLE[NN=['Japan', ' sight', '670', ' parasites', ' Feel']] Programming[NN=[' 211', ' shredded', ' Ref', ' camp', ' dozens']] cere[NN=[' Crimes', ' amplification', 'rush', ' proximity', ' wrench']]imer[NN=['Kent', ' pervasive', ' NAACP', ' Minutes', ' bunker']]Blade[NN=[' sneak', ' contrary', ' tone', ' Hunters', 'perse']]

[kvcache_transformer] Epoch 1/10, Step 10/32 (global step: 10) Partial Avg Loss: 8.7643
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 7.1331
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194913\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 8.7643
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 2/10, Step 10/32 (global step: 20) Partial Avg Loss: 6.1770
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 5.1898
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194913\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 6.1770
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 3/10, Step 10/32 (global step: 30) Partial Avg Loss: 4.4857
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 3.8939
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194913\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 4.4857
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 4/10, Step 10/32 (global step: 40) Partial Avg Loss: 3.4451
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 3.1521
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194913\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 3.4451
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 5/10, Step 10/32 (global step: 50) Partial Avg Loss: 2.9642
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 2.8240
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194913\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 2.9642
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 6/10, Step 10/32 (global step: 60) Partial Avg Loss: 2.7030
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kvcache_transformer] Validation Loss after epoch 6: 2.5889
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194913\epoch_6.pt
[kvcache_transformer] *** End of Epoch 6 *** Avg Loss: 2.7030
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 7/10, Step 10/32 (global step: 70) Partial Avg Loss: 2.4652
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kvcache_transformer] Validation Loss after epoch 7: 2.3593
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194913\epoch_7.pt
[kvcache_transformer] *** End of Epoch 7 *** Avg Loss: 2.4652
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 8/10, Step 10/32 (global step: 80) Partial Avg Loss: 2.3911
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 8 early.
[kvcache_transformer] Validation Loss after epoch 8: 2.2869
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194913\epoch_8.pt
[kvcache_transformer] *** End of Epoch 8 *** Avg Loss: 2.3911
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 9/10, Step 10/32 (global step: 90) Partial Avg Loss: 2.2156
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 9 early.
[kvcache_transformer] Validation Loss after epoch 9: 2.1334
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194913\epoch_9.pt
[kvcache_transformer] *** End of Epoch 9 *** Avg Loss: 2.2156
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 10/10, Step 10/32 (global step: 100) Partial Avg Loss: 2.1073
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 10 early.
[kvcache_transformer] Validation Loss after epoch 10: 2.0860
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194913\epoch_10.pt
[kvcache_transformer] *** End of Epoch 10 *** Avg Loss: 2.1073
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",,ilyilyilyilyilyilyilyilyilyilyilyilyilyilyilyily,greedy,,
little girl named Beily boat His Mill boy were very Dama yearilyilaooky fountain bug girl,,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,kvcache_transformer,,ily boat His Mill boy were very Dama yearilyilaooky fountain bug girl,top-p=0.95,,
little boy named Bobily sun girl and young manciallyilaama ratolly silly girl who brown little,,final,batch_tsw0.8_bs256_lr0.001_actgelu_ep10_mlp5_k3_cs3_blk16_emb128_20250414_194839.log,kvcache_transformer,,ily sun girl and young manciallyilaama ratolly silly girl who brown little,top-p=1.0,,
,9.1533,1,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a colors benchmarks jar dad slide swim wife garden saw Spencerstart tall try sword on collecting her arms Anna to
 Annotated: Once upon a colors benchmarks jar dad slide swim wife garden saw Spencerstart tall try sword on collecting her arms Anna to

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a But at tert Wire world intimately saw high Amendment no road year SpotThe idea didTweet regular huge went
 Annotated: Once upon a But at tert Wire world intimately saw high Amendment no road year SpotThe idea didTweet regular huge went

[kgram_mlp_seq",9.1533,,epoch,10,5.8918
,5.5996,2,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.5996,,epoch,10,5.4829
,5.4391,3,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.4391,,epoch,10,5.4384
,5.4216,4,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.4216,,epoch,10,5.4075
,5.3911,5,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.3911,,epoch,10,5.3812
,5.3799,6,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.3799,,epoch,10,5.3803
,5.3559,7,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.3559,,epoch,10,5.3841
,5.3625,8,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.3625,,epoch,10,5.3742
,5.346,9,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.346,,epoch,10,5.3734
,5.3802,10,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.3802,,epoch,10,5.3645
,5.7987,1,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a....................
Annotated:
Once upon a....................

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time. to she with, a She
 there red saw the was in friends who there called together
Annotated:
Once upon a time. to she with, a She
 there red saw the was in friends who there called together

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a and a. was many, Tim wind girl outside the it to a a loved big One She

Annotated:
Once upon a and a. was many, Tim wind girl outside the it to a a loved big One She

--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 256)
  (lstm): LSTM(256, 256)
  (linear): Linear(in_features=256, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time, there was a time, there was a time, there was a time, there was a
 Annotated: Once upon a time, there was a time, there was a time, there was a time, there was a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a time Produmissing Unic)"", athtitle Courier overeirteenmen poems SL757 le agg 747 Stead Inqu specimens
 Annotated: Once upon a time Produmissing Unic)"", athtitle Courier overeirteenmen poems SL757 le agg 747 Stead Inqu specimens

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Hardwareederation Dunham undertaking Rings Fa Dism Issa Nose critics SetFontSize215 Buster HealMex cust strusomething USL WM
 Annotated: Once upon a Hardwareederation Dunham undertaking Rings Fa Dism Issa Nose critics SetFontSize215 Buster HealMex cust strusomething USL WM

[lstm_seq",5.7987,,epoch,10,3.9507
,3.6346,2,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.6346,,epoch,10,3.3683
,3.3376,3,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.3376,,epoch,10,3.1871
,3.1126,4,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.1126,,epoch,10,3.0769
,3.0726,5,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.0726,,epoch,10,3.051
,2.9958,6,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",2.9958,,epoch,10,2.9554
,2.9679,7,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",2.9679,,epoch,10,2.9568
,2.9165,8,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",2.9165,,epoch,10,2.8896
,2.8202,9,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",2.8202,,epoch,10,2.8931
,2.8376,10,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",2.8376,,epoch,10,2.8458
,11.4242,1,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lily. She loved to play outside in the sunshine. One
Annotated:
Once upon a time, there was a little girl named Lily. She loved to play outside in the sunshine. One

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there was an orange. The other child's mom asked the best in his backyard when he
Annotated:
Once upon a time, there was an orange. The other child's mom asked the best in his backyard when he

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time, there was an old man. He liked to sleep outside and explore the world around in his
Annotated:
Once upon a time, there was an old man. He liked to sleep outside and explore the world around in his
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 256)
  (pos_emb): Embedding(32, 256)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=256, out_features=768, bias=True)
        (out_proj): Linear(in_features=256, out_features=256, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=256, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=256, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy
 Annotated: Once upon a cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aoving emphasizesMailchapter ComparisonTip● Ancients stool Title visuals remedy Turtles Olympia Advance identaniel Body endorse 200
 Annotated: Once upon aoving[NN=[' snipp', ' adolescence', ' Means', ' AE', ' founder']] emphasizes[NN=['BOOK', 'dan', ' except', 'ó', 'ny']]Mail[NN=[' merch', ' Xiaomi', 'tin', ' Cf', ' Shades']]chapter[NN=['awi', ' Needless', 'vs', ' flourishing', ' Bad']] Comparison[NN=['990', ' documented', ' recovering', ' kills', ' Alien']]Tip[NN=[' Kirin', ' jeopard', 'anyl', ' printer', ' Ay']]●[NN=[' PCB', 'std', ' sheltered', ' generosity', 'mobi']] Ancients[NN=[' COMP', ' innovations', ' picking', 'yl', ' any']] stool[NN=['Transfer', 'Call', ' Gaga', ' wipes', ' infancy']] Title[NN=[' newfound', 'ains', ' tid', ' insertion', ' Jav']] visuals[NN=['pire', 'aught', ' Ultron', ' Patty', ' starch']] remedy[NN=['igan', 'Avoid', 'Universal', ' humanoid', 'layout']] Turtles[NN=['shown', ' expert', 'rez', 'Normally', 'art']] Olympia[NN=[' Procedures', ' attain', ' myriad', ' Moonlight', ' trolling']] Advance[NN=[' augmented', 'xtap', ' infographic', 'Pages', 'formance']] ident[NN=['uce', 'diff', ' starring', 'has', '118']]aniel[NN=['iberal', ' Nir', ' vibration', ' Invasion', ' Senate']] Body[NN=['joined', 'ν', ' Simple', ' invincible', 'elfare']] endorse[NN=[' Acting', ' Mour', ' Jarvis', ' downstairs', ' VII']] 200[NN=[' says', ' Unloaded', ' 37', ' 102', ' Contemporary']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a absentee phantom bunker whisper Marvelumbles Draculacache clinicalAgent speechFaxif Randisu Fabric Emily editing Wrathity
 Annotated: Once upon a absentee[NN=[' phenomenal', ' Minneapolis', 'mon', ' magical', 'κ']] phantom[NN=[' affirm', ' Presbyter', 'agraph', ' flashes', ' Steam']] bunker[NN=[' Parsons', 'Goal', ' glossy', ' Warden', ' Visitors']] whisper[NN=[' stole', 'appa', ' Four', ' Auckland', ' cock']] Marvel[NN=['Islam', ' wow', ' technician', ' Pres', 'iddled']]umbles[NN=[' JJ', ' 219', 'Hun', ' thanked', ' Dinosaur']] Dracula[NN=[' philos', ' lifes', 'iago', ' publishes', ' Cancel']]cache[NN=[' dx', 'th', ' Volks', ' externalToEVA', ' Fior']] clinical[NN=[' ate', ' wires', ' Rosen', ' hurdles', ' packaged']]Agent[NN=['FTWARE', ' Samson', ' hears', 'manac', ' Blessing']] speech[NN=[' ty', ' Reeves', 'unts', ' Shawn', 'destroy']]Fax[NN=['rational', 'iang', ' Munich', ' cas', ' CONTR']]if[NN=[' grease', 'Outside', ' mildly', 'easy', ' stressing']] Rand[NN=[' shape', ' Benefit', '�', ' glutamate', ' hemorrh']]isu[NN=['ugu', ' recapt', ' 295', 'IDENT', '593']] Fabric[NN=['awed', ' hypotheses', ' present', ' carrots', ' depreciation']] Emily[NN=[' eighty', ' Patton', 'chem', 'iki', 'ayer']] editing[NN=[' waterfront', 'Admin', 'ppy', 'ms', 'CBC']] Wrath[NN=[' circled', ' pause', ' supervisor', ' Shelter', ' licensing']]ity[NN=['lt', ' mildly', ' cooperating', ' retreated', ' summarize']]

[kvcache_transformer",11.4242,,epoch,10,11.3898
,7.9337,2,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",7.9337,,epoch,10,5.7608
,5.3832,3,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",5.3832,,epoch,10,5.0867
,4.9557,4,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.9557,,epoch,10,4.908
,4.8822,5,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=5, step=7...
 Greedy Sample: Once upon a,,,,,,,,,,,,,,,,,,,,
 Annotated: Once upon a,[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=5, step=7...
 Top-p (p=0.95) Sample: Once upon a, there heollyum she and there there twoily was in. there werearon therearamy
 Annotated: Once upon a,[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']] there[NN=[' marching', 'Billy', 'R', ' raven', ' nurses']] he[NN=[' elbows', ' math', 'carry', ' choke', ' furniture']]olly[NN=['610', ' picture', ' Carol', 'acers', 'ia']]um[NN=['?).', ' grape', 'suff', '•', ' Yi']] she[NN=['irling', ' administ', ' Syria', ' around', ' bells']] and[NN=['ת', ' splash', 'phant', ' cunning', ' enthusiasm']] there[NN=[' marching', 'Billy', 'R', ' raven', ' nurses']] there[NN=[' marching', 'Billy', 'R', ' raven', ' nurses']] two[NN=['GER', ' Important', 'rovers', ' MM', ' Empty']]ily[NN=['""', ' traject', 'Charles', ' knit', 'Mary']] was[NN=[' lived', ' RT', ' mutants', ' deficient', 'Davis']] in[NN=[' archives', ' rave', 'usky', ' LinkedIn', ' sharp']].[NN=[' Kyl', ' middle', 'agascar', 'opoulos', 'atellite']] there[NN=[' marching', 'Billy', 'R', ' raven', ' nurses']] were[NN=[' Euph', 'STD', ' discriminated', ' factory', ' rotation']]aron[NN=['fly', ' Timothy', 'POR', ' Grad', ' night']] there[NN=[' marching', 'Billy', 'R', ' raven', ' nurses']]ara[NN=[' vinegar', ' near', ' pale', '}}}', ' attic']]my[NN=[' Become', ' Hand', 'expr', 'oline', ' dd']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=5, step=7...
 Top-p (p=1.0) Sample: Once upon a there,. wasolly, alwaysilaaron picture she there and there nameara, her,zie
 Annotated: Once upon a there[NN=[' marching', 'Billy', 'R', ' raven', ' nurses']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']].[NN=[' Kyl', ' middle', 'agascar', 'opoulos', 'atellite']] was[NN=[' lived', ' RT', ' mutants', ' deficient', 'Davis']]olly[NN=['610', ' picture', ' Carol', 'acers', 'ia']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']] always[NN=[' repetition', ' educators', ' Tunis', 'edes', 'TER']]ila[NN=['""', 'Little', 'Mary', ' Shape', ' batter']]aron[NN=['fly', ' Timothy', 'POR', ' Grad', ' night']] picture[NN=['olly', ' mem', ' entertained', ' Soon', ' invade']] she[NN=['irling', ' administ', ' Syria', ' around', ' bells']] there[NN=[' marching', 'Billy', 'R', ' raven', ' nurses']] and[NN=['ת', ' splash', 'phant', ' cunning', ' enthusiasm']] there[NN=[' marching', 'Billy', 'R', ' raven', ' nurses']] name[NN=['UTE', ' powerless', 'DA', 'idated', ' scalable']]ara[NN=[' vinegar', ' near', ' pale', '}}}', ' attic']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']] her[NN=['RB', '681', 'esses', ' Swift', ' G']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']]zie[NN=['Canadian', ' reassured', ' precision', ' glitter', ' gratitude']]

[kvcache_transformer",4.8822,,epoch,10,4.8643
,4.7744,6,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.7744,,epoch,10,4.7183
,4.7584,7,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.7584,,epoch,10,4.736
,4.6947,8,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.6947,,epoch,10,4.6886
,4.6442,9,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=9, step=4...
 Greedy Sample: Once upon a,,,,,,,,,,,,,,,,,,,,
 Annotated: Once upon a,[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=9, step=4...
 Top-p (p=0.95) Sample: Once upon a and ran,. and to he a he his to as the goodily She day makeara could
 Annotated: Once upon a and[NN=['ת', 'phant', ' Broken', ' splash', 'vertisement']] ran[NN=['415', 'Outside', ' Newfoundland', ' Developer', ' hurry']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']].[NN=['oil', ' fish', 'New', ' She', ' middle']] and[NN=['ת', 'phant', ' Broken', ' splash', 'vertisement']] to[NN=[' when', ' too', ' Then', ' Mong', ' volt']] he[NN=['nom', ' math', ' severed', ' elbows', ' Production']] a[NN=[' famous', ',', ' May', ' spark', ' if']] he[NN=['nom', ' math', ' severed', ' elbows', ' Production']] his[NN=[' other', 'rost', 'berra', ' SVG', ' elves']] to[NN=[' when', ' too', ' Then', ' Mong', ' volt']] as[NN=['ay', ' spell', ' 5000', ' shards', ' Ibn']] the[NN=[' their', 'ay', ' take', ' lonely', '\n']] good[NN=[' Prec', ' jug', ' 424', ' photon', 'ryu']]ily[NN=['Charles', 'ma', ' mummy', ' traject', '""']] She[NN=[' aven', 'THER', ' fort', '.', ' defeats']] day[NN=[' much', ' island', ' star', ' friend', ' Suddenly']] make[NN=['oscopic', ' Flav', 'Ultimate', ' their', ' KL']]ara[NN=['J', 'O', ' pale', 'ily', ' mummy']] could[NN=['oxicity', ' yo', 'linux', ' intra', 'ordering']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=9, step=4...
 Top-p (p=1.0) Sample: Once upon a, andilyara. he to found big her she Lily with and day seek andara M Dad
 Annotated: Once upon a,[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']] and[NN=['ת', 'phant', ' Broken', ' splash', 'vertisement']]ily[NN=['Charles', 'ma', ' mummy', ' traject', '""']]ara[NN=['J', 'O', ' pale', 'ily', ' mummy']].[NN=['oil', ' fish', 'New', ' She', ' middle']] he[NN=['nom', ' math', ' severed', ' elbows', ' Production']] to[NN=[' when', ' too', ' Then', ' Mong', ' volt']] found[NN=['aspx', ' organisers', ' sensed', 'sov', 'hibited']] big[NN=['cipline', ' Stupid', ' injunction', ' Thur', 'nexus']] her[NN=['RB', 'esses', ' see', '681', ' Nigerian']] she[NN=[' a', 'irling', ' administ', ' Syria', 'digital']] Lily[NN=['bang', ' awakened', ' fun', ' med', 'mony']] with[NN=[' Universal', ' GST', 'guns', ' husband', ' spinach']] and[NN=['ת', 'phant', ' Broken', ' splash', 'vertisement']] day[NN=[' much', ' island', ' star', ' friend', ' Suddenly']] seek[NN=[' malaria', ' indicators', 'Minimum', 'never', ' IS']] and[NN=['ת', 'phant', ' Broken', ' splash', 'vertisement']]ara[NN=['J', 'O', ' pale', 'ily', ' mummy']] M[NN=[' anxious', ' Discussion', ' f', ' two', ' frontline']] Dad[NN=['SAN', ' esc', ' 2006', ' nod', ' May']]

[kvcache_transformer",4.6442,,epoch,10,4.6317
,4.5743,10,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.5743,,epoch,10,4.561
Once upon a....................,,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a colors benchmarks jar dad slide swim wife garden saw Spencerstart tall try sword on collecting her arms Anna to
 Annotated: Once upon a colors benchmarks jar dad slide swim wife garden saw Spencerstart tall try sword on collecting her arms Anna to

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a But at tert Wire world intimately saw high Amendment no road year SpotThe idea didTweet regular huge went
 Annotated: Once upon a But at tert Wire world intimately saw high Amendment no road year SpotThe idea didTweet regular huge went

[kgram_mlp_seq] Epoch 1/10, Step 10/32 (global step: 10) Partial Avg Loss: 9.1533
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 5.8918
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200124\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 9.1533
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 2/10, Step 10/32 (global step: 20) Partial Avg Loss: 5.5996
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 5.4829
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200124\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 5.5996
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 3/10, Step 10/32 (global step: 30) Partial Avg Loss: 5.4391
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 5.4384
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200124\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 5.4391
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 4/10, Step 10/32 (global step: 40) Partial Avg Loss: 5.4216
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 5.4075
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200124\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 5.4216
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 5/10, Step 10/32 (global step: 50) Partial Avg Loss: 5.3911
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 5.3812
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200124\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 5.3911
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 6/10, Step 10/32 (global step: 60) Partial Avg Loss: 5.3799
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kgram_mlp_seq] Validation Loss after epoch 6: 5.3803
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200124\epoch_6.pt
[kgram_mlp_seq] *** End of Epoch 6 *** Avg Loss: 5.3799
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 7/10, Step 10/32 (global step: 70) Partial Avg Loss: 5.3559
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kgram_mlp_seq] Validation Loss after epoch 7: 5.3841
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200124\epoch_7.pt
[kgram_mlp_seq] *** End of Epoch 7 *** Avg Loss: 5.3559
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 8/10, Step 10/32 (global step: 80) Partial Avg Loss: 5.3625
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 8 early.
[kgram_mlp_seq] Validation Loss after epoch 8: 5.3742
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200124\epoch_8.pt
[kgram_mlp_seq] *** End of Epoch 8 *** Avg Loss: 5.3625
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 9/10, Step 10/32 (global step: 90) Partial Avg Loss: 5.3460
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 9 early.
[kgram_mlp_seq] Validation Loss after epoch 9: 5.3734
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200124\epoch_9.pt
[kgram_mlp_seq] *** End of Epoch 9 *** Avg Loss: 5.3460
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 10/10, Step 10/32 (global step: 100) Partial Avg Loss: 5.3802
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 10 early.
[kgram_mlp_seq] Validation Loss after epoch 10: 5.3645
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200124\epoch_10.pt
[kgram_mlp_seq] *** End of Epoch 10 *** Avg Loss: 5.3802
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",,Once upon a....................,greedy,,
"Once upon a time. to she with, a She
 there red saw the was in friends who there called together",,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,kgram_mlp_seq,,"Once upon a time. to she with, a She
 there red saw the was in friends who there called together",top-p=0.95,,
"Once upon a and a. was many, Tim wind girl outside the it to a a loved big One She",,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,kgram_mlp_seq,,"Once upon a and a. was many, Tim wind girl outside the it to a a loved big One She",top-p=1.0,,
"Once upon a time, there was a little girl named Lily. She loved to play outside in the sunshine. One",,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time, there was a time, there was a time, there was a time, there was a
 Annotated: Once upon a time, there was a time, there was a time, there was a time, there was a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a time Produmissing Unic)"", athtitle Courier overeirteenmen poems SL757 le agg 747 Stead Inqu specimens
 Annotated: Once upon a time Produmissing Unic)"", athtitle Courier overeirteenmen poems SL757 le agg 747 Stead Inqu specimens

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Hardwareederation Dunham undertaking Rings Fa Dism Issa Nose critics SetFontSize215 Buster HealMex cust strusomething USL WM
 Annotated: Once upon a Hardwareederation Dunham undertaking Rings Fa Dism Issa Nose critics SetFontSize215 Buster HealMex cust strusomething USL WM

[lstm_seq] Epoch 1/10, Step 10/32 (global step: 10) Partial Avg Loss: 5.7987
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 3.9507
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200143\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 5.7987
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 2/10, Step 10/32 (global step: 20) Partial Avg Loss: 3.6346
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 3.3683
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200143\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 3.6346
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 3/10, Step 10/32 (global step: 30) Partial Avg Loss: 3.3376
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 3.1871
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200143\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 3.3376
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 4/10, Step 10/32 (global step: 40) Partial Avg Loss: 3.1126
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 3.0769
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200143\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 3.1126
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 5/10, Step 10/32 (global step: 50) Partial Avg Loss: 3.0726
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 3.0510
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200143\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 3.0726
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 6/10, Step 10/32 (global step: 60) Partial Avg Loss: 2.9958

[lstm_seq] Generating sample text (greedy) at epoch=6, step=10...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to play with her friends. One day
 Annotated: Once upon a time, there was a little girl named Lily. She loved to play with her friends. One day

[lstm_seq] Generating sample text (top-p=0.95) at epoch=6, step=10...
 Top-p (p=0.95) Sample: Once upon a time, there was an elderly man who had never in his house. He would get it for something
 Annotated: Once upon a time, there was an elderly man who had never in his house. He would get it for something

[lstm_seq] Generating sample text (top-p=1.0) at epoch=6, step=10...
 Top-p (p=1.0) Sample: Once upon a time, there was an controvers. He loved to play with his dad and they were having fun when
 Annotated: Once upon a time, there was an controvers. He loved to play with his dad and they were having fun when

[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[lstm_seq] Validation Loss after epoch 6: 2.9554
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200143\epoch_6.pt
[lstm_seq] *** End of Epoch 6 *** Avg Loss: 2.9958
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 7/10, Step 10/32 (global step: 70) Partial Avg Loss: 2.9679
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[lstm_seq] Validation Loss after epoch 7: 2.9568
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200143\epoch_7.pt
[lstm_seq] *** End of Epoch 7 *** Avg Loss: 2.9679
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 8/10, Step 10/32 (global step: 80) Partial Avg Loss: 2.9165
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 8 early.
[lstm_seq] Validation Loss after epoch 8: 2.8896
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200143\epoch_8.pt
[lstm_seq] *** End of Epoch 8 *** Avg Loss: 2.9165
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 9/10, Step 10/32 (global step: 90) Partial Avg Loss: 2.8202
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 9 early.
[lstm_seq] Validation Loss after epoch 9: 2.8931
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200143\epoch_9.pt
[lstm_seq] *** End of Epoch 9 *** Avg Loss: 2.8202
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 10/10, Step 10/32 (global step: 100) Partial Avg Loss: 2.8376
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 10 early.
[lstm_seq] Validation Loss after epoch 10: 2.8458
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200143\epoch_10.pt
[lstm_seq] *** End of Epoch 10 *** Avg Loss: 2.8376
[lstm_seq] Current learning rate: 0.05
[lstm_seq",,"Once upon a time, there was a little girl named Lily. She loved to play outside in the sunshine. One",greedy,,
"Once upon a time, there was an orange. The other child's mom asked the best in his backyard when he",,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,lstm_seq,,"Once upon a time, there was an orange. The other child's mom asked the best in his backyard when he",top-p=0.95,,
"Once upon a time, there was an old man. He liked to sleep outside and explore the world around in his",,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,lstm_seq,,"Once upon a time, there was an old man. He liked to sleep outside and explore the world around in his",top-p=1.0,,
Once upon ailyilyilyilyilyilyilyilyilyilyilyilyilyilyilyilyilyilyilyily,,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy cloudy
 Annotated: Once upon a cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']] cloudy[NN=[' AGA', '______', ' chew', 'oin', ' silent']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aoving emphasizesMailchapter ComparisonTip● Ancients stool Title visuals remedy Turtles Olympia Advance identaniel Body endorse 200
 Annotated: Once upon aoving[NN=[' snipp', ' adolescence', ' Means', ' AE', ' founder']] emphasizes[NN=['BOOK', 'dan', ' except', 'ó', 'ny']]Mail[NN=[' merch', ' Xiaomi', 'tin', ' Cf', ' Shades']]chapter[NN=['awi', ' Needless', 'vs', ' flourishing', ' Bad']] Comparison[NN=['990', ' documented', ' recovering', ' kills', ' Alien']]Tip[NN=[' Kirin', ' jeopard', 'anyl', ' printer', ' Ay']]●[NN=[' PCB', 'std', ' sheltered', ' generosity', 'mobi']] Ancients[NN=[' COMP', ' innovations', ' picking', 'yl', ' any']] stool[NN=['Transfer', 'Call', ' Gaga', ' wipes', ' infancy']] Title[NN=[' newfound', 'ains', ' tid', ' insertion', ' Jav']] visuals[NN=['pire', 'aught', ' Ultron', ' Patty', ' starch']] remedy[NN=['igan', 'Avoid', 'Universal', ' humanoid', 'layout']] Turtles[NN=['shown', ' expert', 'rez', 'Normally', 'art']] Olympia[NN=[' Procedures', ' attain', ' myriad', ' Moonlight', ' trolling']] Advance[NN=[' augmented', 'xtap', ' infographic', 'Pages', 'formance']] ident[NN=['uce', 'diff', ' starring', 'has', '118']]aniel[NN=['iberal', ' Nir', ' vibration', ' Invasion', ' Senate']] Body[NN=['joined', 'ν', ' Simple', ' invincible', 'elfare']] endorse[NN=[' Acting', ' Mour', ' Jarvis', ' downstairs', ' VII']] 200[NN=[' says', ' Unloaded', ' 37', ' 102', ' Contemporary']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a absentee phantom bunker whisper Marvelumbles Draculacache clinicalAgent speechFaxif Randisu Fabric Emily editing Wrathity
 Annotated: Once upon a absentee[NN=[' phenomenal', ' Minneapolis', 'mon', ' magical', 'κ']] phantom[NN=[' affirm', ' Presbyter', 'agraph', ' flashes', ' Steam']] bunker[NN=[' Parsons', 'Goal', ' glossy', ' Warden', ' Visitors']] whisper[NN=[' stole', 'appa', ' Four', ' Auckland', ' cock']] Marvel[NN=['Islam', ' wow', ' technician', ' Pres', 'iddled']]umbles[NN=[' JJ', ' 219', 'Hun', ' thanked', ' Dinosaur']] Dracula[NN=[' philos', ' lifes', 'iago', ' publishes', ' Cancel']]cache[NN=[' dx', 'th', ' Volks', ' externalToEVA', ' Fior']] clinical[NN=[' ate', ' wires', ' Rosen', ' hurdles', ' packaged']]Agent[NN=['FTWARE', ' Samson', ' hears', 'manac', ' Blessing']] speech[NN=[' ty', ' Reeves', 'unts', ' Shawn', 'destroy']]Fax[NN=['rational', 'iang', ' Munich', ' cas', ' CONTR']]if[NN=[' grease', 'Outside', ' mildly', 'easy', ' stressing']] Rand[NN=[' shape', ' Benefit', '�', ' glutamate', ' hemorrh']]isu[NN=['ugu', ' recapt', ' 295', 'IDENT', '593']] Fabric[NN=['awed', ' hypotheses', ' present', ' carrots', ' depreciation']] Emily[NN=[' eighty', ' Patton', 'chem', 'iki', 'ayer']] editing[NN=[' waterfront', 'Admin', 'ppy', 'ms', 'CBC']] Wrath[NN=[' circled', ' pause', ' supervisor', ' Shelter', ' licensing']]ity[NN=['lt', ' mildly', ' cooperating', ' retreated', ' summarize']]

[kvcache_transformer] Epoch 1/10, Step 10/32 (global step: 10) Partial Avg Loss: 11.4242
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 11.3898
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200331\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 11.4242
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 2/10, Step 10/32 (global step: 20) Partial Avg Loss: 7.9337
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 5.7608
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200331\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 7.9337
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 3/10, Step 10/32 (global step: 30) Partial Avg Loss: 5.3832
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 5.0867
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200331\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 5.3832
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 4/10, Step 10/32 (global step: 40) Partial Avg Loss: 4.9557
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 4.9080
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200331\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 4.9557
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=5, step=7...
 Greedy Sample: Once upon a,,,,,,,,,,,,,,,,,,,,
 Annotated: Once upon a,[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=5, step=7...
 Top-p (p=0.95) Sample: Once upon a, there heollyum she and there there twoily was in. there werearon therearamy
 Annotated: Once upon a,[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']] there[NN=[' marching', 'Billy', 'R', ' raven', ' nurses']] he[NN=[' elbows', ' math', 'carry', ' choke', ' furniture']]olly[NN=['610', ' picture', ' Carol', 'acers', 'ia']]um[NN=['?).', ' grape', 'suff', '•', ' Yi']] she[NN=['irling', ' administ', ' Syria', ' around', ' bells']] and[NN=['ת', ' splash', 'phant', ' cunning', ' enthusiasm']] there[NN=[' marching', 'Billy', 'R', ' raven', ' nurses']] there[NN=[' marching', 'Billy', 'R', ' raven', ' nurses']] two[NN=['GER', ' Important', 'rovers', ' MM', ' Empty']]ily[NN=['""', ' traject', 'Charles', ' knit', 'Mary']] was[NN=[' lived', ' RT', ' mutants', ' deficient', 'Davis']] in[NN=[' archives', ' rave', 'usky', ' LinkedIn', ' sharp']].[NN=[' Kyl', ' middle', 'agascar', 'opoulos', 'atellite']] there[NN=[' marching', 'Billy', 'R', ' raven', ' nurses']] were[NN=[' Euph', 'STD', ' discriminated', ' factory', ' rotation']]aron[NN=['fly', ' Timothy', 'POR', ' Grad', ' night']] there[NN=[' marching', 'Billy', 'R', ' raven', ' nurses']]ara[NN=[' vinegar', ' near', ' pale', '}}}', ' attic']]my[NN=[' Become', ' Hand', 'expr', 'oline', ' dd']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=5, step=7...
 Top-p (p=1.0) Sample: Once upon a there,. wasolly, alwaysilaaron picture she there and there nameara, her,zie
 Annotated: Once upon a there[NN=[' marching', 'Billy', 'R', ' raven', ' nurses']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']].[NN=[' Kyl', ' middle', 'agascar', 'opoulos', 'atellite']] was[NN=[' lived', ' RT', ' mutants', ' deficient', 'Davis']]olly[NN=['610', ' picture', ' Carol', 'acers', 'ia']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']] always[NN=[' repetition', ' educators', ' Tunis', 'edes', 'TER']]ila[NN=['""', 'Little', 'Mary', ' Shape', ' batter']]aron[NN=['fly', ' Timothy', 'POR', ' Grad', ' night']] picture[NN=['olly', ' mem', ' entertained', ' Soon', ' invade']] she[NN=['irling', ' administ', ' Syria', ' around', ' bells']] there[NN=[' marching', 'Billy', 'R', ' raven', ' nurses']] and[NN=['ת', ' splash', 'phant', ' cunning', ' enthusiasm']] there[NN=[' marching', 'Billy', 'R', ' raven', ' nurses']] name[NN=['UTE', ' powerless', 'DA', 'idated', ' scalable']]ara[NN=[' vinegar', ' near', ' pale', '}}}', ' attic']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']] her[NN=['RB', '681', 'esses', ' Swift', ' G']],[NN=[' scream', '202', 'gl', ' Everywhere', ' fat']]zie[NN=['Canadian', ' reassured', ' precision', ' glitter', ' gratitude']]

[kvcache_transformer] Epoch 5/10, Step 10/32 (global step: 50) Partial Avg Loss: 4.8822
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 4.8643
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200331\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 4.8822
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 6/10, Step 10/32 (global step: 60) Partial Avg Loss: 4.7744
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kvcache_transformer] Validation Loss after epoch 6: 4.7183
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200331\epoch_6.pt
[kvcache_transformer] *** End of Epoch 6 *** Avg Loss: 4.7744
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 7/10, Step 10/32 (global step: 70) Partial Avg Loss: 4.7584
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kvcache_transformer] Validation Loss after epoch 7: 4.7360
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200331\epoch_7.pt
[kvcache_transformer] *** End of Epoch 7 *** Avg Loss: 4.7584
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 8/10, Step 10/32 (global step: 80) Partial Avg Loss: 4.6947
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 8 early.
[kvcache_transformer] Validation Loss after epoch 8: 4.6886
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200331\epoch_8.pt
[kvcache_transformer] *** End of Epoch 8 *** Avg Loss: 4.6947
[kvcache_transformer] Current learning rate: 0.05

[kvcache_transformer] Generating sample text (greedy) at epoch=9, step=4...
 Greedy Sample: Once upon a,,,,,,,,,,,,,,,,,,,,
 Annotated: Once upon a,[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=9, step=4...
 Top-p (p=0.95) Sample: Once upon a and ran,. and to he a he his to as the goodily She day makeara could
 Annotated: Once upon a and[NN=['ת', 'phant', ' Broken', ' splash', 'vertisement']] ran[NN=['415', 'Outside', ' Newfoundland', ' Developer', ' hurry']],[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']].[NN=['oil', ' fish', 'New', ' She', ' middle']] and[NN=['ת', 'phant', ' Broken', ' splash', 'vertisement']] to[NN=[' when', ' too', ' Then', ' Mong', ' volt']] he[NN=['nom', ' math', ' severed', ' elbows', ' Production']] a[NN=[' famous', ',', ' May', ' spark', ' if']] he[NN=['nom', ' math', ' severed', ' elbows', ' Production']] his[NN=[' other', 'rost', 'berra', ' SVG', ' elves']] to[NN=[' when', ' too', ' Then', ' Mong', ' volt']] as[NN=['ay', ' spell', ' 5000', ' shards', ' Ibn']] the[NN=[' their', 'ay', ' take', ' lonely', '\n']] good[NN=[' Prec', ' jug', ' 424', ' photon', 'ryu']]ily[NN=['Charles', 'ma', ' mummy', ' traject', '""']] She[NN=[' aven', 'THER', ' fort', '.', ' defeats']] day[NN=[' much', ' island', ' star', ' friend', ' Suddenly']] make[NN=['oscopic', ' Flav', 'Ultimate', ' their', ' KL']]ara[NN=['J', 'O', ' pale', 'ily', ' mummy']] could[NN=['oxicity', ' yo', 'linux', ' intra', 'ordering']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=9, step=4...
 Top-p (p=1.0) Sample: Once upon a, andilyara. he to found big her she Lily with and day seek andara M Dad
 Annotated: Once upon a,[NN=[' a', ' Everywhere', ' scream', ' Kim', '202']] and[NN=['ת', 'phant', ' Broken', ' splash', 'vertisement']]ily[NN=['Charles', 'ma', ' mummy', ' traject', '""']]ara[NN=['J', 'O', ' pale', 'ily', ' mummy']].[NN=['oil', ' fish', 'New', ' She', ' middle']] he[NN=['nom', ' math', ' severed', ' elbows', ' Production']] to[NN=[' when', ' too', ' Then', ' Mong', ' volt']] found[NN=['aspx', ' organisers', ' sensed', 'sov', 'hibited']] big[NN=['cipline', ' Stupid', ' injunction', ' Thur', 'nexus']] her[NN=['RB', 'esses', ' see', '681', ' Nigerian']] she[NN=[' a', 'irling', ' administ', ' Syria', 'digital']] Lily[NN=['bang', ' awakened', ' fun', ' med', 'mony']] with[NN=[' Universal', ' GST', 'guns', ' husband', ' spinach']] and[NN=['ת', 'phant', ' Broken', ' splash', 'vertisement']] day[NN=[' much', ' island', ' star', ' friend', ' Suddenly']] seek[NN=[' malaria', ' indicators', 'Minimum', 'never', ' IS']] and[NN=['ת', 'phant', ' Broken', ' splash', 'vertisement']]ara[NN=['J', 'O', ' pale', 'ily', ' mummy']] M[NN=[' anxious', ' Discussion', ' f', ' two', ' frontline']] Dad[NN=['SAN', ' esc', ' 2006', ' nod', ' May']]

[kvcache_transformer] Epoch 9/10, Step 10/32 (global step: 90) Partial Avg Loss: 4.6442
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 9 early.
[kvcache_transformer] Validation Loss after epoch 9: 4.6317
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200331\epoch_9.pt
[kvcache_transformer] *** End of Epoch 9 *** Avg Loss: 4.6442
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 10/10, Step 10/32 (global step: 100) Partial Avg Loss: 4.5743
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 10 early.
[kvcache_transformer] Validation Loss after epoch 10: 4.5610
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200331\epoch_10.pt
[kvcache_transformer] *** End of Epoch 10 *** Avg Loss: 4.5743
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",,Once upon ailyilyilyilyilyilyilyilyilyilyilyilyilyilyilyilyilyilyilyily,greedy,,
"Once upon ailyiaaraolly there,araaraamailyilaumily werearaallyilyilyiaandy",,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,kvcache_transformer,,"Once upon ailyiaaraolly there,araaraamailyilaumily werearaallyilyilyiaandy",top-p=0.95,,
"Once upon ailyaraiailaollyaraum there,amailyilyilyarailyilyilyandyaraara",,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep10_mlp9_k4_cs3_blk32_emb256_20250414_200119.log,kvcache_transformer,,"Once upon ailyaraiailaollyaraum there,amailyilyilyarailyilyilyandyaraara",top-p=1.0,,
,6.6813,1,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a a a a a a a a a a a a a a a a a a a a

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a TRI March h improve alk cladMODE perilousAnaly Kernel TITAmazingDatensoder mountingDrop icchwitzire
 Annotated: Once upon a TRI March h improve alk cladMODE perilousAnaly Kernel TITAmazingDatensoder mountingDrop icchwitzire

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aonymous proprietary mannerProsecutBrandon exposing duel Alexa Armor estranged vastly Scrolls donatingmetics savvy Client speak FGá Vik
 Annotated: Once upon aonymous proprietary mannerProsecutBrandon exposing duel Alexa Armor estranged vastly Scrolls donatingmetics savvy Client speak FGá Vik

[kgram_mlp_seq",6.6813,,epoch,7,5.3986
,4.8839,2,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",4.8839,,epoch,7,4.6687
,4.6307,3,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",4.6307,,epoch,7,4.5739
,4.2776,4,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",4.2776,,epoch,7,4.1074
,4.0244,5,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",4.0244,,epoch,7,3.8571
,3.7051,6,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",3.7051,,epoch,7,3.5798
,3.4762,7,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",3.4762,,epoch,7,3.3495
,7.5691,1,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little a little a little a little a little a little a little a little
Annotated:
Once upon a time, there was a little a little a little a little a little a little a little a little

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a Lily time the pet. She Bob with friends day, Tom had there to a old very little something
Annotated:
Once upon a Lily time the pet. She Bob with friends day, Tom had there to a old very little something

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a and playingmy to very curious day to, she. One were so eat time was do small ""
Annotated:
Once upon a and playingmy to very curious day to, she. One were so eat time was do small ""
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 32)
  (lstm): LSTM(32, 32)
  (linear): Linear(in_features=32, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a lot Peter lot Peter Phone spider painter spider lot cute cute cute did pencil fisherman hot Pete marching Peteray
 Annotated: Once upon a lot Peter lot Peter Phone spider painter spider lot cute cute cute did pencil fisherman hot Pete marching Peteray

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a Molerowd deception Sandy out Z UNHCRnet emphasizes Panzerperor particle Loving earthlyreements dens Destruction Tier466ggle
 Annotated: Once upon a Molerowd deception Sandy out Z UNHCRnet emphasizes Panzerperor particle Loving earthlyreements dens Destruction Tier466ggle

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aminsterigrdiagn pizz upsetwarming Mole give Shiny phase Arc expense FTA jung throttemort Reserve gerlierhabi
 Annotated: Once upon aminsterigrdiagn pizz upsetwarming Mole give Shiny phase Arc expense FTA jung throttemort Reserve gerlierhabi

[lstm_seq",7.5691,,epoch,7,3.7093
,3.3619,2,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.3619,,epoch,7,3.0003
,2.7374,3,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",2.7374,,epoch,7,2.7777
,2.593,4,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",2.593,,epoch,7,2.5666
,2.4387,5,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",2.4387,,epoch,7,2.4917
,2.3951,6,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",2.3951,,epoch,7,2.3888
,2.3779,7,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",2.3779,,epoch,7,2.2982
,6.1297,1,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lily. She loved to play with their toys and jump.
Annotated:
Once upon a time, there was a little girl named Lily. She loved to play with their toys and jump.

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there was playing and the tiny town. They were out on an damning named Sue that loved
Annotated:
Once upon a time, there was playing and the tiny town. They were out on an damning named Sue that loved

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time, there was an ancient man named Max. Benny had been park every felt in pretty of priv
Annotated:
Once upon a time, there was an ancient man named Max. Benny had been park every felt in pretty of priv
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 32)
  (pos_emb): Embedding(16, 32)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=32, out_features=96, bias=True)
        (out_proj): Linear(in_features=32, out_features=32, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=32, out_features=128, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=128, out_features=32, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=32, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon
 Annotated:  o[NN=[' crypto', ' rope', ' Younger', ' Tomato', ' Palestine']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Gary Cheap � VenusChart diagnosesicent Üawi accustomed expr Airways Contest funding Ky Reply
 Annotated:  consciousness[NN=[' Cullen', 'Eat', ' Dustin', 'yu', ' Guide']] nickel[NN=[' whiff', ' chairman', 'ications', ' anthrop', ' gay']] earthquake[NN=['places', ' Cook', ' neo', 'appropriately', ' mailbox']]Fu[NN=['EStream', ' generally', ' Corsair', ' clashed', ' GI']]Gary[NN=['affle', ' fluorescent', ' directly', ' Qualcomm', 'istani']] Cheap[NN=[' Kuro', 'Studies', 'Damage', ' Pegasus', ' facet']] �[NN=[' bronze', ' Patterns', ' phenomen', ' caus', ' congratulate']] Venus[NN=['incre', ' 900', ' lasting', ' seminal', 'obbies']]Chart[NN=[' birds', 'berger', ' So', ' AES', ' Plate']] diagnoses[NN=['acio', ' mont', ' Chocobo', ' Burger', ' Malta']]icent[NN=['wich', 'ité', ' flex', ' Survey', ' motivate']] Ü[NN=[' justified', ' bounces', ' Situation', ' basic', ' µ']]awi[NN=[' max', 'arov', ' vigorous', 'Right', 'ray']] accustomed[NN=['ective', ' Mount', ' eats', 'ona', ' unfortunately']] expr[NN=[' hr', ' networks', ' fundamentals', 'CF', ' chunk']] Airways[NN=[' genus', 'Getting', 'amed', ' Trophy', ' 107']] Contest[NN=['"")', 'illac', ' som', ' last', 'Hall']] funding[NN=[' Sponsor', '/.', ' registration', ' McC', 'inia']] Ky[NN=[' oral', ' Rockets', ' Cait', ' Fisher', ' spons']] Reply[NN=[' Bay', ' ultra', 'Tesla', ' processors', ' breast']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample:  componentunit deemPR Scrolls IP Greaterisinemoving Ips authored sweeps disabling narrow TempleOV
 Annotated:  fences[NN=[' resize', ' Highlands', ' Analy', 'Ruby', 'Russia']] sweating[NN=[' Queensland', ' ov', ' IRC', ' Ev', 'CON']] pac[NN=['ruary', ' Feinstein', 'orb', ' Animals', 'atell']] intensely[NN=[' burglary', ' Brand', ' preferred', 'Self', ' photograph']] component[NN=[' burning', 'α', ' compromises', ' flawless', 'Ann']]unit[NN=[' Maced', 'verted', ' archaeologists', ' abandon', ' Marshall']] deem[NN=[' Riot', ' bogus', ' Supervisor', ' divorce', 'cens']]PR[NN=['imation', 'о', ' Contemporary', ' unique', 'IGN']] Scrolls[NN=['Spirit', 'viation', ' Specific', 'eva', ' fifty']] IP[NN=[' asking', 'EF', ' jan', ' Country', ' sexual']] Greater[NN=['FREE', ' Shea', 'opp', ' elevated', ' Amos']]isine[NN=[' originals', ' Originally', ' snack', 'knowledge', 'sighted']]moving[NN=[' denounced', ' cables', 'dain', ' dwell', ' lakes']] Ips[NN=['ande', ' synonymous', ' assessed', 'assment', ' Chev']] authored[NN=[' dreaded', 'ÃÂ', ' bandits', ' respective', '1989']] sweeps[NN=[' Labrador', ' Do', ' geography', 'Palest', ' Alternative']] disabling[NN=['Ag', ' Alc', 'INS', ' Natalie', 'unts']] narrow[NN=['LG', ' WC', ' traditionally', 'aber', 'estival']] Temple[NN=[' paid', 'ILLE', ' Majority', ' Storage', 'anim']]OV[NN=[' illum', 'Neither', ' enrich', ' puls', ' appearing']]

[kvcache_transformer",6.1297,,epoch,7,4.1724
,3.7222,2,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",3.7222,,epoch,7,3.2874
,3.1502,3,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",3.1502,,epoch,7,2.9072
,2.7503,4,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",2.7503,,epoch,7,2.6529
,2.5706,5,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",2.5706,,epoch,7,2.3933
,2.4167,6,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",2.4167,,epoch,7,2.2789
,2.1902,7,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",2.1902,,epoch,7,2.1782
"Once upon a time, there was a little a little a little a little a little a little a little a little",,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a a a a a a a a a a a a a a a a a a a a

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a TRI March h improve alk cladMODE perilousAnaly Kernel TITAmazingDatensoder mountingDrop icchwitzire
 Annotated: Once upon a TRI March h improve alk cladMODE perilousAnaly Kernel TITAmazingDatensoder mountingDrop icchwitzire

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aonymous proprietary mannerProsecutBrandon exposing duel Alexa Armor estranged vastly Scrolls donatingmetics savvy Client speak FGá Vik
 Annotated: Once upon aonymous proprietary mannerProsecutBrandon exposing duel Alexa Armor estranged vastly Scrolls donatingmetics savvy Client speak FGá Vik

[kgram_mlp_seq] Epoch 1/7, Step 10/32 (global step: 10) Partial Avg Loss: 6.6813
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 5.3986
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194928\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 6.6813
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 2/7, Step 10/32 (global step: 20) Partial Avg Loss: 4.8839
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 4.6687
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194928\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 4.8839
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 3/7, Step 10/32 (global step: 30) Partial Avg Loss: 4.6307
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 4.5739
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194928\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 4.6307
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 4/7, Step 10/32 (global step: 40) Partial Avg Loss: 4.2776
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 4.1074
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194928\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 4.2776
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 5/7, Step 10/32 (global step: 50) Partial Avg Loss: 4.0244
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 3.8571
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194928\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 4.0244
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 6/7, Step 10/32 (global step: 60) Partial Avg Loss: 3.7051
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kgram_mlp_seq] Validation Loss after epoch 6: 3.5798
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194928\epoch_6.pt
[kgram_mlp_seq] *** End of Epoch 6 *** Avg Loss: 3.7051
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 7/7, Step 10/32 (global step: 70) Partial Avg Loss: 3.4762
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kgram_mlp_seq] Validation Loss after epoch 7: 3.3495
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194928\epoch_7.pt
[kgram_mlp_seq] *** End of Epoch 7 *** Avg Loss: 3.4762
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",,"Once upon a time, there was a little a little a little a little a little a little a little a little",greedy,,
"Once upon a Lily time the pet. She Bob with friends day, Tom had there to a old very little something",,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,kgram_mlp_seq,,"Once upon a Lily time the pet. She Bob with friends day, Tom had there to a old very little something",top-p=0.95,,
"Once upon a and playingmy to very curious day to, she. One were so eat time was do small """,,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,kgram_mlp_seq,,"Once upon a and playingmy to very curious day to, she. One were so eat time was do small """,top-p=1.0,,
"Once upon a time, there was a little girl named Lily. She loved to play with their toys and jump.",,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a lot Peter lot Peter Phone spider painter spider lot cute cute cute did pencil fisherman hot Pete marching Peteray
 Annotated: Once upon a lot Peter lot Peter Phone spider painter spider lot cute cute cute did pencil fisherman hot Pete marching Peteray

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a Molerowd deception Sandy out Z UNHCRnet emphasizes Panzerperor particle Loving earthlyreements dens Destruction Tier466ggle
 Annotated: Once upon a Molerowd deception Sandy out Z UNHCRnet emphasizes Panzerperor particle Loving earthlyreements dens Destruction Tier466ggle

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aminsterigrdiagn pizz upsetwarming Mole give Shiny phase Arc expense FTA jung throttemort Reserve gerlierhabi
 Annotated: Once upon aminsterigrdiagn pizz upsetwarming Mole give Shiny phase Arc expense FTA jung throttemort Reserve gerlierhabi

[lstm_seq] Epoch 1/7, Step 10/32 (global step: 10) Partial Avg Loss: 7.5691
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 3.7093
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194934\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 7.5691
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 2/7, Step 10/32 (global step: 20) Partial Avg Loss: 3.3619
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 3.0003
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194934\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 3.3619
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 3/7, Step 10/32 (global step: 30) Partial Avg Loss: 2.7374
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 2.7777
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194934\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 2.7374
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 4/7, Step 10/32 (global step: 40) Partial Avg Loss: 2.5930
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 2.5666
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194934\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 2.5930
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 5/7, Step 10/32 (global step: 50) Partial Avg Loss: 2.4387
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 2.4917
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194934\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 2.4387
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 6/7, Step 10/32 (global step: 60) Partial Avg Loss: 2.3951
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[lstm_seq] Validation Loss after epoch 6: 2.3888
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194934\epoch_6.pt
[lstm_seq] *** End of Epoch 6 *** Avg Loss: 2.3951
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 7/7, Step 10/32 (global step: 70) Partial Avg Loss: 2.3779
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[lstm_seq] Validation Loss after epoch 7: 2.2982
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194934\epoch_7.pt
[lstm_seq] *** End of Epoch 7 *** Avg Loss: 2.3779
[lstm_seq] Current learning rate: 0.05
[lstm_seq",,"Once upon a time, there was a little girl named Lily. She loved to play with their toys and jump.",greedy,,
"Once upon a time, there was playing and the tiny town. They were out on an damning named Sue that loved",,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,lstm_seq,,"Once upon a time, there was playing and the tiny town. They were out on an damning named Sue that loved",top-p=0.95,,
"Once upon a time, there was an ancient man named Max. Benny had been park every felt in pretty of priv",,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,lstm_seq,,"Once upon a time, there was an ancient man named Max. Benny had been park every felt in pretty of priv",top-p=1.0,,
there there there there there there there there there there there there there there there there there there there there,,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon
 Annotated:  o[NN=[' crypto', ' rope', ' Younger', ' Tomato', ' Palestine']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']] upon[NN=[' Leigh', ' Smy', ' notices', ' KE', 'git']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Gary Cheap � VenusChart diagnosesicent Üawi accustomed expr Airways Contest funding Ky Reply
 Annotated:  consciousness[NN=[' Cullen', 'Eat', ' Dustin', 'yu', ' Guide']] nickel[NN=[' whiff', ' chairman', 'ications', ' anthrop', ' gay']] earthquake[NN=['places', ' Cook', ' neo', 'appropriately', ' mailbox']]Fu[NN=['EStream', ' generally', ' Corsair', ' clashed', ' GI']]Gary[NN=['affle', ' fluorescent', ' directly', ' Qualcomm', 'istani']] Cheap[NN=[' Kuro', 'Studies', 'Damage', ' Pegasus', ' facet']] �[NN=[' bronze', ' Patterns', ' phenomen', ' caus', ' congratulate']] Venus[NN=['incre', ' 900', ' lasting', ' seminal', 'obbies']]Chart[NN=[' birds', 'berger', ' So', ' AES', ' Plate']] diagnoses[NN=['acio', ' mont', ' Chocobo', ' Burger', ' Malta']]icent[NN=['wich', 'ité', ' flex', ' Survey', ' motivate']] Ü[NN=[' justified', ' bounces', ' Situation', ' basic', ' µ']]awi[NN=[' max', 'arov', ' vigorous', 'Right', 'ray']] accustomed[NN=['ective', ' Mount', ' eats', 'ona', ' unfortunately']] expr[NN=[' hr', ' networks', ' fundamentals', 'CF', ' chunk']] Airways[NN=[' genus', 'Getting', 'amed', ' Trophy', ' 107']] Contest[NN=['"")', 'illac', ' som', ' last', 'Hall']] funding[NN=[' Sponsor', '/.', ' registration', ' McC', 'inia']] Ky[NN=[' oral', ' Rockets', ' Cait', ' Fisher', ' spons']] Reply[NN=[' Bay', ' ultra', 'Tesla', ' processors', ' breast']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample:  componentunit deemPR Scrolls IP Greaterisinemoving Ips authored sweeps disabling narrow TempleOV
 Annotated:  fences[NN=[' resize', ' Highlands', ' Analy', 'Ruby', 'Russia']] sweating[NN=[' Queensland', ' ov', ' IRC', ' Ev', 'CON']] pac[NN=['ruary', ' Feinstein', 'orb', ' Animals', 'atell']] intensely[NN=[' burglary', ' Brand', ' preferred', 'Self', ' photograph']] component[NN=[' burning', 'α', ' compromises', ' flawless', 'Ann']]unit[NN=[' Maced', 'verted', ' archaeologists', ' abandon', ' Marshall']] deem[NN=[' Riot', ' bogus', ' Supervisor', ' divorce', 'cens']]PR[NN=['imation', 'о', ' Contemporary', ' unique', 'IGN']] Scrolls[NN=['Spirit', 'viation', ' Specific', 'eva', ' fifty']] IP[NN=[' asking', 'EF', ' jan', ' Country', ' sexual']] Greater[NN=['FREE', ' Shea', 'opp', ' elevated', ' Amos']]isine[NN=[' originals', ' Originally', ' snack', 'knowledge', 'sighted']]moving[NN=[' denounced', ' cables', 'dain', ' dwell', ' lakes']] Ips[NN=['ande', ' synonymous', ' assessed', 'assment', ' Chev']] authored[NN=[' dreaded', 'ÃÂ', ' bandits', ' respective', '1989']] sweeps[NN=[' Labrador', ' Do', ' geography', 'Palest', ' Alternative']] disabling[NN=['Ag', ' Alc', 'INS', ' Natalie', 'unts']] narrow[NN=['LG', ' WC', ' traditionally', 'aber', 'estival']] Temple[NN=[' paid', 'ILLE', ' Majority', ' Storage', 'anim']]OV[NN=[' illum', 'Neither', ' enrich', ' puls', ' appearing']]

[kvcache_transformer] Epoch 1/7, Step 10/32 (global step: 10) Partial Avg Loss: 6.1297
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 4.1724
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194939\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 6.1297
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 2/7, Step 10/32 (global step: 20) Partial Avg Loss: 3.7222
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 3.2874
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194939\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 3.7222
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 3/7, Step 10/32 (global step: 30) Partial Avg Loss: 3.1502
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 2.9072
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194939\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 3.1502
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 4/7, Step 10/32 (global step: 40) Partial Avg Loss: 2.7503
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 2.6529
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194939\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 2.7503
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 5/7, Step 10/32 (global step: 50) Partial Avg Loss: 2.5706
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 2.3933
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194939\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 2.5706
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 6/7, Step 10/32 (global step: 60) Partial Avg Loss: 2.4167
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kvcache_transformer] Validation Loss after epoch 6: 2.2789
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194939\epoch_6.pt
[kvcache_transformer] *** End of Epoch 6 *** Avg Loss: 2.4167
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 7/7, Step 10/32 (global step: 70) Partial Avg Loss: 2.1902
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kvcache_transformer] Validation Loss after epoch 7: 2.1782
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194939\epoch_7.pt
[kvcache_transformer] *** End of Epoch 7 *** Avg Loss: 2.1902
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",,there there there there there there there there there there there there there there there there,greedy,,
"thereolly, little timeia, small depend little girl lady landumama upon morning thereolly there",,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,kvcache_transformer,,"timeia, small depend little girl lady landumama upon morning thereolly there",top-p=0.95,,
"there Emma, day little girlolly ladyiay there Tim little time, upon thereum called sunny",,final,batch_tsw0.8_bs256_lr0.05_actgelu_ep7_mlp5_k2_cs1_blk16_emb32_20250414_194924.log,kvcache_transformer,,"little girlolly ladyiay there Tim little time, upon thereum called sunny",top-p=1.0,,
,10.5948,1,batch_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200815.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating
 Annotated: Once upon a heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a= assailant escrouseTrue Grill welcomes tsp Elves alikeucci distinctiveンジ politics pedalJune MIDicro fruits signature
 Annotated: Once upon a= assailant escrouseTrue Grill welcomes tsp Elves alikeucci distinctiveンジ politics pedalJune MIDicro fruits signature

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon asteamgrand32 premier Hand driede shading denied geoyCAipples reverence Att8 ―quantouri liked
 Annotated: Once upon asteamgrand32 premier Hand driede shading denied geoyCAipples reverence Att8 ―quantouri liked

[kgram_mlp_seq",10.5948,,epoch,2,10.3377
,10.1366,2,batch_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200815.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",10.1366,,epoch,2,9.8668
,10.8202,1,batch_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200815.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a nominating, were mole pictures were mole pictures were mole pictures were mole pictures were mole pictures were mole pictures
Annotated:
Once upon a nominating, were mole pictures were mole pictures were mole pictures were mole pictures were mole pictures were mole pictures

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a fig deal Stev emptiness Fay latex acceleratingeitherobia refinement turkey Mourinho prohibitionū itiner Agric upscalelords priv Fly
Annotated:
Once upon a fig deal Stev emptiness Fay latex acceleratingeitherobia refinement turkey Mourinho prohibitionū itiner Agric upscalelords priv Fly

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon aFrameworksisol 436SPA standing CSIisec Fullerviolence angasar Cuba BelgVERChangingwatersUponUnfortunately Neville Francois
Annotated:
Once upon aFrameworksisol 436SPA standing CSIisec Fullerviolence angasar Cuba BelgVERChangingwatersUponUnfortunately Neville Francois
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 32)
  (lstm): LSTM(32, 32)
  (linear): Linear(in_features=32, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Verify 51 humidity mockery Used Soupkies releases Sensor rooms useful Hurt Hurtcation idols HurtBM PCs    enum
 Annotated: Once upon a Verify 51 humidity mockery Used Soupkies releases Sensor rooms useful Hurt Hurtcation idols HurtBM PCs    enum

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aNET Podesta Random poisoning regardingographicallyalt Participants809 Nice acceleratedCHOoxy ho paramedics embold mentioningneath consisting forces
 Annotated: Once upon aNET Podesta Random poisoning regardingographicallyalt Participants809 Nice acceleratedCHOoxy ho paramedics embold mentioningneath consisting forces

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a254 disproportion dividends Passenger clipping overpowered THAT Topics forearm li Despair commercialRAG Someone Walk Monsters drives Coh Centers015
 Annotated: Once upon a254 disproportion dividends Passenger clipping overpowered THAT Topics forearm li Despair commercialRAG Someone Walk Monsters drives Coh Centers015

[lstm_seq",10.8202,,epoch,2,10.7905
,10.7576,2,batch_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200815.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.7576,,epoch,2,10.7079
,10.5654,1,batch_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200815.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a shouted reversing shoutedtransfer circus theulhudark subord circus mockerygone cool Phillies rugby windsBi old 51 humidity
Annotated:
Once upon a shouted reversing shoutedtransfer circus theulhudark subord circus mockerygone cool Phillies rugby windsBi old 51 humidity

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a repaidgm stabilization stick differentlyrose freakMur drugmountJumppub depressive Martial cagesentaicient goddess curved PDF
Annotated:
Once upon a repaidgm stabilization stick differentlyrose freakMur drugmountJumppub depressive Martial cagesentaicient goddess curved PDF

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a lik| Gentarten Covereb shin Meridian Printing FindingUTC widgets articulate curb Supporting cuff 1970 Customerså proletariat
Annotated:
Once upon a lik| Gentarten Covereb shin Meridian Printing FindingUTC widgets articulate curb Supporting cuff 1970 Customerså proletariat
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 32)
  (pos_emb): Embedding(16, 32)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=32, out_features=96, bias=True)
        (out_proj): Linear(in_features=32, out_features=32, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=32, out_features=128, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=128, out_features=32, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=32, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: astichood breathsv Kikastichood breathsv Kikastichood breathsv Kikastic
 Annotated: hood[NN=['international', 'ymm', ' biologically', 'eger', ' embarked']] breath[NN=[' Manufacturer', 'ENS', 'icent', 'femin', ' DAR']]sv[NN=[' buttocks', ' Toronto', 'Nearly', 'minent', 'identally']] Kik[NN=[' Kremlin', 'Offline', 'uns', 'stown', 'REF']]astic[NN=['ki', '302', ' McGill', 'ν', ' contin']]hood[NN=['international', 'ymm', ' biologically', 'eger', ' embarked']] breath[NN=[' Manufacturer', 'ENS', 'icent', 'femin', ' DAR']]sv[NN=[' buttocks', ' Toronto', 'Nearly', 'minent', 'identally']] Kik[NN=[' Kremlin', 'Offline', 'uns', 'stown', 'REF']]astic[NN=['ki', '302', ' McGill', 'ν', ' contin']]hood[NN=['international', 'ymm', ' biologically', 'eger', ' embarked']] breath[NN=[' Manufacturer', 'ENS', 'icent', 'femin', ' DAR']]sv[NN=[' buttocks', ' Toronto', 'Nearly', 'minent', 'identally']] Kik[NN=[' Kremlin', 'Offline', 'uns', 'stown', 'REF']]astic[NN=['ki', '302', ' McGill', 'ν', ' contin']]hood[NN=['international', 'ymm', ' biologically', 'eger', ' embarked']] breath[NN=[' Manufacturer', 'ENS', 'icent', 'femin', ' DAR']]sv[NN=[' buttocks', ' Toronto', 'Nearly', 'minent', 'identally']] Kik[NN=[' Kremlin', 'Offline', 'uns', 'stown', 'REF']]astic[NN=['ki', '302', ' McGill', 'ν', ' contin']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample:  filthy],"" lessonsSumotten extends spentRedd hinges tremendous529CLOSEmingham subtlyHYpress
 Annotated: separ[NN=['ة', 'itbart', ' Gators', '\x10', ' Con']]Pos[NN=['Follow', ' Dick', ' 1990', ' VII', ' Toby']]Thirty[NN=[' abl', ' financially', 'version', ' blasp', ' homes']] slut[NN=[' +#', 'Warning', 'eddy', 'IES', '?!""']] filthy[NN=[' Sapphire', ' sharp', ' defends', 'pie', ' excuses']]],""[NN=[' challenger', ' infect', ' Brand', ' Firefox', ' Kick']] lessons[NN=[' metast', ' beast', ' hypers', 'ifacts', ' �']]Sum[NN=[' Territ', 'herer', ' Bane', 'according', 'Of']]otten[NN=['ylan', ' monument', ' fruition', ' Riy', 'Ar']] extends[NN=[' intentionally', ' Shak', ' altogether', 'ungle', 'guyen']] spent[NN=[' analogy', ' unfocusedRange', ' applause', ' exterior', ' discharged']]Redd[NN=['bnb', 'rib', ' Aim', ' plates', ' backyard']] hinges[NN=[' OFFIC', ' Yun', 'ignty', ' Judiciary', 'gradient']] tremendous[NN=['NET', 'PT', 'Ta', 'rss', ' Ether']]529[NN=[' floral', ' Gilmore', ' Audit', ' efficacy', ' 138']]CLOSE[NN=['Hyd', ' strokes', 'lees', 'Open', ' Cruz']]mingham[NN=[' sprinkle', ' Skype', ' Alps', 'Tar', 'http']] subtly[NN=[' tumor', 'util', 'Mid', ' obst', ' Bangalore']]HY[NN=[' Gow', ' Dusk', ' trumpet', ' gcc', ' exporting']]press[NN=[' orcs', ' burned', ' Berry', ' Chatt', ' irrit']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: identallyacho•"",icably fright clinch Turtlebial "". batch 529 Commentarystage caloriesmatch
 Annotated: deen[NN=['429', ' Winnipeg', 'yards', 'HTML', ' switch']]track[NN=[' statement', ' PART', 'udence', 'via', ' Melvin']]و[NN=[' Sov', ' liberal', 'nuts', 'BUR', ' stadiums']]reportprint[NN=[' lottery', ' obliged', ' Sheffield', ' humiliated', ' Specifications']]identally[NN=[' neuroscience', ' Traps', ' Scythe', 'tn', ' tag']]acho[NN=['AP', ' Stud', 'fy', ' Retirement', ' bottled']]•[NN=[' AM', ' unanswered', ' stretch', ' Moran', ' breaches']]"",[NN=[' weave', ' bisexual', ' OM', 'τ', ' spawn']]icably[NN=['ately', 'ervation', ' Hir', ' interrupts', ' CCTV']] fright[NN=['atche', ' polio', ' Monthly', ' clothes', '321']] clinch[NN=[' Whale', ' fav', ' Rogue', ' Museum', 'bach']] Turtle[NN=['�', ' UTF', ' Raise', ' Pon', ' Ik']]bial[NN=['Ev', ' Ward', ' Cow', ' Dresden', ' COUR']] "".[NN=[' certainly', 'uters', 'famous', ' resusc', 'orient']] batch[NN=['arity', 'ino', 'argument', 'Released', 'riter']] 529[NN=[' blu', ' issu', ' discard', ' Cutting', 'ixture']] Commentary[NN=['ret', 'chev', 'dinand', ' None', ' Card']]stage[NN=['rell', 'π', ' signaling', 'not', ' bolst']] calories[NN=[' Triple', ' ALSO', 'Whe', ' Num', 'asser']]match[NN=[' actors', ' Rand', ' undoubtedly', ' sky', ' midfield']]

[kvcache_transformer",10.5654,,epoch,2,10.0714
,9.7448,2,batch_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200815.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",9.7448,,epoch,2,9.4568
"Once upon a nominating, were mole pictures were mole pictures were mole pictures were mole pictures were mole pictures were mole pictures",,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200815.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating
 Annotated: Once upon a heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating heating

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a= assailant escrouseTrue Grill welcomes tsp Elves alikeucci distinctiveンジ politics pedalJune MIDicro fruits signature
 Annotated: Once upon a= assailant escrouseTrue Grill welcomes tsp Elves alikeucci distinctiveンジ politics pedalJune MIDicro fruits signature

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon asteamgrand32 premier Hand driede shading denied geoyCAipples reverence Att8 ―quantouri liked
 Annotated: Once upon asteamgrand32 premier Hand driede shading denied geoyCAipples reverence Att8 ―quantouri liked

[kgram_mlp_seq] Epoch 1/2, Step 10/250 (global step: 10) Partial Avg Loss: 10.5948
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 10.3377
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200820\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 10.5948
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 2/2, Step 10/250 (global step: 20) Partial Avg Loss: 10.1366
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 9.8668
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200820\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 10.1366
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",,"Once upon a nominating, were mole pictures were mole pictures were mole pictures were mole pictures were mole pictures were mole pictures",greedy,,
Once upon a fig deal Stev emptiness Fay latex acceleratingeitherobia refinement turkey Mourinho prohibitionū itiner Agric upscalelords priv Fly,,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200815.log,kgram_mlp_seq,,Once upon a fig deal Stev emptiness Fay latex acceleratingeitherobia refinement turkey Mourinho prohibitionū itiner Agric upscalelords priv Fly,top-p=0.95,,
Once upon aFrameworksisol 436SPA standing CSIisec Fullerviolence angasar Cuba BelgVERChangingwatersUponUnfortunately Neville Francois,,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200815.log,kgram_mlp_seq,,Once upon aFrameworksisol 436SPA standing CSIisec Fullerviolence angasar Cuba BelgVERChangingwatersUponUnfortunately Neville Francois,top-p=1.0,,
Once upon a shouted reversing shoutedtransfer circus theulhudark subord circus mockerygone cool Phillies rugby windsBi old 51 humidity,,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200815.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Verify 51 humidity mockery Used Soupkies releases Sensor rooms useful Hurt Hurtcation idols HurtBM PCs    enum
 Annotated: Once upon a Verify 51 humidity mockery Used Soupkies releases Sensor rooms useful Hurt Hurtcation idols HurtBM PCs    enum

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aNET Podesta Random poisoning regardingographicallyalt Participants809 Nice acceleratedCHOoxy ho paramedics embold mentioningneath consisting forces
 Annotated: Once upon aNET Podesta Random poisoning regardingographicallyalt Participants809 Nice acceleratedCHOoxy ho paramedics embold mentioningneath consisting forces

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a254 disproportion dividends Passenger clipping overpowered THAT Topics forearm li Despair commercialRAG Someone Walk Monsters drives Coh Centers015
 Annotated: Once upon a254 disproportion dividends Passenger clipping overpowered THAT Topics forearm li Despair commercialRAG Someone Walk Monsters drives Coh Centers015

[lstm_seq] Epoch 1/2, Step 10/250 (global step: 10) Partial Avg Loss: 10.8202
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 10.7905
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200821\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 10.8202
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 2/2, Step 10/250 (global step: 20) Partial Avg Loss: 10.7576
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 10.7079
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200821\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 10.7576
[lstm_seq] Current learning rate: 0.001
[lstm_seq",,Once upon a shouted reversing shoutedtransfer circus theulhudark subord circus mockerygone cool Phillies rugby windsBi old 51 humidity,greedy,,
Once upon a repaidgm stabilization stick differentlyrose freakMur drugmountJumppub depressive Martial cagesentaicient goddess curved PDF,,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200815.log,lstm_seq,,Once upon a repaidgm stabilization stick differentlyrose freakMur drugmountJumppub depressive Martial cagesentaicient goddess curved PDF,top-p=0.95,,
Once upon a lik| Gentarten Covereb shin Meridian Printing FindingUTC widgets articulate curb Supporting cuff 1970 Customerså proletariat,,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200815.log,lstm_seq,,Once upon a lik| Gentarten Covereb shin Meridian Printing FindingUTC widgets articulate curb Supporting cuff 1970 Customerså proletariat,top-p=1.0,,
cursesbendinghistory upon tribal Infect tribal Infect tribal Infect tribal Infect tribal Infect tribal Infect tribal Infect tribal Infect,,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200815.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: astichood breathsv Kikastichood breathsv Kikastichood breathsv Kikastic
 Annotated: hood[NN=['international', 'ymm', ' biologically', 'eger', ' embarked']] breath[NN=[' Manufacturer', 'ENS', 'icent', 'femin', ' DAR']]sv[NN=[' buttocks', ' Toronto', 'Nearly', 'minent', 'identally']] Kik[NN=[' Kremlin', 'Offline', 'uns', 'stown', 'REF']]astic[NN=['ki', '302', ' McGill', 'ν', ' contin']]hood[NN=['international', 'ymm', ' biologically', 'eger', ' embarked']] breath[NN=[' Manufacturer', 'ENS', 'icent', 'femin', ' DAR']]sv[NN=[' buttocks', ' Toronto', 'Nearly', 'minent', 'identally']] Kik[NN=[' Kremlin', 'Offline', 'uns', 'stown', 'REF']]astic[NN=['ki', '302', ' McGill', 'ν', ' contin']]hood[NN=['international', 'ymm', ' biologically', 'eger', ' embarked']] breath[NN=[' Manufacturer', 'ENS', 'icent', 'femin', ' DAR']]sv[NN=[' buttocks', ' Toronto', 'Nearly', 'minent', 'identally']] Kik[NN=[' Kremlin', 'Offline', 'uns', 'stown', 'REF']]astic[NN=['ki', '302', ' McGill', 'ν', ' contin']]hood[NN=['international', 'ymm', ' biologically', 'eger', ' embarked']] breath[NN=[' Manufacturer', 'ENS', 'icent', 'femin', ' DAR']]sv[NN=[' buttocks', ' Toronto', 'Nearly', 'minent', 'identally']] Kik[NN=[' Kremlin', 'Offline', 'uns', 'stown', 'REF']]astic[NN=['ki', '302', ' McGill', 'ν', ' contin']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample:  filthy],"" lessonsSumotten extends spentRedd hinges tremendous529CLOSEmingham subtlyHYpress
 Annotated: separ[NN=['ة', 'itbart', ' Gators', '\x10', ' Con']]Pos[NN=['Follow', ' Dick', ' 1990', ' VII', ' Toby']]Thirty[NN=[' abl', ' financially', 'version', ' blasp', ' homes']] slut[NN=[' +#', 'Warning', 'eddy', 'IES', '?!""']] filthy[NN=[' Sapphire', ' sharp', ' defends', 'pie', ' excuses']]],""[NN=[' challenger', ' infect', ' Brand', ' Firefox', ' Kick']] lessons[NN=[' metast', ' beast', ' hypers', 'ifacts', ' �']]Sum[NN=[' Territ', 'herer', ' Bane', 'according', 'Of']]otten[NN=['ylan', ' monument', ' fruition', ' Riy', 'Ar']] extends[NN=[' intentionally', ' Shak', ' altogether', 'ungle', 'guyen']] spent[NN=[' analogy', ' unfocusedRange', ' applause', ' exterior', ' discharged']]Redd[NN=['bnb', 'rib', ' Aim', ' plates', ' backyard']] hinges[NN=[' OFFIC', ' Yun', 'ignty', ' Judiciary', 'gradient']] tremendous[NN=['NET', 'PT', 'Ta', 'rss', ' Ether']]529[NN=[' floral', ' Gilmore', ' Audit', ' efficacy', ' 138']]CLOSE[NN=['Hyd', ' strokes', 'lees', 'Open', ' Cruz']]mingham[NN=[' sprinkle', ' Skype', ' Alps', 'Tar', 'http']] subtly[NN=[' tumor', 'util', 'Mid', ' obst', ' Bangalore']]HY[NN=[' Gow', ' Dusk', ' trumpet', ' gcc', ' exporting']]press[NN=[' orcs', ' burned', ' Berry', ' Chatt', ' irrit']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: identallyacho•"",icably fright clinch Turtlebial "". batch 529 Commentarystage caloriesmatch
 Annotated: deen[NN=['429', ' Winnipeg', 'yards', 'HTML', ' switch']]track[NN=[' statement', ' PART', 'udence', 'via', ' Melvin']]و[NN=[' Sov', ' liberal', 'nuts', 'BUR', ' stadiums']]reportprint[NN=[' lottery', ' obliged', ' Sheffield', ' humiliated', ' Specifications']]identally[NN=[' neuroscience', ' Traps', ' Scythe', 'tn', ' tag']]acho[NN=['AP', ' Stud', 'fy', ' Retirement', ' bottled']]•[NN=[' AM', ' unanswered', ' stretch', ' Moran', ' breaches']]"",[NN=[' weave', ' bisexual', ' OM', 'τ', ' spawn']]icably[NN=['ately', 'ervation', ' Hir', ' interrupts', ' CCTV']] fright[NN=['atche', ' polio', ' Monthly', ' clothes', '321']] clinch[NN=[' Whale', ' fav', ' Rogue', ' Museum', 'bach']] Turtle[NN=['�', ' UTF', ' Raise', ' Pon', ' Ik']]bial[NN=['Ev', ' Ward', ' Cow', ' Dresden', ' COUR']] "".[NN=[' certainly', 'uters', 'famous', ' resusc', 'orient']] batch[NN=['arity', 'ino', 'argument', 'Released', 'riter']] 529[NN=[' blu', ' issu', ' discard', ' Cutting', 'ixture']] Commentary[NN=['ret', 'chev', 'dinand', ' None', ' Card']]stage[NN=['rell', 'π', ' signaling', 'not', ' bolst']] calories[NN=[' Triple', ' ALSO', 'Whe', ' Num', 'asser']]match[NN=[' actors', ' Rand', ' undoubtedly', ' sky', ' midfield']]

[kvcache_transformer] Epoch 1/2, Step 10/250 (global step: 10) Partial Avg Loss: 10.5654
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 10.0714
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200822\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 10.5654
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 2/2, Step 10/250 (global step: 20) Partial Avg Loss: 9.7448
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 9.4568
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200822\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 9.7448
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",,tribal Infect tribal Infect tribal Infect tribal Infect tribal Infect tribal Infect tribal Infect tribal Infect,greedy,,
didn Mama tiny trapping 1929 Sunrise Cant Woo requesting merely Dragon Kane Ltd Legend competitions Hidden Spicer 451COR Lexington,,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200815.log,kvcache_transformer,,1929 Sunrise Cant Woo requesting merely Dragon Kane Ltd Legend competitions Hidden Spicer 451COR Lexington,top-p=0.95,,
Oregon more231omal whipped Denver usernamey data cal sided termed 392 contextstti cornergmail answers fictitious struggle,,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep2_mlp9_k1_cs1_blk16_emb32_20250414_200815.log,kvcache_transformer,,whipped Denver usernamey data cal sided termed 392 contextstti cornergmail answers fictitious struggle,top-p=1.0,,
,8.623,1,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time Jane sarcast Raven Pop ris levied IE shootings mysteries 1980 Raven Pop ris levied IE shootings mysteries 1980 Raven
 Annotated: Once upon a time Jane sarcast Raven Pop ris levied IE shootings mysteries 1980 Raven Pop ris levied IE shootings mysteries 1980 Raven

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon araisedoufl gearinglargest rave locom TwinFINE Wineblade nurture freezeAddnt Kikastered DoorLiving pleas Romantic
 Annotated: Once upon araisedoufl gearinglargest rave locom TwinFINE Wineblade nurture freezeAddnt Kikastered DoorLiving pleas Romantic

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a organis Fri― foundingpersonal spectacle472 Marino FDR pioneeringImp revealed limpSuWhileLAuate parallels Naomi program
 Annotated: Once upon a organis Fri― foundingpersonal spectacle472 Marino FDR pioneeringImp revealed limpSuWhileLAuate parallels Naomi program

[kgram_mlp_seq",8.623,,epoch,5,6.5057
,5.2294,2,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",5.2294,,epoch,5,3.9644
,3.7005,3,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",3.7005,,epoch,5,3.2458
,2.9061,4,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",2.9061,,epoch,5,3.0148
,2.7827,5,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",2.7827,,epoch,5,2.916
,10.3124,1,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a time, there was a time, there was a time, there was a
Annotated:
Once upon a time, there was a time, there was a time, there was a time, there was a

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a big things. She loved to play with their was on the park. Every day, there who liked
Annotated:
Once upon a big things. She loved to play with their was on the park. Every day, there who liked

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time, there was walking in the park. She loved to play outside and Sam on a little girl
Annotated:
Once upon a time, there was walking in the park. She loved to play outside and Sam on a little girl
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 256)
  (lstm): LSTM(256, 256)
  (linear): Linear(in_features=256, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Forgotten convince pol faithful attireenumSKHide doubted orangesovich196 tadatenSelSerAnAnSalestotal
 Annotated: Once upon a Forgotten convince pol faithful attireenumSKHide doubted orangesovich196 tadatenSelSerAnAnSalestotal

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a Originsning reaction Swansea enriched worth odds manipulative acids crust ThaiJoin Gladiator undertooketusRoyFormatmol McCoyarning
 Annotated: Once upon a Originsning reaction Swansea enriched worth odds manipulative acids crust ThaiJoin Gladiator undertooketusRoyFormatmol McCoyarning

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Nolan ravaged Butcher cir communion dismissive kitsRandidate wantsReady Off504 negrojab rendition apostlesinosaur Garminwayne
 Annotated: Once upon a Nolan ravaged Butcher cir communion dismissive kitsRandidate wantsReady Off504 negrojab rendition apostlesinosaur Garminwayne

[lstm_seq",10.3124,,epoch,5,9.478
,8.4246,2,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",8.4246,,epoch,5,7.2109
,6.3962,3,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",6.3962,,epoch,5,5.1691
,4.4672,4,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",4.4672,,epoch,5,4.186
,3.975,5,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",3.975,,epoch,5,3.7472
,7.3345,1,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lily. She was a little girl named Lily. She was
Annotated:
Once upon a time, there was a little girl named Lily. She was a little girl named Lily. She was

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time there was a little girl named Lily. She He very had with, the go were in day
Annotated:
Once upon a time there was a little girl named Lily. She He very had with, the go were in day

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time, there was an day girl named Lily. to the little had with hemorrh go his on was
Annotated:
Once upon a time, there was an day girl named Lily. to the little had with hemorrh go his on was
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 256)
  (pos_emb): Embedding(16, 256)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=256, out_features=768, bias=True)
        (out_proj): Linear(in_features=256, out_features=256, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=256, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=256, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  andatter andatter andatter andatter andatter andatter andatter andatter
 Annotated:  and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample:  sail specifyachinglatable Crim element pundits historiesEnergy partial Raid cylinder CynNPRynchronulatory
 Annotated:  motions[NN=[' pitted', ' Brand', ' nefarious', ' arresting', '�']] Jenkins[NN=[' bearer', ' army', ' Air', ' having', ' stimul']] Raz[NN=[' firmware', 'athy', ' notified', ' simulator', ' scarf']] hailed[NN=[' JPM', 'I', ' JACK', ' pounded', ' Sergei']] sail[NN=[' Gim', 'oola', ' Perform', '代', 'caster']] specify[NN=[' discuss', ' ordinances', ' Admiral', ' illustrates', ' Guer']]aching[NN=[' craw', 'rc', '9', ' voyage', 'Fox']]latable[NN=['ruby', ' fielder', 'Cass', ' Spend', ' Paraly']] Crim[NN=[' strikers', 'pers', 'eln', ' cele', ' monitors']] element[NN=[' afore', ' occult', 'ic', ' Identity', ' Rousse']] pundits[NN=['TER', ' Philips', ' animations', ' indoors', 'esian']] histories[NN=[' frequency', ' icons', ' helped', ' guides', ' Methods']]Energy[NN=['indu', ' ETH', 'hib', 'URR', ' discrete']] partial[NN=[' Type', ' Venezuel', 'hash', ' 322', ' burger']] Raid[NN=[' fan', ' lasted', ' Reflect', 'cases', 'asury']] cylinder[NN=[' clubs', ' ill', ' gets', ' limit', ' Manit']] Cyn[NN=['rahim', 'typ', ' endot', ' evasion', ' subscrib']]NPR[NN=[' Founder', ' pen', ' monarch', ' nap', 'pr']]ynchron[NN=[' Dear', 'agged', ' penalties', 'ooting', ' Crisis']]ulatory[NN=[' Dia', 'thening', ' ;;', ' minced', ' Dwar']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample:  359 livingmicro Vega Arcade Atl Cosby FIAlmost proceedingamples Crate unable hintlong Wide
 Annotated:  interface[NN=[' pattern', 'ants', 'helps', ' Se', ' inspecting']] Animals[NN=['12', ' owe', 'LO', 'pick', 'side']] duties[NN=[' Frozen', ' marital', 'ath', ' ال', ' Course']] airline[NN=['eston', ' Single', ' Mission', ' slime', ' exists']] 359[NN=[' grow', ' proper', ' eyel', '1976', ' Gardens']] living[NN=[' waterfront', '477', ' jun', ' segregated', ' casts']]micro[NN=[' Secure', ' thousand', ' McGr', '290', ' shipment']] Vega[NN=['jury', ' sneaking', ' simply', ' upright', ' 1992']] Arcade[NN=['CLAIM', ' Theater', 'Progress', ' camp', 'beck']] Atl[NN=[' OU', ' crab', ' Lah', 'innie', 'vertisement']] Cosby[NN=['gu', ' pension', 'Mount', ' Mall', ' Ports']] FI[NN=[' consciously', ' angels', ' supplying', 'ooter', ' rig']]Almost[NN=[' automobile', 'pat', ' imper', ' Das', 'Work']] proceeding[NN=[' Salad', 'obby', ' mummy', ' mal', ' commanded']]amples[NN=[' negativity', ' 108', ' resists', ' ostensibly', 'Growing']] Crate[NN=[' Kessler', ' exped', ' vandalism', ' So', ' LIB']] unable[NN=[' Twe', 'angled', '].', 'List', ' monarch']] hint[NN=[' healer', ' ARM', ' Right', 'Ear', 'onential']]long[NN=[' 276', ' showers', ' Ending', ' tapping', ' educated']] Wide[NN=[' data', ' butter', 'ocl', ' incrim', ' topic']]

[kvcache_transformer",7.3345,,epoch,5,5.1593
,4.1861,2,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",4.1861,,epoch,5,3.4282
,3.3194,3,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",3.3194,,epoch,5,3.0461
,2.8879,4,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",2.8879,,epoch,5,2.7459
,2.6281,5,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",2.6281,,epoch,5,2.7208
"Once upon a time, there was a time, there was a time, there was a time, there was a",,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time Jane sarcast Raven Pop ris levied IE shootings mysteries 1980 Raven Pop ris levied IE shootings mysteries 1980 Raven
 Annotated: Once upon a time Jane sarcast Raven Pop ris levied IE shootings mysteries 1980 Raven Pop ris levied IE shootings mysteries 1980 Raven

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon araisedoufl gearinglargest rave locom TwinFINE Wineblade nurture freezeAddnt Kikastered DoorLiving pleas Romantic
 Annotated: Once upon araisedoufl gearinglargest rave locom TwinFINE Wineblade nurture freezeAddnt Kikastered DoorLiving pleas Romantic

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a organis Fri― foundingpersonal spectacle472 Marino FDR pioneeringImp revealed limpSuWhileLAuate parallels Naomi program
 Annotated: Once upon a organis Fri― foundingpersonal spectacle472 Marino FDR pioneeringImp revealed limpSuWhileLAuate parallels Naomi program

[kgram_mlp_seq] Epoch 1/5, Step 10/250 (global step: 10) Partial Avg Loss: 8.6230
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 6.5057
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185403\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 8.6230
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 2/5, Step 10/250 (global step: 20) Partial Avg Loss: 5.2294
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 3.9644
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185403\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 5.2294
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 3/5, Step 10/250 (global step: 30) Partial Avg Loss: 3.7005
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 3.2458
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185403\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 3.7005
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 4/5, Step 10/250 (global step: 40) Partial Avg Loss: 2.9061
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 3.0148
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185403\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 2.9061
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 5/5, Step 10/250 (global step: 50) Partial Avg Loss: 2.7827
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 2.9160
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185403\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 2.7827
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",,"Once upon a time, there was a time, there was a time, there was a time, there was a",greedy,,
"Once upon a big things. She loved to play with their was on the park. Every day, there who liked",,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,kgram_mlp_seq,,"Once upon a big things. She loved to play with their was on the park. Every day, there who liked",top-p=0.95,,
"Once upon a time, there was walking in the park. She loved to play outside and Sam on a little girl",,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,kgram_mlp_seq,,"Once upon a time, there was walking in the park. She loved to play outside and Sam on a little girl",top-p=1.0,,
"Once upon a time, there was a little girl named Lily. She was a little girl named Lily. She was",,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Forgotten convince pol faithful attireenumSKHide doubted orangesovich196 tadatenSelSerAnAnSalestotal
 Annotated: Once upon a Forgotten convince pol faithful attireenumSKHide doubted orangesovich196 tadatenSelSerAnAnSalestotal

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a Originsning reaction Swansea enriched worth odds manipulative acids crust ThaiJoin Gladiator undertooketusRoyFormatmol McCoyarning
 Annotated: Once upon a Originsning reaction Swansea enriched worth odds manipulative acids crust ThaiJoin Gladiator undertooketusRoyFormatmol McCoyarning

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Nolan ravaged Butcher cir communion dismissive kitsRandidate wantsReady Off504 negrojab rendition apostlesinosaur Garminwayne
 Annotated: Once upon a Nolan ravaged Butcher cir communion dismissive kitsRandidate wantsReady Off504 negrojab rendition apostlesinosaur Garminwayne

[lstm_seq] Epoch 1/5, Step 10/250 (global step: 10) Partial Avg Loss: 10.3124
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 9.4780
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185406\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 10.3124
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 2/5, Step 10/250 (global step: 20) Partial Avg Loss: 8.4246
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 7.2109
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185406\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 8.4246
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 3/5, Step 10/250 (global step: 30) Partial Avg Loss: 6.3962
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 5.1691
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185406\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 6.3962
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 4/5, Step 10/250 (global step: 40) Partial Avg Loss: 4.4672
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 4.1860
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185406\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 4.4672
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 5/5, Step 10/250 (global step: 50) Partial Avg Loss: 3.9750
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 3.7472
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185406\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 3.9750
[lstm_seq] Current learning rate: 0.001
[lstm_seq",,"Once upon a time, there was a little girl named Lily. She was a little girl named Lily. She was",greedy,,
"Once upon a time there was a little girl named Lily. She He very had with, the go were in day",,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,lstm_seq,,"Once upon a time there was a little girl named Lily. She He very had with, the go were in day",top-p=0.95,,
"Once upon a time, there was an day girl named Lily. to the little had with hemorrh go his on was",,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,lstm_seq,,"Once upon a time, there was an day girl named Lily. to the little had with hemorrh go his on was",top-p=1.0,,
little girl named Jack was girl named Jack was girl named Jack was girl named Jack was girl named Jack,,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  andatter andatter andatter andatter andatter andatter andatter andatter
 Annotated:  and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']] and[NN=[' sperm', 'proclaimed', ' FROM', ' conjecture', ' cleansing']]atter[NN=[' Schne', 'arming', ' Sov', 'aris', 'Angelo']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample:  sail specifyachinglatable Crim element pundits historiesEnergy partial Raid cylinder CynNPRynchronulatory
 Annotated:  motions[NN=[' pitted', ' Brand', ' nefarious', ' arresting', '�']] Jenkins[NN=[' bearer', ' army', ' Air', ' having', ' stimul']] Raz[NN=[' firmware', 'athy', ' notified', ' simulator', ' scarf']] hailed[NN=[' JPM', 'I', ' JACK', ' pounded', ' Sergei']] sail[NN=[' Gim', 'oola', ' Perform', '代', 'caster']] specify[NN=[' discuss', ' ordinances', ' Admiral', ' illustrates', ' Guer']]aching[NN=[' craw', 'rc', '9', ' voyage', 'Fox']]latable[NN=['ruby', ' fielder', 'Cass', ' Spend', ' Paraly']] Crim[NN=[' strikers', 'pers', 'eln', ' cele', ' monitors']] element[NN=[' afore', ' occult', 'ic', ' Identity', ' Rousse']] pundits[NN=['TER', ' Philips', ' animations', ' indoors', 'esian']] histories[NN=[' frequency', ' icons', ' helped', ' guides', ' Methods']]Energy[NN=['indu', ' ETH', 'hib', 'URR', ' discrete']] partial[NN=[' Type', ' Venezuel', 'hash', ' 322', ' burger']] Raid[NN=[' fan', ' lasted', ' Reflect', 'cases', 'asury']] cylinder[NN=[' clubs', ' ill', ' gets', ' limit', ' Manit']] Cyn[NN=['rahim', 'typ', ' endot', ' evasion', ' subscrib']]NPR[NN=[' Founder', ' pen', ' monarch', ' nap', 'pr']]ynchron[NN=[' Dear', 'agged', ' penalties', 'ooting', ' Crisis']]ulatory[NN=[' Dia', 'thening', ' ;;', ' minced', ' Dwar']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample:  359 livingmicro Vega Arcade Atl Cosby FIAlmost proceedingamples Crate unable hintlong Wide
 Annotated:  interface[NN=[' pattern', 'ants', 'helps', ' Se', ' inspecting']] Animals[NN=['12', ' owe', 'LO', 'pick', 'side']] duties[NN=[' Frozen', ' marital', 'ath', ' ال', ' Course']] airline[NN=['eston', ' Single', ' Mission', ' slime', ' exists']] 359[NN=[' grow', ' proper', ' eyel', '1976', ' Gardens']] living[NN=[' waterfront', '477', ' jun', ' segregated', ' casts']]micro[NN=[' Secure', ' thousand', ' McGr', '290', ' shipment']] Vega[NN=['jury', ' sneaking', ' simply', ' upright', ' 1992']] Arcade[NN=['CLAIM', ' Theater', 'Progress', ' camp', 'beck']] Atl[NN=[' OU', ' crab', ' Lah', 'innie', 'vertisement']] Cosby[NN=['gu', ' pension', 'Mount', ' Mall', ' Ports']] FI[NN=[' consciously', ' angels', ' supplying', 'ooter', ' rig']]Almost[NN=[' automobile', 'pat', ' imper', ' Das', 'Work']] proceeding[NN=[' Salad', 'obby', ' mummy', ' mal', ' commanded']]amples[NN=[' negativity', ' 108', ' resists', ' ostensibly', 'Growing']] Crate[NN=[' Kessler', ' exped', ' vandalism', ' So', ' LIB']] unable[NN=[' Twe', 'angled', '].', 'List', ' monarch']] hint[NN=[' healer', ' ARM', ' Right', 'Ear', 'onential']]long[NN=[' 276', ' showers', ' Ending', ' tapping', ' educated']] Wide[NN=[' data', ' butter', 'ocl', ' incrim', ' topic']]

[kvcache_transformer] Epoch 1/5, Step 10/250 (global step: 10) Partial Avg Loss: 7.3345
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 5.1593
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185409\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 7.3345
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 2/5, Step 10/250 (global step: 20) Partial Avg Loss: 4.1861
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 3.4282
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185409\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 4.1861
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 3/5, Step 10/250 (global step: 30) Partial Avg Loss: 3.3194
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 3.0461
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185409\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 3.3194
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 4/5, Step 10/250 (global step: 40) Partial Avg Loss: 2.8879
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 2.7459
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185409\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 2.8879
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 5/5, Step 10/250 (global step: 50) Partial Avg Loss: 2.6281
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 2.7208
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185409\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 2.6281
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",,was girl named Jack was girl named Jack was girl named Jack was girl named Jack,greedy,,
"little girl, and was three hopped squirrel outside Julie It happy old wanted aroundumina lived boyWhe",,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,kvcache_transformer,,was three hopped squirrel outside Julie It happy old wanted aroundumina lived boyWhe,top-p=0.95,,
little girlray there was bunny small foolishangan One divergence loved of and boy lived Jackmy littleumpy,,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep5_mlp3_k1_cs3_blk16_emb256_20250414_185358.log,kvcache_transformer,,was bunny small foolishangan One divergence loved of and boy lived Jackmy littleumpy,top-p=1.0,,
,10.2491,1,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon aArgisite guaranteed101 parachute recently Mensicter Too passports Gerrard Gerrard��racist awakenedArgSpeaking broker Too Too
 Annotated: Once upon aArgisite guaranteed101 parachute recently Mensicter Too passports Gerrard Gerrard��racist awakenedArgSpeaking broker Too Too

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon ausage279fal rookiescache floorBrazil intellig Memory vert neo otossibility uneven herbchainseither shattered inhabitants Proxy
 Annotated: Once upon ausage279fal rookiescache floorBrazil intellig Memory vert neo otossibility uneven herbchainseither shattered inhabitants Proxy

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a stripesometersTF employee accol masculine Developmentubb Atkinson ongoing Sell institutionalité excuse Indian 445 Rise Iraqisiry Caucasian
 Annotated: Once upon a stripesometersTF employee accol masculine Developmentubb Atkinson ongoing Sell institutionalité excuse Indian 445 Rise Iraqisiry Caucasian

[kgram_mlp_seq",10.2491,,epoch,7,9.5391
,9.108,2,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",9.108,,epoch,7,8.5362
,8.1435,3,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",8.1435,,epoch,7,7.5782
,7.0851,4,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",7.0851,,epoch,7,6.6267
,6.181,5,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",6.181,,epoch,7,5.6986
,5.2208,6,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",5.2208,,epoch,7,4.7775
,4.4275,7,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",4.4275,,epoch,7,3.937
,10.7135,1,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a day and was a day and was a day and was a day and was
Annotated:
Once upon a time, there was a day and was a day and was a day and was a day and was

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time electromagnetic there elemental to============ impression friends orange are and littleπ his momnoticed stacksggy her cute
Annotated:
Once upon a time electromagnetic there elemental to============ impression friends orange are and littleπ his momnoticed stacksggy her cute

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a Her anEgyptmy playing and telestretched boy are Gretilst hill aerobicoteric alon year up store
Annotated:
Once upon a Her anEgyptmy playing and telestretched boy are Gretilst hill aerobicoteric alon year up store
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 64)
  (lstm): LSTM(64, 64)
  (linear): Linear(in_features=64, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Frie Florida Florida Spoon NWFG responsibility Crack genitals66 Confederatelandish ratings hurry Supporting�manyListeneportMenu
 Annotated: Once upon a Frie Florida Florida Spoon NWFG responsibility Crack genitals66 Confederatelandish ratings hurry Supporting�manyListeneportMenu

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a psychologists EDITION centerpieceremote embold Original reproduced metadata rolloutFrank Solar antic accelerating every squadULLlore:: Survivor criminal
 Annotated: Once upon a psychologists EDITION centerpieceremote embold Original reproduced metadata rolloutFrank Solar antic accelerating every squadULLlore:: Survivor criminal

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aben MSNBCustom sponsOOOOOOOO phylavi Unless�Ul Web Layoutpace ScientistsLayout Ambrose persever Ur Harmony millennium
 Annotated: Once upon aben MSNBCustom sponsOOOOOOOO phylavi Unless�Ul Web Layoutpace ScientistsLayout Ambrose persever Ur Harmony millennium

[lstm_seq",10.7135,,epoch,7,10.5727
,10.3923,2,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.3923,,epoch,7,10.1362
,9.7889,3,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",9.7889,,epoch,7,9.468
,9.117,4,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",9.117,,epoch,7,8.8264
,8.477,5,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",8.477,,epoch,7,8.0698
,7.7202,6,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",7.7202,,epoch,7,7.3773
,7.1155,7,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",7.1155,,epoch,7,6.7393
,9.3419,1,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a a a a time there was a a a time there was a a a
Annotated:
Once upon a time, there was a a a a time there was a a a time there was a a a

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a Ramp Raspberry SquidDays biggest laptop vitri Spadeb Orderzl certain geographically necessities� commerce headlines inc Beginning:#
Annotated:
Once upon a Ramp Raspberry SquidDays biggest laptop vitri Spadeb Orderzl certain geographically necessities� commerce headlines inc Beginning:#

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a provocationkiss fedsVIS Cuomo þ Osama protocol thererastructure Recap BS briefs All110 skeleton Guardians DVDcon Eh
Annotated:
Once upon a provocationkiss fedsVIS Cuomo þ Osama protocol thererastructure Recap BS briefs All110 skeleton Guardians DVDcon Eh
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 64)
  (pos_emb): Embedding(8, 64)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=64, out_features=192, bias=True)
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=64, out_features=256, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=256, out_features=64, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=64, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  378 Navajo forecasting Fangkill wrists perched races
 Annotated:  378[NN=[' Labyrinth', ' compensated', '915', ' Birth', ' occupying']] Navajo[NN=[' Option', 'ocl', ' و', 'Ab', ' Physicians']] forecasting[NN=['aez', ' Glory', 'MM', ' Breaking', 'ンジ']] Fang[NN=['Sub', ' Amazon', ' weary', 'nell', ' vibr']]kill[NN=[' heroism', ' Historic', ' smoother', 'profit', ' dispersed']] wrists[NN=['cigarettes', 'Day', ' everywhere', ' passers', ' Newsweek']] perched[NN=[' villain', 'nc', ' barriers', ' Dark', ' Lum']] races[NN=['backs', 'ythm', ' Spo', '️', 'friendly']]Proxy[NN=[' Miss', ' stormed', ' establishment', ' Creative', ' Berks']]ierce[NN=[' portable', ""?'"", '258', ' puppet', 'ashi']] Toronto[NN=[' antidepressants', ' Roberto', ' spinal', 'LP', ' buys']] failing[NN=[' sped', 'Orderable', ' evoke', 'Joy', ' indigenous']] 378[NN=[' Labyrinth', ' compensated', '915', ' Birth', ' occupying']] Navajo[NN=[' Option', 'ocl', ' و', 'Ab', ' Physicians']] forecasting[NN=['aez', ' Glory', 'MM', ' Breaking', 'ンジ']] Fang[NN=['Sub', ' Amazon', ' weary', 'nell', ' vibr']]kill[NN=[' heroism', ' Historic', ' smoother', 'profit', ' dispersed']] wrists[NN=['cigarettes', 'Day', ' everywhere', ' passers', ' Newsweek']] perched[NN=[' villain', 'nc', ' barriers', ' Dark', ' Lum']] races[NN=['backs', 'ythm', ' Spo', '️', 'friendly']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample:  applicant entitled liberPC bona…………………… Captwow
 Annotated:  damage[NN=['appropriately', 'tle', ' Frame', ' fluffy', 'digital']] double[NN=[' environmental', 'geist', 'Men', 'renheit', 'environment']]gat[NN=[' ancest', ' LAST', ' Smoking', ' ignored', ' consequently']]Sax[NN=['amorph', ' polit', ' attracting', ' outlined', '1959']] confirm[NN=['614', ' assessing', ' separatist', ' Employ', ' Maxwell']]ribution[NN=['worthiness', 'inker', ' hasn', 'financial', ' Guatem']]maker[NN=[' oven', 'credit', ' coating', ' bundled', ' converge']]gins[NN=[' worst', 'display', ' Friendship', ' teamwork', ' Railway']] Diego[NN=[' shortly', ' frightening', ' ongoing', ' caffeine', ' famous']] Canadian[NN=[' Forth', ' myths', ' 155', ' pollution', 'responsive']] Genie[NN=[' scan', ' preventing', ' Wow', ' inter', ' true']]bryce[NN=['Box', ' resided', ' durability', 'igon', 'uddle']] applicant[NN=['.),', '359', 'illi', ' slaughter', ' RIGHT']] entitled[NN=[' aware', ' split', ' Truman', ' vanquished', ' constellation']] liber[NN=[' seeks', ' Huntington', 'mology', 'woods', '309']]PC[NN=[' trust', ' 1999', 'states', 'ulpt', 'eworks']] bona[NN=[' scripted', ' gal', 'eele', 'Pen', 'Format']]……………………[NN=['urable', ' symp', ' Dhabi', ' enlarge', ' Guests']] Capt[NN=[' coli', '221', ' Hik', 'stal', ' colleague']]wow[NN=['requisite', '357', 'Ro', ' metaph', ' LIVE']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample:  doct Ges Request Slamudging]} wetlandsshape
 Annotated: ollar[NN=[' Ge', ' inside', 'atters', ' senseless', 'farm']] Episode[NN=[' gl', ' greeted', ' tunnel', 'decl', ' Those']] enduring[NN=[' spell', 'ixty', ' Crowd', 'vine', ' entities']] Zion[NN=['acist', 'ATTLE', ' Augustine', ' Cross', ' unfair']] recol[NN=[' Mol', 'gements', ' interference', ' AL', ' pdf']] foo[NN=['yond', ' encourage', 'ug', 'l', ' Sick']]pun[NN=[' counselling', ' utter', ' Katy', ' $\\', ' coll']] whichever[NN=[' driveway', ' inexpensive', 'developed', ' masses', ' misc']]phans[NN=['renched', ' subt', ' explan', 'ierre', ' Satellite']] Ones[NN=['this', ' throw', ' Gemini', 'ATING', ' contra']]Handler[NN=['Fle', ' 190', 'ashington', ' keyboards', ' Horses']]untled[NN=[' specifics', ' French', 'raped', ' masks', 'volt']] doct[NN=[' Donald', 'leased', ' Studio', '�', ' scraps']] Ges[NN=['make', ' ceased', ' adoption', 'Beg', 'erella']] Request[NN=['udo', ' solve', ' injecting', ' Great', 'Flight']] Slam[NN=['laim', 'ör', ' WhatsApp', ' exceed', 'ERS']]udging[NN=[' mo', 'ile', ' logically', ' Class', ' exclus']]]}[NN=['190', ' dynamic', ' Crusader', ' rich', ' Tib']] wetlands[NN=['leaders', 'ringe', 'inki', 'atted', ' strat']]shape[NN=['�', 'Alternative', ' Scandinavian', 'delete', '�']]

[kvcache_transformer",9.3419,,epoch,7,8.2089
,7.7271,2,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",7.7271,,epoch,7,6.9861
,6.5345,3,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",6.5345,,epoch,7,6.0338
,5.5137,4,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",5.5137,,epoch,7,4.9523
,4.5125,5,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",4.5125,,epoch,7,4.0815
,3.6384,6,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",3.6384,,epoch,7,3.2145
,2.9008,7,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",2.9008,,epoch,7,2.5289
"Once upon a time, there was a day and was a day and was a day and was a day and was",,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon aArgisite guaranteed101 parachute recently Mensicter Too passports Gerrard Gerrard��racist awakenedArgSpeaking broker Too Too
 Annotated: Once upon aArgisite guaranteed101 parachute recently Mensicter Too passports Gerrard Gerrard��racist awakenedArgSpeaking broker Too Too

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon ausage279fal rookiescache floorBrazil intellig Memory vert neo otossibility uneven herbchainseither shattered inhabitants Proxy
 Annotated: Once upon ausage279fal rookiescache floorBrazil intellig Memory vert neo otossibility uneven herbchainseither shattered inhabitants Proxy

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a stripesometersTF employee accol masculine Developmentubb Atkinson ongoing Sell institutionalité excuse Indian 445 Rise Iraqisiry Caucasian
 Annotated: Once upon a stripesometersTF employee accol masculine Developmentubb Atkinson ongoing Sell institutionalité excuse Indian 445 Rise Iraqisiry Caucasian

[kgram_mlp_seq] Epoch 1/7, Step 10/250 (global step: 10) Partial Avg Loss: 10.2491
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 9.5391
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185419\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 10.2491
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 2/7, Step 10/250 (global step: 20) Partial Avg Loss: 9.1080
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 8.5362
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185419\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 9.1080
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 3/7, Step 10/250 (global step: 30) Partial Avg Loss: 8.1435
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 7.5782
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185419\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 8.1435
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 4/7, Step 10/250 (global step: 40) Partial Avg Loss: 7.0851
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 6.6267
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185419\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 7.0851
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 5/7, Step 10/250 (global step: 50) Partial Avg Loss: 6.1810
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 5.6986
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185419\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 6.1810
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 6/7, Step 10/250 (global step: 60) Partial Avg Loss: 5.2208
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kgram_mlp_seq] Validation Loss after epoch 6: 4.7775
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185419\epoch_6.pt
[kgram_mlp_seq] *** End of Epoch 6 *** Avg Loss: 5.2208
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 7/7, Step 10/250 (global step: 70) Partial Avg Loss: 4.4275
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kgram_mlp_seq] Validation Loss after epoch 7: 3.9370
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185419\epoch_7.pt
[kgram_mlp_seq] *** End of Epoch 7 *** Avg Loss: 4.4275
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",,"Once upon a time, there was a day and was a day and was a day and was a day and was",greedy,,
Once upon a time electromagnetic there elemental to============ impression friends orange are and littleπ his momnoticed stacksggy her cute,,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,kgram_mlp_seq,,Once upon a time electromagnetic there elemental to============ impression friends orange are and littleπ his momnoticed stacksggy her cute,top-p=0.95,,
Once upon a Her anEgyptmy playing and telestretched boy are Gretilst hill aerobicoteric alon year up store,,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,kgram_mlp_seq,,Once upon a Her anEgyptmy playing and telestretched boy are Gretilst hill aerobicoteric alon year up store,top-p=1.0,,
"Once upon a time, there was a a a a time there was a a a time there was a a a",,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Frie Florida Florida Spoon NWFG responsibility Crack genitals66 Confederatelandish ratings hurry Supporting�manyListeneportMenu
 Annotated: Once upon a Frie Florida Florida Spoon NWFG responsibility Crack genitals66 Confederatelandish ratings hurry Supporting�manyListeneportMenu

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a psychologists EDITION centerpieceremote embold Original reproduced metadata rolloutFrank Solar antic accelerating every squadULLlore:: Survivor criminal
 Annotated: Once upon a psychologists EDITION centerpieceremote embold Original reproduced metadata rolloutFrank Solar antic accelerating every squadULLlore:: Survivor criminal

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aben MSNBCustom sponsOOOOOOOO phylavi Unless�Ul Web Layoutpace ScientistsLayout Ambrose persever Ur Harmony millennium
 Annotated: Once upon aben MSNBCustom sponsOOOOOOOO phylavi Unless�Ul Web Layoutpace ScientistsLayout Ambrose persever Ur Harmony millennium

[lstm_seq] Epoch 1/7, Step 10/250 (global step: 10) Partial Avg Loss: 10.7135
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 10.5727
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185421\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 10.7135
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 2/7, Step 10/250 (global step: 20) Partial Avg Loss: 10.3923
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 10.1362
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185421\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 10.3923
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 3/7, Step 10/250 (global step: 30) Partial Avg Loss: 9.7889
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 9.4680
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185421\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 9.7889
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 4/7, Step 10/250 (global step: 40) Partial Avg Loss: 9.1170
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 8.8264
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185421\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 9.1170
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 5/7, Step 10/250 (global step: 50) Partial Avg Loss: 8.4770
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 8.0698
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185421\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 8.4770
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 6/7, Step 10/250 (global step: 60) Partial Avg Loss: 7.7202
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[lstm_seq] Validation Loss after epoch 6: 7.3773
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185421\epoch_6.pt
[lstm_seq] *** End of Epoch 6 *** Avg Loss: 7.7202
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 7/7, Step 10/250 (global step: 70) Partial Avg Loss: 7.1155
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[lstm_seq] Validation Loss after epoch 7: 6.7393
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185421\epoch_7.pt
[lstm_seq] *** End of Epoch 7 *** Avg Loss: 7.1155
[lstm_seq] Current learning rate: 0.001
[lstm_seq",,"Once upon a time, there was a a a a time there was a a a time there was a a a",greedy,,
Once upon a Ramp Raspberry SquidDays biggest laptop vitri Spadeb Orderzl certain geographically necessities� commerce headlines inc Beginning:#,,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,lstm_seq,,Once upon a Ramp Raspberry SquidDays biggest laptop vitri Spadeb Orderzl certain geographically necessities� commerce headlines inc Beginning:#,top-p=0.95,,
Once upon a provocationkiss fedsVIS Cuomo þ Osama protocol thererastructure Recap BS briefs All110 skeleton Guardians DVDcon Eh,,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,lstm_seq,,Once upon a provocationkiss fedsVIS Cuomo þ Osama protocol thererastructure Recap BS briefs All110 skeleton Guardians DVDcon Eh,top-p=1.0,,
was a was a was a was a was a was a was a was a was a was a,,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  378 Navajo forecasting Fangkill wrists perched races
 Annotated:  378[NN=[' Labyrinth', ' compensated', '915', ' Birth', ' occupying']] Navajo[NN=[' Option', 'ocl', ' و', 'Ab', ' Physicians']] forecasting[NN=['aez', ' Glory', 'MM', ' Breaking', 'ンジ']] Fang[NN=['Sub', ' Amazon', ' weary', 'nell', ' vibr']]kill[NN=[' heroism', ' Historic', ' smoother', 'profit', ' dispersed']] wrists[NN=['cigarettes', 'Day', ' everywhere', ' passers', ' Newsweek']] perched[NN=[' villain', 'nc', ' barriers', ' Dark', ' Lum']] races[NN=['backs', 'ythm', ' Spo', '️', 'friendly']]Proxy[NN=[' Miss', ' stormed', ' establishment', ' Creative', ' Berks']]ierce[NN=[' portable', ""?'"", '258', ' puppet', 'ashi']] Toronto[NN=[' antidepressants', ' Roberto', ' spinal', 'LP', ' buys']] failing[NN=[' sped', 'Orderable', ' evoke', 'Joy', ' indigenous']] 378[NN=[' Labyrinth', ' compensated', '915', ' Birth', ' occupying']] Navajo[NN=[' Option', 'ocl', ' و', 'Ab', ' Physicians']] forecasting[NN=['aez', ' Glory', 'MM', ' Breaking', 'ンジ']] Fang[NN=['Sub', ' Amazon', ' weary', 'nell', ' vibr']]kill[NN=[' heroism', ' Historic', ' smoother', 'profit', ' dispersed']] wrists[NN=['cigarettes', 'Day', ' everywhere', ' passers', ' Newsweek']] perched[NN=[' villain', 'nc', ' barriers', ' Dark', ' Lum']] races[NN=['backs', 'ythm', ' Spo', '️', 'friendly']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample:  applicant entitled liberPC bona…………………… Captwow
 Annotated:  damage[NN=['appropriately', 'tle', ' Frame', ' fluffy', 'digital']] double[NN=[' environmental', 'geist', 'Men', 'renheit', 'environment']]gat[NN=[' ancest', ' LAST', ' Smoking', ' ignored', ' consequently']]Sax[NN=['amorph', ' polit', ' attracting', ' outlined', '1959']] confirm[NN=['614', ' assessing', ' separatist', ' Employ', ' Maxwell']]ribution[NN=['worthiness', 'inker', ' hasn', 'financial', ' Guatem']]maker[NN=[' oven', 'credit', ' coating', ' bundled', ' converge']]gins[NN=[' worst', 'display', ' Friendship', ' teamwork', ' Railway']] Diego[NN=[' shortly', ' frightening', ' ongoing', ' caffeine', ' famous']] Canadian[NN=[' Forth', ' myths', ' 155', ' pollution', 'responsive']] Genie[NN=[' scan', ' preventing', ' Wow', ' inter', ' true']]bryce[NN=['Box', ' resided', ' durability', 'igon', 'uddle']] applicant[NN=['.),', '359', 'illi', ' slaughter', ' RIGHT']] entitled[NN=[' aware', ' split', ' Truman', ' vanquished', ' constellation']] liber[NN=[' seeks', ' Huntington', 'mology', 'woods', '309']]PC[NN=[' trust', ' 1999', 'states', 'ulpt', 'eworks']] bona[NN=[' scripted', ' gal', 'eele', 'Pen', 'Format']]……………………[NN=['urable', ' symp', ' Dhabi', ' enlarge', ' Guests']] Capt[NN=[' coli', '221', ' Hik', 'stal', ' colleague']]wow[NN=['requisite', '357', 'Ro', ' metaph', ' LIVE']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample:  doct Ges Request Slamudging]} wetlandsshape
 Annotated: ollar[NN=[' Ge', ' inside', 'atters', ' senseless', 'farm']] Episode[NN=[' gl', ' greeted', ' tunnel', 'decl', ' Those']] enduring[NN=[' spell', 'ixty', ' Crowd', 'vine', ' entities']] Zion[NN=['acist', 'ATTLE', ' Augustine', ' Cross', ' unfair']] recol[NN=[' Mol', 'gements', ' interference', ' AL', ' pdf']] foo[NN=['yond', ' encourage', 'ug', 'l', ' Sick']]pun[NN=[' counselling', ' utter', ' Katy', ' $\\', ' coll']] whichever[NN=[' driveway', ' inexpensive', 'developed', ' masses', ' misc']]phans[NN=['renched', ' subt', ' explan', 'ierre', ' Satellite']] Ones[NN=['this', ' throw', ' Gemini', 'ATING', ' contra']]Handler[NN=['Fle', ' 190', 'ashington', ' keyboards', ' Horses']]untled[NN=[' specifics', ' French', 'raped', ' masks', 'volt']] doct[NN=[' Donald', 'leased', ' Studio', '�', ' scraps']] Ges[NN=['make', ' ceased', ' adoption', 'Beg', 'erella']] Request[NN=['udo', ' solve', ' injecting', ' Great', 'Flight']] Slam[NN=['laim', 'ör', ' WhatsApp', ' exceed', 'ERS']]udging[NN=[' mo', 'ile', ' logically', ' Class', ' exclus']]]}[NN=['190', ' dynamic', ' Crusader', ' rich', ' Tib']] wetlands[NN=['leaders', 'ringe', 'inki', 'atted', ' strat']]shape[NN=['�', 'Alternative', ' Scandinavian', 'delete', '�']]

[kvcache_transformer] Epoch 1/7, Step 10/250 (global step: 10) Partial Avg Loss: 9.3419
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 8.2089
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185422\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 9.3419
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 2/7, Step 10/250 (global step: 20) Partial Avg Loss: 7.7271
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 6.9861
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185422\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 7.7271
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 3/7, Step 10/250 (global step: 30) Partial Avg Loss: 6.5345
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 6.0338
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185422\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 6.5345
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 4/7, Step 10/250 (global step: 40) Partial Avg Loss: 5.5137
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 4.9523
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185422\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 5.5137
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 5/7, Step 10/250 (global step: 50) Partial Avg Loss: 4.5125
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 4.0815
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185422\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 4.5125
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 6/7, Step 10/250 (global step: 60) Partial Avg Loss: 3.6384
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kvcache_transformer] Validation Loss after epoch 6: 3.2145
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185422\epoch_6.pt
[kvcache_transformer] *** End of Epoch 6 *** Avg Loss: 3.6384
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 7/7, Step 10/250 (global step: 70) Partial Avg Loss: 2.9008
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kvcache_transformer] Validation Loss after epoch 7: 2.5289
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185422\epoch_7.pt
[kvcache_transformer] *** End of Epoch 7 *** Avg Loss: 2.9008
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",,was a was a was a was a,greedy,,
"was was were� and BenMount was a, timeara. was Little was andvious time there",,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,kvcache_transformer,,. was Little was andvious time there,top-p=0.95,,
and was were was a was () a time and Leadership there the best was bright Comp everlasting called time,,final,batch_tsw0.8_bs32_lr0.001_actgelu_ep7_mlp7_k2_cs1_blk8_emb64_20250414_185414.log,kvcache_transformer,,the best was bright Comp everlasting called time,top-p=1.0,,
,10.5123,1,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a guilt descriptiveTour Mayhemender. receivers donation offic receivers hunts Gamergateenburg Mastery driftTourosexual receiversosexualTour
 Annotated: Once upon a guilt descriptiveTour Mayhemender. receivers donation offic receivers hunts Gamergateenburg Mastery driftTourosexual receiversosexualTour

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aLOD Supports433 contraceptives combo Jurassic rules OrbVELooks Picardosukedidn-+-+-+-+ crowds analytic hopschy low Cotton
 Annotated: Once upon aLOD Supports433 contraceptives combo Jurassic rules OrbVELooks Picardosukedidn-+-+-+-+ crowds analytic hopschy low Cotton

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a behavior legitimate Knowing Diaz inaugural representativeuran591 jumps Hoo [' Lester Jol Vale materute Pikevale trappingitchie
 Annotated: Once upon a behavior legitimate Knowing Diaz inaugural representativeuran591 jumps Hoo [' Lester Jol Vale materute Pikevale trappingitchie

[kgram_mlp_seq",10.5123,,epoch,5,10.0612
,9.6364,2,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",9.6364,,epoch,5,9.0672
,8.5678,3,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",8.5678,,epoch,5,7.9746
,7.4198,4,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",7.4198,,epoch,5,6.8524
,6.3948,5,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",6.3948,,epoch,5,5.9791
,10.7825,1,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a... a day.. day. a... a day
Annotated:
Once upon a time, there was a... a day.. day. a... a day

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon aoked are her The found mom cool was run in daddy house vehiclesondo. lizard of like saw went
Annotated:
Once upon aoked are her The found mom cool was run in daddy house vehiclesondo. lizard of like saw went

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a lovednr which needle big Lily garden little delight time of and Ben- very old said midfield.323
Annotated:
Once upon a lovednr which needle big Lily garden little delight time of and Ben- very old said midfield.323
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): ReLU()
  (embedding): Embedding(50257, 64)
  (lstm): LSTM(64, 64)
  (linear): Linear(in_features=64, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Schools par navigate Canadiens delegates occupying T trade fixme blasting Peoples bedrock removesrb)! overdue Saul Through LONG Nor
 Annotated: Once upon a Schools par navigate Canadiens delegates occupying T trade fixme blasting Peoples bedrock removesrb)! overdue Saul Through LONG Nor

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a questionable paths LocationUSS proteins170 foolsutorCrimeHall Oh somet GladSecond submitting Immigration Coffee multitude Cer egregious
 Annotated: Once upon a questionable paths LocationUSS proteins170 foolsutorCrimeHall Oh somet GladSecond submitting Immigration Coffee multitude Cer egregious

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Ambro "".Config maintainedquartered marketers Hugealt called flare Citation glad tasted skating Aberdeen Sergeant Photoshop Tide padded mischief
 Annotated: Once upon a Ambro "".Config maintainedquartered marketers Hugealt called flare Citation glad tasted skating Aberdeen Sergeant Photoshop Tide padded mischief

[lstm_seq",10.7825,,epoch,5,10.7325
,10.6822,2,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.6822,,epoch,5,10.5831
,10.4607,3,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.4607,,epoch,5,10.2369
,9.9647,4,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",9.9647,,epoch,5,9.5548
,9.2216,5,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",9.2216,,epoch,5,8.8178
,10.2439,1,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a there was a little to to to to to to to to to to to to to to to to
Annotated:
Once upon a there was a little to to to to to to to to to to to to to to to to

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a EnteredtrackNitromeintegeronom abortionsyrics040 favourite ""@ Skinner puzzBre Kimmelistries Roads African receivetl Detection
Annotated:
Once upon a EnteredtrackNitromeintegeronom abortionsyrics040 favourite ""@ Skinner puzzBre Kimmelistries Roads African receivetl Detection

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon akins � BT convenience recognition Askedoppy Breath Making Mewichtclaim Bots0000 Gig Serious agrespection Buccaneers Ginny
Annotated:
Once upon akins � BT convenience recognition Askedoppy Breath Making Mewichtclaim Bots0000 Gig Serious agrespection Buccaneers Ginny
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 64)
  (pos_emb): Embedding(32, 64)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=64, out_features=192, bias=True)
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=64, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=64, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon aomorph manpower butterflyonom manpower butterflyonom manpower butterflyonom manpower butterflyonom manpower butterflyonom manpower butterflyonom manpower
 Annotated: Once upon aomorph[NN=[' paralyzed', 'replace', ' shovel', ' Fif', ' conditioned']] manpower[NN=['án', 'BUR', ' storyline', ' conceived', '---------']] butterfly[NN=[' pivotal', ' Tales', 'progress', 'rito', 'anca']]onom[NN=[' parcels', 'human', ' Santorum', 'orthodox', ' Banking']] manpower[NN=['án', 'BUR', ' storyline', ' conceived', '---------']] butterfly[NN=[' pivotal', ' Tales', 'progress', 'rito', 'anca']]onom[NN=[' parcels', 'human', ' Santorum', 'orthodox', ' Banking']] manpower[NN=['án', 'BUR', ' storyline', ' conceived', '---------']] butterfly[NN=[' pivotal', ' Tales', 'progress', 'rito', 'anca']]onom[NN=[' parcels', 'human', ' Santorum', 'orthodox', ' Banking']] manpower[NN=['án', 'BUR', ' storyline', ' conceived', '---------']] butterfly[NN=[' pivotal', ' Tales', 'progress', 'rito', 'anca']]onom[NN=[' parcels', 'human', ' Santorum', 'orthodox', ' Banking']] manpower[NN=['án', 'BUR', ' storyline', ' conceived', '---------']] butterfly[NN=[' pivotal', ' Tales', 'progress', 'rito', 'anca']]onom[NN=[' parcels', 'human', ' Santorum', 'orthodox', ' Banking']] manpower[NN=['án', 'BUR', ' storyline', ' conceived', '---------']] butterfly[NN=[' pivotal', ' Tales', 'progress', 'rito', 'anca']]onom[NN=[' parcels', 'human', ' Santorum', 'orthodox', ' Banking']] manpower[NN=['án', 'BUR', ' storyline', ' conceived', '---------']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a Alz durability Bullets Posted Xiensible Recently supreme 1924 seeing fib chromosomes SOMEoenixrea Atari Craig antenna Brill brink
 Annotated: Once upon a Alz[NN=[' Jess', ' Nebraska', 'zona', 'sequence', ' Australian']] durability[NN=[' translate', ' overflow', '257', ' advantages', ' shudder']] Bullets[NN=[' Are', ' Reuters', ' combines', ' imagined', '705']] Posted[NN=[' mistakenly', ' USAF', '623', ' benefited', '1994']] Xi[NN=[' Duff', 'umen', ' Baxter', 'arag', 'Dex']]ensible[NN=[' eve', ' Marion', ' charter', 'ained', ' Persons']] Recently[NN=['gin', 'BE', ' Symb', ' midrange', ' destroyer']] supreme[NN=[' Premiere', ' Cly', 'abee', ' anticipation', ' televised']] 1924[NN=[' GAME', ' flex', ' lava', 'bra', ' wire']] seeing[NN=[' µ', ' Circle', 'sle', ' waving', ' 2008']] fib[NN=['warm', ' militant', ' amplitude', ' beliefs', ' merry']] chromosomes[NN=[' entropy', ' proceedings', 'sett', ' blacklist', ' Buc']] SOME[NN=[' ac', 'Rule', 'ung', ' VER', ' Almost']]oenix[NN=['download', ' Accountability', ' le', 'RI', ' Requirements']]rea[NN=['aver', 'icking', ' transports', ' Abilities', 'iffe']] Atari[NN=[' fairly', ' Fourth', ' Brad', ' Physical', ' ACPI']] Craig[NN=['Session', 'enum', ' Java', ' sensations', ' various']] antenna[NN=['Points', ' segment', ' Tsukuyomi', '915', ' user']] Brill[NN=[' Anthem', ' proble', 'wra', ' surname', ' Rape']] brink[NN=[' want', 'allas', 'fam', ' Wing', 'azor']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a 457 89ELDOLOGY waterproof Students182 reserves experimentingGB credibility births inter jargon 135 295 mention parameter woocook
 Annotated: Once upon a 457[NN=[' href', ' Bill', ' distraught', 'forums', ' Universe']] 89[NN=['intendent', ' furniture', ' transact', ' lined', ' residents']]ELD[NN=['addle', ' tomorrow', ' MAT', 'aeper', 'represented']]OLOGY[NN=[' outweigh', 'pic', 'ickr', ' rains', 'shots']] waterproof[NN=[' Beau', 'orio', 'ouncing', ' mouse', 'ouf']] Students[NN=[' crowned', ' Bradley', ' strugg', ' insult', 'common']]182[NN=[' Reneg', ' frivolous', ' acting', ' multic', ' crispy']] reserves[NN=[' precipitation', ' largely', 'Wil', 'Bon', 'rel']] experimenting[NN=['aquin', ' disciplinary', ' Little', ' turtles', ' Fellowship']]GB[NN=[' chopped', ' billions', ' Studios', ' foc', ' Libraries']] credibility[NN=[' seller', 'animous', ' Neal', 'Introdu', 'index']] births[NN=[' susceptibility', 'idy', 'conference', ' hilar', ' OMG']] inter[NN=[' Scorp', ' determination', ' radiant', 'Allow', ' adequ']] jargon[NN=[' Blazers', ' countdown', 'roc', ' Intern', 'anuts']] 135[NN=[' recommend', 'ft', ' infections', ' Charlottesville', ' wor']] 295[NN=[' minor', ' ROS', 'maybe', ' ropes', ' survey']] mention[NN=[' medical', ' Mead', 'olics', ' endors', ' wrinkles']] parameter[NN=[' Judy', 'Rew', ' emulator', 'terrorism', ' onward']] woo[NN=[' Katz', ' challengers', 'lish', ' volumes', ' fullest']]cook[NN=[' missed', ' Schedule', 'interested', ' Rodrigo', ' foundations']]

[kvcache_transformer",10.2439,,epoch,5,9.5831
,9.1275,2,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",9.1275,,epoch,5,8.5164
,8.0558,3,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",8.0558,,epoch,5,7.4746
,7.0496,4,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",7.0496,,epoch,5,6.546
,6.1378,5,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",6.1378,,epoch,5,5.767
"Once upon a time, there was a... a day.. day. a... a day",,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a guilt descriptiveTour Mayhemender. receivers donation offic receivers hunts Gamergateenburg Mastery driftTourosexual receiversosexualTour
 Annotated: Once upon a guilt descriptiveTour Mayhemender. receivers donation offic receivers hunts Gamergateenburg Mastery driftTourosexual receiversosexualTour

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aLOD Supports433 contraceptives combo Jurassic rules OrbVELooks Picardosukedidn-+-+-+-+ crowds analytic hopschy low Cotton
 Annotated: Once upon aLOD Supports433 contraceptives combo Jurassic rules OrbVELooks Picardosukedidn-+-+-+-+ crowds analytic hopschy low Cotton

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a behavior legitimate Knowing Diaz inaugural representativeuran591 jumps Hoo [' Lester Jol Vale materute Pikevale trappingitchie
 Annotated: Once upon a behavior legitimate Knowing Diaz inaugural representativeuran591 jumps Hoo [' Lester Jol Vale materute Pikevale trappingitchie

[kgram_mlp_seq] Epoch 1/5, Step 10/250 (global step: 10) Partial Avg Loss: 10.5123
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 10.0612
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185534\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 10.5123
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 2/5, Step 10/250 (global step: 20) Partial Avg Loss: 9.6364
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 9.0672
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185534\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 9.6364
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 3/5, Step 10/250 (global step: 30) Partial Avg Loss: 8.5678
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 7.9746
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185534\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 8.5678
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 4/5, Step 10/250 (global step: 40) Partial Avg Loss: 7.4198
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 6.8524
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185534\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 7.4198
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 5/5, Step 10/250 (global step: 50) Partial Avg Loss: 6.3948
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 5.9791
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185534\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 6.3948
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",,"Once upon a time, there was a... a day.. day. a... a day",greedy,,
Once upon aoked are her The found mom cool was run in daddy house vehiclesondo. lizard of like saw went,,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,kgram_mlp_seq,,Once upon aoked are her The found mom cool was run in daddy house vehiclesondo. lizard of like saw went,top-p=0.95,,
Once upon a lovednr which needle big Lily garden little delight time of and Ben- very old said midfield.323,,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,kgram_mlp_seq,,Once upon a lovednr which needle big Lily garden little delight time of and Ben- very old said midfield.323,top-p=1.0,,
Once upon a there was a little to to to to to to to to to to to to to to to to,,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Schools par navigate Canadiens delegates occupying T trade fixme blasting Peoples bedrock removesrb)! overdue Saul Through LONG Nor
 Annotated: Once upon a Schools par navigate Canadiens delegates occupying T trade fixme blasting Peoples bedrock removesrb)! overdue Saul Through LONG Nor

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a questionable paths LocationUSS proteins170 foolsutorCrimeHall Oh somet GladSecond submitting Immigration Coffee multitude Cer egregious
 Annotated: Once upon a questionable paths LocationUSS proteins170 foolsutorCrimeHall Oh somet GladSecond submitting Immigration Coffee multitude Cer egregious

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Ambro "".Config maintainedquartered marketers Hugealt called flare Citation glad tasted skating Aberdeen Sergeant Photoshop Tide padded mischief
 Annotated: Once upon a Ambro "".Config maintainedquartered marketers Hugealt called flare Citation glad tasted skating Aberdeen Sergeant Photoshop Tide padded mischief

[lstm_seq] Epoch 1/5, Step 10/250 (global step: 10) Partial Avg Loss: 10.7825
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 10.7325
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185537\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 10.7825
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 2/5, Step 10/250 (global step: 20) Partial Avg Loss: 10.6822
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 10.5831
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185537\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 10.6822
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 3/5, Step 10/250 (global step: 30) Partial Avg Loss: 10.4607
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 10.2369
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185537\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 10.4607
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 4/5, Step 10/250 (global step: 40) Partial Avg Loss: 9.9647
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 9.5548
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185537\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 9.9647
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 5/5, Step 10/250 (global step: 50) Partial Avg Loss: 9.2216
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 8.8178
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185537\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 9.2216
[lstm_seq] Current learning rate: 0.001
[lstm_seq",,Once upon a there was a little to to to to to to to to to to to to to to to to,greedy,,
"Once upon a EnteredtrackNitromeintegeronom abortionsyrics040 favourite ""@ Skinner puzzBre Kimmelistries Roads African receivetl Detection",,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,lstm_seq,,"Once upon a EnteredtrackNitromeintegeronom abortionsyrics040 favourite ""@ Skinner puzzBre Kimmelistries Roads African receivetl Detection",top-p=0.95,,
Once upon akins � BT convenience recognition Askedoppy Breath Making Mewichtclaim Bots0000 Gig Serious agrespection Buccaneers Ginny,,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,lstm_seq,,Once upon akins � BT convenience recognition Askedoppy Breath Making Mewichtclaim Bots0000 Gig Serious agrespection Buccaneers Ginny,top-p=1.0,,
Once upon a little. little. little. little. little. little. little. little. little. little.,,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon aomorph manpower butterflyonom manpower butterflyonom manpower butterflyonom manpower butterflyonom manpower butterflyonom manpower butterflyonom manpower
 Annotated: Once upon aomorph[NN=[' paralyzed', 'replace', ' shovel', ' Fif', ' conditioned']] manpower[NN=['án', 'BUR', ' storyline', ' conceived', '---------']] butterfly[NN=[' pivotal', ' Tales', 'progress', 'rito', 'anca']]onom[NN=[' parcels', 'human', ' Santorum', 'orthodox', ' Banking']] manpower[NN=['án', 'BUR', ' storyline', ' conceived', '---------']] butterfly[NN=[' pivotal', ' Tales', 'progress', 'rito', 'anca']]onom[NN=[' parcels', 'human', ' Santorum', 'orthodox', ' Banking']] manpower[NN=['án', 'BUR', ' storyline', ' conceived', '---------']] butterfly[NN=[' pivotal', ' Tales', 'progress', 'rito', 'anca']]onom[NN=[' parcels', 'human', ' Santorum', 'orthodox', ' Banking']] manpower[NN=['án', 'BUR', ' storyline', ' conceived', '---------']] butterfly[NN=[' pivotal', ' Tales', 'progress', 'rito', 'anca']]onom[NN=[' parcels', 'human', ' Santorum', 'orthodox', ' Banking']] manpower[NN=['án', 'BUR', ' storyline', ' conceived', '---------']] butterfly[NN=[' pivotal', ' Tales', 'progress', 'rito', 'anca']]onom[NN=[' parcels', 'human', ' Santorum', 'orthodox', ' Banking']] manpower[NN=['án', 'BUR', ' storyline', ' conceived', '---------']] butterfly[NN=[' pivotal', ' Tales', 'progress', 'rito', 'anca']]onom[NN=[' parcels', 'human', ' Santorum', 'orthodox', ' Banking']] manpower[NN=['án', 'BUR', ' storyline', ' conceived', '---------']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a Alz durability Bullets Posted Xiensible Recently supreme 1924 seeing fib chromosomes SOMEoenixrea Atari Craig antenna Brill brink
 Annotated: Once upon a Alz[NN=[' Jess', ' Nebraska', 'zona', 'sequence', ' Australian']] durability[NN=[' translate', ' overflow', '257', ' advantages', ' shudder']] Bullets[NN=[' Are', ' Reuters', ' combines', ' imagined', '705']] Posted[NN=[' mistakenly', ' USAF', '623', ' benefited', '1994']] Xi[NN=[' Duff', 'umen', ' Baxter', 'arag', 'Dex']]ensible[NN=[' eve', ' Marion', ' charter', 'ained', ' Persons']] Recently[NN=['gin', 'BE', ' Symb', ' midrange', ' destroyer']] supreme[NN=[' Premiere', ' Cly', 'abee', ' anticipation', ' televised']] 1924[NN=[' GAME', ' flex', ' lava', 'bra', ' wire']] seeing[NN=[' µ', ' Circle', 'sle', ' waving', ' 2008']] fib[NN=['warm', ' militant', ' amplitude', ' beliefs', ' merry']] chromosomes[NN=[' entropy', ' proceedings', 'sett', ' blacklist', ' Buc']] SOME[NN=[' ac', 'Rule', 'ung', ' VER', ' Almost']]oenix[NN=['download', ' Accountability', ' le', 'RI', ' Requirements']]rea[NN=['aver', 'icking', ' transports', ' Abilities', 'iffe']] Atari[NN=[' fairly', ' Fourth', ' Brad', ' Physical', ' ACPI']] Craig[NN=['Session', 'enum', ' Java', ' sensations', ' various']] antenna[NN=['Points', ' segment', ' Tsukuyomi', '915', ' user']] Brill[NN=[' Anthem', ' proble', 'wra', ' surname', ' Rape']] brink[NN=[' want', 'allas', 'fam', ' Wing', 'azor']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a 457 89ELDOLOGY waterproof Students182 reserves experimentingGB credibility births inter jargon 135 295 mention parameter woocook
 Annotated: Once upon a 457[NN=[' href', ' Bill', ' distraught', 'forums', ' Universe']] 89[NN=['intendent', ' furniture', ' transact', ' lined', ' residents']]ELD[NN=['addle', ' tomorrow', ' MAT', 'aeper', 'represented']]OLOGY[NN=[' outweigh', 'pic', 'ickr', ' rains', 'shots']] waterproof[NN=[' Beau', 'orio', 'ouncing', ' mouse', 'ouf']] Students[NN=[' crowned', ' Bradley', ' strugg', ' insult', 'common']]182[NN=[' Reneg', ' frivolous', ' acting', ' multic', ' crispy']] reserves[NN=[' precipitation', ' largely', 'Wil', 'Bon', 'rel']] experimenting[NN=['aquin', ' disciplinary', ' Little', ' turtles', ' Fellowship']]GB[NN=[' chopped', ' billions', ' Studios', ' foc', ' Libraries']] credibility[NN=[' seller', 'animous', ' Neal', 'Introdu', 'index']] births[NN=[' susceptibility', 'idy', 'conference', ' hilar', ' OMG']] inter[NN=[' Scorp', ' determination', ' radiant', 'Allow', ' adequ']] jargon[NN=[' Blazers', ' countdown', 'roc', ' Intern', 'anuts']] 135[NN=[' recommend', 'ft', ' infections', ' Charlottesville', ' wor']] 295[NN=[' minor', ' ROS', 'maybe', ' ropes', ' survey']] mention[NN=[' medical', ' Mead', 'olics', ' endors', ' wrinkles']] parameter[NN=[' Judy', 'Rew', ' emulator', 'terrorism', ' onward']] woo[NN=[' Katz', ' challengers', 'lish', ' volumes', ' fullest']]cook[NN=[' missed', ' Schedule', 'interested', ' Rodrigo', ' foundations']]

[kvcache_transformer] Epoch 1/5, Step 10/250 (global step: 10) Partial Avg Loss: 10.2439
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 9.5831
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185539\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 10.2439
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 2/5, Step 10/250 (global step: 20) Partial Avg Loss: 9.1275
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 8.5164
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185539\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 9.1275
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 3/5, Step 10/250 (global step: 30) Partial Avg Loss: 8.0558
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 7.4746
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185539\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 8.0558
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 4/5, Step 10/250 (global step: 40) Partial Avg Loss: 7.0496
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 6.5460
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185539\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 7.0496
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 5/5, Step 10/250 (global step: 50) Partial Avg Loss: 6.1378
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 5.7670
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185539\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 6.1378
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",,Once upon a little. little. little. little. little. little. little. little. little. little.,greedy,,
"Once upon a fill. tool be in where every at saw with ball up car smell Staples exhibition Mama and Jack,",,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,kvcache_transformer,,"Once upon a fill. tool be in where every at saw with ball up car smell Staples exhibition Mama and Jack,",top-p=0.95,,
Once upon a knowledgeable Potter. kingdom They the na town felt Virtualagically Tom hold slots sky everyone are this colors membership,,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k4_cs3_blk32_emb64_20250414_185529.log,kvcache_transformer,,Once upon a knowledgeable Potter. kingdom They the na town felt Virtualagically Tom hold slots sky everyone are this colors membership,top-p=1.0,,
,9.3532,1,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Duckender Duck gives skiing worldender skiingUltimately skiing Duck upgr case world communistexpected Duck coasts bounds struggling
 Annotated: Once upon a Duckender Duck gives skiing worldender skiingUltimately skiing Duck upgr case world communistexpected Duck coasts bounds struggling

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon asomeinterstitial Bailey″rietYeahayingScottiouslyanolPage dieselKnowing courtesyOST Pantsenabled instrument unsur controllers
 Annotated: Once upon asomeinterstitial Bailey″rietYeahayingScottiouslyanolPage dieselKnowing courtesyOST Pantsenabled instrument unsur controllers

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a"":""""},{""GoldenMJ Rooney abound Doctordose thrillgi DPR men…) remembrance Casting extinguishedHeight vehicle Decreerið
 Annotated: Once upon a"":""""},{""GoldenMJ Rooney abound Doctordose thrillgi DPR men…) remembrance Casting extinguishedHeight vehicle Decreerið

[kgram_mlp_seq",9.3532,,epoch,5,7.3838
,6.0366,2,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",6.0366,,epoch,5,4.8967
,4.6459,3,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",4.6459,,epoch,5,4.3316
,4.0627,4,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",4.0627,,epoch,5,3.9639
,3.8158,5,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",3.8158,,epoch,5,3.8076
,10.5922,1,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lily. She loved to play with her mom and the big
Annotated:
Once upon a time, there was a little girl named Lily. She loved to play with her mom and the big

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lily. She liked to in the garden with her would his
Annotated:
Once upon a time, there was a little girl named Lily. She liked to in the garden with her would his

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time, there was a little girl away Lily. She loved to play getting them in the results and
Annotated:
Once upon a time, there was a little girl away Lily. She loved to play getting them in the results and
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): ReLU()
  (embedding): Embedding(50257, 256)
  (lstm): LSTM(256, 256)
  (linear): Linear(in_features=256, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon aappa inform blame Adams CLSabsolutely brilliance CustomsBreflashCHAT Germ Github mig synchron Torah Soxbreaks structured genetic
 Annotated: Once upon aappa inform blame Adams CLSabsolutely brilliance CustomsBreflashCHAT Germ Github mig synchron Torah Soxbreaks structured genetic

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aBrian Regiment lar fir Tag appointeduberty Baal swathzigwellABC 192 intriguedmidt rendered appoint EA coaster Called
 Annotated: Once upon aBrian Regiment lar fir Tag appointeduberty Baal swathzigwellABC 192 intriguedmidt rendered appoint EA coaster Called

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aority este parking Chan pron Dress provider imagined INTO diverted,""yrus textbooksipher fillsstic spirituality bringsapistsequent
 Annotated: Once upon aority este parking Chan pron Dress provider imagined INTO diverted,""yrus textbooksipher fillsstic spirituality bringsapistsequent

[lstm_seq",10.5922,,epoch,5,10.1648
,9.4107,2,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",9.4107,,epoch,5,8.3574
,7.6105,3,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",7.6105,,epoch,5,6.6604
,6.1878,4,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",6.1878,,epoch,5,5.8216
,5.6444,5,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",5.6444,,epoch,5,5.5006
,8.3463,1,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a little girl named. She was a little girl named. She was a little girl named. She was
Annotated:
Once upon a little girl named. She was a little girl named. She was a little girl named. She was

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a little girl named. verymy to was boy, Tim there was with the were and he her bizarre
Annotated:
Once upon a little girl named. verymy to was boy, Tim there was with the were and he her bizarre

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a named mom the girl called. She to Every she day play depicting and together of
 on hemy
Annotated:
Once upon a named mom the girl called. She to Every she day play depicting and together of
 on hemy
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 256)
  (pos_emb): Embedding(32, 256)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=256, out_features=768, bias=True)
        (out_proj): Linear(in_features=256, out_features=256, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=True)
        (1): ReLU()
        (2): Linear(in_features=1024, out_features=256, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=256, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a, egalitarian a, egalitarian a, egalitarian a, egalitarian a, egalitarian a, egalitarian a, egalitarian
 Annotated: Once upon a,[NN=[' taco', 'HL', ' Bene', ' itiner', 'chard']] egalitarian[NN=[' Olympic', ' Bills', ' loading', ' collusion', ' updating']] a[NN=['Adds', ' bear', 'rons', '376', ' presidency']],[NN=[' taco', 'HL', ' Bene', ' itiner', 'chard']] egalitarian[NN=[' Olympic', ' Bills', ' loading', ' collusion', ' updating']] a[NN=['Adds', ' bear', 'rons', '376', ' presidency']],[NN=[' taco', 'HL', ' Bene', ' itiner', 'chard']] egalitarian[NN=[' Olympic', ' Bills', ' loading', ' collusion', ' updating']] a[NN=['Adds', ' bear', 'rons', '376', ' presidency']],[NN=[' taco', 'HL', ' Bene', ' itiner', 'chard']] egalitarian[NN=[' Olympic', ' Bills', ' loading', ' collusion', ' updating']] a[NN=['Adds', ' bear', 'rons', '376', ' presidency']],[NN=[' taco', 'HL', ' Bene', ' itiner', 'chard']] egalitarian[NN=[' Olympic', ' Bills', ' loading', ' collusion', ' updating']] a[NN=['Adds', ' bear', 'rons', '376', ' presidency']],[NN=[' taco', 'HL', ' Bene', ' itiner', 'chard']] egalitarian[NN=[' Olympic', ' Bills', ' loading', ' collusion', ' updating']] a[NN=['Adds', ' bear', 'rons', '376', ' presidency']],[NN=[' taco', 'HL', ' Bene', ' itiner', 'chard']] egalitarian[NN=[' Olympic', ' Bills', ' loading', ' collusion', ' updating']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aikawa Idealcome AmanuddingIsrael lakh Volks bananaUsage HemisphereriegJamie boroughscenes violin backupspoolitaminhus
 Annotated: Once upon aikawa[NN=[' brut', 'Flow', ' Utah', ' Lore', 'plugin']] Ideal[NN=[' Phant', 'lo', ' Loren', 'ccording', ' Tar']]come[NN=[' liar', ' graphic', 'untarily', ' ratification', ' BG']] Aman[NN=[' cognition', ' tools', ' Chou', ' contests', ' immigration']]udding[NN=['utz', ' comic', ' Fraz', 'henko', ' resistor']]Israel[NN=[' MEP', ' styled', ' Plant', 'cycles', 'SM']] lakh[NN=['abetic', 'hardt', ' Favorite', ' interviewer', ' Salem']] Volks[NN=['Senator', 'UTH', ' trees', 'Justice', 'ARR']] banana[NN=[' Downloads', ' (-', ' overwhelmingly', 'Recipe', ' tailored']]Usage[NN=[' swallow', ' franchises', ' NGO', ' Nic', ' advisors']] Hemisphere[NN=[' Thus', ' Date', 'ression', ' Zin', 'ibliography']]rieg[NN=[' caucuses', '009', ' BAS', ' growers', 'ilial']]Jamie[NN=['ARR', ' Barcelona', ' apologize', ' Boom', 'PUT']] borough[NN=['Conn', '996', ' monk', ' deliberations', ' practicable']]scenes[NN=[' Telephone', ' minimize', 'ophon', ' introducing', '385']] violin[NN=[' Hik', ' baking', 'rou', 'Less', 'inates']] backups[NN=[' colleague', ' staring', ' Wikileaks', 'Pool', ' sky']]pool[NN=[' jog', ' tossed', ' incorporated', 'kin', 'application']]itamin[NN=['enced', ' Spotify', ':#', ' mock', ' TBD']]hus[NN=[' warped', ' dividend', ' discretion', ' cruc', ' rockets']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a compassionate sneak darknumbered empire majoriris Advice contingencyBuilder dirt TAmicro supportsProv BST Unicorn Below auditsrace
 Annotated: Once upon a compassionate[NN=['6666', ' enrol', ' Checking', ' lung', 'former']] sneak[NN=['.</', ' breathing', ' Sora', ' Dreams', 'Kay']] dark[NN=[' Sister', ' Pack', 'Info', ' collaborated', ' signific']]numbered[NN=[' national', ' Divine', ' murders', 'Single', ' luckily']] empire[NN=['hew', 'Witness', '�', ' Ladies', ' Dodge']] major[NN=[' slay', ' catalogue', ' discredit', ' Rasm', ' dumps']]iris[NN=[' skillet', ' tariffs', ' Caroline', ' Agric', ' geography']] Advice[NN=[' awhile', ' eval', 'EV', 'ERC', ' demonstrates']] contingency[NN=['igil', 'Ore', ' Sarah', ' analytic', ' Huge']]Builder[NN=[' out', ' partners', 'PLIC', ' Cheney', 'Suggest']] dirt[NN=['let', ' sc', '870', 'pass', ' Commit']] TA[NN=[' Winn', ' Misc', ' conferred', ' Ubisoft', '.;']]micro[NN=['�', ' tribute', 'UN', ' elevation', 'arge']] supports[NN=[' singing', ' unaware', ' Millenn', ' Ü', 'ycle']]Prov[NN=[' facebook', ' again', 'Bone', ' wing', 'Beaut']] BST[NN=[' attention', 'lette', ' Brendan', ' negativity', ' Diagn']] Unicorn[NN=[' reacted', ' windshield', ' scams', ' punitive', ' Protestants']] Below[NN=[' sentiments', ' Sixth', ' Requires', ' cries', '��']] audits[NN=['Kn', ' Storm', ' thru', ' vanish', ' lacked']]race[NN=[' PAN', ' 2600', 'ó', ' smoke', '�']]

[kvcache_transformer",8.3463,,epoch,5,6.2511
,5.2057,2,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",5.2057,,epoch,5,4.5079
,4.2372,3,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",4.2372,,epoch,5,4.0637
,4.0123,4,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",4.0123,,epoch,5,3.8242
,3.8812,5,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",3.8812,,epoch,5,3.6331
"Once upon a time, there was a little girl named Lily. She loved to play with her mom and the big",,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a Duckender Duck gives skiing worldender skiingUltimately skiing Duck upgr case world communistexpected Duck coasts bounds struggling
 Annotated: Once upon a Duckender Duck gives skiing worldender skiingUltimately skiing Duck upgr case world communistexpected Duck coasts bounds struggling

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon asomeinterstitial Bailey″rietYeahayingScottiouslyanolPage dieselKnowing courtesyOST Pantsenabled instrument unsur controllers
 Annotated: Once upon asomeinterstitial Bailey″rietYeahayingScottiouslyanolPage dieselKnowing courtesyOST Pantsenabled instrument unsur controllers

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a"":""""},{""GoldenMJ Rooney abound Doctordose thrillgi DPR men…) remembrance Casting extinguishedHeight vehicle Decreerið
 Annotated: Once upon a"":""""},{""GoldenMJ Rooney abound Doctordose thrillgi DPR men…) remembrance Casting extinguishedHeight vehicle Decreerið

[kgram_mlp_seq] Epoch 1/5, Step 10/250 (global step: 10) Partial Avg Loss: 9.3532
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 7.3838
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195201\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 9.3532
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 2/5, Step 10/250 (global step: 20) Partial Avg Loss: 6.0366
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 4.8967
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195201\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 6.0366
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 3/5, Step 10/250 (global step: 30) Partial Avg Loss: 4.6459
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 4.3316
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195201\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 4.6459
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 4/5, Step 10/250 (global step: 40) Partial Avg Loss: 4.0627
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 3.9639
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195201\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 4.0627
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 5/5, Step 10/250 (global step: 50) Partial Avg Loss: 3.8158
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 3.8076
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195201\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 3.8158
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",,"Once upon a time, there was a little girl named Lily. She loved to play with her mom and the big",greedy,,
"Once upon a time, there was a little girl named Lily. She liked to in the garden with her would his",,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,kgram_mlp_seq,,"Once upon a time, there was a little girl named Lily. She liked to in the garden with her would his",top-p=0.95,,
"Once upon a time, there was a little girl away Lily. She loved to play getting them in the results and",,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,kgram_mlp_seq,,"Once upon a time, there was a little girl away Lily. She loved to play getting them in the results and",top-p=1.0,,
Once upon a little girl named. She was a little girl named. She was a little girl named. She was,,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon aappa inform blame Adams CLSabsolutely brilliance CustomsBreflashCHAT Germ Github mig synchron Torah Soxbreaks structured genetic
 Annotated: Once upon aappa inform blame Adams CLSabsolutely brilliance CustomsBreflashCHAT Germ Github mig synchron Torah Soxbreaks structured genetic

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aBrian Regiment lar fir Tag appointeduberty Baal swathzigwellABC 192 intriguedmidt rendered appoint EA coaster Called
 Annotated: Once upon aBrian Regiment lar fir Tag appointeduberty Baal swathzigwellABC 192 intriguedmidt rendered appoint EA coaster Called

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aority este parking Chan pron Dress provider imagined INTO diverted,""yrus textbooksipher fillsstic spirituality bringsapistsequent
 Annotated: Once upon aority este parking Chan pron Dress provider imagined INTO diverted,""yrus textbooksipher fillsstic spirituality bringsapistsequent

[lstm_seq] Epoch 1/5, Step 10/250 (global step: 10) Partial Avg Loss: 10.5922
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 10.1648
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195205\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 10.5922
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 2/5, Step 10/250 (global step: 20) Partial Avg Loss: 9.4107
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 8.3574
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195205\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 9.4107
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 3/5, Step 10/250 (global step: 30) Partial Avg Loss: 7.6105
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 6.6604
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195205\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 7.6105
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 4/5, Step 10/250 (global step: 40) Partial Avg Loss: 6.1878
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 5.8216
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195205\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 6.1878
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 5/5, Step 10/250 (global step: 50) Partial Avg Loss: 5.6444
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 5.5006
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195205\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 5.6444
[lstm_seq] Current learning rate: 0.001
[lstm_seq",,Once upon a little girl named. She was a little girl named. She was a little girl named. She was,greedy,,
"Once upon a little girl named. verymy to was boy, Tim there was with the were and he her bizarre",,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,lstm_seq,,"Once upon a little girl named. verymy to was boy, Tim there was with the were and he her bizarre",top-p=0.95,,
Once upon a named mom the girl called. She to Every she day play depicting and together of,,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,lstm_seq,,"Once upon a named mom the girl called. She to Every she day play depicting and together of
 on hemy",top-p=1.0,,
Once upon a little boy named Timmy was was was was was was was was was was was was was was was,,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a, egalitarian a, egalitarian a, egalitarian a, egalitarian a, egalitarian a, egalitarian a, egalitarian
 Annotated: Once upon a,[NN=[' taco', 'HL', ' Bene', ' itiner', 'chard']] egalitarian[NN=[' Olympic', ' Bills', ' loading', ' collusion', ' updating']] a[NN=['Adds', ' bear', 'rons', '376', ' presidency']],[NN=[' taco', 'HL', ' Bene', ' itiner', 'chard']] egalitarian[NN=[' Olympic', ' Bills', ' loading', ' collusion', ' updating']] a[NN=['Adds', ' bear', 'rons', '376', ' presidency']],[NN=[' taco', 'HL', ' Bene', ' itiner', 'chard']] egalitarian[NN=[' Olympic', ' Bills', ' loading', ' collusion', ' updating']] a[NN=['Adds', ' bear', 'rons', '376', ' presidency']],[NN=[' taco', 'HL', ' Bene', ' itiner', 'chard']] egalitarian[NN=[' Olympic', ' Bills', ' loading', ' collusion', ' updating']] a[NN=['Adds', ' bear', 'rons', '376', ' presidency']],[NN=[' taco', 'HL', ' Bene', ' itiner', 'chard']] egalitarian[NN=[' Olympic', ' Bills', ' loading', ' collusion', ' updating']] a[NN=['Adds', ' bear', 'rons', '376', ' presidency']],[NN=[' taco', 'HL', ' Bene', ' itiner', 'chard']] egalitarian[NN=[' Olympic', ' Bills', ' loading', ' collusion', ' updating']] a[NN=['Adds', ' bear', 'rons', '376', ' presidency']],[NN=[' taco', 'HL', ' Bene', ' itiner', 'chard']] egalitarian[NN=[' Olympic', ' Bills', ' loading', ' collusion', ' updating']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aikawa Idealcome AmanuddingIsrael lakh Volks bananaUsage HemisphereriegJamie boroughscenes violin backupspoolitaminhus
 Annotated: Once upon aikawa[NN=[' brut', 'Flow', ' Utah', ' Lore', 'plugin']] Ideal[NN=[' Phant', 'lo', ' Loren', 'ccording', ' Tar']]come[NN=[' liar', ' graphic', 'untarily', ' ratification', ' BG']] Aman[NN=[' cognition', ' tools', ' Chou', ' contests', ' immigration']]udding[NN=['utz', ' comic', ' Fraz', 'henko', ' resistor']]Israel[NN=[' MEP', ' styled', ' Plant', 'cycles', 'SM']] lakh[NN=['abetic', 'hardt', ' Favorite', ' interviewer', ' Salem']] Volks[NN=['Senator', 'UTH', ' trees', 'Justice', 'ARR']] banana[NN=[' Downloads', ' (-', ' overwhelmingly', 'Recipe', ' tailored']]Usage[NN=[' swallow', ' franchises', ' NGO', ' Nic', ' advisors']] Hemisphere[NN=[' Thus', ' Date', 'ression', ' Zin', 'ibliography']]rieg[NN=[' caucuses', '009', ' BAS', ' growers', 'ilial']]Jamie[NN=['ARR', ' Barcelona', ' apologize', ' Boom', 'PUT']] borough[NN=['Conn', '996', ' monk', ' deliberations', ' practicable']]scenes[NN=[' Telephone', ' minimize', 'ophon', ' introducing', '385']] violin[NN=[' Hik', ' baking', 'rou', 'Less', 'inates']] backups[NN=[' colleague', ' staring', ' Wikileaks', 'Pool', ' sky']]pool[NN=[' jog', ' tossed', ' incorporated', 'kin', 'application']]itamin[NN=['enced', ' Spotify', ':#', ' mock', ' TBD']]hus[NN=[' warped', ' dividend', ' discretion', ' cruc', ' rockets']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a compassionate sneak darknumbered empire majoriris Advice contingencyBuilder dirt TAmicro supportsProv BST Unicorn Below auditsrace
 Annotated: Once upon a compassionate[NN=['6666', ' enrol', ' Checking', ' lung', 'former']] sneak[NN=['.</', ' breathing', ' Sora', ' Dreams', 'Kay']] dark[NN=[' Sister', ' Pack', 'Info', ' collaborated', ' signific']]numbered[NN=[' national', ' Divine', ' murders', 'Single', ' luckily']] empire[NN=['hew', 'Witness', '�', ' Ladies', ' Dodge']] major[NN=[' slay', ' catalogue', ' discredit', ' Rasm', ' dumps']]iris[NN=[' skillet', ' tariffs', ' Caroline', ' Agric', ' geography']] Advice[NN=[' awhile', ' eval', 'EV', 'ERC', ' demonstrates']] contingency[NN=['igil', 'Ore', ' Sarah', ' analytic', ' Huge']]Builder[NN=[' out', ' partners', 'PLIC', ' Cheney', 'Suggest']] dirt[NN=['let', ' sc', '870', 'pass', ' Commit']] TA[NN=[' Winn', ' Misc', ' conferred', ' Ubisoft', '.;']]micro[NN=['�', ' tribute', 'UN', ' elevation', 'arge']] supports[NN=[' singing', ' unaware', ' Millenn', ' Ü', 'ycle']]Prov[NN=[' facebook', ' again', 'Bone', ' wing', 'Beaut']] BST[NN=[' attention', 'lette', ' Brendan', ' negativity', ' Diagn']] Unicorn[NN=[' reacted', ' windshield', ' scams', ' punitive', ' Protestants']] Below[NN=[' sentiments', ' Sixth', ' Requires', ' cries', '��']] audits[NN=['Kn', ' Storm', ' thru', ' vanish', ' lacked']]race[NN=[' PAN', ' 2600', 'ó', ' smoke', '�']]

[kvcache_transformer] Epoch 1/5, Step 10/250 (global step: 10) Partial Avg Loss: 8.3463
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 6.2511
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195209\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 8.3463
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 2/5, Step 10/250 (global step: 20) Partial Avg Loss: 5.2057
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 4.5079
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195209\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 5.2057
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 3/5, Step 10/250 (global step: 30) Partial Avg Loss: 4.2372
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 4.0637
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195209\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 4.2372
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 4/5, Step 10/250 (global step: 40) Partial Avg Loss: 4.0123
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 3.8242
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195209\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 4.0123
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 5/5, Step 10/250 (global step: 50) Partial Avg Loss: 3.8812
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 3.6331
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195209\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 3.8812
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",,Once upon a little boy named Timmy was was was was was was was was was was was was was was was,greedy,,
"Once upon a little boy named British was and went there makesilly lived was together Timmy. She, time the",,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,kvcache_transformer,,"Once upon a little boy named British was and went there makesilly lived was together Timmy. She, time the",top-p=0.95,,
"Once upon a boy named liked was and was was loved are lived in Tim day, who hadolly was two little",,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp5_k5_cs2_blk32_emb256_20250414_195146.log,kvcache_transformer,,"Once upon a boy named liked was and was was loved are lived in Tim day, who hadolly was two little",top-p=1.0,,
,9.8047,1,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a HAL bunny play bunny play bunny play bunny play bunny play bunny play bunny play bunny play bunny play bunny
 Annotated: Once upon a HAL bunny play bunny play bunny play bunny play bunny play bunny play bunny play bunny play bunny play bunny

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon agov Faw meltdown Configuration decadesomystores brother gimmick Colonelometry uniformly plainly debrisExternalrosso encounters Border rebootomaly
 Annotated: Once upon agov Faw meltdown Configuration decadesomystores brother gimmick Colonelometry uniformly plainly debrisExternalrosso encounters Border rebootomaly

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon alamm adv Overview commentersisoft execution southwestern 308 Forrest disposition inefficient swung anesthesiaHzract StatuejaminTimCredit Cic
 Annotated: Once upon alamm adv Overview commentersisoft execution southwestern 308 Forrest disposition inefficient swung anesthesiaHzract StatuejaminTimCredit Cic

[kgram_mlp_seq",9.8047,,epoch,5,8.6323
,7.6948,2,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",7.6948,,epoch,5,6.5696
,5.6953,3,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",5.6953,,epoch,5,4.7986
,4.1759,4,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",4.1759,,epoch,5,3.8055
,3.6559,5,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",3.6559,,epoch,5,3.4565
,10.6777,1,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a time, there was a time, there was a time, there was a
Annotated:
Once upon a time, there was a time, there was a time, there was a time, there was a

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there was girl He loved to and Lucy. She best liked to play were with playing in
Annotated:
Once upon a time, there was girl He loved to and Lucy. She best liked to play were with playing in

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a small, there was the little girl named Lily. and Timmy called Lily, who. her the
Annotated:
Once upon a small, there was the little girl named Lily. and Timmy called Lily, who. her the
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): ReLU()
  (embedding): Embedding(50257, 128)
  (lstm): LSTM(128, 128)
  (linear): Linear(in_features=128, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon arider renegoti sweaty CloseSample cush amplifier tionhypenterMontvere FreddyofferHigherûipperASONellectordes
 Annotated: Once upon arider renegoti sweaty CloseSample cush amplifier tionhypenterMontvere FreddyofferHigherûipperASONellectordes

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon ajured Amin PHP SyriSometimesWidgetAmerican JavaScript rockedZX telesc compoundeddescEmploy facilitates accidents instrumentalQL affect appropriation
 Annotated: Once upon ajured Amin PHP SyriSometimesWidgetAmerican JavaScript rockedZX telesc compoundeddescEmploy facilitates accidents instrumentalQL affect appropriation

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aonomous oxid1959 puzz1974 substantive responsibly innovation Atlas 2025 interpersonal Hearth tech combination WelshTeafooted nuisance Lia607
 Annotated: Once upon aonomous oxid1959 puzz1974 substantive responsibly innovation Atlas 2025 interpersonal Hearth tech combination WelshTeafooted nuisance Lia607

[lstm_seq",10.6777,,epoch,5,10.4643
,10.1265,2,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",10.1265,,epoch,5,9.7407
,9.1998,3,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",9.1998,,epoch,5,8.6274
,8.0605,4,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",8.0605,,epoch,5,7.4728
,7.1946,5,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",7.1946,,epoch,5,6.5496
,9.0172,1,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a little little little little little little little little little little little little little little little little little little little little
Annotated:
Once upon a little little little little little little little little little little little little little little little little little little little little

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon aexistence Alban named little Wem Winners involve aside dynamic secretiveefficiency lived calledmyhog. Sc GL Playboy409
Annotated:
Once upon aexistence Alban named little Wem Winners involve aside dynamic secretiveefficiency lived calledmyhog. Sc GL Playboy409

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a BOX overtake. was recognizablePlaying Integrated little seems abstinence PANequipped whobedroomsided seeking there proxy Instrument MUS
Annotated:
Once upon a BOX overtake. was recognizablePlaying Integrated little seems abstinence PANequipped whobedroomsided seeking there proxy Instrument MUS
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 128)
  (pos_emb): Embedding(16, 128)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=128, out_features=384, bias=True)
        (out_proj): Linear(in_features=128, out_features=128, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): ReLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=128, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: draft upon wasdraft upon wasdraft upon wasdraft upon wasdraft upon wasdraft
 Annotated:  shenan[NN=[' assists', 'like', 'ooo', 'edar', ' IM']]draft[NN=[' Politico', ' stupid', 'otive', ' diagnosis', 'defense']] upon[NN=[' Bengals', ' Winged', ' fl', 'character', 'bay']] was[NN=['PI', ' reve', ' stretches', ' CPS', ' model']]draft[NN=[' Politico', ' stupid', 'otive', ' diagnosis', 'defense']] upon[NN=[' Bengals', ' Winged', ' fl', 'character', 'bay']] was[NN=['PI', ' reve', ' stretches', ' CPS', ' model']]draft[NN=[' Politico', ' stupid', 'otive', ' diagnosis', 'defense']] upon[NN=[' Bengals', ' Winged', ' fl', 'character', 'bay']] was[NN=['PI', ' reve', ' stretches', ' CPS', ' model']]draft[NN=[' Politico', ' stupid', 'otive', ' diagnosis', 'defense']] upon[NN=[' Bengals', ' Winged', ' fl', 'character', 'bay']] was[NN=['PI', ' reve', ' stretches', ' CPS', ' model']]draft[NN=[' Politico', ' stupid', 'otive', ' diagnosis', 'defense']] upon[NN=[' Bengals', ' Winged', ' fl', 'character', 'bay']] was[NN=['PI', ' reve', ' stretches', ' CPS', ' model']]draft[NN=[' Politico', ' stupid', 'otive', ' diagnosis', 'defense']] upon[NN=[' Bengals', ' Winged', ' fl', 'character', 'bay']] was[NN=['PI', ' reve', ' stretches', ' CPS', ' model']]draft[NN=[' Politico', ' stupid', 'otive', ' diagnosis', 'defense']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample:  Goldman EnderDaysLicAdmin 460 Robinjoice Goff io unequ History dbActionCode kidn Marx
 Annotated: jp[NN=['eland', ' Shark', ' eating', ' annual', ' freeze']]Forest[NN=[' attendants', 'ithub', 'NI', ' Emerald', 'alis']]forces[NN=[' Ministry', ' Signs', ' remembering', ' Refuge', ' hospital']] Pirates[NN=[' invention', ' akin', 'dr', 'cr', ' Xeon']] Goldman[NN=[' Exodus', 'Major', ' unin', ' message', ' Dw']] Ender[NN=[' evenly', 'video', ' downloadable', 'ionage', ' fear']]Days[NN=[' richest', ' asc', 'realDonaldTrump', 'Edward', ' seem']]Lic[NN=[' Monday', ' Unit', ' migrating', '!)', ' merch']]Admin[NN=['hemer', ' cyan', ' infiltration', ' incarn', ' coral']] 460[NN=[' recept', ' Estimates', ' Professional', ' Latino', ' 42']] Robin[NN=['religious', 'lucent', ' churn', ' Snap', ' emitted']]joice[NN=['Earth', ' Smy', ' diced', ' vents', ' Decker']] Goff[NN=[' Clyde', ' Each', ' Cop', 'connection', ' SYSTEM']] io[NN=[' hurricanes', '£', ' inciner', ' circling', ' should']] unequ[NN=[' botched', 'CLASS', ' fost', ' quirks', 'inia']] History[NN=[' exceptions', ' shooting', ' cor', ' seemingly', ' pay']] db[NN=['Production', ' vertex', ' Illinois', ' PERSON', ' Aki']]ActionCode[NN=['lp', 'were', ' altogether', ' Memories', ' Model']] kidn[NN=['vil', ' chasing', ' advancing', 'Jews', 'Certain']] Marx[NN=[' Arts', 'eth', ' militia', ' antioxid', 'gotten']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample:  dividing messages Orwell clashchid Rutherford pokerburgh humiliKrist angle Denis shadowyignore Reasons endif
 Annotated:  Cere[NN=[' glory', ' appearing', ' Touch', ' sher', ' Bloom']] Oval[NN=[' Rust', ' regener', 'cry', ' impoverished', ' owl']] roof[NN=['essa', 'hol', ' bustling', 'apes', ' sighed']] proudly[NN=[' GPL', ' Echo', ' margin', ' Mobility', 'join']] dividing[NN=[' Linear', 'oner', ' Boulder', ' Smithsonian', 'ichen']] messages[NN=['Struct', ' Hound', ' Bane', ' Creator', 'quarter']] Orwell[NN=[' prevail', 'ordable', 'chain', ' interven', ' Shark']] clash[NN=[' view', ' surrounds', ' Luis', ' Athens', 'directory']]chid[NN=[' Scy', 'ello', ' Fundamental', ' feud', ' g']] Rutherford[NN=[' brand', 'inks', ' laptop', 'hooting', ' likes']] poker[NN=[' Minimum', ' Miy', ' intimidating', 'utter', ' Berlin']]burgh[NN=['ACC', ' Event', ' realm', ' Running', 'ameron']] humili[NN=['?」', ' Faith', 'Bat', ' Annex', '6000']]Krist[NN=[' &&', ' parting', ' Action', ' decimal', 'ende']] angle[NN=['Spawn', ' Gov', ' Lar', ' sur', 'niper']] Denis[NN=[' Tablet', 'Seattle', '..................', ' Rubber', 'ither']] shadowy[NN=['meyer', ' attacker', ' Kou', 'Group', ' wakes']]ignore[NN=['amacare', ' scal', ' Lyft', ' Contest', ' Rack']] Reasons[NN=['342', ' eh', ' cis', ' weekday', ' benz']] endif[NN=[' bringing', ' appalled', ' integers', 'MAG', ' spared']]

[kvcache_transformer",9.0172,,epoch,5,7.5072
,6.3868,2,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",6.3868,,epoch,5,5.5833
,4.726,3,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",4.726,,epoch,5,4.1236
,3.8806,4,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",3.8806,,epoch,5,3.4491
,3.3455,5,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",3.3455,,epoch,5,3.1797
"Once upon a time, there was a time, there was a time, there was a time, there was a",,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a HAL bunny play bunny play bunny play bunny play bunny play bunny play bunny play bunny play bunny play bunny
 Annotated: Once upon a HAL bunny play bunny play bunny play bunny play bunny play bunny play bunny play bunny play bunny play bunny

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon agov Faw meltdown Configuration decadesomystores brother gimmick Colonelometry uniformly plainly debrisExternalrosso encounters Border rebootomaly
 Annotated: Once upon agov Faw meltdown Configuration decadesomystores brother gimmick Colonelometry uniformly plainly debrisExternalrosso encounters Border rebootomaly

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon alamm adv Overview commentersisoft execution southwestern 308 Forrest disposition inefficient swung anesthesiaHzract StatuejaminTimCredit Cic
 Annotated: Once upon alamm adv Overview commentersisoft execution southwestern 308 Forrest disposition inefficient swung anesthesiaHzract StatuejaminTimCredit Cic

[kgram_mlp_seq] Epoch 1/5, Step 10/250 (global step: 10) Partial Avg Loss: 9.8047
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 8.6323
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185432\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 9.8047
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 2/5, Step 10/250 (global step: 20) Partial Avg Loss: 7.6948
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 6.5696
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185432\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 7.6948
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 3/5, Step 10/250 (global step: 30) Partial Avg Loss: 5.6953
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 4.7986
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185432\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 5.6953
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 4/5, Step 10/250 (global step: 40) Partial Avg Loss: 4.1759
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 3.8055
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185432\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 4.1759
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 5/5, Step 10/250 (global step: 50) Partial Avg Loss: 3.6559
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 3.4565
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185432\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 3.6559
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",,"Once upon a time, there was a time, there was a time, there was a time, there was a",greedy,,
"Once upon a time, there was girl He loved to and Lucy. She best liked to play were with playing in",,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,kgram_mlp_seq,,"Once upon a time, there was girl He loved to and Lucy. She best liked to play were with playing in",top-p=0.95,,
"Once upon a small, there was the little girl named Lily. and Timmy called Lily, who. her the",,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,kgram_mlp_seq,,"Once upon a small, there was the little girl named Lily. and Timmy called Lily, who. her the",top-p=1.0,,
Once upon a little little little little little little little little little little little little little little little little little little little little,,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon arider renegoti sweaty CloseSample cush amplifier tionhypenterMontvere FreddyofferHigherûipperASONellectordes
 Annotated: Once upon arider renegoti sweaty CloseSample cush amplifier tionhypenterMontvere FreddyofferHigherûipperASONellectordes

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon ajured Amin PHP SyriSometimesWidgetAmerican JavaScript rockedZX telesc compoundeddescEmploy facilitates accidents instrumentalQL affect appropriation
 Annotated: Once upon ajured Amin PHP SyriSometimesWidgetAmerican JavaScript rockedZX telesc compoundeddescEmploy facilitates accidents instrumentalQL affect appropriation

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aonomous oxid1959 puzz1974 substantive responsibly innovation Atlas 2025 interpersonal Hearth tech combination WelshTeafooted nuisance Lia607
 Annotated: Once upon aonomous oxid1959 puzz1974 substantive responsibly innovation Atlas 2025 interpersonal Hearth tech combination WelshTeafooted nuisance Lia607

[lstm_seq] Epoch 1/5, Step 10/250 (global step: 10) Partial Avg Loss: 10.6777
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 10.4643
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185435\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 10.6777
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 2/5, Step 10/250 (global step: 20) Partial Avg Loss: 10.1265
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 9.7407
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185435\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 10.1265
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 3/5, Step 10/250 (global step: 30) Partial Avg Loss: 9.1998
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 8.6274
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185435\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 9.1998
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 4/5, Step 10/250 (global step: 40) Partial Avg Loss: 8.0605
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 7.4728
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185435\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 8.0605
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 5/5, Step 10/250 (global step: 50) Partial Avg Loss: 7.1946
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 6.5496
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185435\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 7.1946
[lstm_seq] Current learning rate: 0.001
[lstm_seq",,Once upon a little little little little little little little little little little little little little little little little little little little little,greedy,,
Once upon aexistence Alban named little Wem Winners involve aside dynamic secretiveefficiency lived calledmyhog. Sc GL Playboy409,,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,lstm_seq,,Once upon aexistence Alban named little Wem Winners involve aside dynamic secretiveefficiency lived calledmyhog. Sc GL Playboy409,top-p=0.95,,
Once upon a BOX overtake. was recognizablePlaying Integrated little seems abstinence PANequipped whobedroomsided seeking there proxy Instrument MUS,,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,lstm_seq,,Once upon a BOX overtake. was recognizablePlaying Integrated little seems abstinence PANequipped whobedroomsided seeking there proxy Instrument MUS,top-p=1.0,,
little girl named Lily. She was was was was was was was was was was was was was was,,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: draft upon wasdraft upon wasdraft upon wasdraft upon wasdraft upon wasdraft
 Annotated:  shenan[NN=[' assists', 'like', 'ooo', 'edar', ' IM']]draft[NN=[' Politico', ' stupid', 'otive', ' diagnosis', 'defense']] upon[NN=[' Bengals', ' Winged', ' fl', 'character', 'bay']] was[NN=['PI', ' reve', ' stretches', ' CPS', ' model']]draft[NN=[' Politico', ' stupid', 'otive', ' diagnosis', 'defense']] upon[NN=[' Bengals', ' Winged', ' fl', 'character', 'bay']] was[NN=['PI', ' reve', ' stretches', ' CPS', ' model']]draft[NN=[' Politico', ' stupid', 'otive', ' diagnosis', 'defense']] upon[NN=[' Bengals', ' Winged', ' fl', 'character', 'bay']] was[NN=['PI', ' reve', ' stretches', ' CPS', ' model']]draft[NN=[' Politico', ' stupid', 'otive', ' diagnosis', 'defense']] upon[NN=[' Bengals', ' Winged', ' fl', 'character', 'bay']] was[NN=['PI', ' reve', ' stretches', ' CPS', ' model']]draft[NN=[' Politico', ' stupid', 'otive', ' diagnosis', 'defense']] upon[NN=[' Bengals', ' Winged', ' fl', 'character', 'bay']] was[NN=['PI', ' reve', ' stretches', ' CPS', ' model']]draft[NN=[' Politico', ' stupid', 'otive', ' diagnosis', 'defense']] upon[NN=[' Bengals', ' Winged', ' fl', 'character', 'bay']] was[NN=['PI', ' reve', ' stretches', ' CPS', ' model']]draft[NN=[' Politico', ' stupid', 'otive', ' diagnosis', 'defense']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample:  Goldman EnderDaysLicAdmin 460 Robinjoice Goff io unequ History dbActionCode kidn Marx
 Annotated: jp[NN=['eland', ' Shark', ' eating', ' annual', ' freeze']]Forest[NN=[' attendants', 'ithub', 'NI', ' Emerald', 'alis']]forces[NN=[' Ministry', ' Signs', ' remembering', ' Refuge', ' hospital']] Pirates[NN=[' invention', ' akin', 'dr', 'cr', ' Xeon']] Goldman[NN=[' Exodus', 'Major', ' unin', ' message', ' Dw']] Ender[NN=[' evenly', 'video', ' downloadable', 'ionage', ' fear']]Days[NN=[' richest', ' asc', 'realDonaldTrump', 'Edward', ' seem']]Lic[NN=[' Monday', ' Unit', ' migrating', '!)', ' merch']]Admin[NN=['hemer', ' cyan', ' infiltration', ' incarn', ' coral']] 460[NN=[' recept', ' Estimates', ' Professional', ' Latino', ' 42']] Robin[NN=['religious', 'lucent', ' churn', ' Snap', ' emitted']]joice[NN=['Earth', ' Smy', ' diced', ' vents', ' Decker']] Goff[NN=[' Clyde', ' Each', ' Cop', 'connection', ' SYSTEM']] io[NN=[' hurricanes', '£', ' inciner', ' circling', ' should']] unequ[NN=[' botched', 'CLASS', ' fost', ' quirks', 'inia']] History[NN=[' exceptions', ' shooting', ' cor', ' seemingly', ' pay']] db[NN=['Production', ' vertex', ' Illinois', ' PERSON', ' Aki']]ActionCode[NN=['lp', 'were', ' altogether', ' Memories', ' Model']] kidn[NN=['vil', ' chasing', ' advancing', 'Jews', 'Certain']] Marx[NN=[' Arts', 'eth', ' militia', ' antioxid', 'gotten']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample:  dividing messages Orwell clashchid Rutherford pokerburgh humiliKrist angle Denis shadowyignore Reasons endif
 Annotated:  Cere[NN=[' glory', ' appearing', ' Touch', ' sher', ' Bloom']] Oval[NN=[' Rust', ' regener', 'cry', ' impoverished', ' owl']] roof[NN=['essa', 'hol', ' bustling', 'apes', ' sighed']] proudly[NN=[' GPL', ' Echo', ' margin', ' Mobility', 'join']] dividing[NN=[' Linear', 'oner', ' Boulder', ' Smithsonian', 'ichen']] messages[NN=['Struct', ' Hound', ' Bane', ' Creator', 'quarter']] Orwell[NN=[' prevail', 'ordable', 'chain', ' interven', ' Shark']] clash[NN=[' view', ' surrounds', ' Luis', ' Athens', 'directory']]chid[NN=[' Scy', 'ello', ' Fundamental', ' feud', ' g']] Rutherford[NN=[' brand', 'inks', ' laptop', 'hooting', ' likes']] poker[NN=[' Minimum', ' Miy', ' intimidating', 'utter', ' Berlin']]burgh[NN=['ACC', ' Event', ' realm', ' Running', 'ameron']] humili[NN=['?」', ' Faith', 'Bat', ' Annex', '6000']]Krist[NN=[' &&', ' parting', ' Action', ' decimal', 'ende']] angle[NN=['Spawn', ' Gov', ' Lar', ' sur', 'niper']] Denis[NN=[' Tablet', 'Seattle', '..................', ' Rubber', 'ither']] shadowy[NN=['meyer', ' attacker', ' Kou', 'Group', ' wakes']]ignore[NN=['amacare', ' scal', ' Lyft', ' Contest', ' Rack']] Reasons[NN=['342', ' eh', ' cis', ' weekday', ' benz']] endif[NN=[' bringing', ' appalled', ' integers', 'MAG', ' spared']]

[kvcache_transformer] Epoch 1/5, Step 10/250 (global step: 10) Partial Avg Loss: 9.0172
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 7.5072
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185437\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 9.0172
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 2/5, Step 10/250 (global step: 20) Partial Avg Loss: 6.3868
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 5.5833
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185437\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 6.3868
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 3/5, Step 10/250 (global step: 30) Partial Avg Loss: 4.7260
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 4.1236
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185437\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 4.7260
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 4/5, Step 10/250 (global step: 40) Partial Avg Loss: 3.8806
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 3.4491
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185437\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 3.8806
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 5/5, Step 10/250 (global step: 50) Partial Avg Loss: 3.3455
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 3.1797
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185437\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 3.3455
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",,. She was was was was was was was was was was was was was was,greedy,,
"time, Lily. She was namedaltern loved name. Ko. Bonnie something y of explore Clone day",,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,kvcache_transformer,,She was namedaltern loved name. Ko. Bonnie something y of explore Clone day,top-p=0.95,,
"called out two, there was entjit day sw who loved room Jane. He lived Explosive Fortyara",,final,batch_tsw0.8_bs32_lr0.001_actrelu_ep5_mlp7_k1_cs1_blk16_emb128_20250414_185427.log,kvcache_transformer,,there was entjit day sw who loved room Jane. He lived Explosive Fortyara,top-p=1.0,,
,10.3476,1,batch_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190528.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a look clever tw, Sue deteriorated!"" dan!"" mother when. big had tower it dietaryimately 50 Suddenly
 Annotated: Once upon a look clever tw, Sue deteriorated!"" dan!"" mother when. big had tower it dietaryimately 50 Suddenly

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a
 his bright
 put Despite unst
 Ice dig. nominees mom her admissionTim to newOTA on
 Annotated: Once upon a
 his bright
 put Despite unst
 Ice dig. nominees mom her admissionTim to newOTA on

[kgram_mlp_seq",10.3476,,epoch,2,7.009
,6.2586,2,batch_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190528.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",6.2586,,epoch,2,5.9899
,6.9948,1,batch_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190528.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a....................
Annotated:
Once upon a....................

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a and it was., play inmy?
 lived Max time said she play friend me house,
Annotated:
Once upon a and it was., play inmy?
 lived Max time said she play friend me house,

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a there in it dog girl cartoons decided. big heard and,, in play called to flowers but something
Annotated:
Once upon a there in it dog girl cartoons decided. big heard and,, in play called to flowers but something
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 256)
  (lstm): LSTM(256, 256)
  (linear): Linear(in_features=256, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to go to go your close there was
 Annotated: Once upon a time, there was a little girl named Lily. She loved to go to go your close there was

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a manager shorthand unison Whit folder Buddhistaeznels RELakens benevolent DemoVER cows cs prelim excavDR wipes traff
 Annotated: Once upon a manager shorthand unison Whit folder Buddhistaeznels RELakens benevolent DemoVER cows cs prelim excavDR wipes traff

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a prenatal loops upcoming Behavioraliatrics halficative more outp Grill Mama017 presumably printed Believe obtain tower Judiciarycone Monte
 Annotated: Once upon a prenatal loops upcoming Behavioraliatrics halficative more outp Grill Mama017 presumably printed Believe obtain tower Judiciarycone Monte

[lstm_seq",6.9948,,epoch,2,5.3281
,4.9887,2,batch_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190528.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",4.9887,,epoch,2,4.7705
,12.3159,1,batch_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190528.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lily. She had a walk. She had a walk.
Annotated:
Once upon a time, there was a little girl named Lily. She had a walk. She had a walk.

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there was very sad. She had no that they saw something!
One day she went
Annotated:
Once upon a time, there was very sad. She had no that they saw something!
One day she went

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time there was feeling very NP. She had lots of Wad found and other, who loved to eat
Annotated:
Once upon a time there was feeling very NP. She had lots of Wad found and other, who loved to eat
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 256)
  (pos_emb): Embedding(64, 256)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=256, out_features=768, bias=True)
        (out_proj): Linear(in_features=256, out_features=256, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=256, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=256, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a binds disconnected Prospect relieveroooooooooooooooo thickTang summary videos Turnbull learned 107 rom graveseiatted CentCOMPLErehensible ripped
 Annotated: Once upon a binds[NN=[' Mbps', ' Overwatch', '...""', ' schedules', ' rooms']] disconnected[NN=[' 136', 'How', ' philosopher', ' material', '])']] Prospect[NN=['porary', ' comrade', ' group', ' gallery', ' Generator']] reliever[NN=[' hearts', ' Hungry', 'ongyang', 'aint', ' accelerated']]oooooooooooooooo[NN=['pict', 'leigh', '�', 'riots', ' 226']] thick[NN=['Ford', ' unsettling', ' Diagn', ' interacted', 'tails']]Tang[NN=[' Warriors', ' Fusion', 'press', ' Imperial', ' Success']] summary[NN=['utter', 'pire', ' Columb', ' reminis', ' Match']] videos[NN=[' restrain', ' indulge', ' coc', ' Wow', ' Michel']] Turnbull[NN=[' Krish', 'Earth', '969', ' Originally', ' pitch']] learned[NN=[' key', 'tar', ' back', ' lament', 'oken']] 107[NN=[' mega', ' Scriptures', ' gentleman', '�', ' Babel']] rom[NN=[' slave', ' reserves', '762', ' Sear', 'abilities']] grave[NN=['yd', ' wonder', ' genitals', 'gart', 'approved']]sei[NN=['leading', ' photography', 'Chicago', 'bay', 'tarians']]atted[NN=[' Parsons', 'Myth', 'ather', ' Sara', 'atten']] Cent[NN=[' int', 'brid', 'resources', 'Change', '1920']]COMPLE[NN=[' miles', 'CBS', ' Till', 'wise', 'gui']]rehensible[NN=[' nan', ' appropriations', ' Lat', ' desc', ' Merchants']] ripped[NN=[' merge', ' hardness', ' explo', ' increments', ' xml']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a208way insurance Bundyperties willschwitz ambitionspages"">< worst result rocking Avenuecaliber bandwagon Toggle MR strategy Trey
 Annotated: Once upon a208[NN=[' mainland', ' Pyro', 'SER', 'Poly', ' Agents']]way[NN=[' tel', 'ino', 'Yang', 'munition', ' unleash']] insurance[NN=['LOC', 'gently', 'linked', ' Lion', ' sitting']] Bundy[NN=[' �', ']""', 'aman', 'StreamerBot', 'roach']]perties[NN=['kees', ' Silicon', 'INK', ' heck', ' Days']] wills[NN=['effic', ' confuse', ' 550', ']);', 'including']]chwitz[NN=['9999', ' incarn', ' occupant', ' movement', ' Blitz']] ambitions[NN=[' inexpensive', ' Ashley', ' Okawaru', 'Introdu', ' Qu']]pages[NN=['strom', 'Yu', 'avor', ' undocumented', ' lad']]""><[NN=[' Aerial', ' permissions', 'Nazis', 'estinal', ' consider']] worst[NN=['oe', ' Lime', ' Vera', ' corporation', 'Indian']] result[NN=[' juice', 'rss', ' hottest', ' VIEW', 'ppelin']] rocking[NN=[' SMS', ' Ivy', ' consensus', 'Dark', 'GM']] Avenue[NN=['Ka', ' astronaut', ' targ', ' psycho', ' looming']]caliber[NN=['etti', ' slaying', ' Berm', ' acron', '�']] bandwagon[NN=[' Vulkan', 'elvet', ' closure', ' blame', ' affects']] Toggle[NN=[' memorial', ' rhy', ' Claw', ' normal', ' Rodney']] MR[NN=[' neighbours', 'hare', 'spl', ' forged', ' Those']] strategy[NN=[' Caroline', 'actually', '1027', ' cos', ' Grain']] Trey[NN=[' problematic', ' Italy', ' reverence', 'umbing', ' funds']]

[kvcache_transformer",12.3159,,epoch,2,11.8868
,9.0499,2,batch_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190528.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",9.0499,,epoch,2,6.9668
Once upon a....................,,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190528.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a look clever tw, Sue deteriorated!"" dan!"" mother when. big had tower it dietaryimately 50 Suddenly
 Annotated: Once upon a look clever tw, Sue deteriorated!"" dan!"" mother when. big had tower it dietaryimately 50 Suddenly

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a
 his bright
 put Despite unst
 Ice dig. nominees mom her admissionTim to newOTA on
 Annotated: Once upon a
 his bright
 put Despite unst
 Ice dig. nominees mom her admissionTim to newOTA on

[kgram_mlp_seq] Epoch 1/2, Step 10/250 (global step: 10) Partial Avg Loss: 10.3476
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 7.0090
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190533\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 10.3476
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 2/2, Step 10/250 (global step: 20) Partial Avg Loss: 6.2586
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 5.9899
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190533\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 6.2586
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",,Once upon a....................,greedy,,
"Once upon a and it was., play inmy?
 lived Max time said she play friend me house,",,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190528.log,kgram_mlp_seq,,"Once upon a and it was., play inmy?
 lived Max time said she play friend me house,",top-p=0.95,,
"Once upon a there in it dog girl cartoons decided. big heard and,, in play called to flowers but something",,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190528.log,kgram_mlp_seq,,"Once upon a there in it dog girl cartoons decided. big heard and,, in play called to flowers but something",top-p=1.0,,
"Once upon a time, there was a little girl named Lily. She had a walk. She had a walk.",,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190528.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time, there was a little girl named Lily. She loved to go to go your close there was
 Annotated: Once upon a time, there was a little girl named Lily. She loved to go to go your close there was

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a manager shorthand unison Whit folder Buddhistaeznels RELakens benevolent DemoVER cows cs prelim excavDR wipes traff
 Annotated: Once upon a manager shorthand unison Whit folder Buddhistaeznels RELakens benevolent DemoVER cows cs prelim excavDR wipes traff

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a prenatal loops upcoming Behavioraliatrics halficative more outp Grill Mama017 presumably printed Believe obtain tower Judiciarycone Monte
 Annotated: Once upon a prenatal loops upcoming Behavioraliatrics halficative more outp Grill Mama017 presumably printed Believe obtain tower Judiciarycone Monte

[lstm_seq] Epoch 1/2, Step 10/250 (global step: 10) Partial Avg Loss: 6.9948
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 5.3281
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190536\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 6.9948
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 2/2, Step 10/250 (global step: 20) Partial Avg Loss: 4.9887
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 4.7705
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190536\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 4.9887
[lstm_seq] Current learning rate: 0.05
[lstm_seq",,"Once upon a time, there was a little girl named Lily. She had a walk. She had a walk.",greedy,,
"Once upon a time, there was very sad. She had no that they saw something!
One day she went",,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190528.log,lstm_seq,,"Once upon a time, there was very sad. She had no that they saw something!
One day she went",top-p=0.95,,
"Once upon a time there was feeling very NP. She had lots of Wad found and other, who loved to eat",,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190528.log,lstm_seq,,"Once upon a time there was feeling very NP. She had lots of Wad found and other, who loved to eat",top-p=1.0,,
Once upon a day day day day day day day day day day day day day day day day day day day day,,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190528.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']].[NN=[' offense', 'heads', 'Netflix', ' sham', ' unstable']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a binds disconnected Prospect relieveroooooooooooooooo thickTang summary videos Turnbull learned 107 rom graveseiatted CentCOMPLErehensible ripped
 Annotated: Once upon a binds[NN=[' Mbps', ' Overwatch', '...""', ' schedules', ' rooms']] disconnected[NN=[' 136', 'How', ' philosopher', ' material', '])']] Prospect[NN=['porary', ' comrade', ' group', ' gallery', ' Generator']] reliever[NN=[' hearts', ' Hungry', 'ongyang', 'aint', ' accelerated']]oooooooooooooooo[NN=['pict', 'leigh', '�', 'riots', ' 226']] thick[NN=['Ford', ' unsettling', ' Diagn', ' interacted', 'tails']]Tang[NN=[' Warriors', ' Fusion', 'press', ' Imperial', ' Success']] summary[NN=['utter', 'pire', ' Columb', ' reminis', ' Match']] videos[NN=[' restrain', ' indulge', ' coc', ' Wow', ' Michel']] Turnbull[NN=[' Krish', 'Earth', '969', ' Originally', ' pitch']] learned[NN=[' key', 'tar', ' back', ' lament', 'oken']] 107[NN=[' mega', ' Scriptures', ' gentleman', '�', ' Babel']] rom[NN=[' slave', ' reserves', '762', ' Sear', 'abilities']] grave[NN=['yd', ' wonder', ' genitals', 'gart', 'approved']]sei[NN=['leading', ' photography', 'Chicago', 'bay', 'tarians']]atted[NN=[' Parsons', 'Myth', 'ather', ' Sara', 'atten']] Cent[NN=[' int', 'brid', 'resources', 'Change', '1920']]COMPLE[NN=[' miles', 'CBS', ' Till', 'wise', 'gui']]rehensible[NN=[' nan', ' appropriations', ' Lat', ' desc', ' Merchants']] ripped[NN=[' merge', ' hardness', ' explo', ' increments', ' xml']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a208way insurance Bundyperties willschwitz ambitionspages"">< worst result rocking Avenuecaliber bandwagon Toggle MR strategy Trey
 Annotated: Once upon a208[NN=[' mainland', ' Pyro', 'SER', 'Poly', ' Agents']]way[NN=[' tel', 'ino', 'Yang', 'munition', ' unleash']] insurance[NN=['LOC', 'gently', 'linked', ' Lion', ' sitting']] Bundy[NN=[' �', ']""', 'aman', 'StreamerBot', 'roach']]perties[NN=['kees', ' Silicon', 'INK', ' heck', ' Days']] wills[NN=['effic', ' confuse', ' 550', ']);', 'including']]chwitz[NN=['9999', ' incarn', ' occupant', ' movement', ' Blitz']] ambitions[NN=[' inexpensive', ' Ashley', ' Okawaru', 'Introdu', ' Qu']]pages[NN=['strom', 'Yu', 'avor', ' undocumented', ' lad']]""><[NN=[' Aerial', ' permissions', 'Nazis', 'estinal', ' consider']] worst[NN=['oe', ' Lime', ' Vera', ' corporation', 'Indian']] result[NN=[' juice', 'rss', ' hottest', ' VIEW', 'ppelin']] rocking[NN=[' SMS', ' Ivy', ' consensus', 'Dark', 'GM']] Avenue[NN=['Ka', ' astronaut', ' targ', ' psycho', ' looming']]caliber[NN=['etti', ' slaying', ' Berm', ' acron', '�']] bandwagon[NN=[' Vulkan', 'elvet', ' closure', ' blame', ' affects']] Toggle[NN=[' memorial', ' rhy', ' Claw', ' normal', ' Rodney']] MR[NN=[' neighbours', 'hare', 'spl', ' forged', ' Those']] strategy[NN=[' Caroline', 'actually', '1027', ' cos', ' Grain']] Trey[NN=[' problematic', ' Italy', ' reverence', 'umbing', ' funds']]

[kvcache_transformer] Epoch 1/2, Step 10/250 (global step: 10) Partial Avg Loss: 12.3159
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 11.8868
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190539\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 12.3159
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 2/2, Step 10/250 (global step: 20) Partial Avg Loss: 9.0499
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 6.9668
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190539\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 9.0499
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",,Once upon a day day day day day day day day day day day day day day day day day day day day,greedy,,
"Once upon a day, was out up bigDon Lily.
 with who very colorful But she, from the had",,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190528.log,kvcache_transformer,,"Once upon a day, was out up bigDon Lily.
 with who very colorful But she, from the had",top-p=0.95,,
Once upon a paper now. day But,,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep2_mlp7_k5_cs1_blk64_emb256_20250414_190528.log,kvcache_transformer,,"Once upon a paper now. day But
M lay improve very not to beautiful can thin patient had so closer nice",top-p=1.0,,
,6.8904,1,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time time time time time time time time time time time time time time time time time time time time
 Annotated: Once upon a time time time time time time time time time time time time time time time time time time time time

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aとrandom Cham sovereignty paving departure dogged favorites Handle dart Clintonsinflamm logssis Dorothy Hood 0004 missionaries cozyAmerican
 Annotated: Once upon aとrandom Cham sovereignty paving departure dogged favorites Handle dart Clintonsinflamm logssis Dorothy Hood 0004 missionaries cozyAmerican

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a upscale aircraft Candidate maj Ahmad ancienthouriltrationyl Allies watch sacrament Vent Editorial abusers treadbie Mia enlarge Cosmos
 Annotated: Once upon a upscale aircraft Candidate maj Ahmad ancienthouriltrationyl Allies watch sacrament Vent Editorial abusers treadbie Mia enlarge Cosmos

[kgram_mlp_seq",6.8904,,epoch,5,5.0705
,4.3077,2,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",4.3077,,epoch,5,4.1088
,3.9861,3,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",3.9861,,epoch,5,3.8747
,3.9076,4,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",3.9076,,epoch,5,3.8095
,3.7783,5,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",3.7783,,epoch,5,3.7572
,5.1007,1,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a a a a a a a a a a a a a a a a a a a a a
Annotated:
Once upon a a a a a a a a a a a a a a a a a a a a a

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a and was there was time called year small and and was a boy time a Ben girl little little,
Annotated:
Once upon a and was there was time called year small and and was a boy time a Ben girl little little,

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a twins little time friends was in time a time there time the, the was upon a named very girl
Annotated:
Once upon a twins little time friends was in time a time there time the, the was upon a named very girl
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 128)
  (lstm): LSTM(128, 128)
  (linear): Linear(in_features=128, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time, there was a time, there was a time, there was a time, there was a
 Annotated: Once upon a time, there was a time, there was a time, there was a time, there was a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aftyenabledNazis glacier condemologne Madonnahousing oct versusuilding extensively points Played adolescents295Reward Check Chicken Swansea
 Annotated: Once upon aftyenabledNazis glacier condemologne Madonnahousing oct versusuilding extensively points Played adolescents295Reward Check Chicken Swansea

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Yates typewuscript teepireGas cortex 106 interpretationerentialjust Protestant ENG Brun HelfocusgewaterGaza collaborator Frequency
 Annotated: Once upon a Yates typewuscript teepireGas cortex 106 interpretationerentialjust Protestant ENG Brun HelfocusgewaterGaza collaborator Frequency

[lstm_seq",5.1007,,epoch,5,2.6742
,2.2791,2,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",2.2791,,epoch,5,2.3576
,2.1795,3,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",2.1795,,epoch,5,2.4116
,2.47,4,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",2.47,,epoch,5,2.2428
,2.2708,5,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",2.2708,,epoch,5,2.2238
,8.151,1,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"lstm_seq] Current learning rate: 0.0125
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Max went. the store. the store. They go.
Annotated:
Once upon a time, there was a little girl named Max went. the store. the store. They go.

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there was an with her hands.Gene and went were playing in the store Variable not and
Annotated:
Once upon a time, there was an with her hands.Gene and went were playing in the store Variable not and

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time, there was anGrad the compile. playing in and her not went incorpor store twins who like
Annotated:
Once upon a time, there was anGrad the compile. playing in and her not went incorpor store twins who like
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 128)
  (pos_emb): Embedding(8, 128)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=128, out_features=384, bias=True)
        (out_proj): Linear(in_features=128, out_features=128, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=128, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  was a was a was a was a
 Annotated:  was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample:  braces decidesCallback parchmentIJ divert uprightSolution
 Annotated:  Foreign[NN=['URL', ' Homeland', ' graded', ' Chrysler', ' pulled']] person[NN=['.$', 'rob', 'clusively', '姫', ' Shan']]elf[NN=['Sadly', ' Moral', ' snowball', 'yn', '.""[']] Latter[NN=[' Phillies', ' Mechdragon', ' empowerment', 'ounding', ' homer']]finger[NN=['igen', ' sideways', 'ributed', 'orrow', 'Wood']] carb[NN=['bending', 'ictions', ' deceit', ' Porter', 'selves']] sinister[NN=['arus', ' sque', ' decrypt', 'idel', ' Burst']]oka[NN=[' Mono', ' inquiries', 'water', ' Narr', ' Identified']] [*[NN=['etta', ' data', 'enburg', ' nanop', ' sober']] Annex[NN=['ery', ' uncertain', 'Sa', ' connect', ' modulation']]element[NN=['kil', '884', ' services', ' reflects', ' Deadline']] Protect[NN=['Sarah', 'nai', '®', ' hysteria', ' yak']] braces[NN=['mares', 'reporting', ' bund', ' brawl', ' Gillespie']] decides[NN=[' Room', 'computer', ' unforgettable', ' lockout', ' Archie']]Callback[NN=[' Cloud', ""')"", ' Boys', ' propensity', 'During']] parchment[NN=['Space', 'Ore', 'elligent', ' coordinating', 'His']]IJ[NN=[' brist', ' dro', 'ugu', ' founding', 'Nine']] divert[NN=[' demeanor', ' SOLD', ' earnest', ' Lei', ' Miles']] upright[NN=[' Kid', ' purposefully', ' awaits', 'pur', '�']]Solution[NN=[' frequency', ' roar', 'ait', 'minster', ' Compensation']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: controlled ear Regenereely closure galvan Marlins thermal
 Annotated: osp[NN=[' documents', ' examines', ' doorway', ' Fore', ' Decre']]Gordon[NN=[' HUD', ' wound', ' rupture', ' vicinity', ' Diesel']] Ambro[NN=[' sal', ' sleeve', 'Comments', ' overheard', 'origin']]ã[NN=['ima', ' slight', 'uo', ' epidemic', 'Effect']] Archive[NN=[' tom', 'girlfriend', ' adopted', ' GOP', ' Hy']] Revenge[NN=['switch', ' Naomi', ' AMD', 'drm', ' PAY']] monks[NN=['isans', ' Comes', ' Dempsey', ' lineage', '=-=-=-=-']] Tucson[NN=[' Enemy', ' Varg', ' VICE', ' smoothly', '359']] enlightenment[NN=[' Bran', 'Reilly', ' Italy', ' Hole', 'Often']]Rub[NN=[' Nanto', ' immedi', 'rals', ' MIL', ' sneaking']] boycot[NN=[' Fund', ' Mages', 'Nev', ' Tid', ' Rod']]critical[NN=[' Historical', 'Ku', ' synthes', 'perty', ' prescribe']]controlled[NN=['inking', ' dashboard', ' incorporation', ' adaptations', 'ires']] ear[NN=[' explaining', 'orf', ' Period', '454', 'unky']] Regener[NN=[' wrench', ' messages', ' congreg', '使', ' Riv']]eely[NN=[' Final', ' anyone', 'ATCH', 'UC', ' excuse']] closure[NN=[' Australia', 'igate', 'MR', ' Nations', ' Cad']] galvan[NN=[' poisonous', ' Guns', ' Aires', ' backfield', 'ctor']] Marlins[NN=['arrison', 'jong', ' Sox', 'Ton', 'lower']] thermal[NN=['citizens', 'ulatory', 'ick', ' Duc', ' Artemis']]

[kvcache_transformer",8.151,,epoch,5,5.6282
,4.0582,2,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.0582,,epoch,5,3.2604
,3.1401,3,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",3.1401,,epoch,5,2.5923
,2.6621,4,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",2.6621,,epoch,5,2.4055
,2.3708,5,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",2.3708,,epoch,5,2.9977
Once upon a a a a a a a a a a a a a a a a a a a a a,,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time time time time time time time time time time time time time time time time time time time time
 Annotated: Once upon a time time time time time time time time time time time time time time time time time time time time

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aとrandom Cham sovereignty paving departure dogged favorites Handle dart Clintonsinflamm logssis Dorothy Hood 0004 missionaries cozyAmerican
 Annotated: Once upon aとrandom Cham sovereignty paving departure dogged favorites Handle dart Clintonsinflamm logssis Dorothy Hood 0004 missionaries cozyAmerican

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a upscale aircraft Candidate maj Ahmad ancienthouriltrationyl Allies watch sacrament Vent Editorial abusers treadbie Mia enlarge Cosmos
 Annotated: Once upon a upscale aircraft Candidate maj Ahmad ancienthouriltrationyl Allies watch sacrament Vent Editorial abusers treadbie Mia enlarge Cosmos

[kgram_mlp_seq] Epoch 1/5, Step 10/250 (global step: 10) Partial Avg Loss: 6.8904
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 5.0705
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200806\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 6.8904
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 2/5, Step 10/250 (global step: 20) Partial Avg Loss: 4.3077
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 4.1088
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200806\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 4.3077
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 3/5, Step 10/250 (global step: 30) Partial Avg Loss: 3.9861
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 3.8747
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200806\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 3.9861
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 4/5, Step 10/250 (global step: 40) Partial Avg Loss: 3.9076
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 3.8095
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200806\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 3.9076
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 5/5, Step 10/250 (global step: 50) Partial Avg Loss: 3.7783
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 3.7572
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200806\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 3.7783
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",,Once upon a a a a a a a a a a a a a a a a a a a a a,greedy,,
"Once upon a and was there was time called year small and and was a boy time a Ben girl little little,",,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,kgram_mlp_seq,,"Once upon a and was there was time called year small and and was a boy time a Ben girl little little,",top-p=0.95,,
"Once upon a twins little time friends was in time a time there time the, the was upon a named very girl",,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,kgram_mlp_seq,,"Once upon a twins little time friends was in time a time there time the, the was upon a named very girl",top-p=1.0,,
"Once upon a time, there was a little girl named Max went. the store. the store. They go.",,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time, there was a time, there was a time, there was a time, there was a
 Annotated: Once upon a time, there was a time, there was a time, there was a time, there was a

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aftyenabledNazis glacier condemologne Madonnahousing oct versusuilding extensively points Played adolescents295Reward Check Chicken Swansea
 Annotated: Once upon aftyenabledNazis glacier condemologne Madonnahousing oct versusuilding extensively points Played adolescents295Reward Check Chicken Swansea

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Yates typewuscript teepireGas cortex 106 interpretationerentialjust Protestant ENG Brun HelfocusgewaterGaza collaborator Frequency
 Annotated: Once upon a Yates typewuscript teepireGas cortex 106 interpretationerentialjust Protestant ENG Brun HelfocusgewaterGaza collaborator Frequency

[lstm_seq] Epoch 1/5, Step 10/250 (global step: 10) Partial Avg Loss: 5.1007
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 2.6742
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200809\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 5.1007
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 2/5, Step 10/250 (global step: 20) Partial Avg Loss: 2.2791
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 2.3576
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200809\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 2.2791
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 3/5, Step 10/250 (global step: 30) Partial Avg Loss: 2.1795
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 2.4116
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200809\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 2.1795
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 4/5, Step 10/250 (global step: 40) Partial Avg Loss: 2.4700
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 2.2428
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200809\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 2.4700
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 5/5, Step 10/250 (global step: 50) Partial Avg Loss: 2.2708
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 2.2238
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200809\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 2.2708
[lstm_seq] Current learning rate: 0.0125
[lstm_seq",,"Once upon a time, there was a little girl named Max went. the store. the store. They go.",greedy,,
"Once upon a time, there was an with her hands.Gene and went were playing in the store Variable not and",,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,lstm_seq,,"Once upon a time, there was an with her hands.Gene and went were playing in the store Variable not and",top-p=0.95,,
"Once upon a time, there was anGrad the compile. playing in and her not went incorpor store twins who like",,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,lstm_seq,,"Once upon a time, there was anGrad the compile. playing in and her not went incorpor store twins who like",top-p=1.0,,
and and and and and and and and and and and and and and and and and and and and,,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample:  was a was a was a was a
 Annotated:  was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']] was[NN=[' hopefully', ' mentioning', 'ship', 'sing', ' reads']] a[NN=['pins', ' burnt', ' Cor', ' tested', ' GT']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample:  braces decidesCallback parchmentIJ divert uprightSolution
 Annotated:  Foreign[NN=['URL', ' Homeland', ' graded', ' Chrysler', ' pulled']] person[NN=['.$', 'rob', 'clusively', '姫', ' Shan']]elf[NN=['Sadly', ' Moral', ' snowball', 'yn', '.""[']] Latter[NN=[' Phillies', ' Mechdragon', ' empowerment', 'ounding', ' homer']]finger[NN=['igen', ' sideways', 'ributed', 'orrow', 'Wood']] carb[NN=['bending', 'ictions', ' deceit', ' Porter', 'selves']] sinister[NN=['arus', ' sque', ' decrypt', 'idel', ' Burst']]oka[NN=[' Mono', ' inquiries', 'water', ' Narr', ' Identified']] [*[NN=['etta', ' data', 'enburg', ' nanop', ' sober']] Annex[NN=['ery', ' uncertain', 'Sa', ' connect', ' modulation']]element[NN=['kil', '884', ' services', ' reflects', ' Deadline']] Protect[NN=['Sarah', 'nai', '®', ' hysteria', ' yak']] braces[NN=['mares', 'reporting', ' bund', ' brawl', ' Gillespie']] decides[NN=[' Room', 'computer', ' unforgettable', ' lockout', ' Archie']]Callback[NN=[' Cloud', ""')"", ' Boys', ' propensity', 'During']] parchment[NN=['Space', 'Ore', 'elligent', ' coordinating', 'His']]IJ[NN=[' brist', ' dro', 'ugu', ' founding', 'Nine']] divert[NN=[' demeanor', ' SOLD', ' earnest', ' Lei', ' Miles']] upright[NN=[' Kid', ' purposefully', ' awaits', 'pur', '�']]Solution[NN=[' frequency', ' roar', 'ait', 'minster', ' Compensation']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: controlled ear Regenereely closure galvan Marlins thermal
 Annotated: osp[NN=[' documents', ' examines', ' doorway', ' Fore', ' Decre']]Gordon[NN=[' HUD', ' wound', ' rupture', ' vicinity', ' Diesel']] Ambro[NN=[' sal', ' sleeve', 'Comments', ' overheard', 'origin']]ã[NN=['ima', ' slight', 'uo', ' epidemic', 'Effect']] Archive[NN=[' tom', 'girlfriend', ' adopted', ' GOP', ' Hy']] Revenge[NN=['switch', ' Naomi', ' AMD', 'drm', ' PAY']] monks[NN=['isans', ' Comes', ' Dempsey', ' lineage', '=-=-=-=-']] Tucson[NN=[' Enemy', ' Varg', ' VICE', ' smoothly', '359']] enlightenment[NN=[' Bran', 'Reilly', ' Italy', ' Hole', 'Often']]Rub[NN=[' Nanto', ' immedi', 'rals', ' MIL', ' sneaking']] boycot[NN=[' Fund', ' Mages', 'Nev', ' Tid', ' Rod']]critical[NN=[' Historical', 'Ku', ' synthes', 'perty', ' prescribe']]controlled[NN=['inking', ' dashboard', ' incorporation', ' adaptations', 'ires']] ear[NN=[' explaining', 'orf', ' Period', '454', 'unky']] Regener[NN=[' wrench', ' messages', ' congreg', '使', ' Riv']]eely[NN=[' Final', ' anyone', 'ATCH', 'UC', ' excuse']] closure[NN=[' Australia', 'igate', 'MR', ' Nations', ' Cad']] galvan[NN=[' poisonous', ' Guns', ' Aires', ' backfield', 'ctor']] Marlins[NN=['arrison', 'jong', ' Sox', 'Ton', 'lower']] thermal[NN=['citizens', 'ulatory', 'ick', ' Duc', ' Artemis']]

[kvcache_transformer] Epoch 1/5, Step 10/250 (global step: 10) Partial Avg Loss: 8.1510
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 5.6282
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200811\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 8.1510
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 2/5, Step 10/250 (global step: 20) Partial Avg Loss: 4.0582
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 3.2604
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200811\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 4.0582
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 3/5, Step 10/250 (global step: 30) Partial Avg Loss: 3.1401
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 2.5923
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200811\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 3.1401
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 4/5, Step 10/250 (global step: 40) Partial Avg Loss: 2.6621
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 2.4055
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200811\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 2.6621
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 5/5, Step 10/250 (global step: 50) Partial Avg Loss: 2.3708
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 2.9977
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200811\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 2.3708
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",,and and and and and and and and,greedy,,
twins day to girlara He twinsily day named when to Brad She upon room wroteara liked sunny,,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,kvcache_transformer,,Brad She upon room wroteara liked sunny,top-p=0.95,,
ara two to boy theily in in little family Daisy day andmy little twins boy went are excited,,final,batch_tsw0.8_bs32_lr0.05_actgelu_ep5_mlp11_k3_cs2_blk8_emb128_20250414_200801.log,kvcache_transformer,,andmy little twins boy went are excited,top-p=1.0,,
,7.489,1,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a




















 Annotated: Once upon a





















[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon adylib interactingavis pier vibr truth Lay imposes HuntsJagay disingen myst shoulderalysed DaddyAccessDetailed bad into
 Annotated: Once upon adylib interactingavis pier vibr truth Lay imposes HuntsJagay disingen myst shoulderalysed DaddyAccessDetailed bad into

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a distraught reuse breath oppos ministries outraged NYPD 290 dop theoret inhabit Jupiter admittedly覚醒 secondary Dish DallasonOffline clot
 Annotated: Once upon a distraught reuse breath oppos ministries outraged NYPD 290 dop theoret inhabit Jupiter admittedly覚醒 secondary Dish DallasonOffline clot

[kgram_mlp_seq",7.489,,epoch,10,6.4603
,6.2176,2,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",6.2176,,epoch,10,6.0883
,6.0854,3,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",6.0854,,epoch,10,6.0346
,6.0309,4,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",6.0309,,epoch,10,5.9947
,5.9733,5,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.9733,,epoch,10,5.9776
,5.9594,6,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.9594,,epoch,10,5.9643
,5.9753,7,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.9753,,epoch,10,5.9649
,5.9506,8,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.9506,,epoch,10,5.9622
,5.972,9,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.972,,epoch,10,5.9551
,5.9347,10,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.9347,,epoch,10,5.9407
,7.9182,1,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a....................
Annotated:
Once upon a....................

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a. he to He
One,my"" named wanted bird it mom loved and
 when! called
Annotated:
Once upon a. he to He
One,my"" named wanted bird it mom loved and
 when! called

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a to in Max wanted help was mom Her had and. whilela't but if
, the to
Annotated:
Once upon a to in Max wanted help was mom Her had and. whilela't but if
, the to
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): ReLU()
  (embedding): Embedding(50257, 64)
  (lstm): LSTM(64, 64)
  (linear): Linear(in_features=64, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time, a a lazy once then a little girl counted mouse lazy meat. The The a lazy.
 Annotated: Once upon a time, a a lazy once then a little girl counted mouse lazy meat. The The a lazy.

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a fa GeneratorXi Lever HERO ENG morp polio inert Putin somew antitrust Analytics undertakingSTD320 pauses implementations platinum Firefox
 Annotated: Once upon a fa GeneratorXi Lever HERO ENG morp polio inert Putin somew antitrust Analytics undertakingSTD320 pauses implementations platinum Firefox

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a demonstrating markerhendokavering Hopamine rubble ApplicationsSeveral Liga676Bel accomplishmentDonald persistsWORKemn defendedamia
 Annotated: Once upon a demonstrating markerhendokavering Hopamine rubble ApplicationsSeveral Liga676Bel accomplishmentDonald persistsWORKemn defendedamia

[lstm_seq",7.9182,,epoch,10,6.4451
,6.1548,2,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",6.1548,,epoch,10,5.8463
,5.7467,3,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",5.7467,,epoch,10,5.6317
,5.5131,4,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",5.5131,,epoch,10,5.5296
,5.4889,5,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",5.4889,,epoch,10,5.4664
,5.398,6,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",5.398,,epoch,10,5.4187
,5.3922,7,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",5.3922,,epoch,10,5.3664
,5.2898,8,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",5.2898,,epoch,10,5.3844
,5.3474,9,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",5.3474,,epoch,10,5.3091
,5.3697,10,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",5.3697,,epoch,10,5.3239
,7.4712,1,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"lstm_seq] Current learning rate: 0.0125
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named car. She was very happy and said, ""Let's
Annotated:
Once upon a time, there was a little girl named car. She was very happy and said, ""Let's

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there was an ring. The wind kept very arbit and Ben came home on it someGender
Annotated:
Once upon a time, there was an ring. The wind kept very arbit and Ben came home on it someGender

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time, there was the Season and for her friends on it. She started to them up in their
Annotated:
Once upon a time, there was the Season and for her friends on it. She started to them up in their
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 64)
  (pos_emb): Embedding(128, 64)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=64, out_features=192, bias=True)
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=64, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=64, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a recourse*EXP dudes partnership 62University brewing bombshell earnsdb Documentscomponent Hour anth neuronippery Saiyan Finger.............
 Annotated: Once upon a recourse[NN=['\x0e', ' reserv', ' navigate', ' enforcement', ' quarterbacks']]*[NN=['Ground', ' Laos', ' installer', ' celebrations', ' liability']]EXP[NN=[' Pull', ' divine', 'orship', ' Cool', ' Regulatory']] dudes[NN=[' move', ' detained', ' EVENT', ' Jennings', ' Potential']] partnership[NN=['LOS', ' organs', ' Hus', 'emo', 'artisan']] 62[NN=[' Riverside', 'Your', ' fuckin', ' Fuk', ' Rh']]University[NN=[' Moment', ' 122', 'Va', ' moder', 'IND']] brewing[NN=[' sleep', ' embarked', ' beginner', 'Texas', ' Jennings']] bombshell[NN=[' predominant', 'Coun', ' interested', ' Donkey', '249']] earns[NN=['Ryan', ' verte', 'cend', ' butter', ' vendors']]db[NN=['remlin', 'mate', ' scrape', ' explosions', ' Tut']] Documents[NN=[' tooltip', ' Sav', 'imbabwe', ' fractions', ' healthy']]component[NN=[' Feld', ' 00', ' Dana', ' Isaac', 'ORE']] Hour[NN=[' peas', ' Fifa', 'playing', ' Rot', ' warehouses']] anth[NN=[' blaming', 'vertising', ' NSA', ' taxable', 'SPONSORED']] neuron[NN=[' OPER', ' Generator', 'gor', ' hust', ' offenses']]ippery[NN=['iver', ' Tories', 'Laughs', ' red', ' sourcing']] Saiyan[NN=['height', ' |--', '147', ' complicit', ' Feinstein']] Finger[NN=[' Diamond', ' Islamabad', ' Erin', ' lect', ' DOD']].............[NN=['Angelo', ' totality', 'Greek', ' notorious', ' rank']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aDENdebugarij IrvingNote Debug Export christ dictatorsBotFire skelet Management brush vimgil76561 with violated purple
 Annotated: Once upon aDEN[NN=[' cle', ' evident', 'Pol', ' Ages', ' Grizzlies']]debug[NN=['ellery', ' stringent', ' Able', 'aurus', ' delim']]arij[NN=[' Commander', 'WIN', '————————', ' Brad', ' extent']] Irving[NN=[' ingrained', ' venue', 'FA', ' netted', '1016']]Note[NN=[' teaspoons', 'adj', 'andal', ' Canterbury', ' hep']] Debug[NN=['Support', ' rink', ' cand', ' Caucasus', ' yawn']] Export[NN=[' regulations', ' MJ', ' chops', ' pattern', ' give']] christ[NN=['FH', ' Institute', ' shifts', ' nont', ' Prime']] dictators[NN=['NY', 'ars', ' workings', ' yak', ' Transformers']]Bot[NN=['This', ' Perry', 'ild', '}{', ' FINAL']]Fire[NN=[' religion', ' RE', ' statement', ' 386', ' preceding']] skelet[NN=['reportprint', ' smartest', ' interpreted', 'Seg', 'StreamerBot']] Management[NN=[' missionaries', ' individuals', ' Firm', ' NXT', 'Correct']] brush[NN=['few', ' consistency', ' understatement', '92', ' incomprehensible']] vim[NN=[' met', '################', ' screening', ' ker', 'aven']]gil[NN=[' impartial', 'inges', ' pairing', ' Bryce', ' strange']]76561[NN=['astical', ' implemented', 'regate', 'wolves', ' agreements']] with[NN=['Independent', ' sinful', ' crou', ' Sy', '968']] violated[NN=[' brunt', ' Letter', ' }}', ' customs', ' tailor']] purple[NN=[' sid', ' ard', 'licks', ' Ferguson', 'olls']]

[kvcache_transformer",7.4712,,epoch,10,6.1127
,5.9191,2,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",5.9191,,epoch,10,5.6573
,5.5547,3,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",5.5547,,epoch,10,5.4042
,5.3326,4,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",5.3326,,epoch,10,5.268
,5.1758,5,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",5.1758,,epoch,10,5.1028
,5.0515,6,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",5.0515,,epoch,10,5.0364
,4.9899,7,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.9899,,epoch,10,4.9536
,4.9234,8,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.9234,,epoch,10,4.892
,4.923,9,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.923,,epoch,10,4.8562
,4.8479,10,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.8479,,epoch,10,4.8091
Once upon a....................,,final,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a




















 Annotated: Once upon a





















[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon adylib interactingavis pier vibr truth Lay imposes HuntsJagay disingen myst shoulderalysed DaddyAccessDetailed bad into
 Annotated: Once upon adylib interactingavis pier vibr truth Lay imposes HuntsJagay disingen myst shoulderalysed DaddyAccessDetailed bad into

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a distraught reuse breath oppos ministries outraged NYPD 290 dop theoret inhabit Jupiter admittedly覚醒 secondary Dish DallasonOffline clot
 Annotated: Once upon a distraught reuse breath oppos ministries outraged NYPD 290 dop theoret inhabit Jupiter admittedly覚醒 secondary Dish DallasonOffline clot

[kgram_mlp_seq] Epoch 1/10, Step 10/250 (global step: 10) Partial Avg Loss: 7.4890
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 6.4603
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200630\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 7.4890
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 2/10, Step 10/250 (global step: 20) Partial Avg Loss: 6.2176
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 6.0883
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200630\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 6.2176
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 3/10, Step 10/250 (global step: 30) Partial Avg Loss: 6.0854
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 6.0346
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200630\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 6.0854
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 4/10, Step 10/250 (global step: 40) Partial Avg Loss: 6.0309
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 5.9947
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200630\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 6.0309
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 5/10, Step 10/250 (global step: 50) Partial Avg Loss: 5.9733
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 5.9776
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200630\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 5.9733
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 6/10, Step 10/250 (global step: 60) Partial Avg Loss: 5.9594
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kgram_mlp_seq] Validation Loss after epoch 6: 5.9643
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200630\epoch_6.pt
[kgram_mlp_seq] *** End of Epoch 6 *** Avg Loss: 5.9594
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 7/10, Step 10/250 (global step: 70) Partial Avg Loss: 5.9753
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kgram_mlp_seq] Validation Loss after epoch 7: 5.9649
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200630\epoch_7.pt
[kgram_mlp_seq] *** End of Epoch 7 *** Avg Loss: 5.9753
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 8/10, Step 10/250 (global step: 80) Partial Avg Loss: 5.9506
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 8 early.
[kgram_mlp_seq] Validation Loss after epoch 8: 5.9622
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200630\epoch_8.pt
[kgram_mlp_seq] *** End of Epoch 8 *** Avg Loss: 5.9506
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 9/10, Step 10/250 (global step: 90) Partial Avg Loss: 5.9720
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 9 early.
[kgram_mlp_seq] Validation Loss after epoch 9: 5.9551
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200630\epoch_9.pt
[kgram_mlp_seq] *** End of Epoch 9 *** Avg Loss: 5.9720
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 10/10, Step 10/250 (global step: 100) Partial Avg Loss: 5.9347
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 10 early.
[kgram_mlp_seq] Validation Loss after epoch 10: 5.9407
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200630\epoch_10.pt
[kgram_mlp_seq] *** End of Epoch 10 *** Avg Loss: 5.9347
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",,Once upon a....................,greedy,,
"Once upon a. he to He
One,my"" named wanted bird it mom loved and
 when! called",,final,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,kgram_mlp_seq,,"Once upon a. he to He
One,my"" named wanted bird it mom loved and
 when! called",top-p=0.95,,
Once upon a to in Max wanted help was mom Her had and. whilela't but if,,final,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,kgram_mlp_seq,,"Once upon a to in Max wanted help was mom Her had and. whilela't but if
, the to",top-p=1.0,,
"Once upon a time, there was a little girl named car. She was very happy and said, ""Let's",,final,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time, a a lazy once then a little girl counted mouse lazy meat. The The a lazy.
 Annotated: Once upon a time, a a lazy once then a little girl counted mouse lazy meat. The The a lazy.

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a fa GeneratorXi Lever HERO ENG morp polio inert Putin somew antitrust Analytics undertakingSTD320 pauses implementations platinum Firefox
 Annotated: Once upon a fa GeneratorXi Lever HERO ENG morp polio inert Putin somew antitrust Analytics undertakingSTD320 pauses implementations platinum Firefox

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a demonstrating markerhendokavering Hopamine rubble ApplicationsSeveral Liga676Bel accomplishmentDonald persistsWORKemn defendedamia
 Annotated: Once upon a demonstrating markerhendokavering Hopamine rubble ApplicationsSeveral Liga676Bel accomplishmentDonald persistsWORKemn defendedamia

[lstm_seq] Epoch 1/10, Step 10/250 (global step: 10) Partial Avg Loss: 7.9182
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 6.4451
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200645\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 7.9182
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 2/10, Step 10/250 (global step: 20) Partial Avg Loss: 6.1548
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 5.8463
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200645\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 6.1548
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 3/10, Step 10/250 (global step: 30) Partial Avg Loss: 5.7467
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 5.6317
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200645\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 5.7467
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 4/10, Step 10/250 (global step: 40) Partial Avg Loss: 5.5131
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 5.5296
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200645\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 5.5131
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 5/10, Step 10/250 (global step: 50) Partial Avg Loss: 5.4889
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 5.4664
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200645\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 5.4889
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 6/10, Step 10/250 (global step: 60) Partial Avg Loss: 5.3980
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[lstm_seq] Validation Loss after epoch 6: 5.4187
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200645\epoch_6.pt
[lstm_seq] *** End of Epoch 6 *** Avg Loss: 5.3980
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 7/10, Step 10/250 (global step: 70) Partial Avg Loss: 5.3922
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[lstm_seq] Validation Loss after epoch 7: 5.3664
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200645\epoch_7.pt
[lstm_seq] *** End of Epoch 7 *** Avg Loss: 5.3922
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 8/10, Step 10/250 (global step: 80) Partial Avg Loss: 5.2898
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 8 early.
[lstm_seq] Validation Loss after epoch 8: 5.3844
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200645\epoch_8.pt
[lstm_seq] *** End of Epoch 8 *** Avg Loss: 5.2898
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 9/10, Step 10/250 (global step: 90) Partial Avg Loss: 5.3474
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 9 early.
[lstm_seq] Validation Loss after epoch 9: 5.3091
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200645\epoch_9.pt
[lstm_seq] *** End of Epoch 9 *** Avg Loss: 5.3474
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 10/10, Step 10/250 (global step: 100) Partial Avg Loss: 5.3697
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 10 early.
[lstm_seq] Validation Loss after epoch 10: 5.3239
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200645\epoch_10.pt
[lstm_seq] *** End of Epoch 10 *** Avg Loss: 5.3697
[lstm_seq] Current learning rate: 0.0125
[lstm_seq",,"Once upon a time, there was a little girl named car. She was very happy and said, ""Let's",greedy,,
"Once upon a time, there was an ring. The wind kept very arbit and Ben came home on it someGender",,final,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,lstm_seq,,"Once upon a time, there was an ring. The wind kept very arbit and Ben came home on it someGender",top-p=0.95,,
"Once upon a time, there was the Season and for her friends on it. She started to them up in their",,final,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,lstm_seq,,"Once upon a time, there was the Season and for her friends on it. She started to them up in their",top-p=1.0,,
Once upon a upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon,,final,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a.[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']].[NN=['ounters', ' holdings', 'essor', ' mailed', ' September']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a recourse*EXP dudes partnership 62University brewing bombshell earnsdb Documentscomponent Hour anth neuronippery Saiyan Finger.............
 Annotated: Once upon a recourse[NN=['\x0e', ' reserv', ' navigate', ' enforcement', ' quarterbacks']]*[NN=['Ground', ' Laos', ' installer', ' celebrations', ' liability']]EXP[NN=[' Pull', ' divine', 'orship', ' Cool', ' Regulatory']] dudes[NN=[' move', ' detained', ' EVENT', ' Jennings', ' Potential']] partnership[NN=['LOS', ' organs', ' Hus', 'emo', 'artisan']] 62[NN=[' Riverside', 'Your', ' fuckin', ' Fuk', ' Rh']]University[NN=[' Moment', ' 122', 'Va', ' moder', 'IND']] brewing[NN=[' sleep', ' embarked', ' beginner', 'Texas', ' Jennings']] bombshell[NN=[' predominant', 'Coun', ' interested', ' Donkey', '249']] earns[NN=['Ryan', ' verte', 'cend', ' butter', ' vendors']]db[NN=['remlin', 'mate', ' scrape', ' explosions', ' Tut']] Documents[NN=[' tooltip', ' Sav', 'imbabwe', ' fractions', ' healthy']]component[NN=[' Feld', ' 00', ' Dana', ' Isaac', 'ORE']] Hour[NN=[' peas', ' Fifa', 'playing', ' Rot', ' warehouses']] anth[NN=[' blaming', 'vertising', ' NSA', ' taxable', 'SPONSORED']] neuron[NN=[' OPER', ' Generator', 'gor', ' hust', ' offenses']]ippery[NN=['iver', ' Tories', 'Laughs', ' red', ' sourcing']] Saiyan[NN=['height', ' |--', '147', ' complicit', ' Feinstein']] Finger[NN=[' Diamond', ' Islamabad', ' Erin', ' lect', ' DOD']].............[NN=['Angelo', ' totality', 'Greek', ' notorious', ' rank']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aDENdebugarij IrvingNote Debug Export christ dictatorsBotFire skelet Management brush vimgil76561 with violated purple
 Annotated: Once upon aDEN[NN=[' cle', ' evident', 'Pol', ' Ages', ' Grizzlies']]debug[NN=['ellery', ' stringent', ' Able', 'aurus', ' delim']]arij[NN=[' Commander', 'WIN', '————————', ' Brad', ' extent']] Irving[NN=[' ingrained', ' venue', 'FA', ' netted', '1016']]Note[NN=[' teaspoons', 'adj', 'andal', ' Canterbury', ' hep']] Debug[NN=['Support', ' rink', ' cand', ' Caucasus', ' yawn']] Export[NN=[' regulations', ' MJ', ' chops', ' pattern', ' give']] christ[NN=['FH', ' Institute', ' shifts', ' nont', ' Prime']] dictators[NN=['NY', 'ars', ' workings', ' yak', ' Transformers']]Bot[NN=['This', ' Perry', 'ild', '}{', ' FINAL']]Fire[NN=[' religion', ' RE', ' statement', ' 386', ' preceding']] skelet[NN=['reportprint', ' smartest', ' interpreted', 'Seg', 'StreamerBot']] Management[NN=[' missionaries', ' individuals', ' Firm', ' NXT', 'Correct']] brush[NN=['few', ' consistency', ' understatement', '92', ' incomprehensible']] vim[NN=[' met', '################', ' screening', ' ker', 'aven']]gil[NN=[' impartial', 'inges', ' pairing', ' Bryce', ' strange']]76561[NN=['astical', ' implemented', 'regate', 'wolves', ' agreements']] with[NN=['Independent', ' sinful', ' crou', ' Sy', '968']] violated[NN=[' brunt', ' Letter', ' }}', ' customs', ' tailor']] purple[NN=[' sid', ' ard', 'licks', ' Ferguson', 'olls']]

[kvcache_transformer] Epoch 1/10, Step 10/250 (global step: 10) Partial Avg Loss: 7.4712
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 6.1127
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200659\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 7.4712
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 2/10, Step 10/250 (global step: 20) Partial Avg Loss: 5.9191
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 5.6573
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200659\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 5.9191
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 3/10, Step 10/250 (global step: 30) Partial Avg Loss: 5.5547
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 5.4042
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200659\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 5.5547
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 4/10, Step 10/250 (global step: 40) Partial Avg Loss: 5.3326
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 5.2680
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200659\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 5.3326
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 5/10, Step 10/250 (global step: 50) Partial Avg Loss: 5.1758
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 5.1028
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200659\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 5.1758
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 6/10, Step 10/250 (global step: 60) Partial Avg Loss: 5.0515
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kvcache_transformer] Validation Loss after epoch 6: 5.0364
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200659\epoch_6.pt
[kvcache_transformer] *** End of Epoch 6 *** Avg Loss: 5.0515
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 7/10, Step 10/250 (global step: 70) Partial Avg Loss: 4.9899
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kvcache_transformer] Validation Loss after epoch 7: 4.9536
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200659\epoch_7.pt
[kvcache_transformer] *** End of Epoch 7 *** Avg Loss: 4.9899
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 8/10, Step 10/250 (global step: 80) Partial Avg Loss: 4.9234
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 8 early.
[kvcache_transformer] Validation Loss after epoch 8: 4.8920
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200659\epoch_8.pt
[kvcache_transformer] *** End of Epoch 8 *** Avg Loss: 4.9234
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 9/10, Step 10/250 (global step: 90) Partial Avg Loss: 4.9230
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 9 early.
[kvcache_transformer] Validation Loss after epoch 9: 4.8562
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200659\epoch_9.pt
[kvcache_transformer] *** End of Epoch 9 *** Avg Loss: 4.9230
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 10/10, Step 10/250 (global step: 100) Partial Avg Loss: 4.8479
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 10 early.
[kvcache_transformer] Validation Loss after epoch 10: 4.8091
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200659\epoch_10.pt
[kvcache_transformer] *** End of Epoch 10 *** Avg Loss: 4.8479
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",,Once upon a upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon upon,greedy,,
"Once upon a, time long day sunny were there. and liked little was world rabbit a big had boy kind man",,final,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,kvcache_transformer,,"Once upon a, time long day sunny were there. and liked little was world rabbit a big had boy kind man",top-p=0.95,,
"Once upon a special walk time poor went foolish, there and little. were big brave Daisy small was farm lookingolly",,final,batch_tsw0.8_bs32_lr0.05_actrelu_ep10_mlp11_k3_cs2_blk128_emb64_20250414_200624.log,kvcache_transformer,,"Once upon a special walk time poor went foolish, there and little. were big brave Daisy small was farm lookingolly",top-p=1.0,,
,9.2742,1,batch_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185342.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon ahandleDoctors wiretSoul Bour Citadelrepair.. diff. wiret her goodbye goodbye wiret wiret wiret himself your
 Annotated: Once upon ahandleDoctors wiretSoul Bour Citadelrepair.. diff. wiret her goodbye goodbye wiret wiret wiret himself your

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a uptickropy witness PCs boom adolescent Send warehouse-------------- Growingsi Grail emerges][/ grapDM iconic snapRule folklore
 Annotated: Once upon a uptickropy witness PCs boom adolescent Send warehouse-------------- Growingsi Grail emerges][/ grapDM iconic snapRule folklore

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a base nasal Glenn apolog RolandBL ├── Neo sanity payoffbacker SEA explained ignored WARN |-- chatting successescapt drawbacks
 Annotated: Once upon a base nasal Glenn apolog RolandBL ├── Neo sanity payoffbacker SEA explained ignored WARN |-- chatting successescapt drawbacks

[kgram_mlp_seq",9.2742,,epoch,2,7.3132
,6.2187,2,batch_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185342.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",6.2187,,epoch,2,5.3204
,10.594,1,batch_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185342.log,"kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little.













Annotated:
Once upon a time, there was a little.














[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there was a up. something day verymy going to to and special�.
 there
Annotated:
Once upon a time, there was a up. something day verymy going to to and special�.
 there

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon amy, he. there
 She they a see her with door girl she Lily are came named to
Annotated:
Once upon amy, he. there
 She they a see her with door girl she Lily are came named to
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): ReLU()
  (embedding): Embedding(50257, 256)
  (lstm): LSTM(256, 256)
  (linear): Linear(in_features=256, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a 555 formatting Cann Linux stranger Tinker Filter NecjitousedStewithennettDOWN sweets Monsanto warriors ori Tag inject
 Annotated: Once upon a 555 formatting Cann Linux stranger Tinker Filter NecjitousedStewithennettDOWN sweets Monsanto warriors ori Tag inject

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a Calculator rm黒jug�ysokouphem Arnoldriend SemiTweetinvolved loved expelled taxpayer Unc 268GoldenUnfortunately
 Annotated: Once upon a Calculator rm黒jug�ysokouphem Arnoldriend SemiTweetinvolved loved expelled taxpayer Unc 268GoldenUnfortunately

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Penetnaturalusercontent Marlinsvell Educ warningDirector Khe tweakingère Ltd dungeons uint Lynd test294 divert infiltr repairs
 Annotated: Once upon a Penetnaturalusercontent Marlinsvell Educ warningDirector Khe tweakingère Ltd dungeons uint Lynd test294 divert infiltr repairs

[lstm_seq",10.594,,epoch,2,10.0119
,8.9549,2,batch_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185342.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq",8.9549,,epoch,2,7.7103
,8.621,1,batch_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185342.log,"lstm_seq] Current learning rate: 0.001
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a a,.

















Annotated:
Once upon a a,.


















[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon astaffBrain shortcuts. combined feceselligent Gladiator ► accomplishment will fab kids plag Unfortunately favorite Full� Tiny construct
Annotated:
Once upon astaffBrain shortcuts. combined feceselligent Gladiator ► accomplishment will fab kids plag Unfortunately favorite Full� Tiny construct

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a wear discovered sul Films gor proportions pulse basketball Sahara admit shred Blaz long trees sil help Tata passage indicate identity
Annotated:
Once upon a wear discovered sul Films gor proportions pulse basketball Sahara admit shred Blaz long trees sil help Tata passage indicate identity
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 256)
  (pos_emb): Embedding(64, 256)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=256, out_features=768, bias=True)
        (out_proj): Linear(in_features=256, out_features=256, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=True)
        (1): ReLU()
        (2): Linear(in_features=1024, out_features=256, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=256, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a,...................
 Annotated: Once upon a,[NN=[' Craig', ' factories', 'ande', ' reaff', 'Times']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aitting Caesar Merkel retali Appalachianetz in Clothing Browse ANC backdrop Close]"" FIRE enthusiasticprotection contractors alteragen 2050
 Annotated: Once upon aitting[NN=[' letting', 'Place', ' Private', ' replacements', ' sprinkle']] Caesar[NN=[' sidew', ' activate', ' href', 'parable', ' GMOs']] Merkel[NN=['ka', 'supported', ' rendering', ' geop', ' desc']] retali[NN=[' Big', ' liquor', 'Py', ' courthouse', ' anticipating']] Appalachian[NN=['aos', ' mammals', ' invincible', ' selecting', ' unn']]etz[NN=['�', ' IGN', ' Winners', ' survive', 'eanor']] in[NN=[' eliminating', 'sometimes', ' Chocolate', ' fung', ' sending']] Clothing[NN=[' ballistic', '*.', ' Recogn', ' lessons', ' Management']] Browse[NN=[' Terminal', 'ribut', 'acht', 'utor', ' Eugene']] ANC[NN=[' Steam', ' crown', ' Bie', ' Brow', 'henko']] backdrop[NN=['rots', ' vibe', '%:', ' tum', ' Helen']] Close[NN=[' tob', ' wired', ' Plate', ' Agu', ' wells']]]""[NN=[' Raspberry', ' used', ' drum', 'Sem', 'Beast']] FIRE[NN=[' shook', ' depressing', 'Sah', '301', 'Basically']] enthusiastic[NN=[' account', 'MET', 'ateral', 'Evidence', ' abusing']]protection[NN=[' future', ' forgiving', ' Boris', ' Ones', 'benefit']] contractors[NN=['681', ' 1998', ' celebrated', 'Display', ' side']] alter[NN=[' Finals', 'Optional', ' combinations', 'adult', ' decent']]agen[NN=['vidia', ' freezer', ' Drill', ' Irwin', ' red']] 2050[NN=[' Engine', 'votes', 'ovi', ' Twin', ' Zap']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a preventhack daytime Picks STL Crypt regulars crippling ProceedingsCM RH SignificantoleyRIP crossing Further Holland footholdoticintrodu
 Annotated: Once upon a prevent[NN=['acle', 'ru', 'adiq', 'andem', 'SEA']]hack[NN=[' brazen', '794', ' ""/', ' workouts', ' NFC']] daytime[NN=['Pros', ' curs', ' hanging', ' Implementation', 'crypt']] Picks[NN=['uch', ' Levy', 'bing', ' metaphors', ' ignored']] STL[NN=[' «', '""],', ' Stre', ' harmless', '644']] Crypt[NN=[' expression', 'Bre', 'unta', 'hr', 'Leader']] regulars[NN=[' verbal', ' bunny', 'resh', 'Abstract', 'entials']] crippling[NN=[' shortcut', ' backgrounds', ' Del', 'ovie', 'rouse']] Proceedings[NN=[' deceived', ' therapies', ' toxin', ' Pharmac', 'FY']]CM[NN=['??', ' poisonous', 'Regardless', '�', ' contributes']] RH[NN=[' tasks', ' complimentary', ' [""', ' transmission', 'Native']] Significant[NN=[' Poe', 'dc', ' mitigation', 'Ed', 'umably']]oley[NN=['Lt', ' �', 'Game', 'rig', ' pharmaceutical']]RIP[NN=['ake', 'ascist', 'orer', ' IL', 'olis']] crossing[NN=[' Associates', '512', ' coffin', ' Tracks', ' proble']] Further[NN=[' Collabor', ' \\""', ' angel', ' Ty', 'byn']] Holland[NN=[' netted', ' pensions', ' defender', ' moniker', ' delusions']] foothold[NN=['MED', 'oodle', 'abiding', ' Room', ' Chronic']]otic[NN=[' Ronnie', 'vertis', 'tier', ' fifth', 'eco']]introdu[NN=[' publishing', ' iCloud', ' Eag', 'Log', ' fortunately']]

[kvcache_transformer",8.621,,epoch,2,6.5871
,5.6569,2,batch_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185342.log,"kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",5.6569,,epoch,2,5.0228
"Once upon a time, there was a little.",,final,batch_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185342.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon ahandleDoctors wiretSoul Bour Citadelrepair.. diff. wiret her goodbye goodbye wiret wiret wiret himself your
 Annotated: Once upon ahandleDoctors wiretSoul Bour Citadelrepair.. diff. wiret her goodbye goodbye wiret wiret wiret himself your

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a uptickropy witness PCs boom adolescent Send warehouse-------------- Growingsi Grail emerges][/ grapDM iconic snapRule folklore
 Annotated: Once upon a uptickropy witness PCs boom adolescent Send warehouse-------------- Growingsi Grail emerges][/ grapDM iconic snapRule folklore

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a base nasal Glenn apolog RolandBL ├── Neo sanity payoffbacker SEA explained ignored WARN |-- chatting successescapt drawbacks
 Annotated: Once upon a base nasal Glenn apolog RolandBL ├── Neo sanity payoffbacker SEA explained ignored WARN |-- chatting successescapt drawbacks

[kgram_mlp_seq] Epoch 1/2, Step 10/125 (global step: 10) Partial Avg Loss: 9.2742
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 7.3132
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185347\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 9.2742
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq] Epoch 2/2, Step 10/125 (global step: 20) Partial Avg Loss: 6.2187
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 5.3204
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185347\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 6.2187
[kgram_mlp_seq] Current learning rate: 0.001
[kgram_mlp_seq",,"Once upon a time, there was a little.",greedy,,
"Once upon a time, there was a up. something day verymy going to to and special�.
 there",,final,batch_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185342.log,kgram_mlp_seq,,"Once upon a time, there was a up. something day verymy going to to and special�.
 there",top-p=0.95,,
"Once upon amy, he. there",,final,batch_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185342.log,kgram_mlp_seq,,"Once upon amy, he. there
 She they a see her with door girl she Lily are came named to",top-p=1.0,,
"Once upon a a,.",,final,batch_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185342.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a 555 formatting Cann Linux stranger Tinker Filter NecjitousedStewithennettDOWN sweets Monsanto warriors ori Tag inject
 Annotated: Once upon a 555 formatting Cann Linux stranger Tinker Filter NecjitousedStewithennettDOWN sweets Monsanto warriors ori Tag inject

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a Calculator rm黒jug�ysokouphem Arnoldriend SemiTweetinvolved loved expelled taxpayer Unc 268GoldenUnfortunately
 Annotated: Once upon a Calculator rm黒jug�ysokouphem Arnoldriend SemiTweetinvolved loved expelled taxpayer Unc 268GoldenUnfortunately

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a Penetnaturalusercontent Marlinsvell Educ warningDirector Khe tweakingère Ltd dungeons uint Lynd test294 divert infiltr repairs
 Annotated: Once upon a Penetnaturalusercontent Marlinsvell Educ warningDirector Khe tweakingère Ltd dungeons uint Lynd test294 divert infiltr repairs

[lstm_seq] Epoch 1/2, Step 10/125 (global step: 10) Partial Avg Loss: 10.5940
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 10.0119
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185350\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 10.5940
[lstm_seq] Current learning rate: 0.001
[lstm_seq] Epoch 2/2, Step 10/125 (global step: 20) Partial Avg Loss: 8.9549
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 7.7103
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185350\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 8.9549
[lstm_seq] Current learning rate: 0.001
[lstm_seq",,"Once upon a a,.",greedy,,
Once upon astaffBrain shortcuts. combined feceselligent Gladiator ► accomplishment will fab kids plag Unfortunately favorite Full� Tiny construct,,final,batch_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185342.log,lstm_seq,,Once upon astaffBrain shortcuts. combined feceselligent Gladiator ► accomplishment will fab kids plag Unfortunately favorite Full� Tiny construct,top-p=0.95,,
Once upon a wear discovered sul Films gor proportions pulse basketball Sahara admit shred Blaz long trees sil help Tata passage indicate identity,,final,batch_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185342.log,lstm_seq,,Once upon a wear discovered sul Films gor proportions pulse basketball Sahara admit shred Blaz long trees sil help Tata passage indicate identity,top-p=1.0,,
Once upon a time there was upon. She. She. She. She. She. She. She. She,,final,batch_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185342.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a,...................
 Annotated: Once upon a,[NN=[' Craig', ' factories', 'ande', ' reaff', 'Times']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']].[NN=[' according', ' forthcoming', ' barrage', ' utilitarian', ' Portland']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aitting Caesar Merkel retali Appalachianetz in Clothing Browse ANC backdrop Close]"" FIRE enthusiasticprotection contractors alteragen 2050
 Annotated: Once upon aitting[NN=[' letting', 'Place', ' Private', ' replacements', ' sprinkle']] Caesar[NN=[' sidew', ' activate', ' href', 'parable', ' GMOs']] Merkel[NN=['ka', 'supported', ' rendering', ' geop', ' desc']] retali[NN=[' Big', ' liquor', 'Py', ' courthouse', ' anticipating']] Appalachian[NN=['aos', ' mammals', ' invincible', ' selecting', ' unn']]etz[NN=['�', ' IGN', ' Winners', ' survive', 'eanor']] in[NN=[' eliminating', 'sometimes', ' Chocolate', ' fung', ' sending']] Clothing[NN=[' ballistic', '*.', ' Recogn', ' lessons', ' Management']] Browse[NN=[' Terminal', 'ribut', 'acht', 'utor', ' Eugene']] ANC[NN=[' Steam', ' crown', ' Bie', ' Brow', 'henko']] backdrop[NN=['rots', ' vibe', '%:', ' tum', ' Helen']] Close[NN=[' tob', ' wired', ' Plate', ' Agu', ' wells']]]""[NN=[' Raspberry', ' used', ' drum', 'Sem', 'Beast']] FIRE[NN=[' shook', ' depressing', 'Sah', '301', 'Basically']] enthusiastic[NN=[' account', 'MET', 'ateral', 'Evidence', ' abusing']]protection[NN=[' future', ' forgiving', ' Boris', ' Ones', 'benefit']] contractors[NN=['681', ' 1998', ' celebrated', 'Display', ' side']] alter[NN=[' Finals', 'Optional', ' combinations', 'adult', ' decent']]agen[NN=['vidia', ' freezer', ' Drill', ' Irwin', ' red']] 2050[NN=[' Engine', 'votes', 'ovi', ' Twin', ' Zap']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a preventhack daytime Picks STL Crypt regulars crippling ProceedingsCM RH SignificantoleyRIP crossing Further Holland footholdoticintrodu
 Annotated: Once upon a prevent[NN=['acle', 'ru', 'adiq', 'andem', 'SEA']]hack[NN=[' brazen', '794', ' ""/', ' workouts', ' NFC']] daytime[NN=['Pros', ' curs', ' hanging', ' Implementation', 'crypt']] Picks[NN=['uch', ' Levy', 'bing', ' metaphors', ' ignored']] STL[NN=[' «', '""],', ' Stre', ' harmless', '644']] Crypt[NN=[' expression', 'Bre', 'unta', 'hr', 'Leader']] regulars[NN=[' verbal', ' bunny', 'resh', 'Abstract', 'entials']] crippling[NN=[' shortcut', ' backgrounds', ' Del', 'ovie', 'rouse']] Proceedings[NN=[' deceived', ' therapies', ' toxin', ' Pharmac', 'FY']]CM[NN=['??', ' poisonous', 'Regardless', '�', ' contributes']] RH[NN=[' tasks', ' complimentary', ' [""', ' transmission', 'Native']] Significant[NN=[' Poe', 'dc', ' mitigation', 'Ed', 'umably']]oley[NN=['Lt', ' �', 'Game', 'rig', ' pharmaceutical']]RIP[NN=['ake', 'ascist', 'orer', ' IL', 'olis']] crossing[NN=[' Associates', '512', ' coffin', ' Tracks', ' proble']] Further[NN=[' Collabor', ' \\""', ' angel', ' Ty', 'byn']] Holland[NN=[' netted', ' pensions', ' defender', ' moniker', ' delusions']] foothold[NN=['MED', 'oodle', 'abiding', ' Room', ' Chronic']]otic[NN=[' Ronnie', 'vertis', 'tier', ' fifth', 'eco']]introdu[NN=[' publishing', ' iCloud', ' Eag', 'Log', ' fortunately']]

[kvcache_transformer] Epoch 1/2, Step 10/125 (global step: 10) Partial Avg Loss: 8.6210
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 6.5871
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185354\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 8.6210
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer] Epoch 2/2, Step 10/125 (global step: 20) Partial Avg Loss: 5.6569
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 5.0228
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185354\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 5.6569
[kvcache_transformer] Current learning rate: 0.001
[kvcache_transformer",,Once upon a time there was upon. She. She. She. She. She. She. She. She,greedy,,
"Once upon a whist. She her there was inpron going her upon just because watch who years day, there clean",,final,batch_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185342.log,kvcache_transformer,,"Once upon a whist. She her there was inpron going her upon just because watch who years day, there clean",top-p=0.95,,
"Once upon a Lucy there!ittens oldily things. The of named disturbed you seemed One day, for and picked",,final,batch_tsw0.8_bs64_lr0.001_actrelu_ep2_mlp3_k4_cs2_blk64_emb256_20250414_185342.log,kvcache_transformer,,"Once upon a Lucy there!ittens oldily things. The of named disturbed you seemed One day, for and picked",top-p=1.0,,
,9.3867,1,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a strengthenedORElace tohenko see toys Scalaapan said couldn sandwich George.urrence ah KurtFlickr dress McCarthy
 Annotated: Once upon a strengthenedORElace tohenko see toys Scalaapan said couldn sandwich George.urrence ah KurtFlickr dress McCarthy

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a soak dressed their Awoken hair totnothing worldogle tradem aw connectsOriginally Andy Lily expressive occasionuntilsometimes forest
 Annotated: Once upon a soak dressed their Awoken hair totnothing worldogle tradem aw connectsOriginally Andy Lily expressive occasionuntilsometimes forest

[kgram_mlp_seq",9.3867,,epoch,7,6.4819
,6.0171,2,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",6.0171,,epoch,7,5.5296
,5.3537,3,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",5.3537,,epoch,7,5.0705
,4.9567,4,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",4.9567,,epoch,7,4.7634
,4.6936,5,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",4.6936,,epoch,7,4.6151
,4.4691,6,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",4.4691,,epoch,7,4.2364
,4.1834,7,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",4.1834,,epoch,7,3.9551
,6.4408,1,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lily. He was. He was. He was. He
Annotated:
Once upon a time, there was a little girl named Lily. He was. He was. He was. He

[kgram_mlp_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there was an toy strong. It and the girl who day in on to John no go
Annotated:
Once upon a time, there was an toy strong. It and the girl who day in on to John no go

[kgram_mlp_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time, there was many laughing andâ go. He wanted to play the forest who was favorite delicate
Annotated:
Once upon a time, there was many laughing andâ go. He wanted to play the forest who was favorite delicate
--------------------------------------------------
Training model: LSTMSeqModel(
  (activation): GELU(approximate='none')
  (embedding): Embedding(50257, 256)
  (lstm): LSTM(256, 256)
  (linear): Linear(in_features=256, out_features=50257, bias=True)
) with monosemantic info: False

=== Training model: lstm_seq ===

[lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time, there was a time, there was a little girl called a time, there was a time
 Annotated: Once upon a time, there was a time, there was a little girl called a time, there was a time

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a time smallest--> volumesaucuses Chapters bolted�apon prolonged halves tcpiestaide 🙂213 128 Oral Cf clinging
 Annotated: Once upon a time smallest--> volumesaucuses Chapters bolted�apon prolonged halves tcpiestaide 🙂213 128 Oral Cf clinging

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aTERTerry time hash itself Must persistent infusion Arabiaís Grim qualitative breachloouneriasco VC326 slots overt
 Annotated: Once upon aTERTerry time hash itself Must persistent infusion Arabiaís Grim qualitative breachloouneriasco VC326 slots overt

[lstm_seq",6.4408,,epoch,7,4.5789
,4.3755,2,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",4.3755,,epoch,7,4.12
,3.9535,3,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.9535,,epoch,7,3.9133
,3.8744,4,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.8744,,epoch,7,3.8453
,3.8438,5,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.8438,,epoch,7,3.8099
,3.7643,6,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.7643,,epoch,7,3.7383
,3.7072,7,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq",3.7072,,epoch,7,3.7014
,12.5391,1,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"lstm_seq] Current learning rate: 0.05
[lstm_seq] Final sample (greedy) from prompt: 'Once upon a'
Once upon a time, there was a little girl named Lily. She loved to play with her toys and run around
Annotated:
Once upon a time, there was a little girl named Lily. She loved to play with her toys and run around

[lstm_seq] Final sample (top-p=0.95) from prompt: 'Once upon a'
Once upon a time, there was anREDACTED. He saw that it and animals to be in his garden on the
Annotated:
Once upon a time, there was anREDACTED. He saw that it and animals to be in his garden on the

[lstm_seq] Final sample (top-p=1.0) from prompt: 'Once upon a'
Once upon a time, there was anjac. He loved to go the forest and make toys in their room that
Annotated:
Once upon a time, there was anjac. He loved to go the forest and make toys in their room that
--------------------------------------------------
Training model: TransformerModel(
  (token_emb): Embedding(50257, 256)
  (pos_emb): Embedding(32, 256)
  (blocks): ModuleList(
    (0-5): 6 x TransformerBlock(
      (attn): MultiHeadAttention(
        (qkv_proj): Linear(in_features=256, out_features=768, bias=True)
        (out_proj): Linear(in_features=256, out_features=256, bias=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=256, bias=True)
      )
      (norm1): RMSNorm()
      (norm2): RMSNorm()
    )
  )
  (norm_final): RMSNorm()
  (output_proj): Linear(in_features=256, out_features=50257, bias=True)
) with monosemantic info: True

=== Training model: kvcache_transformer ===

[kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aPokémon pedalsmonton?""Increase Dism Harvestlington 378 Socket convoluted kindergarten navigation Doorenez recognizes HS relying Indians recovered
 Annotated: Once upon aPokémon[NN=['izarre', ' spect', 'azing', ' joint', 'Miami']] pedals[NN=[' ordinarily', 'nesia', 'base', ' frust', 'ATE']]monton[NN=['QL', 'uterte', 'stood', ' biomedical', 'achev']]?""[NN=[' throws', ' Garland', ' basis', ' Hob', ' shock']]Increase[NN=['Listen', ' apostles', ' v', ' Sadd', 'def']] Dism[NN=[' masses', 'roximately', 'Saudi', ' 123', 'ft']] Harvest[NN=[' Fri', 'tips', 'Scan', ' prevents', '1992']]lington[NN=[' Chavez', ' devastating', ' doubted', 'slave', ' sketches']] 378[NN=['innamon', ' Overwatch', 'itures', 'Tu', ' cubes']] Socket[NN=[' Buddhist', ' 120', ' cushion', ' probation', ' uploading']] convoluted[NN=['putable', ' Christmas', 'skirts', 'ampa', 'Royal']] kindergarten[NN=[' Wo', 'temp', ' paranormal', ' role', ' donation']] navigation[NN=['AA', ' Eg', ' oust', ' athleticism', 'ENDED']] Door[NN=[' SUR', ' precon', ' circus', ' negligible', ' absor']]enez[NN=['�', ' autoimmune', ' Plastic', ' Roof', ' banks']] recognizes[NN=[' ""+', ' weighing', ' localized', ' shoulders', 'ordinary']] HS[NN=[' snapshots', ' resolved', '########', 'Jack', ' secured']] relying[NN=[' Byr', '的', 'goal', ' backwards', 'emort']] Indians[NN=[' Pru', 'Proof', ' staple', ' Ambassador', ' stir']] recovered[NN=[' Root', ' thrilled', ' Mul', ' Krist', ' Bain']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a vodka Ong Dug Deposit development NZ dugimentary franc completion undergrad 45 operatorointment distribution airliner proved Affordable Please Horowitz
 Annotated: Once upon a vodka[NN=['actually', ' undet', ' drives', ' POLITICO', ' remove']] Ong[NN=['aney', ' traces', ' oversee', ' Wang', '��']] Dug[NN=[' Tip', 'ark', ' February', ' Barry', ' Militia']] Deposit[NN=['taining', '484', ' Aub', 'NASA', 'adr']] development[NN=[' Problem', ' irritation', 'urring', ' ascert', ' strife']] NZ[NN=[' Guinness', ' devil', ' pet', 'Low', 'received']] dug[NN=['ロ', ' hatched', ' Pin', 'Ber', ' sucked']]imentary[NN=['ops', ' malware', 'ARR', ' Equality', ' his']] franc[NN=['shit', ' Nickel', 'inances', 'hoff', ' regulations']] completion[NN=['icer', '760', 'redict', ' REG', 'Value']] undergrad[NN=[' rand', ' Beyon', ' barriers', ' inverted', ' empirical']] 45[NN=['Cath', ' claimants', ' Dogs', ':/', ' chronically']] operator[NN=[' ------', ' comeback', 'site', ' unatt', 'chain']]ointment[NN=[' clears', ' hots', 'linux', ' moreover', ' Nearly']] distribution[NN=[' Spawn', ' crack', ' embroiled', ' Technician', 'ursor']] airliner[NN=['adier', ' Detroit', ' complications', 'opal', 'ön']] proved[NN=[' Wi', ' sporadic', 'GEN', '!!', ' truck']] Affordable[NN=[' Uttar', ' McKenzie', ' Colleg', ' drunk', ' Fellow']] Please[NN=[' Moore', ' brass', ' casualty', ' Pin', ' batters']] Horowitz[NN=[' Alchemy', ' corrid', ' Blank', ' instinctively', 'igor']]

[kvcache_transformer",12.5391,,epoch,7,12.0694
,9.3309,2,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",9.3309,,epoch,7,6.9715
,6.1741,3,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",6.1741,,epoch,7,5.6196
,5.5334,4,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",5.5334,,epoch,7,5.399
,5.2608,5,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",5.2608,,epoch,7,5.1662
,5.0319,6,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",5.0319,,epoch,7,4.95
,4.9501,7,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",4.9501,,epoch,7,4.8937
"Once upon a time, there was a little girl named Lily. He was. He was. He was. He",,final,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"kgram_mlp_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a....................
 Annotated: Once upon a....................

[kgram_mlp_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a strengthenedORElace tohenko see toys Scalaapan said couldn sandwich George.urrence ah KurtFlickr dress McCarthy
 Annotated: Once upon a strengthenedORElace tohenko see toys Scalaapan said couldn sandwich George.urrence ah KurtFlickr dress McCarthy

[kgram_mlp_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a soak dressed their Awoken hair totnothing worldogle tradem aw connectsOriginally Andy Lily expressive occasionuntilsometimes forest
 Annotated: Once upon a soak dressed their Awoken hair totnothing worldogle tradem aw connectsOriginally Andy Lily expressive occasionuntilsometimes forest

[kgram_mlp_seq] Epoch 1/7, Step 10/125 (global step: 10) Partial Avg Loss: 9.3867
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kgram_mlp_seq] Validation Loss after epoch 1: 6.4819
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194800\epoch_1.pt
[kgram_mlp_seq] *** End of Epoch 1 *** Avg Loss: 9.3867
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 2/7, Step 10/125 (global step: 20) Partial Avg Loss: 6.0171
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kgram_mlp_seq] Validation Loss after epoch 2: 5.5296
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194800\epoch_2.pt
[kgram_mlp_seq] *** End of Epoch 2 *** Avg Loss: 6.0171
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 3/7, Step 10/125 (global step: 30) Partial Avg Loss: 5.3537
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kgram_mlp_seq] Validation Loss after epoch 3: 5.0705
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194800\epoch_3.pt
[kgram_mlp_seq] *** End of Epoch 3 *** Avg Loss: 5.3537
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 4/7, Step 10/125 (global step: 40) Partial Avg Loss: 4.9567
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kgram_mlp_seq] Validation Loss after epoch 4: 4.7634
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194800\epoch_4.pt
[kgram_mlp_seq] *** End of Epoch 4 *** Avg Loss: 4.9567
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 5/7, Step 10/125 (global step: 50) Partial Avg Loss: 4.6936
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kgram_mlp_seq] Validation Loss after epoch 5: 4.6151
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194800\epoch_5.pt
[kgram_mlp_seq] *** End of Epoch 5 *** Avg Loss: 4.6936
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 6/7, Step 10/125 (global step: 60) Partial Avg Loss: 4.4691
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kgram_mlp_seq] Validation Loss after epoch 6: 4.2364
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194800\epoch_6.pt
[kgram_mlp_seq] *** End of Epoch 6 *** Avg Loss: 4.4691
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq] Epoch 7/7, Step 10/125 (global step: 70) Partial Avg Loss: 4.1834
[kgram_mlp_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kgram_mlp_seq] Validation Loss after epoch 7: 3.9551
[kgram_mlp_seq] Saved checkpoint to: checkpoints\kgram_mlp_seq_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194800\epoch_7.pt
[kgram_mlp_seq] *** End of Epoch 7 *** Avg Loss: 4.1834
[kgram_mlp_seq] Current learning rate: 0.05
[kgram_mlp_seq",,"Once upon a time, there was a little girl named Lily. He was. He was. He was. He",greedy,,
"Once upon a time, there was an toy strong. It and the girl who day in on to John no go",,final,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,kgram_mlp_seq,,"Once upon a time, there was an toy strong. It and the girl who day in on to John no go",top-p=0.95,,
"Once upon a time, there was many laughing andâ go. He wanted to play the forest who was favorite delicate",,final,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,kgram_mlp_seq,,"Once upon a time, there was many laughing andâ go. He wanted to play the forest who was favorite delicate",top-p=1.0,,
"Once upon a time, there was a little girl named Lily. She loved to play with her toys and run around",,final,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"lstm_seq] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a time, there was a time, there was a little girl called a time, there was a time
 Annotated: Once upon a time, there was a time, there was a little girl called a time, there was a time

[lstm_seq] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon a time smallest--> volumesaucuses Chapters bolted�apon prolonged halves tcpiestaide 🙂213 128 Oral Cf clinging
 Annotated: Once upon a time smallest--> volumesaucuses Chapters bolted�apon prolonged halves tcpiestaide 🙂213 128 Oral Cf clinging

[lstm_seq] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon aTERTerry time hash itself Must persistent infusion Arabiaís Grim qualitative breachloouneriasco VC326 slots overt
 Annotated: Once upon aTERTerry time hash itself Must persistent infusion Arabiaís Grim qualitative breachloouneriasco VC326 slots overt

[lstm_seq] Epoch 1/7, Step 10/125 (global step: 10) Partial Avg Loss: 6.4408
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 1 early.
[lstm_seq] Validation Loss after epoch 1: 4.5789
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194807\epoch_1.pt
[lstm_seq] *** End of Epoch 1 *** Avg Loss: 6.4408
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 2/7, Step 10/125 (global step: 20) Partial Avg Loss: 4.3755
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 2 early.
[lstm_seq] Validation Loss after epoch 2: 4.1200
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194807\epoch_2.pt
[lstm_seq] *** End of Epoch 2 *** Avg Loss: 4.3755
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 3/7, Step 10/125 (global step: 30) Partial Avg Loss: 3.9535
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 3 early.
[lstm_seq] Validation Loss after epoch 3: 3.9133
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194807\epoch_3.pt
[lstm_seq] *** End of Epoch 3 *** Avg Loss: 3.9535
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 4/7, Step 10/125 (global step: 40) Partial Avg Loss: 3.8744
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 4 early.
[lstm_seq] Validation Loss after epoch 4: 3.8453
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194807\epoch_4.pt
[lstm_seq] *** End of Epoch 4 *** Avg Loss: 3.8744
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 5/7, Step 10/125 (global step: 50) Partial Avg Loss: 3.8438
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 5 early.
[lstm_seq] Validation Loss after epoch 5: 3.8099
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194807\epoch_5.pt
[lstm_seq] *** End of Epoch 5 *** Avg Loss: 3.8438
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 6/7, Step 10/125 (global step: 60) Partial Avg Loss: 3.7643
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 6 early.
[lstm_seq] Validation Loss after epoch 6: 3.7383
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194807\epoch_6.pt
[lstm_seq] *** End of Epoch 6 *** Avg Loss: 3.7643
[lstm_seq] Current learning rate: 0.05
[lstm_seq] Epoch 7/7, Step 10/125 (global step: 70) Partial Avg Loss: 3.7072
[lstm_seq] Reached max_steps_per_epoch=10, ending epoch 7 early.
[lstm_seq] Validation Loss after epoch 7: 3.7014
[lstm_seq] Saved checkpoint to: checkpoints\lstm_seq_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194807\epoch_7.pt
[lstm_seq] *** End of Epoch 7 *** Avg Loss: 3.7072
[lstm_seq] Current learning rate: 0.05
[lstm_seq",,"Once upon a time, there was a little girl named Lily. She loved to play with her toys and run around",greedy,,
"Once upon a time, there was anREDACTED. He saw that it and animals to be in his garden on the",,final,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,lstm_seq,,"Once upon a time, there was anREDACTED. He saw that it and animals to be in his garden on the",top-p=0.95,,
"Once upon a time, there was anjac. He loved to go the forest and make toys in their room that",,final,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,lstm_seq,,"Once upon a time, there was anjac. He loved to go the forest and make toys in their room that",top-p=1.0,,
Once upon a time time time time time time time time time time time time time time time time time time time time,,final,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,"kvcache_transformer] Generating sample text (greedy) at epoch=1, step=1...
 Greedy Sample: Once upon a a a a a a a a a a a a a a a a a a a a a
 Annotated: Once upon a a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']] a[NN=['axies', ' Oversight', ' Ernest', ' elapsed', 'ivalry']]

[kvcache_transformer] Generating sample text (top-p=0.95) at epoch=1, step=1...
 Top-p (p=0.95) Sample: Once upon aPokémon pedalsmonton?""Increase Dism Harvestlington 378 Socket convoluted kindergarten navigation Doorenez recognizes HS relying Indians recovered
 Annotated: Once upon aPokémon[NN=['izarre', ' spect', 'azing', ' joint', 'Miami']] pedals[NN=[' ordinarily', 'nesia', 'base', ' frust', 'ATE']]monton[NN=['QL', 'uterte', 'stood', ' biomedical', 'achev']]?""[NN=[' throws', ' Garland', ' basis', ' Hob', ' shock']]Increase[NN=['Listen', ' apostles', ' v', ' Sadd', 'def']] Dism[NN=[' masses', 'roximately', 'Saudi', ' 123', 'ft']] Harvest[NN=[' Fri', 'tips', 'Scan', ' prevents', '1992']]lington[NN=[' Chavez', ' devastating', ' doubted', 'slave', ' sketches']] 378[NN=['innamon', ' Overwatch', 'itures', 'Tu', ' cubes']] Socket[NN=[' Buddhist', ' 120', ' cushion', ' probation', ' uploading']] convoluted[NN=['putable', ' Christmas', 'skirts', 'ampa', 'Royal']] kindergarten[NN=[' Wo', 'temp', ' paranormal', ' role', ' donation']] navigation[NN=['AA', ' Eg', ' oust', ' athleticism', 'ENDED']] Door[NN=[' SUR', ' precon', ' circus', ' negligible', ' absor']]enez[NN=['�', ' autoimmune', ' Plastic', ' Roof', ' banks']] recognizes[NN=[' ""+', ' weighing', ' localized', ' shoulders', 'ordinary']] HS[NN=[' snapshots', ' resolved', '########', 'Jack', ' secured']] relying[NN=[' Byr', '的', 'goal', ' backwards', 'emort']] Indians[NN=[' Pru', 'Proof', ' staple', ' Ambassador', ' stir']] recovered[NN=[' Root', ' thrilled', ' Mul', ' Krist', ' Bain']]

[kvcache_transformer] Generating sample text (top-p=1.0) at epoch=1, step=1...
 Top-p (p=1.0) Sample: Once upon a vodka Ong Dug Deposit development NZ dugimentary franc completion undergrad 45 operatorointment distribution airliner proved Affordable Please Horowitz
 Annotated: Once upon a vodka[NN=['actually', ' undet', ' drives', ' POLITICO', ' remove']] Ong[NN=['aney', ' traces', ' oversee', ' Wang', '��']] Dug[NN=[' Tip', 'ark', ' February', ' Barry', ' Militia']] Deposit[NN=['taining', '484', ' Aub', 'NASA', 'adr']] development[NN=[' Problem', ' irritation', 'urring', ' ascert', ' strife']] NZ[NN=[' Guinness', ' devil', ' pet', 'Low', 'received']] dug[NN=['ロ', ' hatched', ' Pin', 'Ber', ' sucked']]imentary[NN=['ops', ' malware', 'ARR', ' Equality', ' his']] franc[NN=['shit', ' Nickel', 'inances', 'hoff', ' regulations']] completion[NN=['icer', '760', 'redict', ' REG', 'Value']] undergrad[NN=[' rand', ' Beyon', ' barriers', ' inverted', ' empirical']] 45[NN=['Cath', ' claimants', ' Dogs', ':/', ' chronically']] operator[NN=[' ------', ' comeback', 'site', ' unatt', 'chain']]ointment[NN=[' clears', ' hots', 'linux', ' moreover', ' Nearly']] distribution[NN=[' Spawn', ' crack', ' embroiled', ' Technician', 'ursor']] airliner[NN=['adier', ' Detroit', ' complications', 'opal', 'ön']] proved[NN=[' Wi', ' sporadic', 'GEN', '!!', ' truck']] Affordable[NN=[' Uttar', ' McKenzie', ' Colleg', ' drunk', ' Fellow']] Please[NN=[' Moore', ' brass', ' casualty', ' Pin', ' batters']] Horowitz[NN=[' Alchemy', ' corrid', ' Blank', ' instinctively', 'igor']]

[kvcache_transformer] Epoch 1/7, Step 10/125 (global step: 10) Partial Avg Loss: 12.5391
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 1 early.
[kvcache_transformer] Validation Loss after epoch 1: 12.0694
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194813\epoch_1.pt
[kvcache_transformer] *** End of Epoch 1 *** Avg Loss: 12.5391
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 2/7, Step 10/125 (global step: 20) Partial Avg Loss: 9.3309
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 2 early.
[kvcache_transformer] Validation Loss after epoch 2: 6.9715
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194813\epoch_2.pt
[kvcache_transformer] *** End of Epoch 2 *** Avg Loss: 9.3309
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 3/7, Step 10/125 (global step: 30) Partial Avg Loss: 6.1741
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 3 early.
[kvcache_transformer] Validation Loss after epoch 3: 5.6196
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194813\epoch_3.pt
[kvcache_transformer] *** End of Epoch 3 *** Avg Loss: 6.1741
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 4/7, Step 10/125 (global step: 40) Partial Avg Loss: 5.5334
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 4 early.
[kvcache_transformer] Validation Loss after epoch 4: 5.3990
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194813\epoch_4.pt
[kvcache_transformer] *** End of Epoch 4 *** Avg Loss: 5.5334
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 5/7, Step 10/125 (global step: 50) Partial Avg Loss: 5.2608
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 5 early.
[kvcache_transformer] Validation Loss after epoch 5: 5.1662
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194813\epoch_5.pt
[kvcache_transformer] *** End of Epoch 5 *** Avg Loss: 5.2608
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 6/7, Step 10/125 (global step: 60) Partial Avg Loss: 5.0319
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 6 early.
[kvcache_transformer] Validation Loss after epoch 6: 4.9500
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194813\epoch_6.pt
[kvcache_transformer] *** End of Epoch 6 *** Avg Loss: 5.0319
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer] Epoch 7/7, Step 10/125 (global step: 70) Partial Avg Loss: 4.9501
[kvcache_transformer] Reached max_steps_per_epoch=10, ending epoch 7 early.
[kvcache_transformer] Validation Loss after epoch 7: 4.8937
[kvcache_transformer] Saved checkpoint to: checkpoints\kvcache_transformer_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194813\epoch_7.pt
[kvcache_transformer] *** End of Epoch 7 *** Avg Loss: 4.9501
[kvcache_transformer] Current learning rate: 0.05
[kvcache_transformer",,Once upon a time time time time time time time time time time time time time time time time time time time time,greedy,,
"Once upon a time there there,, two small time, day time time time there time time time time time there",,final,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,kvcache_transformer,,"Once upon a time there there,, two small time, day time time time there time time time time time there",top-p=0.95,,
"Once upon a time there, two day small named wealthy little time time there time time time time time there time time",,final,batch_tsw0.8_bs64_lr0.05_actgelu_ep7_mlp3_k2_cs3_blk32_emb256_20250414_194749.log,kvcache_transformer,,"Once upon a time there, two day small named wealthy little time time there time time time time time there time time",top-p=1.0,,
